{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IfsjshmjrdIY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "from torch import autograd\n",
    "import torch.nn.functional as F\n",
    "import os, os.path\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torchinfo import summary\n",
    "from torchsummary import summary\n",
    "from torchvision import models\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import re\n",
    "import itertools\n",
    "import functools\n",
    "import operator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 1 # LH agg = 1, LH plan = 2, LH gr = 3, LH col = 4, TH gr = 5, KA plan = 6, all data combined = 7\n",
    "correlation = 2 # Holzer and Sommerfeld = 1, Mola = 2, No correlation, pure Cd prediction = 3\n",
    "custom_loss = 1 # 1 = True, 2 = False. Custom loss turned off when correlation = 3\n",
    "pretrained = 1 # 1 = True, 2 = False. Turned off when correlation = 3\n",
    "rstate = 1 #random 5 kfold splits. Any integer; the same integer will always yield the same splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set directory for images and data\n",
    "dir_LH = '/Users/Crazz/Research Codes/LH_dataset.csv'\n",
    "# dir_TH = \n",
    "# dir_KA =\n",
    "dir_LHim = '/Users/Crazz/Research Codes/256res_LH'\n",
    "# dir_KAim =\n",
    "# dir_KAim =\n",
    "\n",
    "## Set directory for desired pre-trained model to load in\n",
    "dir_premodel = '/Users/Crazz/Research Codes/WORKING MODELS/Mola models/aggmola5model.pth'\n",
    "## Set directory and name for saving model. Will overwrite a file of the same name\n",
    "dir_model = '/Users/Crazz/Research Codes/WORKING MODELS/LHagg_HS_model_k' #split num 0-4 and file ext .pth automatically added "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD ALL DATASETS\n",
    "LH_newdf = pd.read_csv(dir_LH)\n",
    "ids = []\n",
    "for i in range(len(LH_newdf)):\n",
    "    picnum = str(LH_newdf['Pic Number'][i])\n",
    "    rollnum = str(LH_newdf['Roll Number'][i])\n",
    "    if len(picnum) == 1:\n",
    "        picnum = '0' + picnum\n",
    "    if len(rollnum) == 1:\n",
    "        rollnum = '0' + rollnum\n",
    "    ids.append(rollnum + '_' + picnum + '.png')\n",
    "LH_newdf['id'] = ids\n",
    "LH_newdf = LH_newdf[LH_newdf['Cd']<13]\n",
    "imgs = {}\n",
    "path = dir_LHim\n",
    "valid_images = [\".jpg\",\".gif\",\".png\",\".tga\"]\n",
    "for f in os.listdir(path):\n",
    "    ext = os.path.splitext(f)[1]\n",
    "    if ext.lower() not in valid_images:\n",
    "        continue\n",
    "    temp = Image.open(os.path.join(path,f))\n",
    "    imgs[f] = temp.copy()\n",
    "    temp.close()\n",
    "\n",
    "img_df = pd.DataFrame(imgs.items(), columns=['id', 'images'])\n",
    "LH_newdf = LH_newdf.merge(img_df, how='inner', on='id')\n",
    "LH_newdf['t_Re'] = np.log(LH_newdf['Re'])\n",
    "LH_newdf['t_Cd'] = np.log(LH_newdf['Cd'])\n",
    "LH_agg = LH_newdf[LH_newdf['aggregate']==1].reset_index(drop=True)\n",
    "LH_agg['tmp_idx'] = range(len(LH_agg))\n",
    "LH_plan = LH_newdf[LH_newdf['planar_crystal']==1].reset_index(drop=True)\n",
    "LH_plan['tmp_idx'] = range(len(LH_plan))\n",
    "LH_gr = LH_newdf[LH_newdf['graupel']==1].reset_index(drop=True)\n",
    "LH_gr['tmp_idx'] = range(len(LH_gr))\n",
    "LH_col = LH_newdf[LH_newdf['columnar_crystal']==1].reset_index(drop=True)\n",
    "LH_col['tmp_idx'] = range(len(LH_col))\n",
    "LH_comb = LH_newdf[LH_newdf['combo']==1].reset_index(drop=True)             #NONE\n",
    "LH_comb['tmp_idx'] = range(len(LH_comb))\n",
    "\n",
    "Theis_df = pd.read_csv(dir_TH)\n",
    "imgs = {}\n",
    "path = dir_THim\n",
    "valid_images = [\".jpg\",\".gif\",\".png\",\".tga\"]\n",
    "for f in os.listdir(path):\n",
    "    ext = os.path.splitext(f)[1]\n",
    "    if ext.lower() not in valid_images:\n",
    "        continue\n",
    "    temp = Image.open(os.path.join(path,f))\n",
    "    imgs[f] = temp.copy()\n",
    "    temp.close()\n",
    "\n",
    "img_df = pd.DataFrame(imgs.items(), columns=['id', 'images'])\n",
    "Theis_df = Theis_df.merge(img_df, how='inner', on='id')\n",
    "Theis_df = Theis_df.rename(columns={'CHA':'area','Dmax':'diam','Mass':'mass','Vel':'vel'})\n",
    "Theis_df['t_Re'] = np.log(Theis_df['Re'])\n",
    "Theis_df['t_Cd'] = np.log(Theis_df['Cd'])\n",
    "Theis_df['tmp_idx'] = np.arange(0,len(Theis_df),1) \n",
    "\n",
    "KA_df = pd.read_csv(dir_KA)\n",
    "imgs = {}\n",
    "path = dir_KAim\n",
    "valid_images = [\".jpg\",\".gif\",\".png\",\".tga\"]\n",
    "for f in os.listdir(path):\n",
    "    ext = os.path.splitext(f)[1]\n",
    "    if ext.lower() not in valid_images:\n",
    "        continue\n",
    "    temp = Image.open(os.path.join(path,f))\n",
    "    imgs[f] = temp.copy()\n",
    "    temp.close()\n",
    "\n",
    "img_df = pd.DataFrame(imgs.items(), columns=['id', 'images'])\n",
    "KA_df = KA_df.merge(img_df, how='inner', on='id')\n",
    "KA_df['t_Re'] = np.log(KA_df['Re'])\n",
    "KA_df['t_Cd'] = np.log(KA_df['Cd'])\n",
    "KA_df['tmp_idx'] = range(len(KA_df))\n",
    "\n",
    "alldat = pd.concat([KA_df,LH_newdf,Theis_df]).reset_index(drop=True)\n",
    "alldat['t_Re'] = np.log(alldat['Re'])\n",
    "alldat['t_Cd'] = np.log(alldat['Cd'])\n",
    "alldat['tmp_idx'] = range(len(alldat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def save_ckp(state, is_best, checkpoint_dir, best_model_dir):\n",
    "    f_path = checkpoint_dir / 'checkpoint.pt'\n",
    "    torch.save(state, f_path)\n",
    "    if is_best:\n",
    "        best_fpath = best_model_dir / 'best_model.pt'\n",
    "        shutil.copyfile(f_path, best_fpath)\n",
    "def load_ckp(checkpoint_fpath, model, optimizer):\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return model, optimizer, checkpoint['epoch']\n",
    "                                                                                                                                                                                                                               \n",
    "\n",
    "class regloader(torch.utils.data.Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = X['images']\n",
    "        self.label = X['tmp_idx']\n",
    "        self.A_char = X['area']\n",
    "        self.Re = X['t_Re']\n",
    "        self.Cd = X['t_Cd']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = (self.X[idx])\n",
    "        label = torch.tensor(self.label[idx])\n",
    "        A_char = torch.tensor(self.A_char[idx], dtype=torch.float32)\n",
    "        Re = torch.tensor(self.Re[idx], dtype=torch.float32)\n",
    "        Cd = torch.tensor(self.Cd[idx], dtype=torch.float32)\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "            transforms.RandomInvert(0.5),\n",
    "            transforms.RandomHorizontalFlip(0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5), (0.5))]) # might need to change\n",
    "        # seperate ys\n",
    "        return label,transform(X),A_char,Re,Cd\n",
    "    \n",
    "class KGCNN1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KGCNN1, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5),#, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 48, 3),# stride=1, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(48, 64, 3),# stride=1, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 80, 3),# stride=1, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.geom = nn.Sequential(\n",
    "            nn.Linear(80 * 14 * 14, 50), # 48*12*12 if size is 256, *4*4 128\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.15),\n",
    "            nn.Linear(50, 7), # 7 geoms return\n",
    "            nn.Softplus(),\n",
    "        )\n",
    "    def forward(self, image):\n",
    "        top_out = self.conv(image)\n",
    "        middle = top_out.view(top_out.size(0), -1)\n",
    "        geoms_out = self.geom(middle)\n",
    "        #print(image.size())\n",
    "        #print(middle1.size())\n",
    "        #print(data.size())\n",
    "        return geoms_out\n",
    "    \n",
    "class KGCNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KGCNN2, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5),#, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 48, 3),# stride=1, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(48, 64, 3),# stride=1, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 80, 3),# stride=1, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.geom = nn.Sequential(\n",
    "            nn.Linear(80 * 14 * 14, 50), # 48*12*12 if size is 256, *4*4 128\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.15),\n",
    "            nn.Linear(50, 8), # 8 geoms return\n",
    "            nn.Softplus(),\n",
    "        )\n",
    "    def forward(self, image):\n",
    "        top_out = self.conv(image)\n",
    "        middle = top_out.view(top_out.size(0), -1)\n",
    "        geoms_out = self.geom(middle)\n",
    "        #print(image.size())\n",
    "        #print(middle1.size())\n",
    "        #print(data.size())\n",
    "        return geoms_out\n",
    "class KGCNN3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KGCNN3, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5),#, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 48, 3),# stride=1, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(48, 64, 3),# stride=1, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 80, 3),# stride=1, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.geom = nn.Sequential(\n",
    "            nn.Linear(80 * 14 * 14+1, 50), # 48*12*12 if size is 256, *4*4 128\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.15),\n",
    "            nn.Linear(50, 1), # 7 geoms return\n",
    "        )\n",
    "    def forward(self, image,Re):\n",
    "        top_out = self.conv(image)\n",
    "        middle = top_out.view(top_out.size(0), -1)\n",
    "        middle_cd = torch.cat((middle, Re),dim=1)\n",
    "        Cd_out = self.geom(middle_cd)\n",
    "        \n",
    "        #print(image.size())\n",
    "        #print(middle1.size())\n",
    "        #print(data.size())\n",
    "        return Cd_out\n",
    "    \n",
    "# Custom physics loss\n",
    "def physics_loss(sar, sph, length_sph, cross_sph, A_crat, A_lrat):\n",
    "    tiny = 0.000000001\n",
    "    loss_c = (sph/(4*sar) - A_crat*cross_sph)**2\n",
    "    loss_l = (sph/(4*sar) - length_sph*(1/(2*sar) - A_lrat))**2\n",
    "    loss_c = torch.mean(loss_c)\n",
    "    loss_l = torch.mean(loss_l)\n",
    "    # penalize geom outputs if outside range\n",
    "    if torch.max(porosity)>=1:\n",
    "        loss_por = 100*(porosity-0.9)**2\n",
    "    else:\n",
    "        loss_por = torch.tensor(0.000000001, requires_grad=True)\n",
    "    if torch.max(sar) >= 0.5:\n",
    "        loss_sar = 100*(sar-0.4)**2\n",
    "    else:\n",
    "        loss_sar = torch.tensor(0.000000001, requires_grad=True)\n",
    "    if torch.max(sph) >= 1:\n",
    "        loss_sph = 100*(sph-0.9)**2\n",
    "    else:\n",
    "        loss_sph = torch.tensor(0.000000001, requires_grad=True)\n",
    "    loss_pg = torch.mean(loss_c + loss_l + loss_por + loss_sar + loss_sph)\n",
    "    return loss_c, loss_l, loss_pg\n",
    "\n",
    "## Holzer and Sommerfeld correlation\n",
    "def HnS(Re,sph,lsph,csph):\n",
    "    Cd_HS = 8/(Re*torch.sqrt(lsph)) + 16/(Re*torch.sqrt(sph)) + 3/(torch.sqrt(Re)*sph**(3/4)) + (1/csph)*0.4210**(0.4*((-torch.log(sph))**0.2))\n",
    "    return Cd_HS\n",
    "## Mola et al. correlation\n",
    "def Mola(Re,por,sph,lsph,csph,Df):\n",
    "    a1 = 0.10861\n",
    "    a2 = 0.28273\n",
    "    a3 = 0.21479\n",
    "    a4 = 0.65317\n",
    "    a5 = 1.49629\n",
    "    b1 = 8.48137\n",
    "    b2 = 5.07235\n",
    "    b3 = 0.44850\n",
    "    b4 = -0.71\n",
    "    b5 = -1.89037\n",
    "    c1 = 0.66886\n",
    "    c2 = 0.14686\n",
    "    c3 = -0.84224\n",
    "    c4 = 0.02821\n",
    "    c5 = -3.54344\n",
    "    lam1 = 8*(a1*por+a2)*(a3*sph+a4)*Df**a5\n",
    "    lam2 = 16*(b1*por+b2)*(b3*sph+b4)*Df**b5\n",
    "    lam3 = c1*(por**((c2*(1-por)/por)**c3))*(Re**c4)*sph**c5\n",
    "    Cd_M = lam1/(Re*torch.sqrt(csph)) + lam2/(Re*torch.sqrt(sph)) + lam3*(3/(torch.sqrt(Re)*sph**(3/4)) + (1/csph)*0.4210**(0.4*((-torch.log(sph))**0.2)))\n",
    "    return Cd_M\n",
    "\n",
    "if dataset == 1: # LH agg\n",
    "    k_folds = 5\n",
    "    batch_size = 2\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True,random_state=rstate)\n",
    "    lr = 1e-6\n",
    "    num_epochs = 750\n",
    "    fulldata = regloader(LH_agg)\n",
    "    cur_df = LH_agg\n",
    "if dataset == 2: # LH plan\n",
    "    k_folds = 5\n",
    "    batch_size = 2\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True,random_state=rstate)\n",
    "    lr = 1e-6\n",
    "    num_epochs = 750\n",
    "    fulldata = regloader(LH_plan)\n",
    "    cur_df = LH_plan\n",
    "if dataset == 3: # LH graupel\n",
    "    k_folds = 5\n",
    "    batch_size = 6\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True,random_state=rstate)\n",
    "    lr = 1e-5\n",
    "    num_epochs = 750\n",
    "    fulldata = regloader(LH_gr)\n",
    "    cur_df = LH_gr\n",
    "if dataset == 4: # LH col\n",
    "    k_folds = 5\n",
    "    batch_size = 2\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True,random_state=rstate)\n",
    "    lr = 1e-6\n",
    "    num_epochs = 750\n",
    "    fulldata = regloader(LH_col)\n",
    "    cur_df = LH_col\n",
    "if dataset == 5: # TH graupel\n",
    "    k_folds = 5\n",
    "    batch_size = 2\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True,random_state=rstate)\n",
    "    lr = 1e-6\n",
    "    num_epochs = 750\n",
    "    fulldata = regloader(Theis_df)\n",
    "    cur_df = Theis_df\n",
    "if dataset == 6: # KA planar\n",
    "    k_folds = 5\n",
    "    batch_size = 2\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True,random_state=rstate)\n",
    "    lr = 1e-6\n",
    "    num_epochs = 750\n",
    "    fulldata = regloader(KA_df)\n",
    "    cur_df = KA_df\n",
    "if dataset == 7: # all data combined\n",
    "    k_folds = 5\n",
    "    batch_size = 10\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True,random_state=rstate)\n",
    "    lr = 1e-5\n",
    "    num_epochs = 750\n",
    "    fulldata = regloader(alldata)\n",
    "    cur_df = alldata\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if correlation == 1\n",
    "    model = KGCNN1.to(device)\n",
    "if correlation == 2\n",
    "    model = KGCNN2.to(device)\n",
    "if correlation == 3\n",
    "    model = KGCNN3.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss() #MSELoss()  # Mean squared error loss #L1Loss()\n",
    "\n",
    "\n",
    "# Training loop\n",
    "if correlation == 1:\n",
    "    train_Cd_curves = []\n",
    "    train_pg_curves = []\n",
    "\n",
    "    test_Cd_curves = []\n",
    "    test_pg_curves = []\n",
    "\n",
    "    goodplanmodel_epoch = np.array([0,0,0,0,0])\n",
    "\n",
    "    best_test_acc = np.array([100,100,100,100,100])\n",
    "    for fold, (train_ids, test_ids) in enumerate(kf.split(fulldata)):\n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "        train_loader = DataLoader(\n",
    "            dataset=fulldata,\n",
    "            batch_size=batch_size,\n",
    "            sampler=torch.utils.data.SubsetRandomSampler(train_ids),\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            dataset=fulldata,\n",
    "            batch_size=batch_size,\n",
    "            sampler=torch.utils.data.SubsetRandomSampler(test_ids),\n",
    "        )\n",
    "        model = KGCNN1.to(device)\n",
    "        non_frozen_parameters = [p for p in model.parameters() if p.requires_grad]\n",
    "        optimizer = torch.optim.Adam(non_frozen_parameters, lr=lr)  # Choose an optimizer\n",
    "        if pretrained == 1:\n",
    "            model, optimizer, start_epoch = load_ckp(dir_premodel, model, optimizer)\n",
    "\n",
    "        best_test = best_test_acc[fold]\n",
    "        train_llist_Cd = []\n",
    "        train_llist_pg = []\n",
    "\n",
    "        test_llist_Cd = []\n",
    "        test_llist_pg = []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()  # Set the model in training mode\n",
    "\n",
    "            train_Cd_loss = 0.0\n",
    "            train_pg_loss = 0.0\n",
    "\n",
    "            for id,images,A_char,Re,Cd in train_loader:\n",
    "\n",
    "                id = id.to(device)\n",
    "                images = Variable(images, requires_grad=True)\n",
    "                A_char = Variable(A_char, requires_grad=True)\n",
    "                Re = Variable(Re, requires_grad=True)\n",
    "                Cd = Variable(Cd, requires_grad=True)\n",
    "\n",
    "                A_char = A_char.view(A_char.size(0),1)\n",
    "                Re = Re.view(Re.size(0),1)\n",
    "                Cd = Cd.view(Cd.size(0),1)\n",
    "\n",
    "                images = images.to(device)\n",
    "                A_char = A_char.to(device)\n",
    "                Re = Re.to(device)\n",
    "                Cd = Cd.to(device)\n",
    "\n",
    "                #with autograd.detect_anomaly():\n",
    "                # Forward pass\n",
    "                geoms_out = model(images)\n",
    "                sph = geoms_out[:,0]\n",
    "                cross_sph = geoms_out[:,1]\n",
    "                length_sph = geoms_out[:,2]\n",
    "                porosity = geoms_out[:,3]\n",
    "                sar = geoms_out[:,4]\n",
    "                A_crat = geoms_out[:,5]\n",
    "                A_lrat = geoms_out[:,6]\n",
    "\n",
    "                sph = sph.view(Re.size(0),1)\n",
    "                cross_sph = cross_sph.view(Re.size(0),1)\n",
    "                length_sph = length_sph.view(Re.size(0),1)\n",
    "                porosity = porosity.view(Re.size(0),1)\n",
    "                sar = sar.view(Re.size(0),1)\n",
    "                A_crat = A_crat.view(A_crat.size(0),1)\n",
    "                A_lrat = A_lrat.view(A_lrat.size(0),1)\n",
    "\n",
    "                loss_c,loss_l,loss_pg = physics_loss(sar*0.5,sph,length_sph*2,cross_sph*3.5,A_crat*1.5,A_lrat*1.5)\n",
    "\n",
    "                Cd_act = HnS(torch.exp(Re),sph,length_sph*2,cross_sph*3.5)#*(torch.abs(1 - porosity))**0.17)*torch.exp(Re)**-0.13)\n",
    "                Cd_logout = torch.log(Cd_act)\n",
    "\n",
    "                # TOTAL loss w/o phys Cd\n",
    "                # sum physics guided and regular losses from Cd and geom parameters\n",
    "                if torch.max(sph) >= 1:\n",
    "                    loss_Cd = 2*torch.abs(torch.max(sph)-0.5)**2\n",
    "                else:\n",
    "                    loss_Cd = criterion(Cd_logout,Cd)\n",
    "                loss_Cd = loss_Cd.to(device)\n",
    "                loss_tot = loss_Cd + loss_pg\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                if custom_loss == 1:\n",
    "                    loss_tot.backward()\n",
    "                if custom_loss == 2:\n",
    "                    loss_Cd.backward()\n",
    "                #nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                clip_value = 10\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                #####\n",
    "                train_Cd_loss += loss_Cd * id.size(0)\n",
    "                train_pg_loss += loss_pg * id.size(0)\n",
    "\n",
    "            train_Cd_loss /= len(train_loader.dataset)\n",
    "            train_pg_loss /= len(train_loader.dataset)\n",
    "\n",
    "            train_llist_pg.append(train_pg_loss.item())\n",
    "\n",
    "            # Evaluation\n",
    "            model.eval()  # Set the model in evaluation mode\n",
    "\n",
    "            test_Cd_loss = 0.0\n",
    "            test_pg_loss = 0.0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for id,images,A_char,Re,Cd in test_loader:\n",
    "\n",
    "                    id = id.to(device)\n",
    "                    images = Variable(images, requires_grad=True)\n",
    "                    A_char = Variable(A_char, requires_grad=True)\n",
    "                    Re = Variable(Re, requires_grad=True)\n",
    "                    Cd = Variable(Cd, requires_grad=True)\n",
    "\n",
    "                    A_char = A_char.view(A_char.size(0),1)\n",
    "                    Re = Re.view(Re.size(0),1)\n",
    "                    Cd = Cd.view(Cd.size(0),1)\n",
    "\n",
    "                    images = images.to(device)\n",
    "                    A_char = A_char.to(device)\n",
    "                    Re = Re.to(device)\n",
    "                    Cd = Cd.to(device)\n",
    "\n",
    "                    #with autograd.detect_anomaly():\n",
    "                    # Forward pass\n",
    "                    geoms_out = model(images)\n",
    "                    sph = geoms_out[:,0]\n",
    "                    cross_sph = geoms_out[:,1]\n",
    "                    length_sph = geoms_out[:,2]\n",
    "                    porosity = geoms_out[:,3]\n",
    "                    sar = geoms_out[:,4]\n",
    "                    A_crat = geoms_out[:,5]\n",
    "                    A_lrat = geoms_out[:,6]\n",
    "\n",
    "                    sph = sph.view(Re.size(0),1)\n",
    "                    cross_sph = cross_sph.view(Re.size(0),1)\n",
    "                    length_sph = length_sph.view(Re.size(0),1)\n",
    "                    porosity = porosity.view(Re.size(0),1)\n",
    "                    sar = sar.view(Re.size(0),1)\n",
    "                    A_crat = A_crat.view(A_crat.size(0),1)\n",
    "                    A_lrat = A_lrat.view(A_lrat.size(0),1)\n",
    "\n",
    "                    loss_c,loss_l,loss_pg = physics_loss(sar*0.5,sph,length_sph*2,cross_sph*3.5,A_crat*1.5,A_lrat*1.5)\n",
    "\n",
    "                    Cd_act = HnS(torch.exp(Re),sph,length_sph*2,cross_sph*3.5)#*(torch.abs(1 - porosity))**0.17)*torch.exp(Re)**-0.13)\n",
    "                    Cd_logout = torch.log(Cd_act)\n",
    "\n",
    "                    # TOTAL loss w/o phys Cd\n",
    "                    # sum physics guided and regular losses from Cd and geom parameters\n",
    "                    loss_Cd = criterion(Cd_logout,Cd)\n",
    "\n",
    "                    loss_tot = loss_Cd + loss_pg\n",
    "                    # TOTAL loss w/o phys Cd\n",
    "                    # sum physics guided and regular losses from Cd and geom parameters\n",
    "                    test_Cd_loss += loss_Cd * id.size(0)\n",
    "                    test_pg_loss += loss_pg * id.size(0)\n",
    "\n",
    "            test_Cd_loss /= len(test_loader.dataset)\n",
    "            test_pg_loss /= len(test_loader.dataset)\n",
    "\n",
    "            test_llist_Cd.append(test_Cd_loss.item())\n",
    "            test_llist_pg.append(test_pg_loss.item())\n",
    "\n",
    "            if test_Cd_loss < best_test:\n",
    "                torch.save(model.state_dict(), dir_model+str(fold)+'.pth')\n",
    "                goodplanmodel_epoch[fold] = epoch\n",
    "                best_test = test_Cd_loss\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Train Cd Loss: {train_Cd_loss:.6f} - Test Loss: {test_Cd_loss:.6f}\")\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Train pg Loss: {train_pg_loss:.6f} - Test Loss: {test_pg_loss:.6f}\")\n",
    "            print('\\n')\n",
    "            #print(Cd_out)\n",
    "        train_Cd_curves.append(train_llist_Cd)\n",
    "        test_Cd_curves.append(test_llist_Cd)\n",
    "        train_pg_curves.append(train_llist_pg)\n",
    "        test_pg_curves.append(test_llist_pg)\n",
    "\n",
    "if correlation == 2:\n",
    "    train_Cd_curves = []\n",
    "    train_pg_curves = []\n",
    "\n",
    "    test_Cd_curves = []\n",
    "    test_pg_curves = []\n",
    "\n",
    "    best_test_acc = np.array([100,100,100,100,100])\n",
    "\n",
    "    # Training loop\n",
    "\n",
    "    for fold, (train_ids, test_ids) in enumerate(kf.split(fulldata)):\n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "        train_loader = DataLoader(\n",
    "            dataset=fulldata,\n",
    "            batch_size=batch_size,\n",
    "            sampler=torch.utils.data.SubsetRandomSampler(train_ids),\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            dataset=fulldata,\n",
    "            batch_size=batch_size,\n",
    "            sampler=torch.utils.data.SubsetRandomSampler(test_ids),\n",
    "        )\n",
    "        model = KGCNN2.to(device)\n",
    "        non_frozen_parameters = [p for p in model.parameters() if p.requires_grad]\n",
    "        optimizer = torch.optim.Adam(non_frozen_parameters, lr=lr)  # Choose an optimizer\n",
    "        \n",
    "        if pretrained == 1:\n",
    "            model, optimizer, start_epoch = load_ckp(dir_premodel, model, optimizer)\n",
    "    \n",
    "        best_test = best_test_acc[fold]\n",
    "\n",
    "        train_llist_Cd = []\n",
    "        train_llist_pg = []\n",
    "        test_llist_Cd = []\n",
    "        test_llist_pg = []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()  # Set the model in training mode\n",
    "\n",
    "            train_Cd_loss = 0.0\n",
    "            train_Df_loss = 0.0\n",
    "            train_pg_loss = 0.0\n",
    "\n",
    "            for id,images,A_char,Re,Cd,Df_dat in train_loader:\n",
    "\n",
    "                id = id.to(device)\n",
    "                images = Variable(images, requires_grad=True)\n",
    "                A_char = Variable(A_char, requires_grad=True)\n",
    "                Re = Variable(Re, requires_grad=True)\n",
    "                Cd = Variable(Cd, requires_grad=True)\n",
    "                Df_dat = Variable(Df_dat, requires_grad=True)\n",
    "\n",
    "                A_char = A_char.view(A_char.size(0),1)\n",
    "                Re = Re.view(Re.size(0),1)\n",
    "                Cd = Cd.view(Cd.size(0),1)\n",
    "                Df_dat = Df_dat.view(Df_dat.size(0),1)\n",
    "\n",
    "                images = images.to(device)\n",
    "                A_char = A_char.to(device)\n",
    "                Re = Re.to(device)\n",
    "                Cd = Cd.to(device)\n",
    "                Df_dat = Df_dat.to(device)\n",
    "\n",
    "                #with autograd.detect_anomaly():\n",
    "                # Forward pass\n",
    "                geoms_out = model(images)\n",
    "                sph = geoms_out[:,0]\n",
    "                cross_sph = geoms_out[:,1]\n",
    "                length_sph = geoms_out[:,2]\n",
    "                porosity = geoms_out[:,3]\n",
    "                sar = geoms_out[:,4]\n",
    "                A_crat = geoms_out[:,5]\n",
    "                A_lrat = geoms_out[:,6]\n",
    "                Df = geoms_out[:,7]\n",
    "\n",
    "                sph = sph.view(Re.size(0),1)\n",
    "                cross_sph = cross_sph.view(Re.size(0),1)\n",
    "                length_sph = length_sph.view(Re.size(0),1)\n",
    "                porosity = porosity.view(Re.size(0),1)\n",
    "                sar = sar.view(Re.size(0),1)\n",
    "                A_crat = A_crat.view(A_crat.size(0),1)\n",
    "                A_lrat = A_lrat.view(A_lrat.size(0),1)\n",
    "                Df = Df.view(Df.size(0),1)\n",
    "\n",
    "                loss_c,loss_l,loss_pg = physics_loss(sar*0.5,sph,length_sph*2,cross_sph*3.5,A_crat*1.5,A_lrat*1.5)\n",
    "\n",
    "                Cd_act = Mola(torch.exp(Re),porosity,sph,length_sph*2,cross_sph*3.5,Df*3*1.3)\n",
    "                Cd_logout = torch.log(Cd_act)\n",
    "\n",
    "                # TOTAL loss w/o phys Cd\n",
    "                # sum physics guided and regular losses from Cd and geom parameters\n",
    "                if torch.max(sph) >= 1 or torch.max(porosity) >= 1:\n",
    "                    loss_Cd = torch.tensor(0.2,requires_grad=True)\n",
    "                elif torch.min(Cd_act) <= 0.0:\n",
    "                    loss_Cd = torch.abs(torch.min(Cd_act)*50)\n",
    "                else:\n",
    "                    loss_Cd = criterion(Cd_logout,Cd)\n",
    "\n",
    "                if torch.max(Df*3*1.3) >= 3:\n",
    "                    loss_Df = torch.abs(torch.max(Df*3*1.3)-2.9)**2\n",
    "                elif torch.min(Df*3*1.3) <= 1.4:\n",
    "                    loss_Df = torch.abs(torch.min(Df*3*1.3)-1.5)**2\n",
    "                else:\n",
    "                    loss_Df = criterion(Df*3*1.3,Df_dat*3*1.3)/8\n",
    "\n",
    "                loss_Df = loss_Df.to(device)\n",
    "                loss_Cd = loss_Cd.to(device)\n",
    "                loss_tot = loss_Cd + loss_Df + loss_pg\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                if custom_loss == 1:\n",
    "                    loss_tot.backward()\n",
    "                if custom_loss == 2:\n",
    "                    (loss_Cd+loss_Df).backward()\n",
    "                \n",
    "                #nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                clip_value = 10\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                #####\n",
    "                train_Cd_loss += loss_Cd * id.size(0)\n",
    "                train_Df_loss += loss_Df* id.size(0)\n",
    "                train_pg_loss += loss_pg * id.size(0)\n",
    "\n",
    "            train_Cd_loss /= len(train_loader.dataset)\n",
    "            train_Df_loss /= len(train_loader.dataset)\n",
    "            train_pg_loss /= len(train_loader.dataset)\n",
    "\n",
    "            train_llist_pg.append(train_pg_loss.item())\n",
    "\n",
    "            # Evaluation\n",
    "            model.eval()  # Set the model in evaluation mode\n",
    "\n",
    "            test_Cd_loss = 0.0\n",
    "            test_Df_loss = 0.0\n",
    "            test_pg_loss = 0.0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for id,images,A_char,Re,Cd,Df_dat in test_loader:\n",
    "\n",
    "                    id = id.to(device)\n",
    "                    images = Variable(images, requires_grad=True)\n",
    "                    A_char = Variable(A_char, requires_grad=True)\n",
    "                    Re = Variable(Re, requires_grad=True)\n",
    "                    Cd = Variable(Cd, requires_grad=True)\n",
    "                    Df_dat = Variable(Df_dat, requires_grad=True)\n",
    "\n",
    "                    A_char = A_char.view(A_char.size(0),1)\n",
    "                    Re = Re.view(Re.size(0),1)\n",
    "                    Cd = Cd.view(Cd.size(0),1)\n",
    "                    Df_dat = Df_dat.view(Df_dat.size(0),1)\n",
    "\n",
    "                    images = images.to(device)\n",
    "                    A_char = A_char.to(device)\n",
    "                    Re = Re.to(device)\n",
    "                    Cd = Cd.to(device)\n",
    "                    Df_dat = Df_dat.to(device)\n",
    "\n",
    "                    #with autograd.detect_anomaly():\n",
    "                    # Forward pass\n",
    "                    geoms_out = model(images)\n",
    "                    sph = geoms_out[:,0]\n",
    "                    cross_sph = geoms_out[:,1]\n",
    "                    length_sph = geoms_out[:,2]\n",
    "                    porosity = geoms_out[:,3]\n",
    "                    sar = geoms_out[:,4]\n",
    "                    A_crat = geoms_out[:,5]\n",
    "                    A_lrat = geoms_out[:,6]\n",
    "                    Df = geoms_out[:,7]\n",
    "\n",
    "                    sph = sph.view(Re.size(0),1)\n",
    "                    cross_sph = cross_sph.view(Re.size(0),1)\n",
    "                    length_sph = length_sph.view(Re.size(0),1)\n",
    "                    porosity = porosity.view(Re.size(0),1)\n",
    "                    sar = sar.view(Re.size(0),1)\n",
    "                    A_crat = A_crat.view(A_crat.size(0),1)\n",
    "                    A_lrat = A_lrat.view(A_lrat.size(0),1)\n",
    "                    Df = Df.view(Df.size(0),1)\n",
    "\n",
    "                    loss_c,loss_l,loss_pg = physics_loss(sar*0.5,sph,length_sph*2,cross_sph*3.5,A_crat*1.5,A_lrat*1.5)\n",
    "\n",
    "                    Cd_act = Mola(torch.exp(Re),porosity,sph,length_sph*2,cross_sph*3.5,Df*3*1.3)\n",
    "                    Cd_logout = torch.log(Cd_act)\n",
    "\n",
    "                    # TOTAL loss w/o phys Cd\n",
    "                    # sum physics guided and regular losses from Cd and geom parameters\n",
    "                    loss_Cd = criterion(Cd_logout,Cd)\n",
    "                    loss_Df = criterion(Df*3*1.3,Df_dat*3*1.3)/8\n",
    "                    loss_tot = loss_Cd + loss_Df + loss_pg\n",
    "                    # TOTAL loss w/o phys Cd\n",
    "                    # sum physics guided and regular losses from Cd and geom parameters\n",
    "                    test_Cd_loss += loss_Cd * id.size(0)\n",
    "                    test_Df_loss += loss_Df * id.size(0)\n",
    "                    test_pg_loss += loss_pg * id.size(0)\n",
    "\n",
    "            test_Cd_loss /= len(test_loader.dataset)\n",
    "            test_Df_loss /= len(test_loader.dataset)\n",
    "            test_pg_loss /= len(test_loader.dataset)\n",
    "\n",
    "            test_llist_Cd.append(test_Cd_loss.item())\n",
    "            test_llist_pg.append(test_pg_loss.item())\n",
    "\n",
    "            if test_Cd_loss < best_test:\n",
    "                torch.save(model.state_dict(), dir_model+str(fold)+'.pth')\n",
    "                goodplanmodel_epoch = epoch\n",
    "                best_test = test_Cd_loss\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Train Cd Loss: {train_Cd_loss:.6f} - Test Loss: {test_Cd_loss:.6f}\")\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Train Df Loss: {train_Df_loss:.6f} - Test Loss: {test_Df_loss:.6f}\")\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Train pg Loss: {train_pg_loss:.6f} - Test Loss: {test_pg_loss:.6f}\")\n",
    "            print('\\n')\n",
    "            #print(Cd_out)\n",
    "        train_Cd_curves.append(train_llist_Cd)\n",
    "        test_Cd_curves.append(test_llist_Cd)\n",
    "        train_pg_curves.append(train_llist_pg)\n",
    "        test_pg_curves.append(test_llist_pg)\n",
    "\n",
    "if correlation == 3:\n",
    "    train_llist_Cd = []\n",
    "    test_llist_Cd = []\n",
    "    goodplanmodel_epoch = np.array([0,0,0,0,0])\n",
    "\n",
    "    best_test_acc = np.array([100,100,100,100,100])\n",
    "\n",
    "    # Training loop\n",
    "\n",
    "    for fold, (train_ids, test_ids) in enumerate(kf.split(fulldata)):\n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "        train_loader = DataLoader(\n",
    "            dataset=fulldata,\n",
    "            batch_size=batch_size,\n",
    "            sampler=torch.utils.data.SubsetRandomSampler(train_ids),\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            dataset=fulldata,\n",
    "            batch_size=batch_size,\n",
    "            sampler=torch.utils.data.SubsetRandomSampler(test_ids),\n",
    "        )\n",
    "        model = KGCNN3.to(device)\n",
    "        non_frozen_parameters = [p for p in model.parameters() if p.requires_grad]\n",
    "        optimizer = torch.optim.Adam(non_frozen_parameters, lr=lr)  # Choose an optimizer\n",
    "        best_test = best_test_acc[fold]\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()  # Set the model in training mode\n",
    "\n",
    "            train_Cd_loss = 0.0\n",
    "\n",
    "            for id,images,A_char,Re,Cd in train_loader:\n",
    "\n",
    "                id = id.to(device)\n",
    "                images = Variable(images, requires_grad=True)\n",
    "                A_char = Variable(A_char, requires_grad=True)\n",
    "                Re = Variable(Re, requires_grad=True)\n",
    "                Cd = Variable(Cd, requires_grad=True)\n",
    "\n",
    "                A_char = A_char.view(A_char.size(0),1)\n",
    "                Re = Re.view(Re.size(0),1)\n",
    "                Cd = Cd.view(Cd.size(0),1)\n",
    "\n",
    "                images = images.to(device)\n",
    "                A_char = A_char.to(device)\n",
    "                Re = Re.to(device)\n",
    "                Cd = Cd.to(device)\n",
    "\n",
    "                #with autograd.detect_anomaly():\n",
    "                # Forward pass\n",
    "                cd_out = model(images,Re)\n",
    "\n",
    "                loss_Cd = criterion(cd_out,Cd)\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                loss_Cd.backward()\n",
    "                #nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                clip_value = 10\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                #####\n",
    "                train_Cd_loss += loss_Cd * id.size(0)\n",
    "\n",
    "            train_Cd_loss /= len(train_loader.dataset)\n",
    "\n",
    "            # Evaluation\n",
    "            model.eval()  # Set the model in evaluation mode\n",
    "\n",
    "            test_Cd_loss = 0.0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for id,images,A_char,Re,Cd in test_loader:\n",
    "\n",
    "                    id = id.to(device)\n",
    "                    images = Variable(images, requires_grad=True)\n",
    "                    A_char = Variable(A_char, requires_grad=True)\n",
    "                    Re = Variable(Re, requires_grad=True)\n",
    "                    Cd = Variable(Cd, requires_grad=True)\n",
    "\n",
    "                    A_char = A_char.view(A_char.size(0),1)\n",
    "                    Re = Re.view(Re.size(0),1)\n",
    "                    Cd = Cd.view(Cd.size(0),1)\n",
    "\n",
    "                    images = images.to(device)\n",
    "                    A_char = A_char.to(device)\n",
    "                    Re = Re.to(device)\n",
    "                    Cd = Cd.to(device)\n",
    "\n",
    "                    #with autograd.detect_anomaly():\n",
    "                    # Forward pass\n",
    "                    cd_out = model(images,Re)\n",
    "\n",
    "                    loss_Cd = criterion(cd_out,Cd)\n",
    "\n",
    "                    # TOTAL loss w/o phys Cd\n",
    "                    # sum physics guided and regular losses from Cd and geom parameters\n",
    "                    test_Cd_loss += loss_Cd * id.size(0)\n",
    "\n",
    "            test_Cd_loss /= len(test_loader.dataset)\n",
    "\n",
    "            test_llist_Cd.append(test_Cd_loss.item())\n",
    "\n",
    "            if test_Cd_loss < best_test:\n",
    "                torch.save(model.state_dict(), dir_model+str(fold)+'.pth')\n",
    "                goodplanmodel_epoch[fold] = epoch\n",
    "                best_test = test_Cd_loss\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Train Cd Loss: {train_Cd_loss:.6f} - Test Loss: {test_Cd_loss:.6f}\")\n",
    "            print('\\n')\n",
    "print('Completed training.')\n",
    "print('Now evaluating performance')\n",
    "\n",
    "if correlation == 1:\n",
    "    hs_planout = pd.DataFrame(columns=['por','sar','sph','lsph','csph','Acrat','Alrat','Cdout','massout','Rhos','Rhoc','Rhol','id','Cd','Re','mass'])\n",
    "    x,y,z,w,v = kf.split(fulldata)\n",
    "    model = KGCNN1.to(device)\n",
    "    for i in range(5):\n",
    "        model.load_state_dict(torch.load(dir_model+str(i)+\".pth\"))\n",
    "        if i == 0:\n",
    "            test_loader = DataLoader(\n",
    "                dataset=fulldata,\n",
    "                batch_size=1,\n",
    "                sampler=torch.utils.data.SubsetRandomSampler(x[1])\n",
    "            )\n",
    "        elif i == 1:\n",
    "            test_loader = DataLoader(\n",
    "            dataset=fulldata,\n",
    "            batch_size=1,\n",
    "            sampler=torch.utils.data.SubsetRandomSampler(y[1])\n",
    "            )\n",
    "        elif i == 2:\n",
    "            test_loader = DataLoader(\n",
    "            dataset=fulldata,\n",
    "            batch_size=1,\n",
    "            sampler=torch.utils.data.SubsetRandomSampler(z[1])\n",
    "            )\n",
    "        elif i == 3:\n",
    "            test_loader = DataLoader(\n",
    "            dataset=fulldata,\n",
    "            batch_size=1,\n",
    "            sampler=torch.utils.data.SubsetRandomSampler(w[1])\n",
    "            )\n",
    "        elif i == 4:\n",
    "            test_loader = DataLoader(\n",
    "            dataset=fulldata,\n",
    "            batch_size=1,\n",
    "            sampler=torch.utils.data.SubsetRandomSampler(v[1])\n",
    "            )\n",
    "        model.eval()  # Set the model in evaluation mode\n",
    "\n",
    "        Cd_outs = []\n",
    "        por_outs = []\n",
    "        sar_outs = []\n",
    "        sph_outs = []\n",
    "        csph_outs = []\n",
    "        lsph_outs = []\n",
    "        Acrat_outs = []\n",
    "        Alrat_outs = []\n",
    "\n",
    "        Cd_ans = []\n",
    "\n",
    "        test_ids = []\n",
    "        with torch.no_grad():\n",
    "            for id,images,A_char,Re,Cd in test_loader:\n",
    "\n",
    "                id = id.to(device)\n",
    "                images = Variable(images, requires_grad=True)\n",
    "                A_char = Variable(A_char, requires_grad=True)\n",
    "                Re = Variable(Re, requires_grad=True)\n",
    "                Cd = Variable(Cd, requires_grad=True)\n",
    "\n",
    "                A_char = A_char.view(A_char.size(0),1)\n",
    "                Re = Re.view(Re.size(0),1)\n",
    "                Cd = Cd.view(Cd.size(0),1)\n",
    "\n",
    "                images = images.to(device)\n",
    "                A_char = A_char.to(device)\n",
    "                Re = Re.to(device)\n",
    "                Cd = Cd.to(device)\n",
    "\n",
    "                #with autograd.detect_anomaly():\n",
    "                # Forward pass\n",
    "                geoms_out = model(images)\n",
    "                sph = geoms_out[:,0]\n",
    "                cross_sph = geoms_out[:,1]\n",
    "                length_sph = geoms_out[:,2]\n",
    "                porosity = geoms_out[:,3]\n",
    "                sar = geoms_out[:,4]\n",
    "                A_crat = geoms_out[:,5]\n",
    "                A_lrat = geoms_out[:,6]\n",
    "\n",
    "                sph = sph.view(Re.size(0),1)\n",
    "                cross_sph = cross_sph.view(Re.size(0),1)\n",
    "                length_sph = length_sph.view(Re.size(0),1)\n",
    "                porosity = porosity.view(Re.size(0),1)\n",
    "                sar = sar.view(Re.size(0),1)\n",
    "                A_crat = A_crat.view(A_crat.size(0),1)\n",
    "                A_lrat = A_lrat.view(A_lrat.size(0),1)\n",
    "\n",
    "                Cd_out = HnS(torch.exp(Re),sph,length_sph*2,cross_sph*3.5)#*(torch.abs(1 - porosity))**0.17)*torch.exp(Re)**-0.13)\n",
    "                Cd_logout = torch.log(Cd_out)\n",
    "\n",
    "                Cd_outs.append(Cd_out.item())\n",
    "                por_outs.append(porosity.item())\n",
    "                sar_outs.append(sar.item())\n",
    "                sph_outs.append(sph.item())\n",
    "                lsph_outs.append(length_sph.item())\n",
    "                csph_outs.append(cross_sph.item())\n",
    "                Acrat_outs.append(A_crat.item())\n",
    "                Alrat_outs.append(A_lrat.item())\n",
    "\n",
    "                Cd_ans.append(torch.exp(Cd).item())\n",
    "\n",
    "                test_ids.append(id.item())\n",
    "                #err += (abs(outputs - t_Cd)/t_Cd)*100\n",
    "                #print(err)\n",
    "                #loss =  l + loss_mean\n",
    "        #outs_act = np.array(outs)\n",
    "        #answers_act = np.array(answers)\n",
    "        Cd_outs = np.array(Cd_outs)\n",
    "        Cd_acts = np.array(Cd_outs)\n",
    "\n",
    "        por_outs = np.array(por_outs)\n",
    "        sar_outs = np.array(sar_outs)\n",
    "        sph_outs = np.array(sph_outs)\n",
    "        lsph_outs = np.array(lsph_outs)\n",
    "        csph_outs = np.array(csph_outs)\n",
    "        Acrat_outs = np.array(Acrat_outs)\n",
    "        Alrat_outs = np.array(Alrat_outs)\n",
    "        por_outs = por_outs\n",
    "        sar_outs = sar_outs*0.5\n",
    "        sph_outs = sph_outs\n",
    "        l_sph_outs = lsph_outs*2\n",
    "        c_sph_outs = csph_outs*3.5\n",
    "        Acrat_outs = Acrat_outs*1.5\n",
    "        Alrat_outs = Alrat_outs*1.5\n",
    "\n",
    "        Cd_ans = np.array(Cd_ans)\n",
    "        Cd_actans = np.array(Cd_ans)\n",
    "\n",
    "        test_ids = np.array(test_ids)\n",
    "        mass_out = Cd_acts*0.5*cur_df['rho'][test_ids]*(cur_df['vel'][test_ids]**2)*cur_df['area'][test_ids]/9.81\n",
    "        Cd_errs = ((Cd_ans - Cd_outs)/abs(Cd_ans))*100\n",
    "        Cd_errs_abs = (abs(Cd_ans - Cd_outs)/abs(Cd_ans))*100\n",
    "        Cd_aerrs = -((Cd_actans - Cd_acts)/abs(Cd_actans))*100\n",
    "        Cd_aerrs_abs = (abs(Cd_actans - Cd_acts)/abs(Cd_actans))*100\n",
    "        Cd_mse = (Cd_acts - Cd_actans)**2\n",
    "        Cd_rmse = np.sqrt(np.sum(Cd_mse)/len(Cd_mse))\n",
    "        Cd_nrmse = (Cd_rmse/np.mean(Cd_actans))*100\n",
    "        mass_mse = (mass_out - cur_df['mass'][test_ids])**2\n",
    "        mass_rmse = np.sqrt(np.sum(mass_mse)/len(mass_mse))\n",
    "        mass_nrmse = (mass_rmse/2.644140625e-07)*100\n",
    "        Vol_out_s = 4*np.pi/3*(sph_outs/(4*sar_outs) * cur_df['area'][test_ids]/np.pi)**(3/2)\n",
    "        rho_s = mass_out/Vol_out_s\n",
    "        Vol_out_c = 4*np.pi/3*(c_sph_outs*Acrat_outs * cur_df['area'][test_ids]/np.pi)**(3/2)\n",
    "        rho_c = mass_out/Vol_out_c\n",
    "        Vol_out_l = 4*np.pi/3*(l_sph_outs*(1/(2*sar_outs)-Alrat_outs) * cur_df['area'][test_ids]/np.pi)**(3/2)\n",
    "        rho_l = mass_out/Vol_out_l\n",
    "        predout = pd.DataFrame(por_outs,columns=['por'])\n",
    "        predout['sar'] = sar_outs\n",
    "        predout['sph'] = sph_outs\n",
    "        predout['lsph'] = l_sph_outs\n",
    "        predout['csph'] = c_sph_outs\n",
    "        predout['Acrat'] = Acrat_outs\n",
    "        predout['Alrat'] = Alrat_outs\n",
    "        predout['Cdout'] = Cd_outs\n",
    "        predout['massout'] = np.array(mass_out)\n",
    "        predout['Rhos'] = np.array(rho_s)\n",
    "        predout['Rhoc'] = np.array(rho_c)\n",
    "        predout['Rhol'] = np.array(rho_l)\n",
    "        predout['id'] = np.array(cur_df['id'][test_ids])\n",
    "        predout['Cd'] = np.array(cur_df['Cd'][test_ids])\n",
    "        predout['Re'] = np.array(cur_df['Re'][test_ids])\n",
    "        predout['mass'] = np.array(cur_df['mass'][test_ids])\n",
    "        hs_planout = pd.concat([hs_planout,predout],ignore_index=True)\n",
    "        \n",
    "if correlation == 2:\n",
    "    hs_planout = pd.DataFrame(columns=['por','sar','sph','lsph','csph','Acrat','Alrat','Df_out','Cdout','massout','Rhos','Rhoc','Rhol','id','Cd','Re','Df','mass'])\n",
    "    x,y,z,w,v = kf.split(fulldata)\n",
    "    model = KGCNN2.to(device)\n",
    "    for i in range(5):\n",
    "        model.load_state_dict(torch.load(dir_model+str(i)+\".pth\"))\n",
    "        if i == 0:\n",
    "            test_loader = DataLoader(\n",
    "                dataset=fulldata,\n",
    "                batch_size=1,\n",
    "                sampler=torch.utils.data.SubsetRandomSampler(x[1])\n",
    "            )\n",
    "        elif i == 1:\n",
    "            test_loader = DataLoader(\n",
    "            dataset=fulldata,\n",
    "            batch_size=1,\n",
    "            sampler=torch.utils.data.SubsetRandomSampler(y[1])\n",
    "            )\n",
    "        elif i == 2:\n",
    "            test_loader = DataLoader(\n",
    "            dataset=fulldata,\n",
    "            batch_size=1,\n",
    "            sampler=torch.utils.data.SubsetRandomSampler(z[1])\n",
    "            )\n",
    "        elif i == 3:\n",
    "            test_loader = DataLoader(\n",
    "            dataset=fulldata,\n",
    "            batch_size=1,\n",
    "            sampler=torch.utils.data.SubsetRandomSampler(w[1])\n",
    "            )\n",
    "        elif i == 4:\n",
    "            test_loader = DataLoader(\n",
    "            dataset=fulldata,\n",
    "            batch_size=1,\n",
    "            sampler=torch.utils.data.SubsetRandomSampler(v[1])\n",
    "            )\n",
    "        model.eval()  # Set the model in evaluation mode\n",
    "\n",
    "        Cd_outs = []\n",
    "        por_outs = []\n",
    "        sar_outs = []\n",
    "        sph_outs = []\n",
    "        csph_outs = []\n",
    "        lsph_outs = []\n",
    "        Acrat_outs = []\n",
    "        Alrat_outs = []\n",
    "        Df_outs = []\n",
    "\n",
    "        Cd_ans = []\n",
    "        Df_ans = []\n",
    "\n",
    "        test_ids = []\n",
    "        with torch.no_grad():\n",
    "            for id,images,A_char,Re,Cd,Df_dat in test_loader:\n",
    "\n",
    "                id = id.to(device)\n",
    "                images = Variable(images, requires_grad=True)\n",
    "                A_char = Variable(A_char, requires_grad=True)\n",
    "                Re = Variable(Re, requires_grad=True)\n",
    "                Cd = Variable(Cd, requires_grad=True)\n",
    "                Df_dat = Variable(Df_dat, requires_grad=True)\n",
    "\n",
    "                A_char = A_char.view(A_char.size(0),1)\n",
    "                Re = Re.view(Re.size(0),1)\n",
    "                Cd = Cd.view(Cd.size(0),1)\n",
    "                Df_dat = Df_dat.view(Df_dat.size(0),1)\n",
    "\n",
    "                images = images.to(device)\n",
    "                A_char = A_char.to(device)\n",
    "                Re = Re.to(device)\n",
    "                Cd = Cd.to(device)\n",
    "                Df_dat = Df_dat.to(device)\n",
    "\n",
    "                #with autograd.detect_anomaly():\n",
    "                # Forward pass\n",
    "                geoms_out = model(images)\n",
    "                sph = geoms_out[:,0]\n",
    "                cross_sph = geoms_out[:,1]\n",
    "                length_sph = geoms_out[:,2]\n",
    "                porosity = geoms_out[:,3]\n",
    "                sar = geoms_out[:,4]\n",
    "                A_crat = geoms_out[:,5]\n",
    "                A_lrat = geoms_out[:,6]\n",
    "                Df = geoms_out[:,7]\n",
    "\n",
    "                sph = sph.view(Re.size(0),1)\n",
    "                cross_sph = cross_sph.view(Re.size(0),1)\n",
    "                length_sph = length_sph.view(Re.size(0),1)\n",
    "                porosity = porosity.view(Re.size(0),1)\n",
    "                sar = sar.view(Re.size(0),1)\n",
    "                A_crat = A_crat.view(A_crat.size(0),1)\n",
    "                A_lrat = A_lrat.view(A_lrat.size(0),1)\n",
    "                Df = Df.view(Df.size(0),1)\n",
    "\n",
    "                Cd_out = Mola(torch.exp(Re),porosity,sph,length_sph*2,cross_sph*3.5,Df*3*1.3)\n",
    "                Cd_logout = torch.log(Cd_out)\n",
    "\n",
    "                Cd_outs.append(Cd_out.item())\n",
    "                por_outs.append(porosity.item())\n",
    "                sar_outs.append(sar.item())\n",
    "                sph_outs.append(sph.item())\n",
    "                lsph_outs.append(length_sph.item())\n",
    "                csph_outs.append(cross_sph.item())\n",
    "                Acrat_outs.append(A_crat.item())\n",
    "                Alrat_outs.append(A_lrat.item())\n",
    "                Df_outs.append(Df.item())\n",
    "\n",
    "                Cd_ans.append(torch.exp(Cd).item())\n",
    "                Df_ans.append(Df_dat.item())\n",
    "\n",
    "                test_ids.append(id.item())\n",
    "                #err += (abs(outputs - t_Cd)/t_Cd)*100\n",
    "                #print(err)\n",
    "                #loss =  l + loss_mean\n",
    "        #outs_act = np.array(outs)\n",
    "        #answers_act = np.array(answers)\n",
    "        Cd_outs = np.array(Cd_outs)\n",
    "        Cd_acts = np.array(Cd_outs)\n",
    "\n",
    "        por_outs = np.array(por_outs)\n",
    "        sar_outs = np.array(sar_outs)\n",
    "        sph_outs = np.array(sph_outs)\n",
    "        lsph_outs = np.array(lsph_outs)\n",
    "        csph_outs = np.array(csph_outs)\n",
    "        Acrat_outs = np.array(Acrat_outs)\n",
    "        Alrat_outs = np.array(Alrat_outs)\n",
    "        Df_outs = np.array(Df_outs)\n",
    "        por_outs = por_outs\n",
    "        sar_outs = sar_outs*0.5\n",
    "        sph_outs = sph_outs\n",
    "        l_sph_outs = lsph_outs*2\n",
    "        c_sph_outs = csph_outs*3.5\n",
    "        Acrat_outs = Acrat_outs*1.5\n",
    "        Alrat_outs = Alrat_outs*1.5\n",
    "        Df_outs = Df_outs*3*1.3\n",
    "\n",
    "        Cd_ans = np.array(Cd_ans)\n",
    "        Cd_actans = np.array(Cd_ans)\n",
    "        Df_ans = np.array(Df_ans)*3*1.3\n",
    "\n",
    "        test_ids = np.array(test_ids)\n",
    "        mass_out = Cd_acts*0.5*cur_df['rho'][test_ids]*(cur_df['vel'][test_ids]**2)*cur_df['area'][test_ids]/9.81\n",
    "        Cd_errs = ((Cd_ans - Cd_outs)/abs(Cd_ans))*100\n",
    "        Cd_errs_abs = (abs(Cd_ans - Cd_outs)/abs(Cd_ans))*100\n",
    "        Cd_aerrs = -((Cd_actans - Cd_acts)/abs(Cd_actans))*100\n",
    "        Cd_aerrs_abs = (abs(Cd_actans - Cd_acts)/abs(Cd_actans))*100\n",
    "        Cd_mse = (Cd_acts - Cd_actans)**2\n",
    "        Cd_rmse = np.sqrt(np.sum(Cd_mse)/len(Cd_mse))\n",
    "        Cd_nrmse = (Cd_rmse/np.mean(Cd_actans))*100\n",
    "        mass_mse = (mass_out - cur_df['mass'][test_ids])**2\n",
    "        mass_rmse = np.sqrt(np.sum(mass_mse)/len(mass_mse))\n",
    "        mass_nrmse = (mass_rmse/2.644140625e-07)*100\n",
    "        Vol_out_s = 4*np.pi/3*(sph_outs/(4*sar_outs) * cur_df['area'][test_ids]/np.pi)**(3/2)\n",
    "        rho_s = mass_out/Vol_out_s\n",
    "        Vol_out_c = 4*np.pi/3*(c_sph_outs*Acrat_outs * cur_df['area'][test_ids]/np.pi)**(3/2)\n",
    "        rho_c = mass_out/Vol_out_c\n",
    "        Vol_out_l = 4*np.pi/3*(l_sph_outs*(1/(2*sar_outs)-Alrat_outs) * cur_df['area'][test_ids]/np.pi)**(3/2)\n",
    "        rho_l = mass_out/Vol_out_l\n",
    "        predout = pd.DataFrame(por_outs,columns=['por'])\n",
    "        predout['sar'] = sar_outs\n",
    "        predout['sph'] = sph_outs\n",
    "        predout['lsph'] = l_sph_outs\n",
    "        predout['csph'] = c_sph_outs\n",
    "        predout['Acrat'] = Acrat_outs\n",
    "        predout['Alrat'] = Alrat_outs\n",
    "        predout['Df_out'] = Df_outs\n",
    "        predout['Cdout'] = Cd_outs\n",
    "        predout['massout'] = np.array(mass_out)\n",
    "        predout['Rhos'] = np.array(rho_s)\n",
    "        predout['Rhoc'] = np.array(rho_c)\n",
    "        predout['Rhol'] = np.array(rho_l)\n",
    "        predout['id'] = np.array(cur_df['id'][test_ids])\n",
    "        predout['Cd'] = np.array(cur_df['Cd'][test_ids])\n",
    "        predout['Re'] = np.array(cur_df['Re'][test_ids])\n",
    "        predout['Df'] = Df_ans\n",
    "        predout['mass'] = np.array(cur_df['mass'][test_ids])\n",
    "        hs_planout = pd.concat([hs_planout,predout],ignore_index=True)\n",
    "\n",
    "if correlation == 3:\n",
    "    hs_planout = pd.DataFrame(columns=['Cdout','massout','id','Cd','Re','mass'])\n",
    "    x,y,z,w,v = kf.split(fulldata)\n",
    "    model = KGCNN3.to(device)\n",
    "    for i in range(5):\n",
    "        model.load_state_dict(torch.load(dir_model+str(i)+\".pth\"))\n",
    "        if i == 0:\n",
    "            test_loader = DataLoader(\n",
    "                dataset=fulldata,\n",
    "                batch_size=1,\n",
    "                sampler=torch.utils.data.SubsetRandomSampler(x[1])\n",
    "            )\n",
    "        elif i == 1:\n",
    "            test_loader = DataLoader(\n",
    "            dataset=fulldata,\n",
    "            batch_size=1,\n",
    "            sampler=torch.utils.data.SubsetRandomSampler(y[1])\n",
    "            )\n",
    "        elif i == 2:\n",
    "            test_loader = DataLoader(\n",
    "            dataset=fulldata,\n",
    "            batch_size=1,\n",
    "            sampler=torch.utils.data.SubsetRandomSampler(z[1])\n",
    "            )\n",
    "        elif i == 3:\n",
    "            test_loader = DataLoader(\n",
    "            dataset=fulldata,\n",
    "            batch_size=1,\n",
    "            sampler=torch.utils.data.SubsetRandomSampler(w[1])\n",
    "            )\n",
    "        elif i == 4:\n",
    "            test_loader = DataLoader(\n",
    "            dataset=fulldata,\n",
    "            batch_size=1,\n",
    "            sampler=torch.utils.data.SubsetRandomSampler(v[1])\n",
    "            )\n",
    "        model.eval()  # Set the model in evaluation mode\n",
    "\n",
    "        Cd_outs = []\n",
    "\n",
    "        Cd_ans = []\n",
    "\n",
    "        test_ids = []\n",
    "        with torch.no_grad():\n",
    "            for id,images,A_char,Re,Cd in test_loader:\n",
    "\n",
    "                id = id.to(device)\n",
    "                images = Variable(images, requires_grad=True)\n",
    "                A_char = Variable(A_char, requires_grad=True)\n",
    "                Re = Variable(Re, requires_grad=True)\n",
    "                Cd = Variable(Cd, requires_grad=True)\n",
    "\n",
    "                A_char = A_char.view(A_char.size(0),1)\n",
    "                Re = Re.view(Re.size(0),1)\n",
    "                Cd = Cd.view(Cd.size(0),1)\n",
    "\n",
    "                images = images.to(device)\n",
    "                A_char = A_char.to(device)\n",
    "                Re = Re.to(device)\n",
    "                Cd = Cd.to(device)\n",
    "\n",
    "                #with autograd.detect_anomaly():\n",
    "                # Forward pass\n",
    "                cd_out = model(images,Re)\n",
    "\n",
    "                Cd_outs.append(torch.exp(cd_out).item())\n",
    "\n",
    "                Cd_ans.append(torch.exp(Cd).item())\n",
    "\n",
    "                test_ids.append(id.item())\n",
    "                #err += (abs(outputs - t_Cd)/t_Cd)*100\n",
    "                #print(err)\n",
    "                #loss =  l + loss_mean\n",
    "        #outs_act = np.array(outs)\n",
    "        #answers_act = np.array(answers)\n",
    "        Cd_outs = np.array(Cd_outs)\n",
    "        Cd_acts = np.array(Cd_outs)\n",
    "\n",
    "        Cd_ans = np.array(Cd_ans)\n",
    "        Cd_actans = np.array(Cd_ans)\n",
    "\n",
    "        test_ids = np.array(test_ids)\n",
    "        mass_out = Cd_acts*0.5*cur_df['rho'][test_ids]*(cur_df['vel'][test_ids]**2)*cur_df['area'][test_ids]/9.81\n",
    "        Cd_errs = ((Cd_ans - Cd_outs)/abs(Cd_ans))*100\n",
    "        Cd_errs_abs = (abs(Cd_ans - Cd_outs)/abs(Cd_ans))*100\n",
    "        Cd_aerrs = -((Cd_actans - Cd_acts)/abs(Cd_actans))*100\n",
    "        Cd_aerrs_abs = (abs(Cd_actans - Cd_acts)/abs(Cd_actans))*100\n",
    "        Cd_mse = (Cd_acts - Cd_actans)**2\n",
    "        Cd_rmse = np.sqrt(np.sum(Cd_mse)/len(Cd_mse))\n",
    "        Cd_nrmse = (Cd_rmse/np.mean(Cd_actans))*100\n",
    "        mass_mse = (mass_out - cur_df['mass'][test_ids])**2\n",
    "        mass_rmse = np.sqrt(np.sum(mass_mse)/len(mass_mse))\n",
    "        mass_nrmse = (mass_rmse/2.59488188976378e-07)*100\n",
    "        predout = pd.DataFrame(Cd_outs,columns=['Cdout'])\n",
    "        predout['massout'] = np.array(mass_out)\n",
    "        predout['id'] = np.array(cur_df['id'][test_ids])\n",
    "        predout['Cd'] = np.array(cur_df['Cd'][test_ids])\n",
    "        predout['Re'] = np.array(cur_df['Re'][test_ids])\n",
    "        predout['mass'] = np.array(cur_df['mass'][test_ids])\n",
    "        hs_planout = pd.concat([hs_planout,predout],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DjyhBBTYrdIk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 252, 252]             832\n",
      "              ReLU-2         [-1, 32, 252, 252]               0\n",
      "         MaxPool2d-3         [-1, 32, 126, 126]               0\n",
      "            Conv2d-4         [-1, 48, 124, 124]          13,872\n",
      "              ReLU-5         [-1, 48, 124, 124]               0\n",
      "         MaxPool2d-6           [-1, 48, 62, 62]               0\n",
      "            Conv2d-7           [-1, 64, 60, 60]          27,712\n",
      "              ReLU-8           [-1, 64, 60, 60]               0\n",
      "         MaxPool2d-9           [-1, 64, 30, 30]               0\n",
      "           Conv2d-10           [-1, 80, 28, 28]          46,160\n",
      "             ReLU-11           [-1, 80, 28, 28]               0\n",
      "        MaxPool2d-12           [-1, 80, 14, 14]               0\n",
      "           Linear-13                   [-1, 50]         784,050\n",
      "             ReLU-14                   [-1, 50]               0\n",
      "          Dropout-15                   [-1, 50]               0\n",
      "           Linear-16                    [-1, 7]             357\n",
      "         Softplus-17                    [-1, 7]               0\n",
      "================================================================\n",
      "Total params: 872,983\n",
      "Trainable params: 872,983\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 52.59\n",
      "Params size (MB): 3.33\n",
      "Estimated Total Size (MB): 56.17\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = PGCNN_plan()\n",
    "summary(model.cuda(), (1,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_folds = 5\n",
    "# batch_size = 2\n",
    "# kf = KFold(n_splits=k_folds, shuffle=True,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 5e-6\n",
    "# num_epochs = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "872983"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "OUQWxRrqrdIk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Epoch 1/750 - Train Cd Loss: 0.143661 - Test Loss: 0.057604\n",
      "Epoch 1/750 - Train pg Loss: 2.592590 - Test Loss: 0.676452\n",
      "\n",
      "\n",
      "Epoch 2/750 - Train Cd Loss: 0.143745 - Test Loss: 0.057556\n",
      "Epoch 2/750 - Train pg Loss: 2.522755 - Test Loss: 0.648481\n",
      "\n",
      "\n",
      "Epoch 3/750 - Train Cd Loss: 0.143105 - Test Loss: 0.057518\n",
      "Epoch 3/750 - Train pg Loss: 2.467435 - Test Loss: 0.645950\n",
      "\n",
      "\n",
      "Epoch 4/750 - Train Cd Loss: 0.143293 - Test Loss: 0.057487\n",
      "Epoch 4/750 - Train pg Loss: 2.465514 - Test Loss: 0.642027\n",
      "\n",
      "\n",
      "Epoch 5/750 - Train Cd Loss: 0.143254 - Test Loss: 0.057490\n",
      "Epoch 5/750 - Train pg Loss: 2.452523 - Test Loss: 0.641274\n",
      "\n",
      "\n",
      "Epoch 6/750 - Train Cd Loss: 0.143393 - Test Loss: 0.057385\n",
      "Epoch 6/750 - Train pg Loss: 2.444653 - Test Loss: 0.643088\n",
      "\n",
      "\n",
      "Epoch 7/750 - Train Cd Loss: 0.142803 - Test Loss: 0.057492\n",
      "Epoch 7/750 - Train pg Loss: 2.457024 - Test Loss: 0.642663\n",
      "\n",
      "\n",
      "Epoch 8/750 - Train Cd Loss: 0.143045 - Test Loss: 0.057434\n",
      "Epoch 8/750 - Train pg Loss: 2.467444 - Test Loss: 0.647913\n",
      "\n",
      "\n",
      "Epoch 9/750 - Train Cd Loss: 0.143040 - Test Loss: 0.057441\n",
      "Epoch 9/750 - Train pg Loss: 2.473476 - Test Loss: 0.653351\n",
      "\n",
      "\n",
      "Epoch 10/750 - Train Cd Loss: 0.142627 - Test Loss: 0.057334\n",
      "Epoch 10/750 - Train pg Loss: 2.497944 - Test Loss: 0.646020\n",
      "\n",
      "\n",
      "Epoch 11/750 - Train Cd Loss: 0.143230 - Test Loss: 0.057528\n",
      "Epoch 11/750 - Train pg Loss: 2.472855 - Test Loss: 0.648958\n",
      "\n",
      "\n",
      "Epoch 12/750 - Train Cd Loss: 0.142359 - Test Loss: 0.057462\n",
      "Epoch 12/750 - Train pg Loss: 2.461062 - Test Loss: 0.644445\n",
      "\n",
      "\n",
      "Epoch 13/750 - Train Cd Loss: 0.142969 - Test Loss: 0.057475\n",
      "Epoch 13/750 - Train pg Loss: 2.473877 - Test Loss: 0.644237\n",
      "\n",
      "\n",
      "Epoch 14/750 - Train Cd Loss: 0.142881 - Test Loss: 0.057506\n",
      "Epoch 14/750 - Train pg Loss: 2.432362 - Test Loss: 0.634730\n",
      "\n",
      "\n",
      "Epoch 15/750 - Train Cd Loss: 0.143219 - Test Loss: 0.057483\n",
      "Epoch 15/750 - Train pg Loss: 2.427276 - Test Loss: 0.636252\n",
      "\n",
      "\n",
      "Epoch 16/750 - Train Cd Loss: 0.142520 - Test Loss: 0.057266\n",
      "Epoch 16/750 - Train pg Loss: 2.450798 - Test Loss: 0.636703\n",
      "\n",
      "\n",
      "Epoch 17/750 - Train Cd Loss: 0.142410 - Test Loss: 0.057453\n",
      "Epoch 17/750 - Train pg Loss: 2.461257 - Test Loss: 0.640891\n",
      "\n",
      "\n",
      "Epoch 18/750 - Train Cd Loss: 0.143115 - Test Loss: 0.057412\n",
      "Epoch 18/750 - Train pg Loss: 2.464877 - Test Loss: 0.635920\n",
      "\n",
      "\n",
      "Epoch 19/750 - Train Cd Loss: 0.142538 - Test Loss: 0.057294\n",
      "Epoch 19/750 - Train pg Loss: 2.430510 - Test Loss: 0.638356\n",
      "\n",
      "\n",
      "Epoch 20/750 - Train Cd Loss: 0.142728 - Test Loss: 0.057304\n",
      "Epoch 20/750 - Train pg Loss: 2.457047 - Test Loss: 0.648028\n",
      "\n",
      "\n",
      "Epoch 21/750 - Train Cd Loss: 0.142376 - Test Loss: 0.057329\n",
      "Epoch 21/750 - Train pg Loss: 2.456202 - Test Loss: 0.642931\n",
      "\n",
      "\n",
      "Epoch 22/750 - Train Cd Loss: 0.142657 - Test Loss: 0.057207\n",
      "Epoch 22/750 - Train pg Loss: 2.485190 - Test Loss: 0.652264\n",
      "\n",
      "\n",
      "Epoch 23/750 - Train Cd Loss: 0.142100 - Test Loss: 0.057188\n",
      "Epoch 23/750 - Train pg Loss: 2.439469 - Test Loss: 0.639360\n",
      "\n",
      "\n",
      "Epoch 24/750 - Train Cd Loss: 0.142363 - Test Loss: 0.057253\n",
      "Epoch 24/750 - Train pg Loss: 2.472069 - Test Loss: 0.655660\n",
      "\n",
      "\n",
      "Epoch 25/750 - Train Cd Loss: 0.142499 - Test Loss: 0.056993\n",
      "Epoch 25/750 - Train pg Loss: 2.479713 - Test Loss: 0.647559\n",
      "\n",
      "\n",
      "Epoch 26/750 - Train Cd Loss: 0.142572 - Test Loss: 0.057079\n",
      "Epoch 26/750 - Train pg Loss: 2.438904 - Test Loss: 0.635659\n",
      "\n",
      "\n",
      "Epoch 27/750 - Train Cd Loss: 0.141589 - Test Loss: 0.057032\n",
      "Epoch 27/750 - Train pg Loss: 2.456582 - Test Loss: 0.639966\n",
      "\n",
      "\n",
      "Epoch 28/750 - Train Cd Loss: 0.142612 - Test Loss: 0.057189\n",
      "Epoch 28/750 - Train pg Loss: 2.362808 - Test Loss: 0.613024\n",
      "\n",
      "\n",
      "Epoch 29/750 - Train Cd Loss: 0.143194 - Test Loss: 0.057209\n",
      "Epoch 29/750 - Train pg Loss: 2.311826 - Test Loss: 0.616321\n",
      "\n",
      "\n",
      "Epoch 30/750 - Train Cd Loss: 0.142686 - Test Loss: 0.057157\n",
      "Epoch 30/750 - Train pg Loss: 2.354556 - Test Loss: 0.625477\n",
      "\n",
      "\n",
      "Epoch 31/750 - Train Cd Loss: 0.142459 - Test Loss: 0.057311\n",
      "Epoch 31/750 - Train pg Loss: 2.385353 - Test Loss: 0.617347\n",
      "\n",
      "\n",
      "Epoch 32/750 - Train Cd Loss: 0.141616 - Test Loss: 0.057285\n",
      "Epoch 32/750 - Train pg Loss: 2.364291 - Test Loss: 0.624341\n",
      "\n",
      "\n",
      "Epoch 33/750 - Train Cd Loss: 0.141849 - Test Loss: 0.057260\n",
      "Epoch 33/750 - Train pg Loss: 2.377121 - Test Loss: 0.622441\n",
      "\n",
      "\n",
      "Epoch 34/750 - Train Cd Loss: 0.141760 - Test Loss: 0.057199\n",
      "Epoch 34/750 - Train pg Loss: 2.327697 - Test Loss: 0.610526\n",
      "\n",
      "\n",
      "Epoch 35/750 - Train Cd Loss: 0.141390 - Test Loss: 0.057179\n",
      "Epoch 35/750 - Train pg Loss: 2.288518 - Test Loss: 0.624828\n",
      "\n",
      "\n",
      "Epoch 36/750 - Train Cd Loss: 0.141793 - Test Loss: 0.057435\n",
      "Epoch 36/750 - Train pg Loss: 2.359280 - Test Loss: 0.622061\n",
      "\n",
      "\n",
      "Epoch 37/750 - Train Cd Loss: 0.142162 - Test Loss: 0.057216\n",
      "Epoch 37/750 - Train pg Loss: 2.384766 - Test Loss: 0.632058\n",
      "\n",
      "\n",
      "Epoch 38/750 - Train Cd Loss: 0.142833 - Test Loss: 0.057489\n",
      "Epoch 38/750 - Train pg Loss: 2.448349 - Test Loss: 0.644438\n",
      "\n",
      "\n",
      "Epoch 39/750 - Train Cd Loss: 0.142219 - Test Loss: 0.057279\n",
      "Epoch 39/750 - Train pg Loss: 2.428267 - Test Loss: 0.644841\n",
      "\n",
      "\n",
      "Epoch 40/750 - Train Cd Loss: 0.142194 - Test Loss: 0.057152\n",
      "Epoch 40/750 - Train pg Loss: 2.389144 - Test Loss: 0.642455\n",
      "\n",
      "\n",
      "Epoch 41/750 - Train Cd Loss: 0.142218 - Test Loss: 0.057302\n",
      "Epoch 41/750 - Train pg Loss: 2.383649 - Test Loss: 0.630035\n",
      "\n",
      "\n",
      "Epoch 42/750 - Train Cd Loss: 0.140716 - Test Loss: 0.057311\n",
      "Epoch 42/750 - Train pg Loss: 2.393709 - Test Loss: 0.622242\n",
      "\n",
      "\n",
      "Epoch 43/750 - Train Cd Loss: 0.142022 - Test Loss: 0.057356\n",
      "Epoch 43/750 - Train pg Loss: 2.330791 - Test Loss: 0.603499\n",
      "\n",
      "\n",
      "Epoch 44/750 - Train Cd Loss: 0.142393 - Test Loss: 0.057275\n",
      "Epoch 44/750 - Train pg Loss: 2.313265 - Test Loss: 0.608942\n",
      "\n",
      "\n",
      "Epoch 45/750 - Train Cd Loss: 0.140967 - Test Loss: 0.057389\n",
      "Epoch 45/750 - Train pg Loss: 2.370087 - Test Loss: 0.617302\n",
      "\n",
      "\n",
      "Epoch 46/750 - Train Cd Loss: 0.142063 - Test Loss: 0.057279\n",
      "Epoch 46/750 - Train pg Loss: 2.364850 - Test Loss: 0.630034\n",
      "\n",
      "\n",
      "Epoch 47/750 - Train Cd Loss: 0.141295 - Test Loss: 0.057349\n",
      "Epoch 47/750 - Train pg Loss: 2.382441 - Test Loss: 0.623055\n",
      "\n",
      "\n",
      "Epoch 48/750 - Train Cd Loss: 0.141954 - Test Loss: 0.057397\n",
      "Epoch 48/750 - Train pg Loss: 2.379382 - Test Loss: 0.624809\n",
      "\n",
      "\n",
      "Epoch 49/750 - Train Cd Loss: 0.141410 - Test Loss: 0.057397\n",
      "Epoch 49/750 - Train pg Loss: 2.375991 - Test Loss: 0.630842\n",
      "\n",
      "\n",
      "Epoch 50/750 - Train Cd Loss: 0.141117 - Test Loss: 0.057242\n",
      "Epoch 50/750 - Train pg Loss: 2.388877 - Test Loss: 0.615663\n",
      "\n",
      "\n",
      "Epoch 51/750 - Train Cd Loss: 0.141319 - Test Loss: 0.057248\n",
      "Epoch 51/750 - Train pg Loss: 2.380585 - Test Loss: 0.623304\n",
      "\n",
      "\n",
      "Epoch 52/750 - Train Cd Loss: 0.141445 - Test Loss: 0.057121\n",
      "Epoch 52/750 - Train pg Loss: 2.340266 - Test Loss: 0.617532\n",
      "\n",
      "\n",
      "Epoch 53/750 - Train Cd Loss: 0.141251 - Test Loss: 0.057498\n",
      "Epoch 53/750 - Train pg Loss: 2.357302 - Test Loss: 0.622535\n",
      "\n",
      "\n",
      "Epoch 54/750 - Train Cd Loss: 0.142133 - Test Loss: 0.057053\n",
      "Epoch 54/750 - Train pg Loss: 2.455274 - Test Loss: 0.660856\n",
      "\n",
      "\n",
      "Epoch 55/750 - Train Cd Loss: 0.142093 - Test Loss: 0.057344\n",
      "Epoch 55/750 - Train pg Loss: 2.445081 - Test Loss: 0.654814\n",
      "\n",
      "\n",
      "Epoch 56/750 - Train Cd Loss: 0.140523 - Test Loss: 0.057191\n",
      "Epoch 56/750 - Train pg Loss: 2.448452 - Test Loss: 0.638409\n",
      "\n",
      "\n",
      "Epoch 57/750 - Train Cd Loss: 0.140945 - Test Loss: 0.057339\n",
      "Epoch 57/750 - Train pg Loss: 2.449493 - Test Loss: 0.647699\n",
      "\n",
      "\n",
      "Epoch 58/750 - Train Cd Loss: 0.141217 - Test Loss: 0.057363\n",
      "Epoch 58/750 - Train pg Loss: 2.440110 - Test Loss: 0.644728\n",
      "\n",
      "\n",
      "Epoch 59/750 - Train Cd Loss: 0.142182 - Test Loss: 0.057320\n",
      "Epoch 59/750 - Train pg Loss: 2.541950 - Test Loss: 0.677033\n",
      "\n",
      "\n",
      "Epoch 60/750 - Train Cd Loss: 0.140738 - Test Loss: 0.057366\n",
      "Epoch 60/750 - Train pg Loss: 2.567129 - Test Loss: 0.679702\n",
      "\n",
      "\n",
      "Epoch 61/750 - Train Cd Loss: 0.141303 - Test Loss: 0.057147\n",
      "Epoch 61/750 - Train pg Loss: 2.499755 - Test Loss: 0.660792\n",
      "\n",
      "\n",
      "Epoch 62/750 - Train Cd Loss: 0.141454 - Test Loss: 0.057709\n",
      "Epoch 62/750 - Train pg Loss: 2.453585 - Test Loss: 0.640696\n",
      "\n",
      "\n",
      "Epoch 63/750 - Train Cd Loss: 0.141285 - Test Loss: 0.057378\n",
      "Epoch 63/750 - Train pg Loss: 2.423558 - Test Loss: 0.641363\n",
      "\n",
      "\n",
      "Epoch 64/750 - Train Cd Loss: 0.141041 - Test Loss: 0.057334\n",
      "Epoch 64/750 - Train pg Loss: 2.486708 - Test Loss: 0.667553\n",
      "\n",
      "\n",
      "Epoch 65/750 - Train Cd Loss: 0.141248 - Test Loss: 0.057515\n",
      "Epoch 65/750 - Train pg Loss: 2.522012 - Test Loss: 0.658441\n",
      "\n",
      "\n",
      "Epoch 66/750 - Train Cd Loss: 0.140601 - Test Loss: 0.057070\n",
      "Epoch 66/750 - Train pg Loss: 2.517366 - Test Loss: 0.661975\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/750 - Train Cd Loss: 0.139936 - Test Loss: 0.057385\n",
      "Epoch 67/750 - Train pg Loss: 2.539970 - Test Loss: 0.668586\n",
      "\n",
      "\n",
      "Epoch 68/750 - Train Cd Loss: 0.140566 - Test Loss: 0.057147\n",
      "Epoch 68/750 - Train pg Loss: 2.577468 - Test Loss: 0.679473\n",
      "\n",
      "\n",
      "Epoch 69/750 - Train Cd Loss: 0.140966 - Test Loss: 0.057152\n",
      "Epoch 69/750 - Train pg Loss: 2.574435 - Test Loss: 0.680716\n",
      "\n",
      "\n",
      "Epoch 70/750 - Train Cd Loss: 0.139677 - Test Loss: 0.057301\n",
      "Epoch 70/750 - Train pg Loss: 2.565215 - Test Loss: 0.667753\n",
      "\n",
      "\n",
      "Epoch 71/750 - Train Cd Loss: 0.139538 - Test Loss: 0.057158\n",
      "Epoch 71/750 - Train pg Loss: 2.558360 - Test Loss: 0.684157\n",
      "\n",
      "\n",
      "Epoch 72/750 - Train Cd Loss: 0.141246 - Test Loss: 0.057227\n",
      "Epoch 72/750 - Train pg Loss: 2.542249 - Test Loss: 0.664145\n",
      "\n",
      "\n",
      "Epoch 73/750 - Train Cd Loss: 0.140057 - Test Loss: 0.057418\n",
      "Epoch 73/750 - Train pg Loss: 2.474368 - Test Loss: 0.635003\n",
      "\n",
      "\n",
      "Epoch 74/750 - Train Cd Loss: 0.139268 - Test Loss: 0.057464\n",
      "Epoch 74/750 - Train pg Loss: 2.331331 - Test Loss: 0.591524\n",
      "\n",
      "\n",
      "Epoch 75/750 - Train Cd Loss: 0.139335 - Test Loss: 0.057533\n",
      "Epoch 75/750 - Train pg Loss: 2.215542 - Test Loss: 0.606707\n",
      "\n",
      "\n",
      "Epoch 76/750 - Train Cd Loss: 0.139646 - Test Loss: 0.057380\n",
      "Epoch 76/750 - Train pg Loss: 2.317933 - Test Loss: 0.647895\n",
      "\n",
      "\n",
      "Epoch 77/750 - Train Cd Loss: 0.139598 - Test Loss: 0.057373\n",
      "Epoch 77/750 - Train pg Loss: 2.597856 - Test Loss: 0.693589\n",
      "\n",
      "\n",
      "Epoch 78/750 - Train Cd Loss: 0.139306 - Test Loss: 0.057515\n",
      "Epoch 78/750 - Train pg Loss: 2.617239 - Test Loss: 0.684518\n",
      "\n",
      "\n",
      "Epoch 79/750 - Train Cd Loss: 0.138610 - Test Loss: 0.057237\n",
      "Epoch 79/750 - Train pg Loss: 2.666852 - Test Loss: 0.696002\n",
      "\n",
      "\n",
      "Epoch 80/750 - Train Cd Loss: 0.138437 - Test Loss: 0.057461\n",
      "Epoch 80/750 - Train pg Loss: 2.720294 - Test Loss: 0.688645\n",
      "\n",
      "\n",
      "Epoch 81/750 - Train Cd Loss: 0.139266 - Test Loss: 0.057356\n",
      "Epoch 81/750 - Train pg Loss: 2.619242 - Test Loss: 0.670857\n",
      "\n",
      "\n",
      "Epoch 82/750 - Train Cd Loss: 0.137856 - Test Loss: 0.057322\n",
      "Epoch 82/750 - Train pg Loss: 2.560666 - Test Loss: 0.690156\n",
      "\n",
      "\n",
      "Epoch 83/750 - Train Cd Loss: 0.137874 - Test Loss: 0.057195\n",
      "Epoch 83/750 - Train pg Loss: 2.653434 - Test Loss: 0.678329\n",
      "\n",
      "\n",
      "Epoch 84/750 - Train Cd Loss: 0.137708 - Test Loss: 0.056922\n",
      "Epoch 84/750 - Train pg Loss: 2.646948 - Test Loss: 0.693736\n",
      "\n",
      "\n",
      "Epoch 85/750 - Train Cd Loss: 0.138743 - Test Loss: 0.057633\n",
      "Epoch 85/750 - Train pg Loss: 2.629776 - Test Loss: 0.672756\n",
      "\n",
      "\n",
      "Epoch 86/750 - Train Cd Loss: 0.138259 - Test Loss: 0.056570\n",
      "Epoch 86/750 - Train pg Loss: 2.705594 - Test Loss: 0.728083\n",
      "\n",
      "\n",
      "Epoch 87/750 - Train Cd Loss: 0.139850 - Test Loss: 0.058559\n",
      "Epoch 87/750 - Train pg Loss: 2.711255 - Test Loss: 0.689759\n",
      "\n",
      "\n",
      "Epoch 88/750 - Train Cd Loss: 0.138340 - Test Loss: 0.057174\n",
      "Epoch 88/750 - Train pg Loss: 2.705617 - Test Loss: 0.732643\n",
      "\n",
      "\n",
      "Epoch 89/750 - Train Cd Loss: 0.135752 - Test Loss: 0.057361\n",
      "Epoch 89/750 - Train pg Loss: 2.835798 - Test Loss: 0.740445\n",
      "\n",
      "\n",
      "Epoch 90/750 - Train Cd Loss: 0.137578 - Test Loss: 0.057484\n",
      "Epoch 90/750 - Train pg Loss: 2.875422 - Test Loss: 0.733333\n",
      "\n",
      "\n",
      "Epoch 91/750 - Train Cd Loss: 0.137596 - Test Loss: 0.057750\n",
      "Epoch 91/750 - Train pg Loss: 2.757036 - Test Loss: 0.682078\n",
      "\n",
      "\n",
      "Epoch 92/750 - Train Cd Loss: 0.136610 - Test Loss: 0.057552\n",
      "Epoch 92/750 - Train pg Loss: 2.547489 - Test Loss: 0.663172\n",
      "\n",
      "\n",
      "Epoch 93/750 - Train Cd Loss: 0.136859 - Test Loss: 0.057837\n",
      "Epoch 93/750 - Train pg Loss: 2.755879 - Test Loss: 0.755127\n",
      "\n",
      "\n",
      "Epoch 94/750 - Train Cd Loss: 0.136379 - Test Loss: 0.057485\n",
      "Epoch 94/750 - Train pg Loss: 2.748357 - Test Loss: 0.688549\n",
      "\n",
      "\n",
      "Epoch 95/750 - Train Cd Loss: 0.135328 - Test Loss: 0.057631\n",
      "Epoch 95/750 - Train pg Loss: 2.645195 - Test Loss: 0.676470\n",
      "\n",
      "\n",
      "Epoch 96/750 - Train Cd Loss: 0.133492 - Test Loss: 0.057736\n",
      "Epoch 96/750 - Train pg Loss: 2.578007 - Test Loss: 0.680404\n",
      "\n",
      "\n",
      "Epoch 97/750 - Train Cd Loss: 0.135726 - Test Loss: 0.057640\n",
      "Epoch 97/750 - Train pg Loss: 2.531554 - Test Loss: 0.644519\n",
      "\n",
      "\n",
      "Epoch 98/750 - Train Cd Loss: 0.135989 - Test Loss: 0.057463\n",
      "Epoch 98/750 - Train pg Loss: 2.591209 - Test Loss: 0.653731\n",
      "\n",
      "\n",
      "Epoch 99/750 - Train Cd Loss: 0.135203 - Test Loss: 0.058094\n",
      "Epoch 99/750 - Train pg Loss: 2.425760 - Test Loss: 0.570578\n",
      "\n",
      "\n",
      "Epoch 100/750 - Train Cd Loss: 0.133191 - Test Loss: 0.057846\n",
      "Epoch 100/750 - Train pg Loss: 2.105565 - Test Loss: 0.540302\n",
      "\n",
      "\n",
      "Epoch 101/750 - Train Cd Loss: 0.133712 - Test Loss: 0.058020\n",
      "Epoch 101/750 - Train pg Loss: 1.958447 - Test Loss: 0.474415\n",
      "\n",
      "\n",
      "Epoch 102/750 - Train Cd Loss: 0.133090 - Test Loss: 0.058201\n",
      "Epoch 102/750 - Train pg Loss: 1.783716 - Test Loss: 0.425390\n",
      "\n",
      "\n",
      "Epoch 103/750 - Train Cd Loss: 0.135209 - Test Loss: 0.058145\n",
      "Epoch 103/750 - Train pg Loss: 1.858526 - Test Loss: 0.499969\n",
      "\n",
      "\n",
      "Epoch 104/750 - Train Cd Loss: 0.134106 - Test Loss: 0.058296\n",
      "Epoch 104/750 - Train pg Loss: 1.780936 - Test Loss: 0.477780\n",
      "\n",
      "\n",
      "Epoch 105/750 - Train Cd Loss: 0.131073 - Test Loss: 0.058720\n",
      "Epoch 105/750 - Train pg Loss: 1.956177 - Test Loss: 0.503479\n",
      "\n",
      "\n",
      "Epoch 106/750 - Train Cd Loss: 0.132403 - Test Loss: 0.058623\n",
      "Epoch 106/750 - Train pg Loss: 1.889222 - Test Loss: 0.484945\n",
      "\n",
      "\n",
      "Epoch 107/750 - Train Cd Loss: 0.133083 - Test Loss: 0.058489\n",
      "Epoch 107/750 - Train pg Loss: 1.765636 - Test Loss: 0.473168\n",
      "\n",
      "\n",
      "Epoch 108/750 - Train Cd Loss: 0.130505 - Test Loss: 0.057963\n",
      "Epoch 108/750 - Train pg Loss: 1.808416 - Test Loss: 0.468866\n",
      "\n",
      "\n",
      "Epoch 109/750 - Train Cd Loss: 0.133955 - Test Loss: 0.058590\n",
      "Epoch 109/750 - Train pg Loss: 2.016703 - Test Loss: 0.514091\n",
      "\n",
      "\n",
      "Epoch 110/750 - Train Cd Loss: 0.129551 - Test Loss: 0.058046\n",
      "Epoch 110/750 - Train pg Loss: 1.992740 - Test Loss: 0.505273\n",
      "\n",
      "\n",
      "Epoch 111/750 - Train Cd Loss: 0.130102 - Test Loss: 0.058293\n",
      "Epoch 111/750 - Train pg Loss: 1.951610 - Test Loss: 0.476413\n",
      "\n",
      "\n",
      "Epoch 112/750 - Train Cd Loss: 0.128963 - Test Loss: 0.058208\n",
      "Epoch 112/750 - Train pg Loss: 2.075305 - Test Loss: 0.576810\n",
      "\n",
      "\n",
      "Epoch 113/750 - Train Cd Loss: 0.130451 - Test Loss: 0.057869\n",
      "Epoch 113/750 - Train pg Loss: 2.181880 - Test Loss: 0.541162\n",
      "\n",
      "\n",
      "Epoch 114/750 - Train Cd Loss: 0.128489 - Test Loss: 0.057790\n",
      "Epoch 114/750 - Train pg Loss: 2.189018 - Test Loss: 0.539094\n",
      "\n",
      "\n",
      "Epoch 115/750 - Train Cd Loss: 0.127837 - Test Loss: 0.058637\n",
      "Epoch 115/750 - Train pg Loss: 2.413950 - Test Loss: 0.593080\n",
      "\n",
      "\n",
      "Epoch 116/750 - Train Cd Loss: 0.131387 - Test Loss: 0.058312\n",
      "Epoch 116/750 - Train pg Loss: 2.314853 - Test Loss: 0.567776\n",
      "\n",
      "\n",
      "Epoch 117/750 - Train Cd Loss: 0.125418 - Test Loss: 0.059153\n",
      "Epoch 117/750 - Train pg Loss: 2.493889 - Test Loss: 0.623787\n",
      "\n",
      "\n",
      "Epoch 118/750 - Train Cd Loss: 0.126331 - Test Loss: 0.058629\n",
      "Epoch 118/750 - Train pg Loss: 2.595891 - Test Loss: 0.654832\n",
      "\n",
      "\n",
      "Epoch 119/750 - Train Cd Loss: 0.124925 - Test Loss: 0.057278\n",
      "Epoch 119/750 - Train pg Loss: 3.089248 - Test Loss: 0.739451\n",
      "\n",
      "\n",
      "Epoch 120/750 - Train Cd Loss: 0.127584 - Test Loss: 0.059099\n",
      "Epoch 120/750 - Train pg Loss: 2.837364 - Test Loss: 0.589387\n",
      "\n",
      "\n",
      "Epoch 121/750 - Train Cd Loss: 0.126543 - Test Loss: 0.057960\n",
      "Epoch 121/750 - Train pg Loss: 2.554421 - Test Loss: 0.701543\n",
      "\n",
      "\n",
      "Epoch 122/750 - Train Cd Loss: 0.132169 - Test Loss: 0.057760\n",
      "Epoch 122/750 - Train pg Loss: 2.818834 - Test Loss: 0.726737\n",
      "\n",
      "\n",
      "Epoch 123/750 - Train Cd Loss: 0.125054 - Test Loss: 0.057923\n",
      "Epoch 123/750 - Train pg Loss: 3.581141 - Test Loss: 1.014133\n",
      "\n",
      "\n",
      "Epoch 124/750 - Train Cd Loss: 0.123076 - Test Loss: 0.057761\n",
      "Epoch 124/750 - Train pg Loss: 4.334400 - Test Loss: 1.023348\n",
      "\n",
      "\n",
      "Epoch 125/750 - Train Cd Loss: 0.122690 - Test Loss: 0.057963\n",
      "Epoch 125/750 - Train pg Loss: 3.498294 - Test Loss: 0.724367\n",
      "\n",
      "\n",
      "Epoch 126/750 - Train Cd Loss: 0.128832 - Test Loss: 0.058961\n",
      "Epoch 126/750 - Train pg Loss: 2.660439 - Test Loss: 0.625912\n",
      "\n",
      "\n",
      "Epoch 127/750 - Train Cd Loss: 0.130754 - Test Loss: 0.058271\n",
      "Epoch 127/750 - Train pg Loss: 2.883594 - Test Loss: 0.744276\n",
      "\n",
      "\n",
      "Epoch 128/750 - Train Cd Loss: 0.119143 - Test Loss: 0.057728\n",
      "Epoch 128/750 - Train pg Loss: 3.368901 - Test Loss: 0.847075\n",
      "\n",
      "\n",
      "Epoch 129/750 - Train Cd Loss: 0.123448 - Test Loss: 0.057747\n",
      "Epoch 129/750 - Train pg Loss: 3.963205 - Test Loss: 0.898839\n",
      "\n",
      "\n",
      "Epoch 130/750 - Train Cd Loss: 0.118125 - Test Loss: 0.058697\n",
      "Epoch 130/750 - Train pg Loss: 3.270225 - Test Loss: 0.529477\n",
      "\n",
      "\n",
      "Epoch 131/750 - Train Cd Loss: 0.149322 - Test Loss: 0.057865\n",
      "Epoch 131/750 - Train pg Loss: 3.385143 - Test Loss: 1.025391\n",
      "\n",
      "\n",
      "Epoch 132/750 - Train Cd Loss: 0.125243 - Test Loss: 0.056978\n",
      "Epoch 132/750 - Train pg Loss: 4.996156 - Test Loss: 1.232263\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/750 - Train Cd Loss: 0.122559 - Test Loss: 0.057680\n",
      "Epoch 133/750 - Train pg Loss: 4.635199 - Test Loss: 1.009755\n",
      "\n",
      "\n",
      "Epoch 134/750 - Train Cd Loss: 0.122302 - Test Loss: 0.057153\n",
      "Epoch 134/750 - Train pg Loss: 4.023293 - Test Loss: 0.947991\n",
      "\n",
      "\n",
      "Epoch 135/750 - Train Cd Loss: 0.119968 - Test Loss: 0.057624\n",
      "Epoch 135/750 - Train pg Loss: 3.799832 - Test Loss: 0.816514\n",
      "\n",
      "\n",
      "Epoch 136/750 - Train Cd Loss: 0.123088 - Test Loss: 0.058050\n",
      "Epoch 136/750 - Train pg Loss: 3.127391 - Test Loss: 0.648466\n",
      "\n",
      "\n",
      "Epoch 137/750 - Train Cd Loss: 0.118529 - Test Loss: 0.058670\n",
      "Epoch 137/750 - Train pg Loss: 3.030884 - Test Loss: 0.698134\n",
      "\n",
      "\n",
      "Epoch 138/750 - Train Cd Loss: 0.117789 - Test Loss: 0.059050\n",
      "Epoch 138/750 - Train pg Loss: 3.078278 - Test Loss: 0.670819\n",
      "\n",
      "\n",
      "Epoch 139/750 - Train Cd Loss: 0.119726 - Test Loss: 0.059091\n",
      "Epoch 139/750 - Train pg Loss: 2.756469 - Test Loss: 0.527843\n",
      "\n",
      "\n",
      "Epoch 140/750 - Train Cd Loss: 0.121408 - Test Loss: 0.059930\n",
      "Epoch 140/750 - Train pg Loss: 3.048969 - Test Loss: 0.748932\n",
      "\n",
      "\n",
      "Epoch 141/750 - Train Cd Loss: 0.129518 - Test Loss: 0.056212\n",
      "Epoch 141/750 - Train pg Loss: 5.596000 - Test Loss: 1.546749\n",
      "\n",
      "\n",
      "Epoch 142/750 - Train Cd Loss: 0.119084 - Test Loss: 0.056236\n",
      "Epoch 142/750 - Train pg Loss: 6.634199 - Test Loss: 1.494224\n",
      "\n",
      "\n",
      "Epoch 143/750 - Train Cd Loss: 0.120016 - Test Loss: 0.056701\n",
      "Epoch 143/750 - Train pg Loss: 5.828011 - Test Loss: 1.194278\n",
      "\n",
      "\n",
      "Epoch 144/750 - Train Cd Loss: 0.117581 - Test Loss: 0.057286\n",
      "Epoch 144/750 - Train pg Loss: 4.463695 - Test Loss: 0.985336\n",
      "\n",
      "\n",
      "Epoch 145/750 - Train Cd Loss: 0.112486 - Test Loss: 0.057841\n",
      "Epoch 145/750 - Train pg Loss: 3.999563 - Test Loss: 0.962215\n",
      "\n",
      "\n",
      "Epoch 146/750 - Train Cd Loss: 0.114179 - Test Loss: 0.057351\n",
      "Epoch 146/750 - Train pg Loss: 4.571491 - Test Loss: 0.965713\n",
      "\n",
      "\n",
      "Epoch 147/750 - Train Cd Loss: 0.118167 - Test Loss: 0.057867\n",
      "Epoch 147/750 - Train pg Loss: 4.038746 - Test Loss: 0.814051\n",
      "\n",
      "\n",
      "Epoch 148/750 - Train Cd Loss: 0.112979 - Test Loss: 0.058326\n",
      "Epoch 148/750 - Train pg Loss: 3.997536 - Test Loss: 0.795265\n",
      "\n",
      "\n",
      "Epoch 149/750 - Train Cd Loss: 0.110913 - Test Loss: 0.058040\n",
      "Epoch 149/750 - Train pg Loss: 4.333622 - Test Loss: 0.836888\n",
      "\n",
      "\n",
      "Epoch 150/750 - Train Cd Loss: 0.130946 - Test Loss: 0.056996\n",
      "Epoch 150/750 - Train pg Loss: 5.021373 - Test Loss: 1.097539\n",
      "\n",
      "\n",
      "Epoch 151/750 - Train Cd Loss: 0.111018 - Test Loss: 0.057267\n",
      "Epoch 151/750 - Train pg Loss: 4.743803 - Test Loss: 0.957372\n",
      "\n",
      "\n",
      "Epoch 152/750 - Train Cd Loss: 0.113606 - Test Loss: 0.057042\n",
      "Epoch 152/750 - Train pg Loss: 4.133244 - Test Loss: 0.890371\n",
      "\n",
      "\n",
      "Epoch 153/750 - Train Cd Loss: 0.111621 - Test Loss: 0.058889\n",
      "Epoch 153/750 - Train pg Loss: 3.456433 - Test Loss: 0.603173\n",
      "\n",
      "\n",
      "Epoch 154/750 - Train Cd Loss: 0.118359 - Test Loss: 0.060059\n",
      "Epoch 154/750 - Train pg Loss: 3.291477 - Test Loss: 0.644602\n",
      "\n",
      "\n",
      "Epoch 155/750 - Train Cd Loss: 0.106561 - Test Loss: 0.057801\n",
      "Epoch 155/750 - Train pg Loss: 3.483128 - Test Loss: 0.729285\n",
      "\n",
      "\n",
      "Epoch 156/750 - Train Cd Loss: 0.126134 - Test Loss: 0.057754\n",
      "Epoch 156/750 - Train pg Loss: 4.472325 - Test Loss: 0.740947\n",
      "\n",
      "\n",
      "Epoch 157/750 - Train Cd Loss: 0.111663 - Test Loss: 0.056557\n",
      "Epoch 157/750 - Train pg Loss: 4.636787 - Test Loss: 1.086059\n",
      "\n",
      "\n",
      "Epoch 158/750 - Train Cd Loss: 0.112341 - Test Loss: 0.057607\n",
      "Epoch 158/750 - Train pg Loss: 4.587789 - Test Loss: 0.911507\n",
      "\n",
      "\n",
      "Epoch 159/750 - Train Cd Loss: 0.123195 - Test Loss: 0.057037\n",
      "Epoch 159/750 - Train pg Loss: 4.476041 - Test Loss: 0.870205\n",
      "\n",
      "\n",
      "Epoch 160/750 - Train Cd Loss: 0.107003 - Test Loss: 0.057235\n",
      "Epoch 160/750 - Train pg Loss: 4.916364 - Test Loss: 1.020568\n",
      "\n",
      "\n",
      "Epoch 161/750 - Train Cd Loss: 0.117828 - Test Loss: 0.056262\n",
      "Epoch 161/750 - Train pg Loss: 4.895858 - Test Loss: 0.952115\n",
      "\n",
      "\n",
      "Epoch 162/750 - Train Cd Loss: 0.111973 - Test Loss: 0.056835\n",
      "Epoch 162/750 - Train pg Loss: 5.395739 - Test Loss: 1.269032\n",
      "\n",
      "\n",
      "Epoch 163/750 - Train Cd Loss: 0.113164 - Test Loss: 0.057976\n",
      "Epoch 163/750 - Train pg Loss: 4.984303 - Test Loss: 0.839185\n",
      "\n",
      "\n",
      "Epoch 164/750 - Train Cd Loss: 0.102980 - Test Loss: 0.058967\n",
      "Epoch 164/750 - Train pg Loss: 3.171215 - Test Loss: 0.602305\n",
      "\n",
      "\n",
      "Epoch 165/750 - Train Cd Loss: 0.111761 - Test Loss: 0.059430\n",
      "Epoch 165/750 - Train pg Loss: 3.425719 - Test Loss: 0.744034\n",
      "\n",
      "\n",
      "Epoch 166/750 - Train Cd Loss: 0.107317 - Test Loss: 0.056158\n",
      "Epoch 166/750 - Train pg Loss: 4.341661 - Test Loss: 1.010475\n",
      "\n",
      "\n",
      "Epoch 167/750 - Train Cd Loss: 0.112085 - Test Loss: 0.057119\n",
      "Epoch 167/750 - Train pg Loss: 4.559946 - Test Loss: 0.909222\n",
      "\n",
      "\n",
      "Epoch 168/750 - Train Cd Loss: 0.109402 - Test Loss: 0.056696\n",
      "Epoch 168/750 - Train pg Loss: 4.808849 - Test Loss: 0.857901\n",
      "\n",
      "\n",
      "Epoch 169/750 - Train Cd Loss: 0.117165 - Test Loss: 0.055683\n",
      "Epoch 169/750 - Train pg Loss: 6.509567 - Test Loss: 1.344801\n",
      "\n",
      "\n",
      "Epoch 170/750 - Train Cd Loss: 0.107615 - Test Loss: 0.055458\n",
      "Epoch 170/750 - Train pg Loss: 6.628629 - Test Loss: 1.076199\n",
      "\n",
      "\n",
      "Epoch 171/750 - Train Cd Loss: 0.108995 - Test Loss: 0.055461\n",
      "Epoch 171/750 - Train pg Loss: 5.638422 - Test Loss: 1.126004\n",
      "\n",
      "\n",
      "Epoch 172/750 - Train Cd Loss: 0.110195 - Test Loss: 0.056557\n",
      "Epoch 172/750 - Train pg Loss: 5.319530 - Test Loss: 1.283444\n",
      "\n",
      "\n",
      "Epoch 173/750 - Train Cd Loss: 0.107793 - Test Loss: 0.056705\n",
      "Epoch 173/750 - Train pg Loss: 5.116873 - Test Loss: 1.020643\n",
      "\n",
      "\n",
      "Epoch 174/750 - Train Cd Loss: 0.106232 - Test Loss: 0.059098\n",
      "Epoch 174/750 - Train pg Loss: 4.504422 - Test Loss: 0.872236\n",
      "\n",
      "\n",
      "Epoch 175/750 - Train Cd Loss: 0.101525 - Test Loss: 0.057655\n",
      "Epoch 175/750 - Train pg Loss: 4.119667 - Test Loss: 0.764306\n",
      "\n",
      "\n",
      "Epoch 176/750 - Train Cd Loss: 0.116581 - Test Loss: 0.056541\n",
      "Epoch 176/750 - Train pg Loss: 4.852131 - Test Loss: 1.000613\n",
      "\n",
      "\n",
      "Epoch 177/750 - Train Cd Loss: 0.126015 - Test Loss: 0.055690\n",
      "Epoch 177/750 - Train pg Loss: 5.781637 - Test Loss: 1.206446\n",
      "\n",
      "\n",
      "Epoch 178/750 - Train Cd Loss: 0.105221 - Test Loss: 0.055404\n",
      "Epoch 178/750 - Train pg Loss: 5.526052 - Test Loss: 1.018030\n",
      "\n",
      "\n",
      "Epoch 179/750 - Train Cd Loss: 0.106000 - Test Loss: 0.056083\n",
      "Epoch 179/750 - Train pg Loss: 4.854616 - Test Loss: 0.831969\n",
      "\n",
      "\n",
      "Epoch 180/750 - Train Cd Loss: 0.120020 - Test Loss: 0.053928\n",
      "Epoch 180/750 - Train pg Loss: 5.534146 - Test Loss: 1.109044\n",
      "\n",
      "\n",
      "Epoch 181/750 - Train Cd Loss: 0.106643 - Test Loss: 0.056077\n",
      "Epoch 181/750 - Train pg Loss: 5.935356 - Test Loss: 1.046902\n",
      "\n",
      "\n",
      "Epoch 182/750 - Train Cd Loss: 0.109604 - Test Loss: 0.056185\n",
      "Epoch 182/750 - Train pg Loss: 4.551069 - Test Loss: 0.977277\n",
      "\n",
      "\n",
      "Epoch 183/750 - Train Cd Loss: 0.109696 - Test Loss: 0.054818\n",
      "Epoch 183/750 - Train pg Loss: 4.470336 - Test Loss: 0.833808\n",
      "\n",
      "\n",
      "Epoch 184/750 - Train Cd Loss: 0.108850 - Test Loss: 0.057184\n",
      "Epoch 184/750 - Train pg Loss: 4.166449 - Test Loss: 0.757661\n",
      "\n",
      "\n",
      "Epoch 185/750 - Train Cd Loss: 0.099373 - Test Loss: 0.056505\n",
      "Epoch 185/750 - Train pg Loss: 3.686613 - Test Loss: 0.663566\n",
      "\n",
      "\n",
      "Epoch 186/750 - Train Cd Loss: 0.114190 - Test Loss: 0.057406\n",
      "Epoch 186/750 - Train pg Loss: 3.781650 - Test Loss: 0.738826\n",
      "\n",
      "\n",
      "Epoch 187/750 - Train Cd Loss: 0.101907 - Test Loss: 0.055184\n",
      "Epoch 187/750 - Train pg Loss: 4.936981 - Test Loss: 0.969665\n",
      "\n",
      "\n",
      "Epoch 188/750 - Train Cd Loss: 0.103264 - Test Loss: 0.055929\n",
      "Epoch 188/750 - Train pg Loss: 5.357286 - Test Loss: 0.710030\n",
      "\n",
      "\n",
      "Epoch 189/750 - Train Cd Loss: 0.114469 - Test Loss: 0.055827\n",
      "Epoch 189/750 - Train pg Loss: 6.057405 - Test Loss: 1.119598\n",
      "\n",
      "\n",
      "Epoch 190/750 - Train Cd Loss: 0.110331 - Test Loss: 0.054155\n",
      "Epoch 190/750 - Train pg Loss: 6.155419 - Test Loss: 1.273418\n",
      "\n",
      "\n",
      "Epoch 191/750 - Train Cd Loss: 0.106307 - Test Loss: 0.056674\n",
      "Epoch 191/750 - Train pg Loss: 6.127968 - Test Loss: 1.116188\n",
      "\n",
      "\n",
      "Epoch 192/750 - Train Cd Loss: 0.102748 - Test Loss: 0.057841\n",
      "Epoch 192/750 - Train pg Loss: 5.113618 - Test Loss: 1.002334\n",
      "\n",
      "\n",
      "Epoch 193/750 - Train Cd Loss: 0.097538 - Test Loss: 0.055029\n",
      "Epoch 193/750 - Train pg Loss: 4.953600 - Test Loss: 1.050846\n",
      "\n",
      "\n",
      "Epoch 194/750 - Train Cd Loss: 0.103449 - Test Loss: 0.055961\n",
      "Epoch 194/750 - Train pg Loss: 5.228581 - Test Loss: 0.883233\n",
      "\n",
      "\n",
      "Epoch 195/750 - Train Cd Loss: 0.098539 - Test Loss: 0.057388\n",
      "Epoch 195/750 - Train pg Loss: 4.096441 - Test Loss: 0.751424\n",
      "\n",
      "\n",
      "Epoch 196/750 - Train Cd Loss: 0.101976 - Test Loss: 0.053683\n",
      "Epoch 196/750 - Train pg Loss: 5.745253 - Test Loss: 1.140417\n",
      "\n",
      "\n",
      "Epoch 197/750 - Train Cd Loss: 0.106075 - Test Loss: 0.057459\n",
      "Epoch 197/750 - Train pg Loss: 6.751639 - Test Loss: 1.123686\n",
      "\n",
      "\n",
      "Epoch 198/750 - Train Cd Loss: 0.100982 - Test Loss: 0.058121\n",
      "Epoch 198/750 - Train pg Loss: 5.513456 - Test Loss: 0.915936\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/750 - Train Cd Loss: 0.120318 - Test Loss: 0.055474\n",
      "Epoch 199/750 - Train pg Loss: 6.477032 - Test Loss: 1.169965\n",
      "\n",
      "\n",
      "Epoch 200/750 - Train Cd Loss: 0.109779 - Test Loss: 0.056075\n",
      "Epoch 200/750 - Train pg Loss: 5.716607 - Test Loss: 1.029623\n",
      "\n",
      "\n",
      "Epoch 201/750 - Train Cd Loss: 0.097727 - Test Loss: 0.057357\n",
      "Epoch 201/750 - Train pg Loss: 5.570862 - Test Loss: 1.024270\n",
      "\n",
      "\n",
      "Epoch 202/750 - Train Cd Loss: 0.101537 - Test Loss: 0.053108\n",
      "Epoch 202/750 - Train pg Loss: 7.351127 - Test Loss: 1.393947\n",
      "\n",
      "\n",
      "Epoch 203/750 - Train Cd Loss: 0.100263 - Test Loss: 0.052501\n",
      "Epoch 203/750 - Train pg Loss: 6.718142 - Test Loss: 1.290905\n",
      "\n",
      "\n",
      "Epoch 204/750 - Train Cd Loss: 0.097102 - Test Loss: 0.055006\n",
      "Epoch 204/750 - Train pg Loss: 6.492934 - Test Loss: 1.001147\n",
      "\n",
      "\n",
      "Epoch 205/750 - Train Cd Loss: 0.103939 - Test Loss: 0.056976\n",
      "Epoch 205/750 - Train pg Loss: 4.108537 - Test Loss: 0.811134\n",
      "\n",
      "\n",
      "Epoch 206/750 - Train Cd Loss: 0.110393 - Test Loss: 0.053320\n",
      "Epoch 206/750 - Train pg Loss: 6.407240 - Test Loss: 1.055371\n",
      "\n",
      "\n",
      "Epoch 207/750 - Train Cd Loss: 0.098803 - Test Loss: 0.055507\n",
      "Epoch 207/750 - Train pg Loss: 5.349252 - Test Loss: 1.035849\n",
      "\n",
      "\n",
      "Epoch 208/750 - Train Cd Loss: 0.094300 - Test Loss: 0.052203\n",
      "Epoch 208/750 - Train pg Loss: 5.951203 - Test Loss: 1.026729\n",
      "\n",
      "\n",
      "Epoch 209/750 - Train Cd Loss: 0.098783 - Test Loss: 0.053079\n",
      "Epoch 209/750 - Train pg Loss: 6.183754 - Test Loss: 1.225585\n",
      "\n",
      "\n",
      "Epoch 210/750 - Train Cd Loss: 0.094298 - Test Loss: 0.055289\n",
      "Epoch 210/750 - Train pg Loss: 6.250668 - Test Loss: 1.053972\n",
      "\n",
      "\n",
      "Epoch 211/750 - Train Cd Loss: 0.095320 - Test Loss: 0.056018\n",
      "Epoch 211/750 - Train pg Loss: 5.113205 - Test Loss: 0.835047\n",
      "\n",
      "\n",
      "Epoch 212/750 - Train Cd Loss: 0.108346 - Test Loss: 0.053108\n",
      "Epoch 212/750 - Train pg Loss: 5.076882 - Test Loss: 0.931607\n",
      "\n",
      "\n",
      "Epoch 213/750 - Train Cd Loss: 0.100100 - Test Loss: 0.053843\n",
      "Epoch 213/750 - Train pg Loss: 6.073744 - Test Loss: 1.207917\n",
      "\n",
      "\n",
      "Epoch 214/750 - Train Cd Loss: 0.099671 - Test Loss: 0.055086\n",
      "Epoch 214/750 - Train pg Loss: 5.703010 - Test Loss: 0.949139\n",
      "\n",
      "\n",
      "Epoch 215/750 - Train Cd Loss: 0.098145 - Test Loss: 0.057124\n",
      "Epoch 215/750 - Train pg Loss: 5.513085 - Test Loss: 0.822337\n",
      "\n",
      "\n",
      "Epoch 216/750 - Train Cd Loss: 0.108509 - Test Loss: 0.055020\n",
      "Epoch 216/750 - Train pg Loss: 4.193702 - Test Loss: 0.820000\n",
      "\n",
      "\n",
      "Epoch 217/750 - Train Cd Loss: 0.099513 - Test Loss: 0.053632\n",
      "Epoch 217/750 - Train pg Loss: 5.505103 - Test Loss: 1.225255\n",
      "\n",
      "\n",
      "Epoch 218/750 - Train Cd Loss: 0.094904 - Test Loss: 0.057222\n",
      "Epoch 218/750 - Train pg Loss: 6.365983 - Test Loss: 0.961075\n",
      "\n",
      "\n",
      "Epoch 219/750 - Train Cd Loss: 0.100871 - Test Loss: 0.054355\n",
      "Epoch 219/750 - Train pg Loss: 6.015505 - Test Loss: 1.112980\n",
      "\n",
      "\n",
      "Epoch 220/750 - Train Cd Loss: 0.098242 - Test Loss: 0.051361\n",
      "Epoch 220/750 - Train pg Loss: 6.291469 - Test Loss: 1.334196\n",
      "\n",
      "\n",
      "Epoch 221/750 - Train Cd Loss: 0.111397 - Test Loss: 0.051715\n",
      "Epoch 221/750 - Train pg Loss: 8.405757 - Test Loss: 1.661957\n",
      "\n",
      "\n",
      "Epoch 222/750 - Train Cd Loss: 0.095039 - Test Loss: 0.053783\n",
      "Epoch 222/750 - Train pg Loss: 8.613508 - Test Loss: 1.698337\n",
      "\n",
      "\n",
      "Epoch 223/750 - Train Cd Loss: 0.096771 - Test Loss: 0.052310\n",
      "Epoch 223/750 - Train pg Loss: 7.155281 - Test Loss: 1.149145\n",
      "\n",
      "\n",
      "Epoch 224/750 - Train Cd Loss: 0.122498 - Test Loss: 0.053587\n",
      "Epoch 224/750 - Train pg Loss: 5.625109 - Test Loss: 1.021123\n",
      "\n",
      "\n",
      "Epoch 225/750 - Train Cd Loss: 0.095708 - Test Loss: 0.054719\n",
      "Epoch 225/750 - Train pg Loss: 5.827765 - Test Loss: 1.140129\n",
      "\n",
      "\n",
      "Epoch 226/750 - Train Cd Loss: 0.106911 - Test Loss: 0.053806\n",
      "Epoch 226/750 - Train pg Loss: 6.718431 - Test Loss: 1.317176\n",
      "\n",
      "\n",
      "Epoch 227/750 - Train Cd Loss: 0.093745 - Test Loss: 0.054143\n",
      "Epoch 227/750 - Train pg Loss: 6.587034 - Test Loss: 1.056529\n",
      "\n",
      "\n",
      "Epoch 228/750 - Train Cd Loss: 0.108421 - Test Loss: 0.054584\n",
      "Epoch 228/750 - Train pg Loss: 7.033236 - Test Loss: 1.242630\n",
      "\n",
      "\n",
      "Epoch 229/750 - Train Cd Loss: 0.098589 - Test Loss: 0.053607\n",
      "Epoch 229/750 - Train pg Loss: 6.339639 - Test Loss: 1.270090\n",
      "\n",
      "\n",
      "Epoch 230/750 - Train Cd Loss: 0.095837 - Test Loss: 0.054277\n",
      "Epoch 230/750 - Train pg Loss: 6.389388 - Test Loss: 1.290152\n",
      "\n",
      "\n",
      "Epoch 231/750 - Train Cd Loss: 0.097570 - Test Loss: 0.056401\n",
      "Epoch 231/750 - Train pg Loss: 6.200236 - Test Loss: 0.958829\n",
      "\n",
      "\n",
      "Epoch 232/750 - Train Cd Loss: 0.101411 - Test Loss: 0.055501\n",
      "Epoch 232/750 - Train pg Loss: 6.345608 - Test Loss: 1.265772\n",
      "\n",
      "\n",
      "Epoch 233/750 - Train Cd Loss: 0.094490 - Test Loss: 0.055089\n",
      "Epoch 233/750 - Train pg Loss: 6.565594 - Test Loss: 1.111301\n",
      "\n",
      "\n",
      "Epoch 234/750 - Train Cd Loss: 0.101164 - Test Loss: 0.054979\n",
      "Epoch 234/750 - Train pg Loss: 5.646559 - Test Loss: 1.042268\n",
      "\n",
      "\n",
      "Epoch 235/750 - Train Cd Loss: 0.098475 - Test Loss: 0.054251\n",
      "Epoch 235/750 - Train pg Loss: 6.620766 - Test Loss: 1.333938\n",
      "\n",
      "\n",
      "Epoch 236/750 - Train Cd Loss: 0.109748 - Test Loss: 0.052237\n",
      "Epoch 236/750 - Train pg Loss: 8.212067 - Test Loss: 1.264356\n",
      "\n",
      "\n",
      "Epoch 237/750 - Train Cd Loss: 0.088673 - Test Loss: 0.053629\n",
      "Epoch 237/750 - Train pg Loss: 7.056078 - Test Loss: 1.287921\n",
      "\n",
      "\n",
      "Epoch 238/750 - Train Cd Loss: 0.095286 - Test Loss: 0.053809\n",
      "Epoch 238/750 - Train pg Loss: 7.877239 - Test Loss: 1.534574\n",
      "\n",
      "\n",
      "Epoch 239/750 - Train Cd Loss: 0.095983 - Test Loss: 0.053990\n",
      "Epoch 239/750 - Train pg Loss: 8.247385 - Test Loss: 1.480766\n",
      "\n",
      "\n",
      "Epoch 240/750 - Train Cd Loss: 0.095554 - Test Loss: 0.054584\n",
      "Epoch 240/750 - Train pg Loss: 8.133892 - Test Loss: 1.163399\n",
      "\n",
      "\n",
      "Epoch 241/750 - Train Cd Loss: 0.096204 - Test Loss: 0.053976\n",
      "Epoch 241/750 - Train pg Loss: 6.332615 - Test Loss: 0.900795\n",
      "\n",
      "\n",
      "Epoch 242/750 - Train Cd Loss: 0.105335 - Test Loss: 0.057502\n",
      "Epoch 242/750 - Train pg Loss: 6.435275 - Test Loss: 0.855472\n",
      "\n",
      "\n",
      "Epoch 243/750 - Train Cd Loss: 0.090908 - Test Loss: 0.051764\n",
      "Epoch 243/750 - Train pg Loss: 5.684410 - Test Loss: 1.299153\n",
      "\n",
      "\n",
      "Epoch 244/750 - Train Cd Loss: 0.105791 - Test Loss: 0.052790\n",
      "Epoch 244/750 - Train pg Loss: 8.460331 - Test Loss: 1.455267\n",
      "\n",
      "\n",
      "Epoch 245/750 - Train Cd Loss: 0.089249 - Test Loss: 0.052809\n",
      "Epoch 245/750 - Train pg Loss: 6.783988 - Test Loss: 1.134062\n",
      "\n",
      "\n",
      "Epoch 246/750 - Train Cd Loss: 0.096091 - Test Loss: 0.053784\n",
      "Epoch 246/750 - Train pg Loss: 6.449574 - Test Loss: 1.183398\n",
      "\n",
      "\n",
      "Epoch 247/750 - Train Cd Loss: 0.106741 - Test Loss: 0.051960\n",
      "Epoch 247/750 - Train pg Loss: 7.507930 - Test Loss: 1.554546\n",
      "\n",
      "\n",
      "Epoch 248/750 - Train Cd Loss: 0.096126 - Test Loss: 0.051989\n",
      "Epoch 248/750 - Train pg Loss: 8.101108 - Test Loss: 1.628277\n",
      "\n",
      "\n",
      "Epoch 249/750 - Train Cd Loss: 0.094632 - Test Loss: 0.053000\n",
      "Epoch 249/750 - Train pg Loss: 8.037405 - Test Loss: 1.400944\n",
      "\n",
      "\n",
      "Epoch 250/750 - Train Cd Loss: 0.094043 - Test Loss: 0.052233\n",
      "Epoch 250/750 - Train pg Loss: 6.855060 - Test Loss: 1.205776\n",
      "\n",
      "\n",
      "Epoch 251/750 - Train Cd Loss: 0.107269 - Test Loss: 0.052274\n",
      "Epoch 251/750 - Train pg Loss: 8.540339 - Test Loss: 1.686318\n",
      "\n",
      "\n",
      "Epoch 252/750 - Train Cd Loss: 0.097404 - Test Loss: 0.053215\n",
      "Epoch 252/750 - Train pg Loss: 9.192684 - Test Loss: 1.785130\n",
      "\n",
      "\n",
      "Epoch 253/750 - Train Cd Loss: 0.089579 - Test Loss: 0.053326\n",
      "Epoch 253/750 - Train pg Loss: 8.382280 - Test Loss: 1.296950\n",
      "\n",
      "\n",
      "Epoch 254/750 - Train Cd Loss: 0.108228 - Test Loss: 0.052402\n",
      "Epoch 254/750 - Train pg Loss: 8.466410 - Test Loss: 1.348557\n",
      "\n",
      "\n",
      "Epoch 255/750 - Train Cd Loss: 0.092604 - Test Loss: 0.054893\n",
      "Epoch 255/750 - Train pg Loss: 8.793988 - Test Loss: 1.559989\n",
      "\n",
      "\n",
      "Epoch 256/750 - Train Cd Loss: 0.096220 - Test Loss: 0.054459\n",
      "Epoch 256/750 - Train pg Loss: 7.781782 - Test Loss: 1.407173\n",
      "\n",
      "\n",
      "Epoch 257/750 - Train Cd Loss: 0.085223 - Test Loss: 0.053597\n",
      "Epoch 257/750 - Train pg Loss: 7.308954 - Test Loss: 1.490443\n",
      "\n",
      "\n",
      "Epoch 258/750 - Train Cd Loss: 0.094720 - Test Loss: 0.054341\n",
      "Epoch 258/750 - Train pg Loss: 8.262353 - Test Loss: 1.475939\n",
      "\n",
      "\n",
      "Epoch 259/750 - Train Cd Loss: 0.099192 - Test Loss: 0.051855\n",
      "Epoch 259/750 - Train pg Loss: 8.684333 - Test Loss: 1.653483\n",
      "\n",
      "\n",
      "Epoch 260/750 - Train Cd Loss: 0.093128 - Test Loss: 0.049876\n",
      "Epoch 260/750 - Train pg Loss: 9.711420 - Test Loss: 1.945405\n",
      "\n",
      "\n",
      "Epoch 261/750 - Train Cd Loss: 0.093437 - Test Loss: 0.049683\n",
      "Epoch 261/750 - Train pg Loss: 9.749641 - Test Loss: 1.637820\n",
      "\n",
      "\n",
      "Epoch 262/750 - Train Cd Loss: 0.091638 - Test Loss: 0.052020\n",
      "Epoch 262/750 - Train pg Loss: 7.503701 - Test Loss: 1.285509\n",
      "\n",
      "\n",
      "Epoch 263/750 - Train Cd Loss: 0.096528 - Test Loss: 0.056267\n",
      "Epoch 263/750 - Train pg Loss: 7.662242 - Test Loss: 1.194267\n",
      "\n",
      "\n",
      "Epoch 264/750 - Train Cd Loss: 0.090849 - Test Loss: 0.054525\n",
      "Epoch 264/750 - Train pg Loss: 7.769004 - Test Loss: 1.635688\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 265/750 - Train Cd Loss: 0.086622 - Test Loss: 0.052102\n",
      "Epoch 265/750 - Train pg Loss: 9.176568 - Test Loss: 1.670914\n",
      "\n",
      "\n",
      "Epoch 266/750 - Train Cd Loss: 0.094626 - Test Loss: 0.052718\n",
      "Epoch 266/750 - Train pg Loss: 8.820391 - Test Loss: 1.376400\n",
      "\n",
      "\n",
      "Epoch 267/750 - Train Cd Loss: 0.086689 - Test Loss: 0.050929\n",
      "Epoch 267/750 - Train pg Loss: 9.487051 - Test Loss: 1.866595\n",
      "\n",
      "\n",
      "Epoch 268/750 - Train Cd Loss: 0.086860 - Test Loss: 0.053993\n",
      "Epoch 268/750 - Train pg Loss: 8.654301 - Test Loss: 1.357550\n",
      "\n",
      "\n",
      "Epoch 269/750 - Train Cd Loss: 0.090847 - Test Loss: 0.051833\n",
      "Epoch 269/750 - Train pg Loss: 7.829138 - Test Loss: 1.489782\n",
      "\n",
      "\n",
      "Epoch 270/750 - Train Cd Loss: 0.089201 - Test Loss: 0.051934\n",
      "Epoch 270/750 - Train pg Loss: 6.955209 - Test Loss: 1.211951\n",
      "\n",
      "\n",
      "Epoch 271/750 - Train Cd Loss: 0.090702 - Test Loss: 0.051326\n",
      "Epoch 271/750 - Train pg Loss: 7.727114 - Test Loss: 1.479701\n",
      "\n",
      "\n",
      "Epoch 272/750 - Train Cd Loss: 0.091338 - Test Loss: 0.051396\n",
      "Epoch 272/750 - Train pg Loss: 9.605712 - Test Loss: 1.896861\n",
      "\n",
      "\n",
      "Epoch 273/750 - Train Cd Loss: 0.092823 - Test Loss: 0.049792\n",
      "Epoch 273/750 - Train pg Loss: 11.361601 - Test Loss: 1.976973\n",
      "\n",
      "\n",
      "Epoch 274/750 - Train Cd Loss: 0.087336 - Test Loss: 0.051538\n",
      "Epoch 274/750 - Train pg Loss: 8.730865 - Test Loss: 1.356929\n",
      "\n",
      "\n",
      "Epoch 275/750 - Train Cd Loss: 0.090997 - Test Loss: 0.051534\n",
      "Epoch 275/750 - Train pg Loss: 7.400934 - Test Loss: 1.558331\n",
      "\n",
      "\n",
      "Epoch 276/750 - Train Cd Loss: 0.107994 - Test Loss: 0.048324\n",
      "Epoch 276/750 - Train pg Loss: 9.762173 - Test Loss: 2.412052\n",
      "\n",
      "\n",
      "Epoch 277/750 - Train Cd Loss: 0.089858 - Test Loss: 0.050827\n",
      "Epoch 277/750 - Train pg Loss: 10.744393 - Test Loss: 1.741518\n",
      "\n",
      "\n",
      "Epoch 278/750 - Train Cd Loss: 0.088178 - Test Loss: 0.052601\n",
      "Epoch 278/750 - Train pg Loss: 7.983387 - Test Loss: 1.358589\n",
      "\n",
      "\n",
      "Epoch 279/750 - Train Cd Loss: 0.106673 - Test Loss: 0.050191\n",
      "Epoch 279/750 - Train pg Loss: 7.816845 - Test Loss: 1.395405\n",
      "\n",
      "\n",
      "Epoch 280/750 - Train Cd Loss: 0.089237 - Test Loss: 0.051779\n",
      "Epoch 280/750 - Train pg Loss: 8.079036 - Test Loss: 1.757922\n",
      "\n",
      "\n",
      "Epoch 281/750 - Train Cd Loss: 0.091759 - Test Loss: 0.050588\n",
      "Epoch 281/750 - Train pg Loss: 9.269638 - Test Loss: 1.853513\n",
      "\n",
      "\n",
      "Epoch 282/750 - Train Cd Loss: 0.091571 - Test Loss: 0.049692\n",
      "Epoch 282/750 - Train pg Loss: 8.583222 - Test Loss: 1.450951\n",
      "\n",
      "\n",
      "Epoch 283/750 - Train Cd Loss: 0.088686 - Test Loss: 0.051763\n",
      "Epoch 283/750 - Train pg Loss: 7.306176 - Test Loss: 1.345639\n",
      "\n",
      "\n",
      "Epoch 284/750 - Train Cd Loss: 0.086932 - Test Loss: 0.052405\n",
      "Epoch 284/750 - Train pg Loss: 7.604290 - Test Loss: 1.595611\n",
      "\n",
      "\n",
      "Epoch 285/750 - Train Cd Loss: 0.086467 - Test Loss: 0.051652\n",
      "Epoch 285/750 - Train pg Loss: 8.430992 - Test Loss: 1.642692\n",
      "\n",
      "\n",
      "Epoch 286/750 - Train Cd Loss: 0.092065 - Test Loss: 0.049094\n",
      "Epoch 286/750 - Train pg Loss: 10.288427 - Test Loss: 2.179809\n",
      "\n",
      "\n",
      "Epoch 287/750 - Train Cd Loss: 0.084273 - Test Loss: 0.053254\n",
      "Epoch 287/750 - Train pg Loss: 9.808461 - Test Loss: 1.589071\n",
      "\n",
      "\n",
      "Epoch 288/750 - Train Cd Loss: 0.090477 - Test Loss: 0.048514\n",
      "Epoch 288/750 - Train pg Loss: 8.370058 - Test Loss: 1.561041\n",
      "\n",
      "\n",
      "Epoch 289/750 - Train Cd Loss: 0.089818 - Test Loss: 0.048989\n",
      "Epoch 289/750 - Train pg Loss: 11.258158 - Test Loss: 2.179366\n",
      "\n",
      "\n",
      "Epoch 290/750 - Train Cd Loss: 0.095286 - Test Loss: 0.049359\n",
      "Epoch 290/750 - Train pg Loss: 10.394863 - Test Loss: 1.834274\n",
      "\n",
      "\n",
      "Epoch 291/750 - Train Cd Loss: 0.096355 - Test Loss: 0.048033\n",
      "Epoch 291/750 - Train pg Loss: 8.970266 - Test Loss: 1.631765\n",
      "\n",
      "\n",
      "Epoch 292/750 - Train Cd Loss: 0.093076 - Test Loss: 0.049418\n",
      "Epoch 292/750 - Train pg Loss: 9.071263 - Test Loss: 2.229727\n",
      "\n",
      "\n",
      "Epoch 293/750 - Train Cd Loss: 0.090096 - Test Loss: 0.049265\n",
      "Epoch 293/750 - Train pg Loss: 11.595794 - Test Loss: 2.215972\n",
      "\n",
      "\n",
      "Epoch 294/750 - Train Cd Loss: 0.088043 - Test Loss: 0.050895\n",
      "Epoch 294/750 - Train pg Loss: 10.291464 - Test Loss: 1.801762\n",
      "\n",
      "\n",
      "Epoch 295/750 - Train Cd Loss: 0.087832 - Test Loss: 0.051441\n",
      "Epoch 295/750 - Train pg Loss: 8.873911 - Test Loss: 1.360040\n",
      "\n",
      "\n",
      "Epoch 296/750 - Train Cd Loss: 0.085404 - Test Loss: 0.051366\n",
      "Epoch 296/750 - Train pg Loss: 8.326471 - Test Loss: 1.675678\n",
      "\n",
      "\n",
      "Epoch 297/750 - Train Cd Loss: 0.092468 - Test Loss: 0.049977\n",
      "Epoch 297/750 - Train pg Loss: 10.493591 - Test Loss: 2.129794\n",
      "\n",
      "\n",
      "Epoch 298/750 - Train Cd Loss: 0.099116 - Test Loss: 0.051385\n",
      "Epoch 298/750 - Train pg Loss: 9.707470 - Test Loss: 1.747344\n",
      "\n",
      "\n",
      "Epoch 299/750 - Train Cd Loss: 0.089668 - Test Loss: 0.051776\n",
      "Epoch 299/750 - Train pg Loss: 9.380494 - Test Loss: 1.650192\n",
      "\n",
      "\n",
      "Epoch 300/750 - Train Cd Loss: 0.085348 - Test Loss: 0.050432\n",
      "Epoch 300/750 - Train pg Loss: 8.628786 - Test Loss: 1.677309\n",
      "\n",
      "\n",
      "Epoch 301/750 - Train Cd Loss: 0.090494 - Test Loss: 0.053105\n",
      "Epoch 301/750 - Train pg Loss: 9.376673 - Test Loss: 1.510738\n",
      "\n",
      "\n",
      "Epoch 302/750 - Train Cd Loss: 0.090757 - Test Loss: 0.049715\n",
      "Epoch 302/750 - Train pg Loss: 8.379257 - Test Loss: 1.596089\n",
      "\n",
      "\n",
      "Epoch 303/750 - Train Cd Loss: 0.097510 - Test Loss: 0.048002\n",
      "Epoch 303/750 - Train pg Loss: 11.546469 - Test Loss: 2.093830\n",
      "\n",
      "\n",
      "Epoch 304/750 - Train Cd Loss: 0.088498 - Test Loss: 0.048857\n",
      "Epoch 304/750 - Train pg Loss: 8.722122 - Test Loss: 1.789910\n",
      "\n",
      "\n",
      "Epoch 305/750 - Train Cd Loss: 0.084928 - Test Loss: 0.048544\n",
      "Epoch 305/750 - Train pg Loss: 7.708261 - Test Loss: 1.519137\n",
      "\n",
      "\n",
      "Epoch 306/750 - Train Cd Loss: 0.091181 - Test Loss: 0.050929\n",
      "Epoch 306/750 - Train pg Loss: 7.800429 - Test Loss: 1.471065\n",
      "\n",
      "\n",
      "Epoch 307/750 - Train Cd Loss: 0.085221 - Test Loss: 0.050165\n",
      "Epoch 307/750 - Train pg Loss: 7.306949 - Test Loss: 1.440804\n",
      "\n",
      "\n",
      "Epoch 308/750 - Train Cd Loss: 0.086410 - Test Loss: 0.048601\n",
      "Epoch 308/750 - Train pg Loss: 8.362638 - Test Loss: 1.669353\n",
      "\n",
      "\n",
      "Epoch 309/750 - Train Cd Loss: 0.079308 - Test Loss: 0.047342\n",
      "Epoch 309/750 - Train pg Loss: 10.971707 - Test Loss: 2.189482\n",
      "\n",
      "\n",
      "Epoch 310/750 - Train Cd Loss: 0.082329 - Test Loss: 0.048783\n",
      "Epoch 310/750 - Train pg Loss: 10.586308 - Test Loss: 1.938947\n",
      "\n",
      "\n",
      "Epoch 311/750 - Train Cd Loss: 0.081154 - Test Loss: 0.048150\n",
      "Epoch 311/750 - Train pg Loss: 10.182286 - Test Loss: 1.902213\n",
      "\n",
      "\n",
      "Epoch 312/750 - Train Cd Loss: 0.096319 - Test Loss: 0.048924\n",
      "Epoch 312/750 - Train pg Loss: 10.233583 - Test Loss: 2.220047\n",
      "\n",
      "\n",
      "Epoch 313/750 - Train Cd Loss: 0.087144 - Test Loss: 0.048885\n",
      "Epoch 313/750 - Train pg Loss: 11.158231 - Test Loss: 2.064190\n",
      "\n",
      "\n",
      "Epoch 314/750 - Train Cd Loss: 0.079681 - Test Loss: 0.047703\n",
      "Epoch 314/750 - Train pg Loss: 9.204635 - Test Loss: 1.838739\n",
      "\n",
      "\n",
      "Epoch 315/750 - Train Cd Loss: 0.086163 - Test Loss: 0.051312\n",
      "Epoch 315/750 - Train pg Loss: 9.029352 - Test Loss: 1.697447\n",
      "\n",
      "\n",
      "Epoch 316/750 - Train Cd Loss: 0.081366 - Test Loss: 0.049132\n",
      "Epoch 316/750 - Train pg Loss: 8.347508 - Test Loss: 1.537883\n",
      "\n",
      "\n",
      "Epoch 317/750 - Train Cd Loss: 0.087602 - Test Loss: 0.049120\n",
      "Epoch 317/750 - Train pg Loss: 7.113231 - Test Loss: 1.428574\n",
      "\n",
      "\n",
      "Epoch 318/750 - Train Cd Loss: 0.091230 - Test Loss: 0.047787\n",
      "Epoch 318/750 - Train pg Loss: 7.752767 - Test Loss: 1.644872\n",
      "\n",
      "\n",
      "Epoch 319/750 - Train Cd Loss: 0.080681 - Test Loss: 0.048907\n",
      "Epoch 319/750 - Train pg Loss: 8.651419 - Test Loss: 1.612365\n",
      "\n",
      "\n",
      "Epoch 320/750 - Train Cd Loss: 0.084084 - Test Loss: 0.048950\n",
      "Epoch 320/750 - Train pg Loss: 7.972067 - Test Loss: 1.532175\n",
      "\n",
      "\n",
      "Epoch 321/750 - Train Cd Loss: 0.085336 - Test Loss: 0.048625\n",
      "Epoch 321/750 - Train pg Loss: 7.977827 - Test Loss: 1.366700\n",
      "\n",
      "\n",
      "Epoch 322/750 - Train Cd Loss: 0.079270 - Test Loss: 0.051523\n",
      "Epoch 322/750 - Train pg Loss: 7.956657 - Test Loss: 1.409457\n",
      "\n",
      "\n",
      "Epoch 323/750 - Train Cd Loss: 0.091364 - Test Loss: 0.046440\n",
      "Epoch 323/750 - Train pg Loss: 9.844900 - Test Loss: 1.863907\n",
      "\n",
      "\n",
      "Epoch 324/750 - Train Cd Loss: 0.083404 - Test Loss: 0.052207\n",
      "Epoch 324/750 - Train pg Loss: 10.036078 - Test Loss: 1.376196\n",
      "\n",
      "\n",
      "Epoch 325/750 - Train Cd Loss: 0.078084 - Test Loss: 0.050910\n",
      "Epoch 325/750 - Train pg Loss: 6.947142 - Test Loss: 1.201610\n",
      "\n",
      "\n",
      "Epoch 326/750 - Train Cd Loss: 0.090862 - Test Loss: 0.047600\n",
      "Epoch 326/750 - Train pg Loss: 8.515895 - Test Loss: 1.676653\n",
      "\n",
      "\n",
      "Epoch 327/750 - Train Cd Loss: 0.086817 - Test Loss: 0.045693\n",
      "Epoch 327/750 - Train pg Loss: 9.595377 - Test Loss: 1.712003\n",
      "\n",
      "\n",
      "Epoch 328/750 - Train Cd Loss: 0.083078 - Test Loss: 0.050743\n",
      "Epoch 328/750 - Train pg Loss: 8.027907 - Test Loss: 1.306253\n",
      "\n",
      "\n",
      "Epoch 329/750 - Train Cd Loss: 0.090233 - Test Loss: 0.048109\n",
      "Epoch 329/750 - Train pg Loss: 8.021361 - Test Loss: 1.638389\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330/750 - Train Cd Loss: 0.082684 - Test Loss: 0.047483\n",
      "Epoch 330/750 - Train pg Loss: 8.545231 - Test Loss: 1.612985\n",
      "\n",
      "\n",
      "Epoch 331/750 - Train Cd Loss: 0.086603 - Test Loss: 0.048521\n",
      "Epoch 331/750 - Train pg Loss: 8.455719 - Test Loss: 1.417027\n",
      "\n",
      "\n",
      "Epoch 332/750 - Train Cd Loss: 0.081610 - Test Loss: 0.048118\n",
      "Epoch 332/750 - Train pg Loss: 9.378280 - Test Loss: 1.497948\n",
      "\n",
      "\n",
      "Epoch 333/750 - Train Cd Loss: 0.097887 - Test Loss: 0.047985\n",
      "Epoch 333/750 - Train pg Loss: 10.224796 - Test Loss: 2.505984\n",
      "\n",
      "\n",
      "Epoch 334/750 - Train Cd Loss: 0.080056 - Test Loss: 0.047539\n",
      "Epoch 334/750 - Train pg Loss: 11.429590 - Test Loss: 1.790724\n",
      "\n",
      "\n",
      "Epoch 335/750 - Train Cd Loss: 0.083226 - Test Loss: 0.050382\n",
      "Epoch 335/750 - Train pg Loss: 8.320407 - Test Loss: 1.458082\n",
      "\n",
      "\n",
      "Epoch 336/750 - Train Cd Loss: 0.083305 - Test Loss: 0.047806\n",
      "Epoch 336/750 - Train pg Loss: 7.967774 - Test Loss: 1.660816\n",
      "\n",
      "\n",
      "Epoch 337/750 - Train Cd Loss: 0.085294 - Test Loss: 0.048914\n",
      "Epoch 337/750 - Train pg Loss: 10.620101 - Test Loss: 1.828251\n",
      "\n",
      "\n",
      "Epoch 338/750 - Train Cd Loss: 0.086178 - Test Loss: 0.046666\n",
      "Epoch 338/750 - Train pg Loss: 11.375838 - Test Loss: 2.267489\n",
      "\n",
      "\n",
      "Epoch 339/750 - Train Cd Loss: 0.079673 - Test Loss: 0.050026\n",
      "Epoch 339/750 - Train pg Loss: 11.379962 - Test Loss: 1.995968\n",
      "\n",
      "\n",
      "Epoch 340/750 - Train Cd Loss: 0.080266 - Test Loss: 0.050679\n",
      "Epoch 340/750 - Train pg Loss: 10.075105 - Test Loss: 1.670844\n",
      "\n",
      "\n",
      "Epoch 341/750 - Train Cd Loss: 0.076664 - Test Loss: 0.049570\n",
      "Epoch 341/750 - Train pg Loss: 9.022843 - Test Loss: 1.716119\n",
      "\n",
      "\n",
      "Epoch 342/750 - Train Cd Loss: 0.088972 - Test Loss: 0.048136\n",
      "Epoch 342/750 - Train pg Loss: 11.569066 - Test Loss: 2.083094\n",
      "\n",
      "\n",
      "Epoch 343/750 - Train Cd Loss: 0.081666 - Test Loss: 0.047328\n",
      "Epoch 343/750 - Train pg Loss: 11.553354 - Test Loss: 2.378563\n",
      "\n",
      "\n",
      "Epoch 344/750 - Train Cd Loss: 0.078835 - Test Loss: 0.049041\n",
      "Epoch 344/750 - Train pg Loss: 11.576138 - Test Loss: 1.930925\n",
      "\n",
      "\n",
      "Epoch 345/750 - Train Cd Loss: 0.081347 - Test Loss: 0.050289\n",
      "Epoch 345/750 - Train pg Loss: 9.521486 - Test Loss: 1.830625\n",
      "\n",
      "\n",
      "Epoch 346/750 - Train Cd Loss: 0.080947 - Test Loss: 0.048398\n",
      "Epoch 346/750 - Train pg Loss: 9.995907 - Test Loss: 1.751818\n",
      "\n",
      "\n",
      "Epoch 347/750 - Train Cd Loss: 0.088839 - Test Loss: 0.046825\n",
      "Epoch 347/750 - Train pg Loss: 10.983183 - Test Loss: 2.455539\n",
      "\n",
      "\n",
      "Epoch 348/750 - Train Cd Loss: 0.079529 - Test Loss: 0.046946\n",
      "Epoch 348/750 - Train pg Loss: 11.432646 - Test Loss: 2.195339\n",
      "\n",
      "\n",
      "Epoch 349/750 - Train Cd Loss: 0.078506 - Test Loss: 0.047049\n",
      "Epoch 349/750 - Train pg Loss: 11.174515 - Test Loss: 2.135079\n",
      "\n",
      "\n",
      "Epoch 350/750 - Train Cd Loss: 0.071796 - Test Loss: 0.045883\n",
      "Epoch 350/750 - Train pg Loss: 10.783969 - Test Loss: 2.079632\n",
      "\n",
      "\n",
      "Epoch 351/750 - Train Cd Loss: 0.079497 - Test Loss: 0.051189\n",
      "Epoch 351/750 - Train pg Loss: 11.802363 - Test Loss: 1.915383\n",
      "\n",
      "\n",
      "Epoch 352/750 - Train Cd Loss: 0.087320 - Test Loss: 0.049835\n",
      "Epoch 352/750 - Train pg Loss: 11.117895 - Test Loss: 2.238556\n",
      "\n",
      "\n",
      "Epoch 353/750 - Train Cd Loss: 0.089231 - Test Loss: 0.044729\n",
      "Epoch 353/750 - Train pg Loss: 15.219123 - Test Loss: 3.172649\n",
      "\n",
      "\n",
      "Epoch 354/750 - Train Cd Loss: 0.075871 - Test Loss: 0.048353\n",
      "Epoch 354/750 - Train pg Loss: 13.713982 - Test Loss: 2.186901\n",
      "\n",
      "\n",
      "Epoch 355/750 - Train Cd Loss: 0.079732 - Test Loss: 0.047889\n",
      "Epoch 355/750 - Train pg Loss: 13.306534 - Test Loss: 2.288343\n",
      "\n",
      "\n",
      "Epoch 356/750 - Train Cd Loss: 0.106951 - Test Loss: 0.047402\n",
      "Epoch 356/750 - Train pg Loss: 14.756594 - Test Loss: 2.354748\n",
      "\n",
      "\n",
      "Epoch 357/750 - Train Cd Loss: 0.083227 - Test Loss: 0.049602\n",
      "Epoch 357/750 - Train pg Loss: 11.197948 - Test Loss: 1.789625\n",
      "\n",
      "\n",
      "Epoch 358/750 - Train Cd Loss: 0.080686 - Test Loss: 0.048418\n",
      "Epoch 358/750 - Train pg Loss: 9.498138 - Test Loss: 1.794299\n",
      "\n",
      "\n",
      "Epoch 359/750 - Train Cd Loss: 0.080422 - Test Loss: 0.046293\n",
      "Epoch 359/750 - Train pg Loss: 10.475002 - Test Loss: 1.858215\n",
      "\n",
      "\n",
      "Epoch 360/750 - Train Cd Loss: 0.084280 - Test Loss: 0.045953\n",
      "Epoch 360/750 - Train pg Loss: 11.488282 - Test Loss: 2.476245\n",
      "\n",
      "\n",
      "Epoch 361/750 - Train Cd Loss: 0.075675 - Test Loss: 0.048485\n",
      "Epoch 361/750 - Train pg Loss: 11.431324 - Test Loss: 1.987697\n",
      "\n",
      "\n",
      "Epoch 362/750 - Train Cd Loss: 0.074056 - Test Loss: 0.047413\n",
      "Epoch 362/750 - Train pg Loss: 11.076570 - Test Loss: 2.046246\n",
      "\n",
      "\n",
      "Epoch 363/750 - Train Cd Loss: 0.081567 - Test Loss: 0.046248\n",
      "Epoch 363/750 - Train pg Loss: 10.893577 - Test Loss: 2.108266\n",
      "\n",
      "\n",
      "Epoch 364/750 - Train Cd Loss: 0.081473 - Test Loss: 0.050279\n",
      "Epoch 364/750 - Train pg Loss: 10.807675 - Test Loss: 2.045267\n",
      "\n",
      "\n",
      "Epoch 365/750 - Train Cd Loss: 0.075832 - Test Loss: 0.047844\n",
      "Epoch 365/750 - Train pg Loss: 11.424564 - Test Loss: 1.949971\n",
      "\n",
      "\n",
      "Epoch 366/750 - Train Cd Loss: 0.075294 - Test Loss: 0.047339\n",
      "Epoch 366/750 - Train pg Loss: 10.824049 - Test Loss: 2.046120\n",
      "\n",
      "\n",
      "Epoch 367/750 - Train Cd Loss: 0.089198 - Test Loss: 0.046895\n",
      "Epoch 367/750 - Train pg Loss: 11.146846 - Test Loss: 2.092853\n",
      "\n",
      "\n",
      "Epoch 368/750 - Train Cd Loss: 0.071269 - Test Loss: 0.046970\n",
      "Epoch 368/750 - Train pg Loss: 11.375093 - Test Loss: 1.949693\n",
      "\n",
      "\n",
      "Epoch 369/750 - Train Cd Loss: 0.074772 - Test Loss: 0.048982\n",
      "Epoch 369/750 - Train pg Loss: 10.197717 - Test Loss: 2.116346\n",
      "\n",
      "\n",
      "Epoch 370/750 - Train Cd Loss: 0.095255 - Test Loss: 0.046912\n",
      "Epoch 370/750 - Train pg Loss: 11.835494 - Test Loss: 2.120532\n",
      "\n",
      "\n",
      "Epoch 371/750 - Train Cd Loss: 0.083199 - Test Loss: 0.047827\n",
      "Epoch 371/750 - Train pg Loss: 12.801328 - Test Loss: 2.578673\n",
      "\n",
      "\n",
      "Epoch 372/750 - Train Cd Loss: 0.078353 - Test Loss: 0.050090\n",
      "Epoch 372/750 - Train pg Loss: 11.936121 - Test Loss: 2.096193\n",
      "\n",
      "\n",
      "Epoch 373/750 - Train Cd Loss: 0.078420 - Test Loss: 0.046536\n",
      "Epoch 373/750 - Train pg Loss: 8.889486 - Test Loss: 1.816544\n",
      "\n",
      "\n",
      "Epoch 374/750 - Train Cd Loss: 0.075947 - Test Loss: 0.044305\n",
      "Epoch 374/750 - Train pg Loss: 12.764467 - Test Loss: 2.453396\n",
      "\n",
      "\n",
      "Epoch 375/750 - Train Cd Loss: 0.069783 - Test Loss: 0.046362\n",
      "Epoch 375/750 - Train pg Loss: 11.330733 - Test Loss: 1.960919\n",
      "\n",
      "\n",
      "Epoch 376/750 - Train Cd Loss: 0.073620 - Test Loss: 0.046114\n",
      "Epoch 376/750 - Train pg Loss: 9.627482 - Test Loss: 1.917596\n",
      "\n",
      "\n",
      "Epoch 377/750 - Train Cd Loss: 0.085942 - Test Loss: 0.045070\n",
      "Epoch 377/750 - Train pg Loss: 11.204875 - Test Loss: 2.346068\n",
      "\n",
      "\n",
      "Epoch 378/750 - Train Cd Loss: 0.074929 - Test Loss: 0.044267\n",
      "Epoch 378/750 - Train pg Loss: 12.203587 - Test Loss: 2.233350\n",
      "\n",
      "\n",
      "Epoch 379/750 - Train Cd Loss: 0.077853 - Test Loss: 0.048644\n",
      "Epoch 379/750 - Train pg Loss: 13.348078 - Test Loss: 2.689440\n",
      "\n",
      "\n",
      "Epoch 380/750 - Train Cd Loss: 0.075000 - Test Loss: 0.048992\n",
      "Epoch 380/750 - Train pg Loss: 15.383131 - Test Loss: 2.482808\n",
      "\n",
      "\n",
      "Epoch 381/750 - Train Cd Loss: 0.076818 - Test Loss: 0.047763\n",
      "Epoch 381/750 - Train pg Loss: 12.711688 - Test Loss: 2.286621\n",
      "\n",
      "\n",
      "Epoch 382/750 - Train Cd Loss: 0.079092 - Test Loss: 0.042514\n",
      "Epoch 382/750 - Train pg Loss: 13.313345 - Test Loss: 3.079845\n",
      "\n",
      "\n",
      "Epoch 383/750 - Train Cd Loss: 0.076148 - Test Loss: 0.047281\n",
      "Epoch 383/750 - Train pg Loss: 14.652435 - Test Loss: 2.529234\n",
      "\n",
      "\n",
      "Epoch 384/750 - Train Cd Loss: 0.074351 - Test Loss: 0.047186\n",
      "Epoch 384/750 - Train pg Loss: 13.286653 - Test Loss: 2.244480\n",
      "\n",
      "\n",
      "Epoch 385/750 - Train Cd Loss: 0.088552 - Test Loss: 0.044085\n",
      "Epoch 385/750 - Train pg Loss: 11.188910 - Test Loss: 2.273349\n",
      "\n",
      "\n",
      "Epoch 386/750 - Train Cd Loss: 0.073485 - Test Loss: 0.043585\n",
      "Epoch 386/750 - Train pg Loss: 13.620314 - Test Loss: 2.326892\n",
      "\n",
      "\n",
      "Epoch 387/750 - Train Cd Loss: 0.087466 - Test Loss: 0.045794\n",
      "Epoch 387/750 - Train pg Loss: 12.539142 - Test Loss: 2.456397\n",
      "\n",
      "\n",
      "Epoch 388/750 - Train Cd Loss: 0.074952 - Test Loss: 0.045858\n",
      "Epoch 388/750 - Train pg Loss: 11.593127 - Test Loss: 2.162455\n",
      "\n",
      "\n",
      "Epoch 389/750 - Train Cd Loss: 0.070680 - Test Loss: 0.049921\n",
      "Epoch 389/750 - Train pg Loss: 10.937014 - Test Loss: 1.780381\n",
      "\n",
      "\n",
      "Epoch 390/750 - Train Cd Loss: 0.075394 - Test Loss: 0.044507\n",
      "Epoch 390/750 - Train pg Loss: 10.244692 - Test Loss: 1.942852\n",
      "\n",
      "\n",
      "Epoch 391/750 - Train Cd Loss: 0.068861 - Test Loss: 0.046398\n",
      "Epoch 391/750 - Train pg Loss: 10.717363 - Test Loss: 1.869261\n",
      "\n",
      "\n",
      "Epoch 392/750 - Train Cd Loss: 0.075171 - Test Loss: 0.045701\n",
      "Epoch 392/750 - Train pg Loss: 10.259340 - Test Loss: 1.953523\n",
      "\n",
      "\n",
      "Epoch 393/750 - Train Cd Loss: 0.089568 - Test Loss: 0.042369\n",
      "Epoch 393/750 - Train pg Loss: 11.204093 - Test Loss: 2.164887\n",
      "\n",
      "\n",
      "Epoch 394/750 - Train Cd Loss: 0.074488 - Test Loss: 0.042964\n",
      "Epoch 394/750 - Train pg Loss: 13.270906 - Test Loss: 2.592069\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395/750 - Train Cd Loss: 0.068156 - Test Loss: 0.047588\n",
      "Epoch 395/750 - Train pg Loss: 13.106735 - Test Loss: 2.427325\n",
      "\n",
      "\n",
      "Epoch 396/750 - Train Cd Loss: 0.073477 - Test Loss: 0.044105\n",
      "Epoch 396/750 - Train pg Loss: 12.394974 - Test Loss: 2.550873\n",
      "\n",
      "\n",
      "Epoch 397/750 - Train Cd Loss: 0.077085 - Test Loss: 0.046786\n",
      "Epoch 397/750 - Train pg Loss: 13.651635 - Test Loss: 2.623015\n",
      "\n",
      "\n",
      "Epoch 398/750 - Train Cd Loss: 0.076869 - Test Loss: 0.042305\n",
      "Epoch 398/750 - Train pg Loss: 15.300919 - Test Loss: 2.676384\n",
      "\n",
      "\n",
      "Epoch 399/750 - Train Cd Loss: 0.086730 - Test Loss: 0.041870\n",
      "Epoch 399/750 - Train pg Loss: 15.069898 - Test Loss: 3.202478\n",
      "\n",
      "\n",
      "Epoch 400/750 - Train Cd Loss: 0.072053 - Test Loss: 0.044013\n",
      "Epoch 400/750 - Train pg Loss: 14.030544 - Test Loss: 2.905226\n",
      "\n",
      "\n",
      "Epoch 401/750 - Train Cd Loss: 0.063058 - Test Loss: 0.044721\n",
      "Epoch 401/750 - Train pg Loss: 13.528272 - Test Loss: 2.382702\n",
      "\n",
      "\n",
      "Epoch 402/750 - Train Cd Loss: 0.068081 - Test Loss: 0.045833\n",
      "Epoch 402/750 - Train pg Loss: 12.815891 - Test Loss: 2.184441\n",
      "\n",
      "\n",
      "Epoch 403/750 - Train Cd Loss: 0.083290 - Test Loss: 0.046141\n",
      "Epoch 403/750 - Train pg Loss: 12.437685 - Test Loss: 2.229143\n",
      "\n",
      "\n",
      "Epoch 404/750 - Train Cd Loss: 0.075482 - Test Loss: 0.044759\n",
      "Epoch 404/750 - Train pg Loss: 13.735435 - Test Loss: 2.991304\n",
      "\n",
      "\n",
      "Epoch 405/750 - Train Cd Loss: 0.079891 - Test Loss: 0.044744\n",
      "Epoch 405/750 - Train pg Loss: 16.874872 - Test Loss: 3.169813\n",
      "\n",
      "\n",
      "Epoch 406/750 - Train Cd Loss: 0.074053 - Test Loss: 0.044545\n",
      "Epoch 406/750 - Train pg Loss: 15.536469 - Test Loss: 2.459981\n",
      "\n",
      "\n",
      "Epoch 407/750 - Train Cd Loss: 0.064639 - Test Loss: 0.044980\n",
      "Epoch 407/750 - Train pg Loss: 11.635287 - Test Loss: 2.293490\n",
      "\n",
      "\n",
      "Epoch 408/750 - Train Cd Loss: 0.079801 - Test Loss: 0.042866\n",
      "Epoch 408/750 - Train pg Loss: 13.518032 - Test Loss: 3.255212\n",
      "\n",
      "\n",
      "Epoch 409/750 - Train Cd Loss: 0.064129 - Test Loss: 0.042945\n",
      "Epoch 409/750 - Train pg Loss: 17.673208 - Test Loss: 3.033384\n",
      "\n",
      "\n",
      "Epoch 410/750 - Train Cd Loss: 0.070848 - Test Loss: 0.044301\n",
      "Epoch 410/750 - Train pg Loss: 14.491348 - Test Loss: 2.290166\n",
      "\n",
      "\n",
      "Epoch 411/750 - Train Cd Loss: 0.068611 - Test Loss: 0.047570\n",
      "Epoch 411/750 - Train pg Loss: 11.514976 - Test Loss: 2.134257\n",
      "\n",
      "\n",
      "Epoch 412/750 - Train Cd Loss: 0.075374 - Test Loss: 0.049292\n",
      "Epoch 412/750 - Train pg Loss: 11.495448 - Test Loss: 1.830553\n",
      "\n",
      "\n",
      "Epoch 413/750 - Train Cd Loss: 0.074331 - Test Loss: 0.046527\n",
      "Epoch 413/750 - Train pg Loss: 10.733013 - Test Loss: 2.335330\n",
      "\n",
      "\n",
      "Epoch 414/750 - Train Cd Loss: 0.069017 - Test Loss: 0.044522\n",
      "Epoch 414/750 - Train pg Loss: 12.571280 - Test Loss: 2.250190\n",
      "\n",
      "\n",
      "Epoch 415/750 - Train Cd Loss: 0.068778 - Test Loss: 0.046474\n",
      "Epoch 415/750 - Train pg Loss: 11.752331 - Test Loss: 1.995659\n",
      "\n",
      "\n",
      "Epoch 416/750 - Train Cd Loss: 0.083742 - Test Loss: 0.044093\n",
      "Epoch 416/750 - Train pg Loss: 12.322484 - Test Loss: 2.629048\n",
      "\n",
      "\n",
      "Epoch 417/750 - Train Cd Loss: 0.060175 - Test Loss: 0.040697\n",
      "Epoch 417/750 - Train pg Loss: 13.889502 - Test Loss: 2.758682\n",
      "\n",
      "\n",
      "Epoch 418/750 - Train Cd Loss: 0.067865 - Test Loss: 0.045475\n",
      "Epoch 418/750 - Train pg Loss: 14.900229 - Test Loss: 2.694765\n",
      "\n",
      "\n",
      "Epoch 419/750 - Train Cd Loss: 0.074254 - Test Loss: 0.043810\n",
      "Epoch 419/750 - Train pg Loss: 13.320029 - Test Loss: 2.816474\n",
      "\n",
      "\n",
      "Epoch 420/750 - Train Cd Loss: 0.066690 - Test Loss: 0.042793\n",
      "Epoch 420/750 - Train pg Loss: 13.988558 - Test Loss: 2.806431\n",
      "\n",
      "\n",
      "Epoch 421/750 - Train Cd Loss: 0.065449 - Test Loss: 0.042388\n",
      "Epoch 421/750 - Train pg Loss: 13.855883 - Test Loss: 2.443957\n",
      "\n",
      "\n",
      "Epoch 422/750 - Train Cd Loss: 0.076345 - Test Loss: 0.045075\n",
      "Epoch 422/750 - Train pg Loss: 13.158763 - Test Loss: 3.099478\n",
      "\n",
      "\n",
      "Epoch 423/750 - Train Cd Loss: 0.063981 - Test Loss: 0.043321\n",
      "Epoch 423/750 - Train pg Loss: 14.714100 - Test Loss: 2.680043\n",
      "\n",
      "\n",
      "Epoch 424/750 - Train Cd Loss: 0.068313 - Test Loss: 0.042620\n",
      "Epoch 424/750 - Train pg Loss: 13.904635 - Test Loss: 2.665490\n",
      "\n",
      "\n",
      "Epoch 425/750 - Train Cd Loss: 0.095670 - Test Loss: 0.043835\n",
      "Epoch 425/750 - Train pg Loss: 14.690244 - Test Loss: 3.245879\n",
      "\n",
      "\n",
      "Epoch 426/750 - Train Cd Loss: 0.067901 - Test Loss: 0.042019\n",
      "Epoch 426/750 - Train pg Loss: 17.654228 - Test Loss: 3.210202\n",
      "\n",
      "\n",
      "Epoch 427/750 - Train Cd Loss: 0.066999 - Test Loss: 0.044049\n",
      "Epoch 427/750 - Train pg Loss: 14.766232 - Test Loss: 2.596130\n",
      "\n",
      "\n",
      "Epoch 428/750 - Train Cd Loss: 0.069079 - Test Loss: 0.044298\n",
      "Epoch 428/750 - Train pg Loss: 12.564932 - Test Loss: 2.447116\n",
      "\n",
      "\n",
      "Epoch 429/750 - Train Cd Loss: 0.065910 - Test Loss: 0.043571\n",
      "Epoch 429/750 - Train pg Loss: 13.956669 - Test Loss: 2.495126\n",
      "\n",
      "\n",
      "Epoch 430/750 - Train Cd Loss: 0.067058 - Test Loss: 0.044098\n",
      "Epoch 430/750 - Train pg Loss: 13.144200 - Test Loss: 2.481822\n",
      "\n",
      "\n",
      "Epoch 431/750 - Train Cd Loss: 0.077398 - Test Loss: 0.042326\n",
      "Epoch 431/750 - Train pg Loss: 15.412910 - Test Loss: 3.276884\n",
      "\n",
      "\n",
      "Epoch 432/750 - Train Cd Loss: 0.078640 - Test Loss: 0.044553\n",
      "Epoch 432/750 - Train pg Loss: 15.517311 - Test Loss: 3.287667\n",
      "\n",
      "\n",
      "Epoch 433/750 - Train Cd Loss: 0.069198 - Test Loss: 0.042596\n",
      "Epoch 433/750 - Train pg Loss: 17.314844 - Test Loss: 3.248677\n",
      "\n",
      "\n",
      "Epoch 434/750 - Train Cd Loss: 0.064787 - Test Loss: 0.042938\n",
      "Epoch 434/750 - Train pg Loss: 15.739242 - Test Loss: 3.017915\n",
      "\n",
      "\n",
      "Epoch 435/750 - Train Cd Loss: 0.081050 - Test Loss: 0.043319\n",
      "Epoch 435/750 - Train pg Loss: 17.468761 - Test Loss: 3.229643\n",
      "\n",
      "\n",
      "Epoch 436/750 - Train Cd Loss: 0.065514 - Test Loss: 0.044501\n",
      "Epoch 436/750 - Train pg Loss: 15.294688 - Test Loss: 2.684685\n",
      "\n",
      "\n",
      "Epoch 437/750 - Train Cd Loss: 0.062215 - Test Loss: 0.042474\n",
      "Epoch 437/750 - Train pg Loss: 14.725650 - Test Loss: 2.668371\n",
      "\n",
      "\n",
      "Epoch 438/750 - Train Cd Loss: 0.080907 - Test Loss: 0.040858\n",
      "Epoch 438/750 - Train pg Loss: 16.929556 - Test Loss: 3.302538\n",
      "\n",
      "\n",
      "Epoch 439/750 - Train Cd Loss: 0.066609 - Test Loss: 0.041137\n",
      "Epoch 439/750 - Train pg Loss: 19.491810 - Test Loss: 3.036312\n",
      "\n",
      "\n",
      "Epoch 440/750 - Train Cd Loss: 0.082761 - Test Loss: 0.043209\n",
      "Epoch 440/750 - Train pg Loss: 18.355440 - Test Loss: 3.266499\n",
      "\n",
      "\n",
      "Epoch 441/750 - Train Cd Loss: 0.065013 - Test Loss: 0.044856\n",
      "Epoch 441/750 - Train pg Loss: 16.372728 - Test Loss: 2.721014\n",
      "\n",
      "\n",
      "Epoch 442/750 - Train Cd Loss: 0.079565 - Test Loss: 0.044684\n",
      "Epoch 442/750 - Train pg Loss: 14.103046 - Test Loss: 2.600074\n",
      "\n",
      "\n",
      "Epoch 443/750 - Train Cd Loss: 0.062852 - Test Loss: 0.042487\n",
      "Epoch 443/750 - Train pg Loss: 15.495806 - Test Loss: 3.183666\n",
      "\n",
      "\n",
      "Epoch 444/750 - Train Cd Loss: 0.065291 - Test Loss: 0.041904\n",
      "Epoch 444/750 - Train pg Loss: 14.473891 - Test Loss: 3.042668\n",
      "\n",
      "\n",
      "Epoch 445/750 - Train Cd Loss: 0.064958 - Test Loss: 0.040981\n",
      "Epoch 445/750 - Train pg Loss: 12.877026 - Test Loss: 2.770978\n",
      "\n",
      "\n",
      "Epoch 446/750 - Train Cd Loss: 0.064940 - Test Loss: 0.042333\n",
      "Epoch 446/750 - Train pg Loss: 14.151270 - Test Loss: 2.653370\n",
      "\n",
      "\n",
      "Epoch 447/750 - Train Cd Loss: 0.074347 - Test Loss: 0.045071\n",
      "Epoch 447/750 - Train pg Loss: 13.085441 - Test Loss: 2.323350\n",
      "\n",
      "\n",
      "Epoch 448/750 - Train Cd Loss: 0.063413 - Test Loss: 0.042745\n",
      "Epoch 448/750 - Train pg Loss: 12.231210 - Test Loss: 2.410259\n",
      "\n",
      "\n",
      "Epoch 449/750 - Train Cd Loss: 0.086919 - Test Loss: 0.044109\n",
      "Epoch 449/750 - Train pg Loss: 14.069783 - Test Loss: 2.732989\n",
      "\n",
      "\n",
      "Epoch 450/750 - Train Cd Loss: 0.066013 - Test Loss: 0.041889\n",
      "Epoch 450/750 - Train pg Loss: 12.460485 - Test Loss: 3.052746\n",
      "\n",
      "\n",
      "Epoch 451/750 - Train Cd Loss: 0.072587 - Test Loss: 0.041793\n",
      "Epoch 451/750 - Train pg Loss: 17.180067 - Test Loss: 3.107326\n",
      "\n",
      "\n",
      "Epoch 452/750 - Train Cd Loss: 0.062575 - Test Loss: 0.040511\n",
      "Epoch 452/750 - Train pg Loss: 15.507367 - Test Loss: 3.459066\n",
      "\n",
      "\n",
      "Epoch 453/750 - Train Cd Loss: 0.058572 - Test Loss: 0.044978\n",
      "Epoch 453/750 - Train pg Loss: 15.095529 - Test Loss: 2.852819\n",
      "\n",
      "\n",
      "Epoch 454/750 - Train Cd Loss: 0.078097 - Test Loss: 0.038635\n",
      "Epoch 454/750 - Train pg Loss: 14.283937 - Test Loss: 3.201579\n",
      "\n",
      "\n",
      "Epoch 455/750 - Train Cd Loss: 0.077310 - Test Loss: 0.039379\n",
      "Epoch 455/750 - Train pg Loss: 16.313454 - Test Loss: 3.081497\n",
      "\n",
      "\n",
      "Epoch 456/750 - Train Cd Loss: 0.072585 - Test Loss: 0.039727\n",
      "Epoch 456/750 - Train pg Loss: 15.295733 - Test Loss: 3.279727\n",
      "\n",
      "\n",
      "Epoch 457/750 - Train Cd Loss: 0.063815 - Test Loss: 0.042094\n",
      "Epoch 457/750 - Train pg Loss: 14.737677 - Test Loss: 3.020348\n",
      "\n",
      "\n",
      "Epoch 458/750 - Train Cd Loss: 0.062356 - Test Loss: 0.043890\n",
      "Epoch 458/750 - Train pg Loss: 15.146006 - Test Loss: 2.755587\n",
      "\n",
      "\n",
      "Epoch 459/750 - Train Cd Loss: 0.061918 - Test Loss: 0.041446\n",
      "Epoch 459/750 - Train pg Loss: 12.795583 - Test Loss: 2.845615\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 460/750 - Train Cd Loss: 0.082162 - Test Loss: 0.041257\n",
      "Epoch 460/750 - Train pg Loss: 16.814516 - Test Loss: 3.300984\n",
      "\n",
      "\n",
      "Epoch 461/750 - Train Cd Loss: 0.064704 - Test Loss: 0.041079\n",
      "Epoch 461/750 - Train pg Loss: 15.615614 - Test Loss: 2.783528\n",
      "\n",
      "\n",
      "Epoch 462/750 - Train Cd Loss: 0.054605 - Test Loss: 0.044750\n",
      "Epoch 462/750 - Train pg Loss: 15.156327 - Test Loss: 2.408899\n",
      "\n",
      "\n",
      "Epoch 463/750 - Train Cd Loss: 0.069301 - Test Loss: 0.039548\n",
      "Epoch 463/750 - Train pg Loss: 14.361386 - Test Loss: 2.977424\n",
      "\n",
      "\n",
      "Epoch 464/750 - Train Cd Loss: 0.062291 - Test Loss: 0.041537\n",
      "Epoch 464/750 - Train pg Loss: 15.508908 - Test Loss: 2.755419\n",
      "\n",
      "\n",
      "Epoch 465/750 - Train Cd Loss: 0.096207 - Test Loss: 0.044388\n",
      "Epoch 465/750 - Train pg Loss: 15.227780 - Test Loss: 2.743706\n",
      "\n",
      "\n",
      "Epoch 466/750 - Train Cd Loss: 0.068780 - Test Loss: 0.042084\n",
      "Epoch 466/750 - Train pg Loss: 18.411928 - Test Loss: 3.695609\n",
      "\n",
      "\n",
      "Epoch 467/750 - Train Cd Loss: 0.061626 - Test Loss: 0.042823\n",
      "Epoch 467/750 - Train pg Loss: 18.298159 - Test Loss: 3.435085\n",
      "\n",
      "\n",
      "Epoch 468/750 - Train Cd Loss: 0.065638 - Test Loss: 0.043532\n",
      "Epoch 468/750 - Train pg Loss: 11.925724 - Test Loss: 2.365576\n",
      "\n",
      "\n",
      "Epoch 469/750 - Train Cd Loss: 0.065054 - Test Loss: 0.042760\n",
      "Epoch 469/750 - Train pg Loss: 11.944807 - Test Loss: 2.232434\n",
      "\n",
      "\n",
      "Epoch 470/750 - Train Cd Loss: 0.079356 - Test Loss: 0.042948\n",
      "Epoch 470/750 - Train pg Loss: 14.953537 - Test Loss: 3.192509\n",
      "\n",
      "\n",
      "Epoch 471/750 - Train Cd Loss: 0.061399 - Test Loss: 0.042025\n",
      "Epoch 471/750 - Train pg Loss: 14.430034 - Test Loss: 2.790418\n",
      "\n",
      "\n",
      "Epoch 472/750 - Train Cd Loss: 0.063668 - Test Loss: 0.042075\n",
      "Epoch 472/750 - Train pg Loss: 12.521892 - Test Loss: 2.451255\n",
      "\n",
      "\n",
      "Epoch 473/750 - Train Cd Loss: 0.075704 - Test Loss: 0.043168\n",
      "Epoch 473/750 - Train pg Loss: 13.266554 - Test Loss: 3.117163\n",
      "\n",
      "\n",
      "Epoch 474/750 - Train Cd Loss: 0.066511 - Test Loss: 0.042032\n",
      "Epoch 474/750 - Train pg Loss: 16.216394 - Test Loss: 2.743113\n",
      "\n",
      "\n",
      "Epoch 475/750 - Train Cd Loss: 0.077134 - Test Loss: 0.044091\n",
      "Epoch 475/750 - Train pg Loss: 12.949666 - Test Loss: 2.492908\n",
      "\n",
      "\n",
      "Epoch 476/750 - Train Cd Loss: 0.072955 - Test Loss: 0.039477\n",
      "Epoch 476/750 - Train pg Loss: 15.352404 - Test Loss: 3.508213\n",
      "\n",
      "\n",
      "Epoch 477/750 - Train Cd Loss: 0.057453 - Test Loss: 0.043512\n",
      "Epoch 477/750 - Train pg Loss: 15.409048 - Test Loss: 2.933849\n",
      "\n",
      "\n",
      "Epoch 478/750 - Train Cd Loss: 0.060391 - Test Loss: 0.038006\n",
      "Epoch 478/750 - Train pg Loss: 15.368631 - Test Loss: 2.952359\n",
      "\n",
      "\n",
      "Epoch 479/750 - Train Cd Loss: 0.085845 - Test Loss: 0.039944\n",
      "Epoch 479/750 - Train pg Loss: 14.480831 - Test Loss: 2.912317\n",
      "\n",
      "\n",
      "Epoch 480/750 - Train Cd Loss: 0.065042 - Test Loss: 0.042705\n",
      "Epoch 480/750 - Train pg Loss: 14.769805 - Test Loss: 3.002736\n",
      "\n",
      "\n",
      "Epoch 481/750 - Train Cd Loss: 0.058992 - Test Loss: 0.039029\n",
      "Epoch 481/750 - Train pg Loss: 14.262778 - Test Loss: 2.965532\n",
      "\n",
      "\n",
      "Epoch 482/750 - Train Cd Loss: 0.070561 - Test Loss: 0.041373\n",
      "Epoch 482/750 - Train pg Loss: 15.257755 - Test Loss: 2.379227\n",
      "\n",
      "\n",
      "Epoch 483/750 - Train Cd Loss: 0.062008 - Test Loss: 0.041479\n",
      "Epoch 483/750 - Train pg Loss: 14.550285 - Test Loss: 2.763203\n",
      "\n",
      "\n",
      "Epoch 484/750 - Train Cd Loss: 0.056512 - Test Loss: 0.038204\n",
      "Epoch 484/750 - Train pg Loss: 16.350658 - Test Loss: 3.073650\n",
      "\n",
      "\n",
      "Epoch 485/750 - Train Cd Loss: 0.059506 - Test Loss: 0.040312\n",
      "Epoch 485/750 - Train pg Loss: 17.043459 - Test Loss: 3.336574\n",
      "\n",
      "\n",
      "Epoch 486/750 - Train Cd Loss: 0.073792 - Test Loss: 0.037304\n",
      "Epoch 486/750 - Train pg Loss: 20.589327 - Test Loss: 3.402789\n",
      "\n",
      "\n",
      "Epoch 487/750 - Train Cd Loss: 0.065664 - Test Loss: 0.041774\n",
      "Epoch 487/750 - Train pg Loss: 16.140745 - Test Loss: 2.874402\n",
      "\n",
      "\n",
      "Epoch 488/750 - Train Cd Loss: 0.058261 - Test Loss: 0.043160\n",
      "Epoch 488/750 - Train pg Loss: 14.641792 - Test Loss: 2.679911\n",
      "\n",
      "\n",
      "Epoch 489/750 - Train Cd Loss: 0.054193 - Test Loss: 0.039388\n",
      "Epoch 489/750 - Train pg Loss: 15.923780 - Test Loss: 2.987925\n",
      "\n",
      "\n",
      "Epoch 490/750 - Train Cd Loss: 0.056041 - Test Loss: 0.038710\n",
      "Epoch 490/750 - Train pg Loss: 16.029991 - Test Loss: 3.555142\n",
      "\n",
      "\n",
      "Epoch 491/750 - Train Cd Loss: 0.061352 - Test Loss: nan\n",
      "Epoch 491/750 - Train pg Loss: 18.567680 - Test Loss: 4.377781\n",
      "\n",
      "\n",
      "Epoch 492/750 - Train Cd Loss: 0.084199 - Test Loss: 0.038622\n",
      "Epoch 492/750 - Train pg Loss: 22.505253 - Test Loss: 4.321519\n",
      "\n",
      "\n",
      "Epoch 493/750 - Train Cd Loss: 0.070999 - Test Loss: 0.036875\n",
      "Epoch 493/750 - Train pg Loss: 23.686287 - Test Loss: 4.273569\n",
      "\n",
      "\n",
      "Epoch 494/750 - Train Cd Loss: 0.065991 - Test Loss: 0.041467\n",
      "Epoch 494/750 - Train pg Loss: 18.802254 - Test Loss: 3.110394\n",
      "\n",
      "\n",
      "Epoch 495/750 - Train Cd Loss: 0.055933 - Test Loss: 0.042183\n",
      "Epoch 495/750 - Train pg Loss: 16.121765 - Test Loss: 3.186120\n",
      "\n",
      "\n",
      "Epoch 496/750 - Train Cd Loss: 0.055478 - Test Loss: 0.039326\n",
      "Epoch 496/750 - Train pg Loss: 18.743235 - Test Loss: 3.285643\n",
      "\n",
      "\n",
      "Epoch 497/750 - Train Cd Loss: 0.059745 - Test Loss: 0.038758\n",
      "Epoch 497/750 - Train pg Loss: 15.416189 - Test Loss: 2.946996\n",
      "\n",
      "\n",
      "Epoch 498/750 - Train Cd Loss: 0.066471 - Test Loss: 0.038996\n",
      "Epoch 498/750 - Train pg Loss: 18.450565 - Test Loss: 3.684403\n",
      "\n",
      "\n",
      "Epoch 499/750 - Train Cd Loss: 0.053925 - Test Loss: 0.043252\n",
      "Epoch 499/750 - Train pg Loss: 17.219955 - Test Loss: 3.119527\n",
      "\n",
      "\n",
      "Epoch 500/750 - Train Cd Loss: 0.065196 - Test Loss: 0.040987\n",
      "Epoch 500/750 - Train pg Loss: 15.937590 - Test Loss: 3.494807\n",
      "\n",
      "\n",
      "Epoch 501/750 - Train Cd Loss: 0.060413 - Test Loss: 0.043162\n",
      "Epoch 501/750 - Train pg Loss: 19.801941 - Test Loss: 3.882287\n",
      "\n",
      "\n",
      "Epoch 502/750 - Train Cd Loss: 0.067320 - Test Loss: 0.039860\n",
      "Epoch 502/750 - Train pg Loss: 21.031885 - Test Loss: 3.967710\n",
      "\n",
      "\n",
      "Epoch 503/750 - Train Cd Loss: 0.054209 - Test Loss: 0.041998\n",
      "Epoch 503/750 - Train pg Loss: 22.472918 - Test Loss: 3.316948\n",
      "\n",
      "\n",
      "Epoch 504/750 - Train Cd Loss: 0.078027 - Test Loss: 0.040587\n",
      "Epoch 504/750 - Train pg Loss: 21.901718 - Test Loss: 4.165234\n",
      "\n",
      "\n",
      "Epoch 505/750 - Train Cd Loss: 0.055381 - Test Loss: 0.041095\n",
      "Epoch 505/750 - Train pg Loss: 17.037519 - Test Loss: 2.980759\n",
      "\n",
      "\n",
      "Epoch 506/750 - Train Cd Loss: 0.053465 - Test Loss: 0.044356\n",
      "Epoch 506/750 - Train pg Loss: 15.635376 - Test Loss: 2.680455\n",
      "\n",
      "\n",
      "Epoch 507/750 - Train Cd Loss: 0.075399 - Test Loss: 0.036513\n",
      "Epoch 507/750 - Train pg Loss: 17.708792 - Test Loss: 3.397784\n",
      "\n",
      "\n",
      "Epoch 508/750 - Train Cd Loss: 0.058558 - Test Loss: 0.039987\n",
      "Epoch 508/750 - Train pg Loss: 20.184362 - Test Loss: 3.802270\n",
      "\n",
      "\n",
      "Epoch 509/750 - Train Cd Loss: 0.066504 - Test Loss: 0.043869\n",
      "Epoch 509/750 - Train pg Loss: 18.655895 - Test Loss: 2.988630\n",
      "\n",
      "\n",
      "Epoch 510/750 - Train Cd Loss: 0.054773 - Test Loss: 0.041163\n",
      "Epoch 510/750 - Train pg Loss: 18.261086 - Test Loss: 3.592113\n",
      "\n",
      "\n",
      "Epoch 511/750 - Train Cd Loss: 0.057736 - Test Loss: 0.042688\n",
      "Epoch 511/750 - Train pg Loss: 18.484663 - Test Loss: 3.140829\n",
      "\n",
      "\n",
      "Epoch 512/750 - Train Cd Loss: 0.056976 - Test Loss: 0.039604\n",
      "Epoch 512/750 - Train pg Loss: 19.566202 - Test Loss: 4.068352\n",
      "\n",
      "\n",
      "Epoch 513/750 - Train Cd Loss: 0.057096 - Test Loss: 0.038007\n",
      "Epoch 513/750 - Train pg Loss: 22.229568 - Test Loss: 3.841331\n",
      "\n",
      "\n",
      "Epoch 514/750 - Train Cd Loss: 0.052720 - Test Loss: 0.039653\n",
      "Epoch 514/750 - Train pg Loss: 18.212257 - Test Loss: 3.195390\n",
      "\n",
      "\n",
      "Epoch 515/750 - Train Cd Loss: 0.058351 - Test Loss: 0.040834\n",
      "Epoch 515/750 - Train pg Loss: 16.088343 - Test Loss: 3.376571\n",
      "\n",
      "\n",
      "Epoch 516/750 - Train Cd Loss: 0.062011 - Test Loss: 0.043228\n",
      "Epoch 516/750 - Train pg Loss: 16.440126 - Test Loss: 2.833061\n",
      "\n",
      "\n",
      "Epoch 517/750 - Train Cd Loss: 0.073561 - Test Loss: nan\n",
      "Epoch 517/750 - Train pg Loss: 15.340544 - Test Loss: 4.481467\n",
      "\n",
      "\n",
      "Epoch 518/750 - Train Cd Loss: 0.066372 - Test Loss: 0.040449\n",
      "Epoch 518/750 - Train pg Loss: 21.649729 - Test Loss: 3.807610\n",
      "\n",
      "\n",
      "Epoch 519/750 - Train Cd Loss: 0.057630 - Test Loss: 0.037563\n",
      "Epoch 519/750 - Train pg Loss: 16.489372 - Test Loss: 3.331304\n",
      "\n",
      "\n",
      "Epoch 520/750 - Train Cd Loss: 0.060293 - Test Loss: 0.040594\n",
      "Epoch 520/750 - Train pg Loss: 18.520786 - Test Loss: 3.216219\n",
      "\n",
      "\n",
      "Epoch 521/750 - Train Cd Loss: 0.055950 - Test Loss: 0.042076\n",
      "Epoch 521/750 - Train pg Loss: 19.000015 - Test Loss: 3.506866\n",
      "\n",
      "\n",
      "Epoch 522/750 - Train Cd Loss: 0.073720 - Test Loss: 0.035463\n",
      "Epoch 522/750 - Train pg Loss: 18.419060 - Test Loss: 3.622575\n",
      "\n",
      "\n",
      "Epoch 523/750 - Train Cd Loss: 0.053522 - Test Loss: 0.037891\n",
      "Epoch 523/750 - Train pg Loss: 20.388092 - Test Loss: 4.002185\n",
      "\n",
      "\n",
      "Epoch 524/750 - Train Cd Loss: 0.056727 - Test Loss: 0.043342\n",
      "Epoch 524/750 - Train pg Loss: 21.284218 - Test Loss: 3.328988\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 525/750 - Train Cd Loss: 0.070697 - Test Loss: 0.040766\n",
      "Epoch 525/750 - Train pg Loss: 18.452019 - Test Loss: 3.413615\n",
      "\n",
      "\n",
      "Epoch 526/750 - Train Cd Loss: 0.046964 - Test Loss: 0.040543\n",
      "Epoch 526/750 - Train pg Loss: 17.905264 - Test Loss: 3.412104\n",
      "\n",
      "\n",
      "Epoch 527/750 - Train Cd Loss: 0.059590 - Test Loss: 0.039115\n",
      "Epoch 527/750 - Train pg Loss: 19.780153 - Test Loss: 3.306310\n",
      "\n",
      "\n",
      "Epoch 528/750 - Train Cd Loss: 0.079577 - Test Loss: 0.038277\n",
      "Epoch 528/750 - Train pg Loss: 20.408089 - Test Loss: 3.836783\n",
      "\n",
      "\n",
      "Epoch 529/750 - Train Cd Loss: 0.054731 - Test Loss: 0.039353\n",
      "Epoch 529/750 - Train pg Loss: 23.211706 - Test Loss: 4.372019\n",
      "\n",
      "\n",
      "Epoch 530/750 - Train Cd Loss: 0.052693 - Test Loss: 0.041701\n",
      "Epoch 530/750 - Train pg Loss: 20.316296 - Test Loss: 3.636950\n",
      "\n",
      "\n",
      "Epoch 531/750 - Train Cd Loss: 0.061360 - Test Loss: 0.040079\n",
      "Epoch 531/750 - Train pg Loss: 18.569759 - Test Loss: 3.702411\n",
      "\n",
      "\n",
      "Epoch 532/750 - Train Cd Loss: 0.066405 - Test Loss: 0.037489\n",
      "Epoch 532/750 - Train pg Loss: 19.330359 - Test Loss: 3.447152\n",
      "\n",
      "\n",
      "Epoch 533/750 - Train Cd Loss: 0.050730 - Test Loss: 0.040680\n",
      "Epoch 533/750 - Train pg Loss: 20.208370 - Test Loss: 3.156944\n",
      "\n",
      "\n",
      "Epoch 534/750 - Train Cd Loss: 0.052422 - Test Loss: 0.038537\n",
      "Epoch 534/750 - Train pg Loss: 19.460869 - Test Loss: 3.181887\n",
      "\n",
      "\n",
      "Epoch 535/750 - Train Cd Loss: 0.046618 - Test Loss: 0.040367\n",
      "Epoch 535/750 - Train pg Loss: 16.555189 - Test Loss: 2.982320\n",
      "\n",
      "\n",
      "Epoch 536/750 - Train Cd Loss: 0.045009 - Test Loss: 0.039669\n",
      "Epoch 536/750 - Train pg Loss: 17.808516 - Test Loss: 3.311482\n",
      "\n",
      "\n",
      "Epoch 537/750 - Train Cd Loss: 0.053614 - Test Loss: nan\n",
      "Epoch 537/750 - Train pg Loss: 19.372143 - Test Loss: 4.131176\n",
      "\n",
      "\n",
      "Epoch 538/750 - Train Cd Loss: 0.077614 - Test Loss: 0.039261\n",
      "Epoch 538/750 - Train pg Loss: 19.416826 - Test Loss: 3.681066\n",
      "\n",
      "\n",
      "Epoch 539/750 - Train Cd Loss: 0.055082 - Test Loss: 0.042631\n",
      "Epoch 539/750 - Train pg Loss: 19.237366 - Test Loss: 3.409771\n",
      "\n",
      "\n",
      "Epoch 540/750 - Train Cd Loss: 0.053171 - Test Loss: 0.039965\n",
      "Epoch 540/750 - Train pg Loss: 17.475517 - Test Loss: 3.480183\n",
      "\n",
      "\n",
      "Epoch 541/750 - Train Cd Loss: 0.073269 - Test Loss: 0.036884\n",
      "Epoch 541/750 - Train pg Loss: 21.029957 - Test Loss: 4.267190\n",
      "\n",
      "\n",
      "Epoch 542/750 - Train Cd Loss: 0.050942 - Test Loss: 0.039297\n",
      "Epoch 542/750 - Train pg Loss: 23.959465 - Test Loss: 4.398070\n",
      "\n",
      "\n",
      "Epoch 543/750 - Train Cd Loss: 0.064183 - Test Loss: 0.044435\n",
      "Epoch 543/750 - Train pg Loss: 21.318733 - Test Loss: 3.508843\n",
      "\n",
      "\n",
      "Epoch 544/750 - Train Cd Loss: 0.065333 - Test Loss: 0.039321\n",
      "Epoch 544/750 - Train pg Loss: 21.901821 - Test Loss: 5.175750\n",
      "\n",
      "\n",
      "Epoch 545/750 - Train Cd Loss: 0.051061 - Test Loss: 0.039780\n",
      "Epoch 545/750 - Train pg Loss: 26.711302 - Test Loss: 4.751240\n",
      "\n",
      "\n",
      "Epoch 546/750 - Train Cd Loss: 0.044548 - Test Loss: nan\n",
      "Epoch 546/750 - Train pg Loss: 27.210300 - Test Loss: 5.745574\n",
      "\n",
      "\n",
      "Epoch 547/750 - Train Cd Loss: 0.053288 - Test Loss: 0.036100\n",
      "Epoch 547/750 - Train pg Loss: 23.068729 - Test Loss: 4.318036\n",
      "\n",
      "\n",
      "Epoch 548/750 - Train Cd Loss: 0.074841 - Test Loss: 0.036845\n",
      "Epoch 548/750 - Train pg Loss: 28.089945 - Test Loss: 5.265965\n",
      "\n",
      "\n",
      "Epoch 549/750 - Train Cd Loss: 0.051163 - Test Loss: 0.037722\n",
      "Epoch 549/750 - Train pg Loss: 28.059822 - Test Loss: 4.349692\n",
      "\n",
      "\n",
      "Epoch 550/750 - Train Cd Loss: 0.051136 - Test Loss: nan\n",
      "Epoch 550/750 - Train pg Loss: 21.274536 - Test Loss: 4.037119\n",
      "\n",
      "\n",
      "Epoch 551/750 - Train Cd Loss: 0.059346 - Test Loss: 0.037796\n",
      "Epoch 551/750 - Train pg Loss: 23.927908 - Test Loss: 4.430988\n",
      "\n",
      "\n",
      "Epoch 552/750 - Train Cd Loss: 0.058685 - Test Loss: nan\n",
      "Epoch 552/750 - Train pg Loss: 21.368637 - Test Loss: 5.282065\n",
      "\n",
      "\n",
      "Epoch 553/750 - Train Cd Loss: 0.049218 - Test Loss: nan\n",
      "Epoch 553/750 - Train pg Loss: 20.759016 - Test Loss: 4.531033\n",
      "\n",
      "\n",
      "Epoch 554/750 - Train Cd Loss: 0.074306 - Test Loss: 0.035548\n",
      "Epoch 554/750 - Train pg Loss: 24.560871 - Test Loss: 4.988522\n",
      "\n",
      "\n",
      "Epoch 555/750 - Train Cd Loss: 0.051118 - Test Loss: nan\n",
      "Epoch 555/750 - Train pg Loss: 24.590542 - Test Loss: 4.204301\n",
      "\n",
      "\n",
      "Epoch 556/750 - Train Cd Loss: 0.061570 - Test Loss: 0.043528\n",
      "Epoch 556/750 - Train pg Loss: 19.974165 - Test Loss: 3.392970\n",
      "\n",
      "\n",
      "Epoch 557/750 - Train Cd Loss: 0.059263 - Test Loss: 0.037378\n",
      "Epoch 557/750 - Train pg Loss: 19.996635 - Test Loss: 4.686817\n",
      "\n",
      "\n",
      "Epoch 558/750 - Train Cd Loss: 0.048192 - Test Loss: nan\n",
      "Epoch 558/750 - Train pg Loss: 22.172220 - Test Loss: 5.080544\n",
      "\n",
      "\n",
      "Epoch 559/750 - Train Cd Loss: 0.060860 - Test Loss: 0.035522\n",
      "Epoch 559/750 - Train pg Loss: 18.344378 - Test Loss: 4.061657\n",
      "\n",
      "\n",
      "Epoch 560/750 - Train Cd Loss: 0.066275 - Test Loss: 0.037329\n",
      "Epoch 560/750 - Train pg Loss: 25.462320 - Test Loss: 4.126407\n",
      "\n",
      "\n",
      "Epoch 561/750 - Train Cd Loss: 0.041618 - Test Loss: nan\n",
      "Epoch 561/750 - Train pg Loss: 18.781128 - Test Loss: 4.669185\n",
      "\n",
      "\n",
      "Epoch 562/750 - Train Cd Loss: 0.070978 - Test Loss: 0.037409\n",
      "Epoch 562/750 - Train pg Loss: 17.894531 - Test Loss: 4.351484\n",
      "\n",
      "\n",
      "Epoch 563/750 - Train Cd Loss: 0.058047 - Test Loss: 0.041490\n",
      "Epoch 563/750 - Train pg Loss: 22.638365 - Test Loss: 4.168751\n",
      "\n",
      "\n",
      "Epoch 564/750 - Train Cd Loss: 0.046484 - Test Loss: 0.036306\n",
      "Epoch 564/750 - Train pg Loss: 21.457085 - Test Loss: 3.694454\n",
      "\n",
      "\n",
      "Epoch 565/750 - Train Cd Loss: 0.061327 - Test Loss: 0.034480\n",
      "Epoch 565/750 - Train pg Loss: 22.607924 - Test Loss: 4.292059\n",
      "\n",
      "\n",
      "Epoch 566/750 - Train Cd Loss: 0.062092 - Test Loss: 0.039749\n",
      "Epoch 566/750 - Train pg Loss: 23.072668 - Test Loss: 3.856877\n",
      "\n",
      "\n",
      "Epoch 567/750 - Train Cd Loss: 0.050378 - Test Loss: 0.036450\n",
      "Epoch 567/750 - Train pg Loss: 18.315414 - Test Loss: 3.356847\n",
      "\n",
      "\n",
      "Epoch 568/750 - Train Cd Loss: 0.049239 - Test Loss: 0.037521\n",
      "Epoch 568/750 - Train pg Loss: 19.256193 - Test Loss: 3.444151\n",
      "\n",
      "\n",
      "Epoch 569/750 - Train Cd Loss: 0.062035 - Test Loss: 0.037892\n",
      "Epoch 569/750 - Train pg Loss: 17.282286 - Test Loss: 3.238760\n",
      "\n",
      "\n",
      "Epoch 570/750 - Train Cd Loss: 0.058704 - Test Loss: 0.038919\n",
      "Epoch 570/750 - Train pg Loss: 23.420183 - Test Loss: 4.753860\n",
      "\n",
      "\n",
      "Epoch 571/750 - Train Cd Loss: 0.048814 - Test Loss: 0.039486\n",
      "Epoch 571/750 - Train pg Loss: 25.196932 - Test Loss: 3.955340\n",
      "\n",
      "\n",
      "Epoch 572/750 - Train Cd Loss: 0.057827 - Test Loss: 0.038845\n",
      "Epoch 572/750 - Train pg Loss: 20.527807 - Test Loss: 3.985944\n",
      "\n",
      "\n",
      "Epoch 573/750 - Train Cd Loss: 0.046598 - Test Loss: 0.038682\n",
      "Epoch 573/750 - Train pg Loss: 19.610451 - Test Loss: 4.072894\n",
      "\n",
      "\n",
      "Epoch 574/750 - Train Cd Loss: 0.068558 - Test Loss: 0.037994\n",
      "Epoch 574/750 - Train pg Loss: 26.280647 - Test Loss: 6.153897\n",
      "\n",
      "\n",
      "Epoch 575/750 - Train Cd Loss: 0.061477 - Test Loss: 0.040216\n",
      "Epoch 575/750 - Train pg Loss: 33.000351 - Test Loss: 4.124744\n",
      "\n",
      "\n",
      "Epoch 576/750 - Train Cd Loss: 0.055175 - Test Loss: nan\n",
      "Epoch 576/750 - Train pg Loss: 17.712551 - Test Loss: 4.459810\n",
      "\n",
      "\n",
      "Epoch 577/750 - Train Cd Loss: 0.067675 - Test Loss: nan\n",
      "Epoch 577/750 - Train pg Loss: 22.571016 - Test Loss: 4.363634\n",
      "\n",
      "\n",
      "Epoch 578/750 - Train Cd Loss: 0.052271 - Test Loss: 0.034985\n",
      "Epoch 578/750 - Train pg Loss: 22.950747 - Test Loss: 3.942508\n",
      "\n",
      "\n",
      "Epoch 579/750 - Train Cd Loss: 0.059568 - Test Loss: 0.038744\n",
      "Epoch 579/750 - Train pg Loss: 20.275375 - Test Loss: 3.945148\n",
      "\n",
      "\n",
      "Epoch 580/750 - Train Cd Loss: 0.067187 - Test Loss: 0.040676\n",
      "Epoch 580/750 - Train pg Loss: 21.063995 - Test Loss: 3.344784\n",
      "\n",
      "\n",
      "Epoch 581/750 - Train Cd Loss: 0.047320 - Test Loss: 0.037902\n",
      "Epoch 581/750 - Train pg Loss: 16.885221 - Test Loss: 3.453672\n",
      "\n",
      "\n",
      "Epoch 582/750 - Train Cd Loss: 0.057989 - Test Loss: nan\n",
      "Epoch 582/750 - Train pg Loss: 17.486053 - Test Loss: 3.976922\n",
      "\n",
      "\n",
      "Epoch 583/750 - Train Cd Loss: 0.054291 - Test Loss: 0.039405\n",
      "Epoch 583/750 - Train pg Loss: 18.486012 - Test Loss: 4.119005\n",
      "\n",
      "\n",
      "Epoch 584/750 - Train Cd Loss: 0.049000 - Test Loss: 0.038679\n",
      "Epoch 584/750 - Train pg Loss: 22.386568 - Test Loss: 3.806327\n",
      "\n",
      "\n",
      "Epoch 585/750 - Train Cd Loss: 0.060386 - Test Loss: 0.036914\n",
      "Epoch 585/750 - Train pg Loss: 18.970928 - Test Loss: 4.180219\n",
      "\n",
      "\n",
      "Epoch 586/750 - Train Cd Loss: 0.049203 - Test Loss: 0.037621\n",
      "Epoch 586/750 - Train pg Loss: 24.819574 - Test Loss: 4.667451\n",
      "\n",
      "\n",
      "Epoch 587/750 - Train Cd Loss: 0.060475 - Test Loss: 0.034746\n",
      "Epoch 587/750 - Train pg Loss: 26.509895 - Test Loss: 5.357650\n",
      "\n",
      "\n",
      "Epoch 588/750 - Train Cd Loss: 0.064125 - Test Loss: nan\n",
      "Epoch 588/750 - Train pg Loss: 25.246469 - Test Loss: 5.248549\n",
      "\n",
      "\n",
      "Epoch 589/750 - Train Cd Loss: 0.050758 - Test Loss: 0.038674\n",
      "Epoch 589/750 - Train pg Loss: 22.250469 - Test Loss: 4.737796\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 590/750 - Train Cd Loss: 0.046532 - Test Loss: 0.040660\n",
      "Epoch 590/750 - Train pg Loss: 26.625195 - Test Loss: 4.187876\n",
      "\n",
      "\n",
      "Epoch 591/750 - Train Cd Loss: 0.058114 - Test Loss: 0.036715\n",
      "Epoch 591/750 - Train pg Loss: 20.658764 - Test Loss: 3.770875\n",
      "\n",
      "\n",
      "Epoch 592/750 - Train Cd Loss: 0.047564 - Test Loss: 0.038118\n",
      "Epoch 592/750 - Train pg Loss: 22.514734 - Test Loss: 3.910379\n",
      "\n",
      "\n",
      "Epoch 593/750 - Train Cd Loss: 0.058156 - Test Loss: 0.036797\n",
      "Epoch 593/750 - Train pg Loss: 22.767742 - Test Loss: 4.410043\n",
      "\n",
      "\n",
      "Epoch 594/750 - Train Cd Loss: 0.047949 - Test Loss: 0.038273\n",
      "Epoch 594/750 - Train pg Loss: 22.690771 - Test Loss: 4.516409\n",
      "\n",
      "\n",
      "Epoch 595/750 - Train Cd Loss: 0.046063 - Test Loss: 0.034695\n",
      "Epoch 595/750 - Train pg Loss: 22.229288 - Test Loss: 5.289990\n",
      "\n",
      "\n",
      "Epoch 596/750 - Train Cd Loss: 0.054299 - Test Loss: 0.035646\n",
      "Epoch 596/750 - Train pg Loss: 26.983227 - Test Loss: 5.466189\n",
      "\n",
      "\n",
      "Epoch 597/750 - Train Cd Loss: 0.049515 - Test Loss: 0.036216\n",
      "Epoch 597/750 - Train pg Loss: 27.506765 - Test Loss: 4.921320\n",
      "\n",
      "\n",
      "Epoch 598/750 - Train Cd Loss: 0.046764 - Test Loss: nan\n",
      "Epoch 598/750 - Train pg Loss: 26.690737 - Test Loss: 4.915008\n",
      "\n",
      "\n",
      "Epoch 599/750 - Train Cd Loss: 0.070724 - Test Loss: 0.038607\n",
      "Epoch 599/750 - Train pg Loss: 29.884653 - Test Loss: 6.066444\n",
      "\n",
      "\n",
      "Epoch 600/750 - Train Cd Loss: 0.043923 - Test Loss: nan\n",
      "Epoch 600/750 - Train pg Loss: 29.122721 - Test Loss: 5.521338\n",
      "\n",
      "\n",
      "Epoch 601/750 - Train Cd Loss: 0.076211 - Test Loss: 0.039230\n",
      "Epoch 601/750 - Train pg Loss: 27.550341 - Test Loss: 4.826556\n",
      "\n",
      "\n",
      "Epoch 602/750 - Train Cd Loss: 0.055813 - Test Loss: 0.038204\n",
      "Epoch 602/750 - Train pg Loss: 27.416851 - Test Loss: 4.841607\n",
      "\n",
      "\n",
      "Epoch 603/750 - Train Cd Loss: 0.044970 - Test Loss: 0.037297\n",
      "Epoch 603/750 - Train pg Loss: 26.048429 - Test Loss: 4.008240\n",
      "\n",
      "\n",
      "Epoch 604/750 - Train Cd Loss: 0.047484 - Test Loss: nan\n",
      "Epoch 604/750 - Train pg Loss: 25.704878 - Test Loss: 5.035289\n",
      "\n",
      "\n",
      "Epoch 605/750 - Train Cd Loss: 0.055284 - Test Loss: 0.037353\n",
      "Epoch 605/750 - Train pg Loss: 27.628811 - Test Loss: 5.076843\n",
      "\n",
      "\n",
      "Epoch 606/750 - Train Cd Loss: 0.049388 - Test Loss: 0.036106\n",
      "Epoch 606/750 - Train pg Loss: 27.231676 - Test Loss: 4.080884\n",
      "\n",
      "\n",
      "Epoch 607/750 - Train Cd Loss: 0.060626 - Test Loss: nan\n",
      "Epoch 607/750 - Train pg Loss: 22.593424 - Test Loss: 5.213852\n",
      "\n",
      "\n",
      "Epoch 608/750 - Train Cd Loss: 0.041980 - Test Loss: nan\n",
      "Epoch 608/750 - Train pg Loss: 25.566118 - Test Loss: 5.380975\n",
      "\n",
      "\n",
      "Epoch 609/750 - Train Cd Loss: 0.049171 - Test Loss: nan\n",
      "Epoch 609/750 - Train pg Loss: 23.501295 - Test Loss: 5.358191\n",
      "\n",
      "\n",
      "Epoch 610/750 - Train Cd Loss: 0.054906 - Test Loss: 0.037913\n",
      "Epoch 610/750 - Train pg Loss: 25.812218 - Test Loss: 4.400373\n",
      "\n",
      "\n",
      "Epoch 611/750 - Train Cd Loss: 0.041130 - Test Loss: nan\n",
      "Epoch 611/750 - Train pg Loss: 25.243954 - Test Loss: 5.211338\n",
      "\n",
      "\n",
      "Epoch 612/750 - Train Cd Loss: 0.045373 - Test Loss: 0.036599\n",
      "Epoch 612/750 - Train pg Loss: 20.977095 - Test Loss: 4.312268\n",
      "\n",
      "\n",
      "Epoch 613/750 - Train Cd Loss: 0.054169 - Test Loss: 0.034012\n",
      "Epoch 613/750 - Train pg Loss: 26.582367 - Test Loss: 4.374697\n",
      "\n",
      "\n",
      "Epoch 614/750 - Train Cd Loss: 0.044400 - Test Loss: 0.038987\n",
      "Epoch 614/750 - Train pg Loss: 24.201120 - Test Loss: 4.137688\n",
      "\n",
      "\n",
      "Epoch 615/750 - Train Cd Loss: 0.054722 - Test Loss: nan\n",
      "Epoch 615/750 - Train pg Loss: 22.475624 - Test Loss: 5.201651\n",
      "\n",
      "\n",
      "Epoch 616/750 - Train Cd Loss: 0.041238 - Test Loss: 0.034390\n",
      "Epoch 616/750 - Train pg Loss: 26.244553 - Test Loss: 4.948477\n",
      "\n",
      "\n",
      "Epoch 617/750 - Train Cd Loss: 0.041916 - Test Loss: 0.037026\n",
      "Epoch 617/750 - Train pg Loss: 22.520348 - Test Loss: 4.769660\n",
      "\n",
      "\n",
      "Epoch 618/750 - Train Cd Loss: 0.062462 - Test Loss: 0.034368\n",
      "Epoch 618/750 - Train pg Loss: 27.170237 - Test Loss: 5.115381\n",
      "\n",
      "\n",
      "Epoch 619/750 - Train Cd Loss: 0.046337 - Test Loss: 0.039131\n",
      "Epoch 619/750 - Train pg Loss: 25.243797 - Test Loss: 4.746088\n",
      "\n",
      "\n",
      "Epoch 620/750 - Train Cd Loss: 0.041892 - Test Loss: nan\n",
      "Epoch 620/750 - Train pg Loss: 26.321962 - Test Loss: 7.043756\n",
      "\n",
      "\n",
      "Epoch 621/750 - Train Cd Loss: 0.046274 - Test Loss: 0.036607\n",
      "Epoch 621/750 - Train pg Loss: 26.156904 - Test Loss: 4.677855\n",
      "\n",
      "\n",
      "Epoch 622/750 - Train Cd Loss: 0.056049 - Test Loss: 0.034519\n",
      "Epoch 622/750 - Train pg Loss: 27.750906 - Test Loss: 5.514877\n",
      "\n",
      "\n",
      "Epoch 623/750 - Train Cd Loss: 0.045898 - Test Loss: 0.035525\n",
      "Epoch 623/750 - Train pg Loss: 28.217684 - Test Loss: 4.980579\n",
      "\n",
      "\n",
      "Epoch 624/750 - Train Cd Loss: 0.055495 - Test Loss: 0.037359\n",
      "Epoch 624/750 - Train pg Loss: 27.644432 - Test Loss: 4.382864\n",
      "\n",
      "\n",
      "Epoch 625/750 - Train Cd Loss: 0.044803 - Test Loss: nan\n",
      "Epoch 625/750 - Train pg Loss: 25.751438 - Test Loss: 4.952603\n",
      "\n",
      "\n",
      "Epoch 626/750 - Train Cd Loss: 0.040438 - Test Loss: nan\n",
      "Epoch 626/750 - Train pg Loss: 26.082939 - Test Loss: 5.199142\n",
      "\n",
      "\n",
      "Epoch 627/750 - Train Cd Loss: 0.042004 - Test Loss: nan\n",
      "Epoch 627/750 - Train pg Loss: 24.146076 - Test Loss: 4.333228\n",
      "\n",
      "\n",
      "Epoch 628/750 - Train Cd Loss: 0.075675 - Test Loss: 0.035004\n",
      "Epoch 628/750 - Train pg Loss: 21.749819 - Test Loss: 5.280407\n",
      "\n",
      "\n",
      "Epoch 629/750 - Train Cd Loss: 0.062021 - Test Loss: 0.033015\n",
      "Epoch 629/750 - Train pg Loss: 30.447666 - Test Loss: 5.337733\n",
      "\n",
      "\n",
      "Epoch 630/750 - Train Cd Loss: 0.038832 - Test Loss: 0.034872\n",
      "Epoch 630/750 - Train pg Loss: 25.931263 - Test Loss: 4.854634\n",
      "\n",
      "\n",
      "Epoch 631/750 - Train Cd Loss: 0.054698 - Test Loss: 0.036530\n",
      "Epoch 631/750 - Train pg Loss: 29.257471 - Test Loss: 4.800984\n",
      "\n",
      "\n",
      "Epoch 632/750 - Train Cd Loss: 0.058078 - Test Loss: 0.033789\n",
      "Epoch 632/750 - Train pg Loss: 23.328035 - Test Loss: 5.157064\n",
      "\n",
      "\n",
      "Epoch 633/750 - Train Cd Loss: 0.054302 - Test Loss: 0.034063\n",
      "Epoch 633/750 - Train pg Loss: 31.814791 - Test Loss: 5.802448\n",
      "\n",
      "\n",
      "Epoch 634/750 - Train Cd Loss: 0.047642 - Test Loss: 0.037913\n",
      "Epoch 634/750 - Train pg Loss: 26.398945 - Test Loss: 4.747053\n",
      "\n",
      "\n",
      "Epoch 635/750 - Train Cd Loss: 0.037651 - Test Loss: 0.033406\n",
      "Epoch 635/750 - Train pg Loss: 25.829094 - Test Loss: 4.780189\n",
      "\n",
      "\n",
      "Epoch 636/750 - Train Cd Loss: 0.070300 - Test Loss: 0.037153\n",
      "Epoch 636/750 - Train pg Loss: 26.636198 - Test Loss: 5.939137\n",
      "\n",
      "\n",
      "Epoch 637/750 - Train Cd Loss: 0.049360 - Test Loss: nan\n",
      "Epoch 637/750 - Train pg Loss: 25.311508 - Test Loss: 5.013123\n",
      "\n",
      "\n",
      "Epoch 638/750 - Train Cd Loss: 0.042189 - Test Loss: 0.037607\n",
      "Epoch 638/750 - Train pg Loss: 22.169506 - Test Loss: 4.184986\n",
      "\n",
      "\n",
      "Epoch 639/750 - Train Cd Loss: 0.059018 - Test Loss: nan\n",
      "Epoch 639/750 - Train pg Loss: 24.922377 - Test Loss: 4.958300\n",
      "\n",
      "\n",
      "Epoch 640/750 - Train Cd Loss: 0.039246 - Test Loss: 0.033911\n",
      "Epoch 640/750 - Train pg Loss: 23.966763 - Test Loss: 4.384474\n",
      "\n",
      "\n",
      "Epoch 641/750 - Train Cd Loss: 0.034870 - Test Loss: 0.033283\n",
      "Epoch 641/750 - Train pg Loss: 23.126011 - Test Loss: 4.618774\n",
      "\n",
      "\n",
      "Epoch 642/750 - Train Cd Loss: 0.062951 - Test Loss: 0.036046\n",
      "Epoch 642/750 - Train pg Loss: 26.972080 - Test Loss: 4.198422\n",
      "\n",
      "\n",
      "Epoch 643/750 - Train Cd Loss: 0.036808 - Test Loss: nan\n",
      "Epoch 643/750 - Train pg Loss: 20.317211 - Test Loss: 5.224605\n",
      "\n",
      "\n",
      "Epoch 644/750 - Train Cd Loss: 0.077226 - Test Loss: 0.036095\n",
      "Epoch 644/750 - Train pg Loss: 24.812006 - Test Loss: 4.451306\n",
      "\n",
      "\n",
      "Epoch 645/750 - Train Cd Loss: 0.042897 - Test Loss: 0.037218\n",
      "Epoch 645/750 - Train pg Loss: 21.939636 - Test Loss: 4.022468\n",
      "\n",
      "\n",
      "Epoch 646/750 - Train Cd Loss: 0.039259 - Test Loss: 0.034853\n",
      "Epoch 646/750 - Train pg Loss: 22.395761 - Test Loss: 4.142013\n",
      "\n",
      "\n",
      "Epoch 647/750 - Train Cd Loss: 0.059138 - Test Loss: nan\n",
      "Epoch 647/750 - Train pg Loss: 22.725840 - Test Loss: 4.815514\n",
      "\n",
      "\n",
      "Epoch 648/750 - Train Cd Loss: 0.053254 - Test Loss: 0.035726\n",
      "Epoch 648/750 - Train pg Loss: 20.787863 - Test Loss: 4.647362\n",
      "\n",
      "\n",
      "Epoch 649/750 - Train Cd Loss: 0.040665 - Test Loss: 0.032336\n",
      "Epoch 649/750 - Train pg Loss: 24.184057 - Test Loss: 4.430165\n",
      "\n",
      "\n",
      "Epoch 650/750 - Train Cd Loss: 0.038532 - Test Loss: 0.035518\n",
      "Epoch 650/750 - Train pg Loss: 25.225460 - Test Loss: 4.579567\n",
      "\n",
      "\n",
      "Epoch 651/750 - Train Cd Loss: 0.067740 - Test Loss: nan\n",
      "Epoch 651/750 - Train pg Loss: 23.696764 - Test Loss: 4.870265\n",
      "\n",
      "\n",
      "Epoch 652/750 - Train Cd Loss: 0.038194 - Test Loss: nan\n",
      "Epoch 652/750 - Train pg Loss: 21.287664 - Test Loss: 5.138937\n",
      "\n",
      "\n",
      "Epoch 653/750 - Train Cd Loss: 0.036927 - Test Loss: nan\n",
      "Epoch 653/750 - Train pg Loss: 21.728743 - Test Loss: 5.621325\n",
      "\n",
      "\n",
      "Epoch 654/750 - Train Cd Loss: 0.056739 - Test Loss: nan\n",
      "Epoch 654/750 - Train pg Loss: 22.895380 - Test Loss: 5.291273\n",
      "\n",
      "\n",
      "Epoch 655/750 - Train Cd Loss: 0.047094 - Test Loss: nan\n",
      "Epoch 655/750 - Train pg Loss: 24.432690 - Test Loss: 4.760966\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 656/750 - Train Cd Loss: 0.039454 - Test Loss: nan\n",
      "Epoch 656/750 - Train pg Loss: 25.338028 - Test Loss: 4.668808\n",
      "\n",
      "\n",
      "Epoch 657/750 - Train Cd Loss: 0.057690 - Test Loss: nan\n",
      "Epoch 657/750 - Train pg Loss: 22.040962 - Test Loss: 4.638951\n",
      "\n",
      "\n",
      "Epoch 658/750 - Train Cd Loss: 0.038118 - Test Loss: nan\n",
      "Epoch 658/750 - Train pg Loss: 23.851646 - Test Loss: 5.303657\n",
      "\n",
      "\n",
      "Epoch 659/750 - Train Cd Loss: 0.056179 - Test Loss: nan\n",
      "Epoch 659/750 - Train pg Loss: 26.323706 - Test Loss: 6.063066\n",
      "\n",
      "\n",
      "Epoch 660/750 - Train Cd Loss: 0.044795 - Test Loss: nan\n",
      "Epoch 660/750 - Train pg Loss: 27.277552 - Test Loss: 5.385563\n",
      "\n",
      "\n",
      "Epoch 661/750 - Train Cd Loss: 0.053046 - Test Loss: 0.032425\n",
      "Epoch 661/750 - Train pg Loss: 30.233814 - Test Loss: 5.623841\n",
      "\n",
      "\n",
      "Epoch 662/750 - Train Cd Loss: 0.046502 - Test Loss: 0.038124\n",
      "Epoch 662/750 - Train pg Loss: 26.459328 - Test Loss: 4.689484\n",
      "\n",
      "\n",
      "Epoch 663/750 - Train Cd Loss: 0.038780 - Test Loss: 0.031892\n",
      "Epoch 663/750 - Train pg Loss: 23.164389 - Test Loss: 4.765088\n",
      "\n",
      "\n",
      "Epoch 664/750 - Train Cd Loss: 0.068085 - Test Loss: 0.034213\n",
      "Epoch 664/750 - Train pg Loss: 28.808310 - Test Loss: 5.294837\n",
      "\n",
      "\n",
      "Epoch 665/750 - Train Cd Loss: 0.042516 - Test Loss: 0.038298\n",
      "Epoch 665/750 - Train pg Loss: 25.177191 - Test Loss: 4.849534\n",
      "\n",
      "\n",
      "Epoch 666/750 - Train Cd Loss: 0.065294 - Test Loss: 0.036327\n",
      "Epoch 666/750 - Train pg Loss: 26.329712 - Test Loss: 5.209034\n",
      "\n",
      "\n",
      "Epoch 667/750 - Train Cd Loss: 0.046786 - Test Loss: 0.036184\n",
      "Epoch 667/750 - Train pg Loss: 27.348396 - Test Loss: 4.117674\n",
      "\n",
      "\n",
      "Epoch 668/750 - Train Cd Loss: 0.045038 - Test Loss: nan\n",
      "Epoch 668/750 - Train pg Loss: 24.103481 - Test Loss: 5.368533\n",
      "\n",
      "\n",
      "Epoch 669/750 - Train Cd Loss: 0.042563 - Test Loss: 0.034118\n",
      "Epoch 669/750 - Train pg Loss: 24.233212 - Test Loss: 4.924421\n",
      "\n",
      "\n",
      "Epoch 670/750 - Train Cd Loss: 0.040696 - Test Loss: 0.035705\n",
      "Epoch 670/750 - Train pg Loss: 22.336159 - Test Loss: 4.093098\n",
      "\n",
      "\n",
      "Epoch 671/750 - Train Cd Loss: 0.041902 - Test Loss: nan\n",
      "Epoch 671/750 - Train pg Loss: 21.725138 - Test Loss: 5.795564\n",
      "\n",
      "\n",
      "Epoch 672/750 - Train Cd Loss: 0.050524 - Test Loss: 0.039035\n",
      "Epoch 672/750 - Train pg Loss: 24.403313 - Test Loss: 4.466633\n",
      "\n",
      "\n",
      "Epoch 673/750 - Train Cd Loss: 0.039253 - Test Loss: 0.038562\n",
      "Epoch 673/750 - Train pg Loss: 26.111908 - Test Loss: 4.375744\n",
      "\n",
      "\n",
      "Epoch 674/750 - Train Cd Loss: 0.064805 - Test Loss: 0.036962\n",
      "Epoch 674/750 - Train pg Loss: 22.880484 - Test Loss: 4.828050\n",
      "\n",
      "\n",
      "Epoch 675/750 - Train Cd Loss: 0.036608 - Test Loss: 0.037467\n",
      "Epoch 675/750 - Train pg Loss: 25.161819 - Test Loss: 4.534999\n",
      "\n",
      "\n",
      "Epoch 676/750 - Train Cd Loss: 0.040104 - Test Loss: 0.037670\n",
      "Epoch 676/750 - Train pg Loss: 23.999512 - Test Loss: 4.226296\n",
      "\n",
      "\n",
      "Epoch 677/750 - Train Cd Loss: 0.040789 - Test Loss: 0.033339\n",
      "Epoch 677/750 - Train pg Loss: 21.264204 - Test Loss: 4.799873\n",
      "\n",
      "\n",
      "Epoch 678/750 - Train Cd Loss: 0.048168 - Test Loss: 0.034265\n",
      "Epoch 678/750 - Train pg Loss: 26.122847 - Test Loss: 5.069113\n",
      "\n",
      "\n",
      "Epoch 679/750 - Train Cd Loss: 0.055186 - Test Loss: 0.031607\n",
      "Epoch 679/750 - Train pg Loss: 24.547272 - Test Loss: 4.938958\n",
      "\n",
      "\n",
      "Epoch 680/750 - Train Cd Loss: 0.039864 - Test Loss: 0.040953\n",
      "Epoch 680/750 - Train pg Loss: 24.785963 - Test Loss: 3.763178\n",
      "\n",
      "\n",
      "Epoch 681/750 - Train Cd Loss: 0.046511 - Test Loss: nan\n",
      "Epoch 681/750 - Train pg Loss: 22.868509 - Test Loss: 5.263123\n",
      "\n",
      "\n",
      "Epoch 682/750 - Train Cd Loss: 0.036020 - Test Loss: 0.034702\n",
      "Epoch 682/750 - Train pg Loss: 26.104774 - Test Loss: 4.653149\n",
      "\n",
      "\n",
      "Epoch 683/750 - Train Cd Loss: 0.035268 - Test Loss: nan\n",
      "Epoch 683/750 - Train pg Loss: 29.508257 - Test Loss: 6.337955\n",
      "\n",
      "\n",
      "Epoch 684/750 - Train Cd Loss: 0.053346 - Test Loss: nan\n",
      "Epoch 684/750 - Train pg Loss: 27.448784 - Test Loss: 5.036819\n",
      "\n",
      "\n",
      "Epoch 685/750 - Train Cd Loss: 0.036853 - Test Loss: 0.032774\n",
      "Epoch 685/750 - Train pg Loss: 26.085424 - Test Loss: 5.470235\n",
      "\n",
      "\n",
      "Epoch 686/750 - Train Cd Loss: 0.040597 - Test Loss: nan\n",
      "Epoch 686/750 - Train pg Loss: 27.377913 - Test Loss: 5.281411\n",
      "\n",
      "\n",
      "Epoch 687/750 - Train Cd Loss: 0.055299 - Test Loss: nan\n",
      "Epoch 687/750 - Train pg Loss: 30.123674 - Test Loss: 5.777425\n",
      "\n",
      "\n",
      "Epoch 688/750 - Train Cd Loss: 0.037213 - Test Loss: nan\n",
      "Epoch 688/750 - Train pg Loss: 26.357168 - Test Loss: 5.883498\n",
      "\n",
      "\n",
      "Epoch 689/750 - Train Cd Loss: 0.049583 - Test Loss: 0.038018\n",
      "Epoch 689/750 - Train pg Loss: 29.339828 - Test Loss: 5.397348\n",
      "\n",
      "\n",
      "Epoch 690/750 - Train Cd Loss: 0.041797 - Test Loss: nan\n",
      "Epoch 690/750 - Train pg Loss: 31.925924 - Test Loss: 5.632938\n",
      "\n",
      "\n",
      "Epoch 691/750 - Train Cd Loss: 0.046664 - Test Loss: nan\n",
      "Epoch 691/750 - Train pg Loss: 25.975933 - Test Loss: 6.697739\n",
      "\n",
      "\n",
      "Epoch 692/750 - Train Cd Loss: 0.037999 - Test Loss: 0.035193\n",
      "Epoch 692/750 - Train pg Loss: 28.795252 - Test Loss: 5.485269\n",
      "\n",
      "\n",
      "Epoch 693/750 - Train Cd Loss: 0.033981 - Test Loss: nan\n",
      "Epoch 693/750 - Train pg Loss: 26.305677 - Test Loss: 6.303155\n",
      "\n",
      "\n",
      "Epoch 694/750 - Train Cd Loss: 0.029084 - Test Loss: nan\n",
      "Epoch 694/750 - Train pg Loss: 29.028370 - Test Loss: 7.509001\n",
      "\n",
      "\n",
      "Epoch 695/750 - Train Cd Loss: 0.051798 - Test Loss: nan\n",
      "Epoch 695/750 - Train pg Loss: 28.449923 - Test Loss: 6.353573\n",
      "\n",
      "\n",
      "Epoch 696/750 - Train Cd Loss: 0.045485 - Test Loss: 0.031951\n",
      "Epoch 696/750 - Train pg Loss: 31.338989 - Test Loss: 5.445263\n",
      "\n",
      "\n",
      "Epoch 697/750 - Train Cd Loss: 0.036704 - Test Loss: nan\n",
      "Epoch 697/750 - Train pg Loss: 25.873230 - Test Loss: 5.345200\n",
      "\n",
      "\n",
      "Epoch 698/750 - Train Cd Loss: 0.033405 - Test Loss: 0.033774\n",
      "Epoch 698/750 - Train pg Loss: 27.481712 - Test Loss: 5.132600\n",
      "\n",
      "\n",
      "Epoch 699/750 - Train Cd Loss: 0.040531 - Test Loss: nan\n",
      "Epoch 699/750 - Train pg Loss: 27.874161 - Test Loss: 6.043006\n",
      "\n",
      "\n",
      "Epoch 700/750 - Train Cd Loss: 0.048095 - Test Loss: nan\n",
      "Epoch 700/750 - Train pg Loss: 32.295834 - Test Loss: 5.956620\n",
      "\n",
      "\n",
      "Epoch 701/750 - Train Cd Loss: 0.046843 - Test Loss: nan\n",
      "Epoch 701/750 - Train pg Loss: 29.719112 - Test Loss: 6.749851\n",
      "\n",
      "\n",
      "Epoch 702/750 - Train Cd Loss: 0.032595 - Test Loss: 0.032020\n",
      "Epoch 702/750 - Train pg Loss: 29.156033 - Test Loss: 5.981633\n",
      "\n",
      "\n",
      "Epoch 703/750 - Train Cd Loss: 0.058231 - Test Loss: 0.035355\n",
      "Epoch 703/750 - Train pg Loss: 27.729177 - Test Loss: 5.086552\n",
      "\n",
      "\n",
      "Epoch 704/750 - Train Cd Loss: 0.036845 - Test Loss: nan\n",
      "Epoch 704/750 - Train pg Loss: 27.538027 - Test Loss: 5.163087\n",
      "\n",
      "\n",
      "Epoch 705/750 - Train Cd Loss: 0.070209 - Test Loss: nan\n",
      "Epoch 705/750 - Train pg Loss: 29.978130 - Test Loss: 5.902490\n",
      "\n",
      "\n",
      "Epoch 706/750 - Train Cd Loss: 0.038394 - Test Loss: 0.035236\n",
      "Epoch 706/750 - Train pg Loss: 26.731047 - Test Loss: 4.625372\n",
      "\n",
      "\n",
      "Epoch 707/750 - Train Cd Loss: 0.044725 - Test Loss: 0.035916\n",
      "Epoch 707/750 - Train pg Loss: 25.275131 - Test Loss: 5.164740\n",
      "\n",
      "\n",
      "Epoch 708/750 - Train Cd Loss: 0.034392 - Test Loss: nan\n",
      "Epoch 708/750 - Train pg Loss: 28.198532 - Test Loss: 5.787133\n",
      "\n",
      "\n",
      "Epoch 709/750 - Train Cd Loss: 0.055477 - Test Loss: 0.037015\n",
      "Epoch 709/750 - Train pg Loss: 30.594278 - Test Loss: 6.177310\n",
      "\n",
      "\n",
      "Epoch 710/750 - Train Cd Loss: 0.050784 - Test Loss: nan\n",
      "Epoch 710/750 - Train pg Loss: 31.249643 - Test Loss: 7.163961\n",
      "\n",
      "\n",
      "Epoch 711/750 - Train Cd Loss: 0.052563 - Test Loss: 0.034554\n",
      "Epoch 711/750 - Train pg Loss: 29.462208 - Test Loss: 5.691140\n",
      "\n",
      "\n",
      "Epoch 712/750 - Train Cd Loss: 0.035054 - Test Loss: nan\n",
      "Epoch 712/750 - Train pg Loss: 34.224354 - Test Loss: 6.952991\n",
      "\n",
      "\n",
      "Epoch 713/750 - Train Cd Loss: 0.047232 - Test Loss: 0.037551\n",
      "Epoch 713/750 - Train pg Loss: 31.354927 - Test Loss: 6.418154\n",
      "\n",
      "\n",
      "Epoch 714/750 - Train Cd Loss: 0.033987 - Test Loss: nan\n",
      "Epoch 714/750 - Train pg Loss: 35.304005 - Test Loss: 6.087477\n",
      "\n",
      "\n",
      "Epoch 715/750 - Train Cd Loss: 0.043686 - Test Loss: 0.034506\n",
      "Epoch 715/750 - Train pg Loss: 30.225973 - Test Loss: 5.915526\n",
      "\n",
      "\n",
      "Epoch 716/750 - Train Cd Loss: 0.054381 - Test Loss: nan\n",
      "Epoch 716/750 - Train pg Loss: 28.732676 - Test Loss: 7.575921\n",
      "\n",
      "\n",
      "Epoch 717/750 - Train Cd Loss: 0.037926 - Test Loss: 0.034891\n",
      "Epoch 717/750 - Train pg Loss: 35.633038 - Test Loss: 6.941656\n",
      "\n",
      "\n",
      "Epoch 718/750 - Train Cd Loss: 0.041327 - Test Loss: nan\n",
      "Epoch 718/750 - Train pg Loss: 35.976711 - Test Loss: 7.009190\n",
      "\n",
      "\n",
      "Epoch 719/750 - Train Cd Loss: 0.053424 - Test Loss: nan\n",
      "Epoch 719/750 - Train pg Loss: 32.375675 - Test Loss: 6.470719\n",
      "\n",
      "\n",
      "Epoch 720/750 - Train Cd Loss: 0.032844 - Test Loss: nan\n",
      "Epoch 720/750 - Train pg Loss: 30.749308 - Test Loss: 6.930413\n",
      "\n",
      "\n",
      "Epoch 721/750 - Train Cd Loss: 0.048612 - Test Loss: nan\n",
      "Epoch 721/750 - Train pg Loss: 32.018024 - Test Loss: 5.624677\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 722/750 - Train Cd Loss: 0.032357 - Test Loss: nan\n",
      "Epoch 722/750 - Train pg Loss: 27.755140 - Test Loss: 6.365408\n",
      "\n",
      "\n",
      "Epoch 723/750 - Train Cd Loss: 0.045502 - Test Loss: nan\n",
      "Epoch 723/750 - Train pg Loss: 32.879574 - Test Loss: 7.105690\n",
      "\n",
      "\n",
      "Epoch 724/750 - Train Cd Loss: 0.062506 - Test Loss: 0.037247\n",
      "Epoch 724/750 - Train pg Loss: 40.602482 - Test Loss: 6.661149\n",
      "\n",
      "\n",
      "Epoch 725/750 - Train Cd Loss: 0.040561 - Test Loss: nan\n",
      "Epoch 725/750 - Train pg Loss: 38.849934 - Test Loss: 7.227386\n",
      "\n",
      "\n",
      "Epoch 726/750 - Train Cd Loss: 0.039060 - Test Loss: nan\n",
      "Epoch 726/750 - Train pg Loss: 29.608810 - Test Loss: 7.743237\n",
      "\n",
      "\n",
      "Epoch 727/750 - Train Cd Loss: 0.035468 - Test Loss: nan\n",
      "Epoch 727/750 - Train pg Loss: 33.903515 - Test Loss: 6.043518\n",
      "\n",
      "\n",
      "Epoch 728/750 - Train Cd Loss: 0.034201 - Test Loss: nan\n",
      "Epoch 728/750 - Train pg Loss: 28.148985 - Test Loss: 7.605192\n",
      "\n",
      "\n",
      "Epoch 729/750 - Train Cd Loss: 0.047042 - Test Loss: 0.032590\n",
      "Epoch 729/750 - Train pg Loss: 30.013620 - Test Loss: 6.000612\n",
      "\n",
      "\n",
      "Epoch 730/750 - Train Cd Loss: 0.036817 - Test Loss: 0.036424\n",
      "Epoch 730/750 - Train pg Loss: 27.870583 - Test Loss: 4.885828\n",
      "\n",
      "\n",
      "Epoch 731/750 - Train Cd Loss: 0.049851 - Test Loss: nan\n",
      "Epoch 731/750 - Train pg Loss: 28.420578 - Test Loss: 5.012204\n",
      "\n",
      "\n",
      "Epoch 732/750 - Train Cd Loss: 0.032164 - Test Loss: nan\n",
      "Epoch 732/750 - Train pg Loss: 25.622633 - Test Loss: 6.419906\n",
      "\n",
      "\n",
      "Epoch 733/750 - Train Cd Loss: 0.047871 - Test Loss: 0.032831\n",
      "Epoch 733/750 - Train pg Loss: 30.985126 - Test Loss: 6.385685\n",
      "\n",
      "\n",
      "Epoch 734/750 - Train Cd Loss: 0.032886 - Test Loss: nan\n",
      "Epoch 734/750 - Train pg Loss: 29.257473 - Test Loss: 6.208182\n",
      "\n",
      "\n",
      "Epoch 735/750 - Train Cd Loss: 0.055182 - Test Loss: nan\n",
      "Epoch 735/750 - Train pg Loss: 32.324558 - Test Loss: 6.331859\n",
      "\n",
      "\n",
      "Epoch 736/750 - Train Cd Loss: 0.051135 - Test Loss: 0.037739\n",
      "Epoch 736/750 - Train pg Loss: 31.624891 - Test Loss: 5.442609\n",
      "\n",
      "\n",
      "Epoch 737/750 - Train Cd Loss: 0.046302 - Test Loss: 0.035320\n",
      "Epoch 737/750 - Train pg Loss: 27.571180 - Test Loss: 5.331326\n",
      "\n",
      "\n",
      "Epoch 738/750 - Train Cd Loss: 0.035939 - Test Loss: 0.036983\n",
      "Epoch 738/750 - Train pg Loss: 31.556803 - Test Loss: 5.409471\n",
      "\n",
      "\n",
      "Epoch 739/750 - Train Cd Loss: 0.051031 - Test Loss: 0.037429\n",
      "Epoch 739/750 - Train pg Loss: 29.188774 - Test Loss: 5.784446\n",
      "\n",
      "\n",
      "Epoch 740/750 - Train Cd Loss: 0.051094 - Test Loss: 0.034570\n",
      "Epoch 740/750 - Train pg Loss: 30.141567 - Test Loss: 5.964935\n",
      "\n",
      "\n",
      "Epoch 741/750 - Train Cd Loss: 0.037181 - Test Loss: 0.032167\n",
      "Epoch 741/750 - Train pg Loss: 32.023582 - Test Loss: 5.948868\n",
      "\n",
      "\n",
      "Epoch 742/750 - Train Cd Loss: 0.037153 - Test Loss: nan\n",
      "Epoch 742/750 - Train pg Loss: 30.346100 - Test Loss: 6.538991\n",
      "\n",
      "\n",
      "Epoch 743/750 - Train Cd Loss: 0.044686 - Test Loss: nan\n",
      "Epoch 743/750 - Train pg Loss: 27.739006 - Test Loss: 7.660066\n",
      "\n",
      "\n",
      "Epoch 744/750 - Train Cd Loss: 0.032984 - Test Loss: 0.034073\n",
      "Epoch 744/750 - Train pg Loss: 35.444279 - Test Loss: 6.147561\n",
      "\n",
      "\n",
      "Epoch 745/750 - Train Cd Loss: 0.054349 - Test Loss: 0.039460\n",
      "Epoch 745/750 - Train pg Loss: 32.339176 - Test Loss: 5.251786\n",
      "\n",
      "\n",
      "Epoch 746/750 - Train Cd Loss: 0.031763 - Test Loss: 0.034524\n",
      "Epoch 746/750 - Train pg Loss: 33.075550 - Test Loss: 6.181395\n",
      "\n",
      "\n",
      "Epoch 747/750 - Train Cd Loss: 0.030345 - Test Loss: 0.035818\n",
      "Epoch 747/750 - Train pg Loss: 33.461842 - Test Loss: 6.164604\n",
      "\n",
      "\n",
      "Epoch 748/750 - Train Cd Loss: 0.031213 - Test Loss: nan\n",
      "Epoch 748/750 - Train pg Loss: 34.852325 - Test Loss: 7.452024\n",
      "\n",
      "\n",
      "Epoch 749/750 - Train Cd Loss: 0.040749 - Test Loss: nan\n",
      "Epoch 749/750 - Train pg Loss: 31.054760 - Test Loss: 6.169069\n",
      "\n",
      "\n",
      "Epoch 750/750 - Train Cd Loss: 0.036453 - Test Loss: nan\n",
      "Epoch 750/750 - Train pg Loss: 32.566792 - Test Loss: 6.945956\n",
      "\n",
      "\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch 1/750 - Train Cd Loss: 0.174313 - Test Loss: 0.025903\n",
      "Epoch 1/750 - Train pg Loss: 3.032728 - Test Loss: 0.739378\n",
      "\n",
      "\n",
      "Epoch 2/750 - Train Cd Loss: 0.174135 - Test Loss: 0.025907\n",
      "Epoch 2/750 - Train pg Loss: 3.005386 - Test Loss: 0.742893\n",
      "\n",
      "\n",
      "Epoch 3/750 - Train Cd Loss: 0.173918 - Test Loss: 0.025802\n",
      "Epoch 3/750 - Train pg Loss: 2.973781 - Test Loss: 0.728121\n",
      "\n",
      "\n",
      "Epoch 4/750 - Train Cd Loss: 0.173811 - Test Loss: 0.025784\n",
      "Epoch 4/750 - Train pg Loss: 2.937229 - Test Loss: 0.725159\n",
      "\n",
      "\n",
      "Epoch 5/750 - Train Cd Loss: 0.173689 - Test Loss: 0.025801\n",
      "Epoch 5/750 - Train pg Loss: 2.951670 - Test Loss: 0.730463\n",
      "\n",
      "\n",
      "Epoch 6/750 - Train Cd Loss: 0.173695 - Test Loss: 0.025780\n",
      "Epoch 6/750 - Train pg Loss: 2.957261 - Test Loss: 0.730206\n",
      "\n",
      "\n",
      "Epoch 7/750 - Train Cd Loss: 0.173838 - Test Loss: 0.025662\n",
      "Epoch 7/750 - Train pg Loss: 2.923648 - Test Loss: 0.715618\n",
      "\n",
      "\n",
      "Epoch 8/750 - Train Cd Loss: 0.173211 - Test Loss: 0.025576\n",
      "Epoch 8/750 - Train pg Loss: 2.891638 - Test Loss: 0.719150\n",
      "\n",
      "\n",
      "Epoch 9/750 - Train Cd Loss: 0.173433 - Test Loss: 0.025620\n",
      "Epoch 9/750 - Train pg Loss: 2.938865 - Test Loss: 0.732588\n",
      "\n",
      "\n",
      "Epoch 10/750 - Train Cd Loss: 0.173337 - Test Loss: 0.025562\n",
      "Epoch 10/750 - Train pg Loss: 2.944721 - Test Loss: 0.726404\n",
      "\n",
      "\n",
      "Epoch 11/750 - Train Cd Loss: 0.173384 - Test Loss: 0.025655\n",
      "Epoch 11/750 - Train pg Loss: 2.951941 - Test Loss: 0.727315\n",
      "\n",
      "\n",
      "Epoch 12/750 - Train Cd Loss: 0.172795 - Test Loss: 0.025576\n",
      "Epoch 12/750 - Train pg Loss: 2.931088 - Test Loss: 0.719856\n",
      "\n",
      "\n",
      "Epoch 13/750 - Train Cd Loss: 0.173467 - Test Loss: 0.025564\n",
      "Epoch 13/750 - Train pg Loss: 2.908819 - Test Loss: 0.717626\n",
      "\n",
      "\n",
      "Epoch 14/750 - Train Cd Loss: 0.173235 - Test Loss: 0.025627\n",
      "Epoch 14/750 - Train pg Loss: 2.886487 - Test Loss: 0.716491\n",
      "\n",
      "\n",
      "Epoch 15/750 - Train Cd Loss: 0.173224 - Test Loss: 0.025618\n",
      "Epoch 15/750 - Train pg Loss: 2.872464 - Test Loss: 0.708254\n",
      "\n",
      "\n",
      "Epoch 16/750 - Train Cd Loss: 0.173540 - Test Loss: 0.025511\n",
      "Epoch 16/750 - Train pg Loss: 2.856369 - Test Loss: 0.705198\n",
      "\n",
      "\n",
      "Epoch 17/750 - Train Cd Loss: 0.172823 - Test Loss: 0.025540\n",
      "Epoch 17/750 - Train pg Loss: 2.856387 - Test Loss: 0.706830\n",
      "\n",
      "\n",
      "Epoch 18/750 - Train Cd Loss: 0.173030 - Test Loss: 0.025515\n",
      "Epoch 18/750 - Train pg Loss: 2.884836 - Test Loss: 0.717320\n",
      "\n",
      "\n",
      "Epoch 19/750 - Train Cd Loss: 0.172509 - Test Loss: 0.025579\n",
      "Epoch 19/750 - Train pg Loss: 2.917250 - Test Loss: 0.720771\n",
      "\n",
      "\n",
      "Epoch 20/750 - Train Cd Loss: 0.172335 - Test Loss: 0.025561\n",
      "Epoch 20/750 - Train pg Loss: 2.899878 - Test Loss: 0.714459\n",
      "\n",
      "\n",
      "Epoch 21/750 - Train Cd Loss: 0.173283 - Test Loss: 0.025561\n",
      "Epoch 21/750 - Train pg Loss: 2.914721 - Test Loss: 0.720547\n",
      "\n",
      "\n",
      "Epoch 22/750 - Train Cd Loss: 0.173434 - Test Loss: 0.025724\n",
      "Epoch 22/750 - Train pg Loss: 2.965841 - Test Loss: 0.737857\n",
      "\n",
      "\n",
      "Epoch 23/750 - Train Cd Loss: 0.172766 - Test Loss: 0.025663\n",
      "Epoch 23/750 - Train pg Loss: 2.999766 - Test Loss: 0.746506\n",
      "\n",
      "\n",
      "Epoch 24/750 - Train Cd Loss: 0.172940 - Test Loss: 0.025609\n",
      "Epoch 24/750 - Train pg Loss: 3.004483 - Test Loss: 0.738061\n",
      "\n",
      "\n",
      "Epoch 25/750 - Train Cd Loss: 0.173283 - Test Loss: 0.025613\n",
      "Epoch 25/750 - Train pg Loss: 2.937080 - Test Loss: 0.714798\n",
      "\n",
      "\n",
      "Epoch 26/750 - Train Cd Loss: 0.172983 - Test Loss: 0.025513\n",
      "Epoch 26/750 - Train pg Loss: 2.876037 - Test Loss: 0.708334\n",
      "\n",
      "\n",
      "Epoch 27/750 - Train Cd Loss: 0.172910 - Test Loss: 0.025690\n",
      "Epoch 27/750 - Train pg Loss: 2.872165 - Test Loss: 0.707651\n",
      "\n",
      "\n",
      "Epoch 28/750 - Train Cd Loss: 0.173013 - Test Loss: 0.025864\n",
      "Epoch 28/750 - Train pg Loss: 2.861243 - Test Loss: 0.715058\n",
      "\n",
      "\n",
      "Epoch 29/750 - Train Cd Loss: 0.173178 - Test Loss: 0.025813\n",
      "Epoch 29/750 - Train pg Loss: 2.892665 - Test Loss: 0.721170\n",
      "\n",
      "\n",
      "Epoch 30/750 - Train Cd Loss: 0.173182 - Test Loss: 0.025817\n",
      "Epoch 30/750 - Train pg Loss: 2.951535 - Test Loss: 0.734382\n",
      "\n",
      "\n",
      "Epoch 31/750 - Train Cd Loss: 0.172775 - Test Loss: 0.025750\n",
      "Epoch 31/750 - Train pg Loss: 2.951977 - Test Loss: 0.737588\n",
      "\n",
      "\n",
      "Epoch 32/750 - Train Cd Loss: 0.172383 - Test Loss: 0.025888\n",
      "Epoch 32/750 - Train pg Loss: 2.997592 - Test Loss: 0.749497\n",
      "\n",
      "\n",
      "Epoch 33/750 - Train Cd Loss: 0.172427 - Test Loss: 0.025723\n",
      "Epoch 33/750 - Train pg Loss: 2.990063 - Test Loss: 0.733975\n",
      "\n",
      "\n",
      "Epoch 34/750 - Train Cd Loss: 0.172458 - Test Loss: 0.026032\n",
      "Epoch 34/750 - Train pg Loss: 2.948033 - Test Loss: 0.730178\n",
      "\n",
      "\n",
      "Epoch 35/750 - Train Cd Loss: 0.173172 - Test Loss: 0.025438\n",
      "Epoch 35/750 - Train pg Loss: 2.947654 - Test Loss: 0.729615\n",
      "\n",
      "\n",
      "Epoch 36/750 - Train Cd Loss: 0.172121 - Test Loss: 0.025606\n",
      "Epoch 36/750 - Train pg Loss: 2.959478 - Test Loss: 0.734409\n",
      "\n",
      "\n",
      "Epoch 37/750 - Train Cd Loss: 0.172723 - Test Loss: 0.025805\n",
      "Epoch 37/750 - Train pg Loss: 2.950762 - Test Loss: 0.736933\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/750 - Train Cd Loss: 0.171266 - Test Loss: 0.025711\n",
      "Epoch 38/750 - Train pg Loss: 2.968595 - Test Loss: 0.741392\n",
      "\n",
      "\n",
      "Epoch 39/750 - Train Cd Loss: 0.172685 - Test Loss: 0.025603\n",
      "Epoch 39/750 - Train pg Loss: 2.966676 - Test Loss: 0.724345\n",
      "\n",
      "\n",
      "Epoch 40/750 - Train Cd Loss: 0.171532 - Test Loss: 0.025789\n",
      "Epoch 40/750 - Train pg Loss: 2.930258 - Test Loss: 0.731789\n",
      "\n",
      "\n",
      "Epoch 41/750 - Train Cd Loss: 0.169948 - Test Loss: 0.025981\n",
      "Epoch 41/750 - Train pg Loss: 2.952883 - Test Loss: 0.730857\n",
      "\n",
      "\n",
      "Epoch 42/750 - Train Cd Loss: 0.171473 - Test Loss: 0.025640\n",
      "Epoch 42/750 - Train pg Loss: 2.885136 - Test Loss: 0.710849\n",
      "\n",
      "\n",
      "Epoch 43/750 - Train Cd Loss: 0.169275 - Test Loss: 0.025438\n",
      "Epoch 43/750 - Train pg Loss: 2.868096 - Test Loss: 0.719872\n",
      "\n",
      "\n",
      "Epoch 44/750 - Train Cd Loss: 0.172281 - Test Loss: 0.026075\n",
      "Epoch 44/750 - Train pg Loss: 2.922684 - Test Loss: 0.711373\n",
      "\n",
      "\n",
      "Epoch 45/750 - Train Cd Loss: 0.170572 - Test Loss: 0.026213\n",
      "Epoch 45/750 - Train pg Loss: 2.899936 - Test Loss: 0.717776\n",
      "\n",
      "\n",
      "Epoch 46/750 - Train Cd Loss: 0.172642 - Test Loss: 0.026212\n",
      "Epoch 46/750 - Train pg Loss: 2.897988 - Test Loss: 0.719337\n",
      "\n",
      "\n",
      "Epoch 47/750 - Train Cd Loss: 0.171279 - Test Loss: 0.025819\n",
      "Epoch 47/750 - Train pg Loss: 2.952079 - Test Loss: 0.751167\n",
      "\n",
      "\n",
      "Epoch 48/750 - Train Cd Loss: 0.169250 - Test Loss: 0.026612\n",
      "Epoch 48/750 - Train pg Loss: 2.977358 - Test Loss: 0.732531\n",
      "\n",
      "\n",
      "Epoch 49/750 - Train Cd Loss: 0.172347 - Test Loss: 0.025835\n",
      "Epoch 49/750 - Train pg Loss: 2.947454 - Test Loss: 0.726549\n",
      "\n",
      "\n",
      "Epoch 50/750 - Train Cd Loss: 0.170556 - Test Loss: 0.025790\n",
      "Epoch 50/750 - Train pg Loss: 2.970445 - Test Loss: 0.743831\n",
      "\n",
      "\n",
      "Epoch 51/750 - Train Cd Loss: 0.171106 - Test Loss: 0.025468\n",
      "Epoch 51/750 - Train pg Loss: 3.089423 - Test Loss: 0.768250\n",
      "\n",
      "\n",
      "Epoch 52/750 - Train Cd Loss: 0.170894 - Test Loss: 0.026093\n",
      "Epoch 52/750 - Train pg Loss: 3.161725 - Test Loss: 0.794018\n",
      "\n",
      "\n",
      "Epoch 53/750 - Train Cd Loss: 0.170644 - Test Loss: 0.026265\n",
      "Epoch 53/750 - Train pg Loss: 3.157326 - Test Loss: 0.793313\n",
      "\n",
      "\n",
      "Epoch 54/750 - Train Cd Loss: 0.169371 - Test Loss: 0.026385\n",
      "Epoch 54/750 - Train pg Loss: 3.230070 - Test Loss: 0.821690\n",
      "\n",
      "\n",
      "Epoch 55/750 - Train Cd Loss: 0.170210 - Test Loss: 0.025963\n",
      "Epoch 55/750 - Train pg Loss: 3.187994 - Test Loss: 0.781330\n",
      "\n",
      "\n",
      "Epoch 56/750 - Train Cd Loss: 0.170124 - Test Loss: 0.026026\n",
      "Epoch 56/750 - Train pg Loss: 3.188056 - Test Loss: 0.794707\n",
      "\n",
      "\n",
      "Epoch 57/750 - Train Cd Loss: 0.170578 - Test Loss: 0.026565\n",
      "Epoch 57/750 - Train pg Loss: 3.323151 - Test Loss: 0.829888\n",
      "\n",
      "\n",
      "Epoch 58/750 - Train Cd Loss: 0.168068 - Test Loss: 0.026712\n",
      "Epoch 58/750 - Train pg Loss: 3.343513 - Test Loss: 0.839208\n",
      "\n",
      "\n",
      "Epoch 59/750 - Train Cd Loss: 0.169178 - Test Loss: 0.026009\n",
      "Epoch 59/750 - Train pg Loss: 3.362055 - Test Loss: 0.822277\n",
      "\n",
      "\n",
      "Epoch 60/750 - Train Cd Loss: 0.171036 - Test Loss: 0.026157\n",
      "Epoch 60/750 - Train pg Loss: 3.195724 - Test Loss: 0.773091\n",
      "\n",
      "\n",
      "Epoch 61/750 - Train Cd Loss: 0.168105 - Test Loss: 0.026253\n",
      "Epoch 61/750 - Train pg Loss: 3.174081 - Test Loss: 0.806858\n",
      "\n",
      "\n",
      "Epoch 62/750 - Train Cd Loss: 0.168281 - Test Loss: 0.026642\n",
      "Epoch 62/750 - Train pg Loss: 3.313708 - Test Loss: 0.837312\n",
      "\n",
      "\n",
      "Epoch 63/750 - Train Cd Loss: 0.166560 - Test Loss: 0.026107\n",
      "Epoch 63/750 - Train pg Loss: 3.335483 - Test Loss: 0.838487\n",
      "\n",
      "\n",
      "Epoch 64/750 - Train Cd Loss: 0.166247 - Test Loss: 0.027130\n",
      "Epoch 64/750 - Train pg Loss: 3.429463 - Test Loss: 0.852079\n",
      "\n",
      "\n",
      "Epoch 65/750 - Train Cd Loss: 0.166831 - Test Loss: 0.026925\n",
      "Epoch 65/750 - Train pg Loss: 3.373340 - Test Loss: 0.837897\n",
      "\n",
      "\n",
      "Epoch 66/750 - Train Cd Loss: 0.166681 - Test Loss: 0.025750\n",
      "Epoch 66/750 - Train pg Loss: 3.302554 - Test Loss: 0.808872\n",
      "\n",
      "\n",
      "Epoch 67/750 - Train Cd Loss: 0.165968 - Test Loss: 0.026382\n",
      "Epoch 67/750 - Train pg Loss: 3.353294 - Test Loss: 0.840110\n",
      "\n",
      "\n",
      "Epoch 68/750 - Train Cd Loss: 0.166017 - Test Loss: 0.025287\n",
      "Epoch 68/750 - Train pg Loss: 3.395556 - Test Loss: 0.828714\n",
      "\n",
      "\n",
      "Epoch 69/750 - Train Cd Loss: 0.167986 - Test Loss: 0.026345\n",
      "Epoch 69/750 - Train pg Loss: 3.409942 - Test Loss: 0.878542\n",
      "\n",
      "\n",
      "Epoch 70/750 - Train Cd Loss: 0.163868 - Test Loss: 0.025814\n",
      "Epoch 70/750 - Train pg Loss: 3.378239 - Test Loss: 0.816392\n",
      "\n",
      "\n",
      "Epoch 71/750 - Train Cd Loss: 0.169246 - Test Loss: 0.026318\n",
      "Epoch 71/750 - Train pg Loss: 3.466585 - Test Loss: 0.896783\n",
      "\n",
      "\n",
      "Epoch 72/750 - Train Cd Loss: 0.164285 - Test Loss: 0.026419\n",
      "Epoch 72/750 - Train pg Loss: 3.432345 - Test Loss: 0.817788\n",
      "\n",
      "\n",
      "Epoch 73/750 - Train Cd Loss: 0.168856 - Test Loss: 0.025207\n",
      "Epoch 73/750 - Train pg Loss: 3.319416 - Test Loss: 0.844483\n",
      "\n",
      "\n",
      "Epoch 74/750 - Train Cd Loss: 0.165219 - Test Loss: 0.027036\n",
      "Epoch 74/750 - Train pg Loss: 3.476488 - Test Loss: 0.897460\n",
      "\n",
      "\n",
      "Epoch 75/750 - Train Cd Loss: 0.163625 - Test Loss: 0.027407\n",
      "Epoch 75/750 - Train pg Loss: 3.649461 - Test Loss: 0.950892\n",
      "\n",
      "\n",
      "Epoch 76/750 - Train Cd Loss: 0.163352 - Test Loss: 0.026710\n",
      "Epoch 76/750 - Train pg Loss: 3.693539 - Test Loss: 0.877307\n",
      "\n",
      "\n",
      "Epoch 77/750 - Train Cd Loss: 0.165828 - Test Loss: 0.025882\n",
      "Epoch 77/750 - Train pg Loss: 3.441119 - Test Loss: 0.832430\n",
      "\n",
      "\n",
      "Epoch 78/750 - Train Cd Loss: 0.164517 - Test Loss: 0.026295\n",
      "Epoch 78/750 - Train pg Loss: 3.325230 - Test Loss: 0.850430\n",
      "\n",
      "\n",
      "Epoch 79/750 - Train Cd Loss: 0.162629 - Test Loss: 0.026533\n",
      "Epoch 79/750 - Train pg Loss: 3.443687 - Test Loss: 0.854142\n",
      "\n",
      "\n",
      "Epoch 80/750 - Train Cd Loss: 0.164785 - Test Loss: 0.027634\n",
      "Epoch 80/750 - Train pg Loss: 3.523658 - Test Loss: 0.900736\n",
      "\n",
      "\n",
      "Epoch 81/750 - Train Cd Loss: 0.163280 - Test Loss: 0.028006\n",
      "Epoch 81/750 - Train pg Loss: 3.651576 - Test Loss: 0.895681\n",
      "\n",
      "\n",
      "Epoch 82/750 - Train Cd Loss: 0.161178 - Test Loss: 0.027747\n",
      "Epoch 82/750 - Train pg Loss: 3.449714 - Test Loss: 0.855067\n",
      "\n",
      "\n",
      "Epoch 83/750 - Train Cd Loss: 0.162988 - Test Loss: 0.027196\n",
      "Epoch 83/750 - Train pg Loss: 3.244080 - Test Loss: 0.798168\n",
      "\n",
      "\n",
      "Epoch 84/750 - Train Cd Loss: 0.157795 - Test Loss: 0.026866\n",
      "Epoch 84/750 - Train pg Loss: 3.177024 - Test Loss: 0.808703\n",
      "\n",
      "\n",
      "Epoch 85/750 - Train Cd Loss: 0.161886 - Test Loss: 0.027416\n",
      "Epoch 85/750 - Train pg Loss: 3.198741 - Test Loss: 0.842217\n",
      "\n",
      "\n",
      "Epoch 86/750 - Train Cd Loss: 0.156158 - Test Loss: 0.027842\n",
      "Epoch 86/750 - Train pg Loss: 3.567075 - Test Loss: 0.940844\n",
      "\n",
      "\n",
      "Epoch 87/750 - Train Cd Loss: 0.160303 - Test Loss: 0.028487\n",
      "Epoch 87/750 - Train pg Loss: 3.969823 - Test Loss: 1.006713\n",
      "\n",
      "\n",
      "Epoch 88/750 - Train Cd Loss: 0.159104 - Test Loss: 0.027937\n",
      "Epoch 88/750 - Train pg Loss: 3.850342 - Test Loss: 0.951276\n",
      "\n",
      "\n",
      "Epoch 89/750 - Train Cd Loss: 0.160804 - Test Loss: 0.028900\n",
      "Epoch 89/750 - Train pg Loss: 3.990779 - Test Loss: 1.013154\n",
      "\n",
      "\n",
      "Epoch 90/750 - Train Cd Loss: 0.160015 - Test Loss: 0.027879\n",
      "Epoch 90/750 - Train pg Loss: 3.930581 - Test Loss: 0.976490\n",
      "\n",
      "\n",
      "Epoch 91/750 - Train Cd Loss: 0.161198 - Test Loss: 0.028400\n",
      "Epoch 91/750 - Train pg Loss: 3.668430 - Test Loss: 0.975600\n",
      "\n",
      "\n",
      "Epoch 92/750 - Train Cd Loss: 0.154315 - Test Loss: 0.028297\n",
      "Epoch 92/750 - Train pg Loss: 3.865553 - Test Loss: 1.043423\n",
      "\n",
      "\n",
      "Epoch 93/750 - Train Cd Loss: 0.157979 - Test Loss: 0.028782\n",
      "Epoch 93/750 - Train pg Loss: 4.097739 - Test Loss: 1.042865\n",
      "\n",
      "\n",
      "Epoch 94/750 - Train Cd Loss: 0.156850 - Test Loss: 0.028992\n",
      "Epoch 94/750 - Train pg Loss: 4.154360 - Test Loss: 1.061774\n",
      "\n",
      "\n",
      "Epoch 95/750 - Train Cd Loss: 0.155386 - Test Loss: 0.028637\n",
      "Epoch 95/750 - Train pg Loss: 4.131808 - Test Loss: 1.045686\n",
      "\n",
      "\n",
      "Epoch 96/750 - Train Cd Loss: 0.154362 - Test Loss: 0.028574\n",
      "Epoch 96/750 - Train pg Loss: 4.388815 - Test Loss: 1.131531\n",
      "\n",
      "\n",
      "Epoch 97/750 - Train Cd Loss: 0.153980 - Test Loss: 0.029327\n",
      "Epoch 97/750 - Train pg Loss: 4.301170 - Test Loss: 1.085915\n",
      "\n",
      "\n",
      "Epoch 98/750 - Train Cd Loss: 0.152078 - Test Loss: 0.030168\n",
      "Epoch 98/750 - Train pg Loss: 4.721328 - Test Loss: 1.209020\n",
      "\n",
      "\n",
      "Epoch 99/750 - Train Cd Loss: 0.151389 - Test Loss: 0.029741\n",
      "Epoch 99/750 - Train pg Loss: 4.956837 - Test Loss: 1.231660\n",
      "\n",
      "\n",
      "Epoch 100/750 - Train Cd Loss: 0.151519 - Test Loss: 0.029515\n",
      "Epoch 100/750 - Train pg Loss: 4.818218 - Test Loss: 1.196091\n",
      "\n",
      "\n",
      "Epoch 101/750 - Train Cd Loss: 0.150417 - Test Loss: 0.029175\n",
      "Epoch 101/750 - Train pg Loss: 4.924456 - Test Loss: 1.283859\n",
      "\n",
      "\n",
      "Epoch 102/750 - Train Cd Loss: 0.149725 - Test Loss: 0.029502\n",
      "Epoch 102/750 - Train pg Loss: 5.249661 - Test Loss: 1.278417\n",
      "\n",
      "\n",
      "Epoch 103/750 - Train Cd Loss: 0.159774 - Test Loss: 0.031637\n",
      "Epoch 103/750 - Train pg Loss: 5.511858 - Test Loss: 1.307176\n",
      "\n",
      "\n",
      "Epoch 104/750 - Train Cd Loss: 0.148107 - Test Loss: 0.029161\n",
      "Epoch 104/750 - Train pg Loss: 5.142695 - Test Loss: 1.155334\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/750 - Train Cd Loss: 0.155583 - Test Loss: 0.030145\n",
      "Epoch 105/750 - Train pg Loss: 5.054407 - Test Loss: 1.271992\n",
      "\n",
      "\n",
      "Epoch 106/750 - Train Cd Loss: 0.150406 - Test Loss: 0.030595\n",
      "Epoch 106/750 - Train pg Loss: 5.169948 - Test Loss: 1.222551\n",
      "\n",
      "\n",
      "Epoch 107/750 - Train Cd Loss: 0.151727 - Test Loss: 0.031363\n",
      "Epoch 107/750 - Train pg Loss: 5.726167 - Test Loss: 1.363286\n",
      "\n",
      "\n",
      "Epoch 108/750 - Train Cd Loss: 0.148188 - Test Loss: 0.031197\n",
      "Epoch 108/750 - Train pg Loss: 5.658820 - Test Loss: 1.342689\n",
      "\n",
      "\n",
      "Epoch 109/750 - Train Cd Loss: 0.146847 - Test Loss: 0.030903\n",
      "Epoch 109/750 - Train pg Loss: 5.502508 - Test Loss: 1.393874\n",
      "\n",
      "\n",
      "Epoch 110/750 - Train Cd Loss: 0.143341 - Test Loss: 0.031295\n",
      "Epoch 110/750 - Train pg Loss: 5.610878 - Test Loss: 1.313635\n",
      "\n",
      "\n",
      "Epoch 111/750 - Train Cd Loss: 0.142477 - Test Loss: 0.031466\n",
      "Epoch 111/750 - Train pg Loss: 5.541930 - Test Loss: 1.386281\n",
      "\n",
      "\n",
      "Epoch 112/750 - Train Cd Loss: 0.151451 - Test Loss: 0.031767\n",
      "Epoch 112/750 - Train pg Loss: 6.116984 - Test Loss: 1.564432\n",
      "\n",
      "\n",
      "Epoch 113/750 - Train Cd Loss: 0.144460 - Test Loss: 0.031289\n",
      "Epoch 113/750 - Train pg Loss: 6.208004 - Test Loss: 1.386603\n",
      "\n",
      "\n",
      "Epoch 114/750 - Train Cd Loss: 0.145837 - Test Loss: 0.031356\n",
      "Epoch 114/750 - Train pg Loss: 5.234537 - Test Loss: 1.254092\n",
      "\n",
      "\n",
      "Epoch 115/750 - Train Cd Loss: 0.138316 - Test Loss: 0.031574\n",
      "Epoch 115/750 - Train pg Loss: 5.860917 - Test Loss: 1.546681\n",
      "\n",
      "\n",
      "Epoch 116/750 - Train Cd Loss: 0.141222 - Test Loss: 0.032103\n",
      "Epoch 116/750 - Train pg Loss: 6.607244 - Test Loss: 1.576747\n",
      "\n",
      "\n",
      "Epoch 117/750 - Train Cd Loss: 0.144175 - Test Loss: 0.032368\n",
      "Epoch 117/750 - Train pg Loss: 6.371651 - Test Loss: 1.637257\n",
      "\n",
      "\n",
      "Epoch 118/750 - Train Cd Loss: 0.139745 - Test Loss: 0.032394\n",
      "Epoch 118/750 - Train pg Loss: 7.243218 - Test Loss: 1.640527\n",
      "\n",
      "\n",
      "Epoch 119/750 - Train Cd Loss: 0.141571 - Test Loss: 0.031418\n",
      "Epoch 119/750 - Train pg Loss: 6.547204 - Test Loss: 1.421566\n",
      "\n",
      "\n",
      "Epoch 120/750 - Train Cd Loss: 0.133210 - Test Loss: 0.032031\n",
      "Epoch 120/750 - Train pg Loss: 5.805850 - Test Loss: 1.415624\n",
      "\n",
      "\n",
      "Epoch 121/750 - Train Cd Loss: 0.137308 - Test Loss: 0.032873\n",
      "Epoch 121/750 - Train pg Loss: 5.859558 - Test Loss: 1.541840\n",
      "\n",
      "\n",
      "Epoch 122/750 - Train Cd Loss: 0.135023 - Test Loss: 0.032286\n",
      "Epoch 122/750 - Train pg Loss: 6.654021 - Test Loss: 1.566090\n",
      "\n",
      "\n",
      "Epoch 123/750 - Train Cd Loss: 0.139907 - Test Loss: 0.033022\n",
      "Epoch 123/750 - Train pg Loss: 6.761504 - Test Loss: 1.677743\n",
      "\n",
      "\n",
      "Epoch 124/750 - Train Cd Loss: 0.130716 - Test Loss: 0.034074\n",
      "Epoch 124/750 - Train pg Loss: 7.371061 - Test Loss: 1.688707\n",
      "\n",
      "\n",
      "Epoch 125/750 - Train Cd Loss: 0.141706 - Test Loss: 0.033110\n",
      "Epoch 125/750 - Train pg Loss: 6.465157 - Test Loss: 1.498493\n",
      "\n",
      "\n",
      "Epoch 126/750 - Train Cd Loss: 0.134324 - Test Loss: 0.033434\n",
      "Epoch 126/750 - Train pg Loss: 6.420750 - Test Loss: 1.621638\n",
      "\n",
      "\n",
      "Epoch 127/750 - Train Cd Loss: 0.134618 - Test Loss: 0.033672\n",
      "Epoch 127/750 - Train pg Loss: 6.577095 - Test Loss: 1.629575\n",
      "\n",
      "\n",
      "Epoch 128/750 - Train Cd Loss: 0.134148 - Test Loss: 0.033010\n",
      "Epoch 128/750 - Train pg Loss: 6.680142 - Test Loss: 1.571753\n",
      "\n",
      "\n",
      "Epoch 129/750 - Train Cd Loss: 0.133786 - Test Loss: 0.034578\n",
      "Epoch 129/750 - Train pg Loss: 7.521440 - Test Loss: 1.792052\n",
      "\n",
      "\n",
      "Epoch 130/750 - Train Cd Loss: 0.134515 - Test Loss: 0.034345\n",
      "Epoch 130/750 - Train pg Loss: 8.221388 - Test Loss: 1.790191\n",
      "\n",
      "\n",
      "Epoch 131/750 - Train Cd Loss: 0.134052 - Test Loss: 0.034054\n",
      "Epoch 131/750 - Train pg Loss: 7.593404 - Test Loss: 1.828450\n",
      "\n",
      "\n",
      "Epoch 132/750 - Train Cd Loss: 0.135128 - Test Loss: 0.033087\n",
      "Epoch 132/750 - Train pg Loss: 7.068778 - Test Loss: 1.732547\n",
      "\n",
      "\n",
      "Epoch 133/750 - Train Cd Loss: 0.131429 - Test Loss: 0.033375\n",
      "Epoch 133/750 - Train pg Loss: 6.605767 - Test Loss: 1.549223\n",
      "\n",
      "\n",
      "Epoch 134/750 - Train Cd Loss: 0.138475 - Test Loss: 0.034691\n",
      "Epoch 134/750 - Train pg Loss: 6.722848 - Test Loss: 1.739358\n",
      "\n",
      "\n",
      "Epoch 135/750 - Train Cd Loss: 0.129870 - Test Loss: 0.034650\n",
      "Epoch 135/750 - Train pg Loss: 6.511170 - Test Loss: 1.499611\n",
      "\n",
      "\n",
      "Epoch 136/750 - Train Cd Loss: 0.129635 - Test Loss: 0.034293\n",
      "Epoch 136/750 - Train pg Loss: 6.810233 - Test Loss: 1.738678\n",
      "\n",
      "\n",
      "Epoch 137/750 - Train Cd Loss: 0.132205 - Test Loss: 0.034847\n",
      "Epoch 137/750 - Train pg Loss: 7.679796 - Test Loss: 1.877202\n",
      "\n",
      "\n",
      "Epoch 138/750 - Train Cd Loss: 0.136985 - Test Loss: 0.033849\n",
      "Epoch 138/750 - Train pg Loss: 7.728026 - Test Loss: 1.837818\n",
      "\n",
      "\n",
      "Epoch 139/750 - Train Cd Loss: 0.131259 - Test Loss: 0.034670\n",
      "Epoch 139/750 - Train pg Loss: 7.182188 - Test Loss: 1.710776\n",
      "\n",
      "\n",
      "Epoch 140/750 - Train Cd Loss: 0.128930 - Test Loss: 0.032995\n",
      "Epoch 140/750 - Train pg Loss: 6.563878 - Test Loss: 1.576390\n",
      "\n",
      "\n",
      "Epoch 141/750 - Train Cd Loss: 0.128650 - Test Loss: 0.033922\n",
      "Epoch 141/750 - Train pg Loss: 7.055264 - Test Loss: 1.945371\n",
      "\n",
      "\n",
      "Epoch 142/750 - Train Cd Loss: 0.134379 - Test Loss: 0.034018\n",
      "Epoch 142/750 - Train pg Loss: 8.086556 - Test Loss: 1.902792\n",
      "\n",
      "\n",
      "Epoch 143/750 - Train Cd Loss: 0.130550 - Test Loss: 0.034640\n",
      "Epoch 143/750 - Train pg Loss: 7.592275 - Test Loss: 1.710246\n",
      "\n",
      "\n",
      "Epoch 144/750 - Train Cd Loss: 0.124239 - Test Loss: 0.034752\n",
      "Epoch 144/750 - Train pg Loss: 6.044889 - Test Loss: 1.497523\n",
      "\n",
      "\n",
      "Epoch 145/750 - Train Cd Loss: 0.123855 - Test Loss: 0.035002\n",
      "Epoch 145/750 - Train pg Loss: 6.162020 - Test Loss: 1.578455\n",
      "\n",
      "\n",
      "Epoch 146/750 - Train Cd Loss: 0.119999 - Test Loss: 0.036428\n",
      "Epoch 146/750 - Train pg Loss: 7.252224 - Test Loss: 1.788300\n",
      "\n",
      "\n",
      "Epoch 147/750 - Train Cd Loss: 0.122234 - Test Loss: 0.034761\n",
      "Epoch 147/750 - Train pg Loss: 7.679805 - Test Loss: 1.855822\n",
      "\n",
      "\n",
      "Epoch 148/750 - Train Cd Loss: 0.118176 - Test Loss: 0.036371\n",
      "Epoch 148/750 - Train pg Loss: 7.951635 - Test Loss: 1.697290\n",
      "\n",
      "\n",
      "Epoch 149/750 - Train Cd Loss: 0.136102 - Test Loss: 0.035956\n",
      "Epoch 149/750 - Train pg Loss: 7.618133 - Test Loss: 1.393854\n",
      "\n",
      "\n",
      "Epoch 150/750 - Train Cd Loss: 0.121039 - Test Loss: 0.034382\n",
      "Epoch 150/750 - Train pg Loss: 7.270584 - Test Loss: 1.902231\n",
      "\n",
      "\n",
      "Epoch 151/750 - Train Cd Loss: 0.120473 - Test Loss: 0.033973\n",
      "Epoch 151/750 - Train pg Loss: 7.673713 - Test Loss: 1.602649\n",
      "\n",
      "\n",
      "Epoch 152/750 - Train Cd Loss: 0.131282 - Test Loss: 0.033801\n",
      "Epoch 152/750 - Train pg Loss: 6.538009 - Test Loss: 1.287238\n",
      "\n",
      "\n",
      "Epoch 153/750 - Train Cd Loss: 0.124039 - Test Loss: 0.033113\n",
      "Epoch 153/750 - Train pg Loss: 6.028092 - Test Loss: 1.389657\n",
      "\n",
      "\n",
      "Epoch 154/750 - Train Cd Loss: 0.121308 - Test Loss: 0.034648\n",
      "Epoch 154/750 - Train pg Loss: 6.277779 - Test Loss: 1.520256\n",
      "\n",
      "\n",
      "Epoch 155/750 - Train Cd Loss: 0.123220 - Test Loss: 0.034540\n",
      "Epoch 155/750 - Train pg Loss: 6.131527 - Test Loss: 1.399898\n",
      "\n",
      "\n",
      "Epoch 156/750 - Train Cd Loss: 0.119453 - Test Loss: 0.035330\n",
      "Epoch 156/750 - Train pg Loss: 5.909522 - Test Loss: 1.321602\n",
      "\n",
      "\n",
      "Epoch 157/750 - Train Cd Loss: 0.114554 - Test Loss: 0.036013\n",
      "Epoch 157/750 - Train pg Loss: 6.140704 - Test Loss: 1.553892\n",
      "\n",
      "\n",
      "Epoch 158/750 - Train Cd Loss: 0.134823 - Test Loss: 0.036361\n",
      "Epoch 158/750 - Train pg Loss: 7.825114 - Test Loss: 1.883579\n",
      "\n",
      "\n",
      "Epoch 159/750 - Train Cd Loss: 0.110776 - Test Loss: 0.035629\n",
      "Epoch 159/750 - Train pg Loss: 7.962271 - Test Loss: 1.965596\n",
      "\n",
      "\n",
      "Epoch 160/750 - Train Cd Loss: 0.123596 - Test Loss: 0.035381\n",
      "Epoch 160/750 - Train pg Loss: 8.022100 - Test Loss: 1.667189\n",
      "\n",
      "\n",
      "Epoch 161/750 - Train Cd Loss: 0.111623 - Test Loss: 0.036414\n",
      "Epoch 161/750 - Train pg Loss: 7.144581 - Test Loss: 1.739844\n",
      "\n",
      "\n",
      "Epoch 162/750 - Train Cd Loss: 0.121679 - Test Loss: 0.035960\n",
      "Epoch 162/750 - Train pg Loss: 8.051242 - Test Loss: 1.674418\n",
      "\n",
      "\n",
      "Epoch 163/750 - Train Cd Loss: 0.116259 - Test Loss: 0.036966\n",
      "Epoch 163/750 - Train pg Loss: 6.986851 - Test Loss: 1.764300\n",
      "\n",
      "\n",
      "Epoch 164/750 - Train Cd Loss: 0.121652 - Test Loss: 0.036694\n",
      "Epoch 164/750 - Train pg Loss: 8.258272 - Test Loss: 1.926038\n",
      "\n",
      "\n",
      "Epoch 165/750 - Train Cd Loss: 0.118726 - Test Loss: 0.035844\n",
      "Epoch 165/750 - Train pg Loss: 9.679919 - Test Loss: 2.282483\n",
      "\n",
      "\n",
      "Epoch 166/750 - Train Cd Loss: 0.119567 - Test Loss: 0.034815\n",
      "Epoch 166/750 - Train pg Loss: 8.876212 - Test Loss: 2.118884\n",
      "\n",
      "\n",
      "Epoch 167/750 - Train Cd Loss: 0.119349 - Test Loss: 0.036696\n",
      "Epoch 167/750 - Train pg Loss: 9.530684 - Test Loss: 1.896284\n",
      "\n",
      "\n",
      "Epoch 168/750 - Train Cd Loss: 0.117276 - Test Loss: 0.037180\n",
      "Epoch 168/750 - Train pg Loss: 8.053595 - Test Loss: 1.822914\n",
      "\n",
      "\n",
      "Epoch 169/750 - Train Cd Loss: 0.107799 - Test Loss: 0.036382\n",
      "Epoch 169/750 - Train pg Loss: 8.778030 - Test Loss: 2.190892\n",
      "\n",
      "\n",
      "Epoch 170/750 - Train Cd Loss: 0.119320 - Test Loss: 0.035077\n",
      "Epoch 170/750 - Train pg Loss: 10.606494 - Test Loss: 2.242149\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/750 - Train Cd Loss: 0.116527 - Test Loss: 0.035881\n",
      "Epoch 171/750 - Train pg Loss: 10.237060 - Test Loss: 2.115149\n",
      "\n",
      "\n",
      "Epoch 172/750 - Train Cd Loss: 0.114365 - Test Loss: 0.036873\n",
      "Epoch 172/750 - Train pg Loss: 8.869929 - Test Loss: 1.965817\n",
      "\n",
      "\n",
      "Epoch 173/750 - Train Cd Loss: 0.112308 - Test Loss: 0.035837\n",
      "Epoch 173/750 - Train pg Loss: 9.078959 - Test Loss: 2.002600\n",
      "\n",
      "\n",
      "Epoch 174/750 - Train Cd Loss: 0.123292 - Test Loss: 0.036474\n",
      "Epoch 174/750 - Train pg Loss: 9.992858 - Test Loss: 2.203177\n",
      "\n",
      "\n",
      "Epoch 175/750 - Train Cd Loss: 0.112215 - Test Loss: 0.035724\n",
      "Epoch 175/750 - Train pg Loss: 11.036657 - Test Loss: 2.289029\n",
      "\n",
      "\n",
      "Epoch 176/750 - Train Cd Loss: 0.114376 - Test Loss: 0.036176\n",
      "Epoch 176/750 - Train pg Loss: 8.928379 - Test Loss: 1.868606\n",
      "\n",
      "\n",
      "Epoch 177/750 - Train Cd Loss: 0.119501 - Test Loss: 0.035738\n",
      "Epoch 177/750 - Train pg Loss: 7.000550 - Test Loss: 1.676748\n",
      "\n",
      "\n",
      "Epoch 178/750 - Train Cd Loss: 0.110963 - Test Loss: 0.036051\n",
      "Epoch 178/750 - Train pg Loss: 7.313481 - Test Loss: 1.862294\n",
      "\n",
      "\n",
      "Epoch 179/750 - Train Cd Loss: 0.110398 - Test Loss: 0.036841\n",
      "Epoch 179/750 - Train pg Loss: 8.044733 - Test Loss: 1.941985\n",
      "\n",
      "\n",
      "Epoch 180/750 - Train Cd Loss: 0.099221 - Test Loss: 0.036293\n",
      "Epoch 180/750 - Train pg Loss: 8.035796 - Test Loss: 1.995721\n",
      "\n",
      "\n",
      "Epoch 181/750 - Train Cd Loss: 0.107394 - Test Loss: 0.037159\n",
      "Epoch 181/750 - Train pg Loss: 9.288682 - Test Loss: 2.083194\n",
      "\n",
      "\n",
      "Epoch 182/750 - Train Cd Loss: 0.110891 - Test Loss: 0.037403\n",
      "Epoch 182/750 - Train pg Loss: 8.316318 - Test Loss: 2.132705\n",
      "\n",
      "\n",
      "Epoch 183/750 - Train Cd Loss: 0.112656 - Test Loss: 0.036708\n",
      "Epoch 183/750 - Train pg Loss: 9.712492 - Test Loss: 2.203470\n",
      "\n",
      "\n",
      "Epoch 184/750 - Train Cd Loss: 0.109086 - Test Loss: 0.037603\n",
      "Epoch 184/750 - Train pg Loss: 9.159216 - Test Loss: 2.137718\n",
      "\n",
      "\n",
      "Epoch 185/750 - Train Cd Loss: 0.104900 - Test Loss: 0.038729\n",
      "Epoch 185/750 - Train pg Loss: 9.146056 - Test Loss: 2.100698\n",
      "\n",
      "\n",
      "Epoch 186/750 - Train Cd Loss: 0.104190 - Test Loss: 0.037142\n",
      "Epoch 186/750 - Train pg Loss: 9.441309 - Test Loss: 2.223949\n",
      "\n",
      "\n",
      "Epoch 187/750 - Train Cd Loss: 0.117979 - Test Loss: 0.035829\n",
      "Epoch 187/750 - Train pg Loss: 10.934303 - Test Loss: 2.573811\n",
      "\n",
      "\n",
      "Epoch 188/750 - Train Cd Loss: 0.106304 - Test Loss: 0.036929\n",
      "Epoch 188/750 - Train pg Loss: 10.844378 - Test Loss: 2.596838\n",
      "\n",
      "\n",
      "Epoch 189/750 - Train Cd Loss: 0.106087 - Test Loss: 0.037349\n",
      "Epoch 189/750 - Train pg Loss: 10.565902 - Test Loss: 2.416273\n",
      "\n",
      "\n",
      "Epoch 190/750 - Train Cd Loss: 0.107368 - Test Loss: 0.038275\n",
      "Epoch 190/750 - Train pg Loss: 11.086679 - Test Loss: 2.412729\n",
      "\n",
      "\n",
      "Epoch 191/750 - Train Cd Loss: 0.107835 - Test Loss: 0.037146\n",
      "Epoch 191/750 - Train pg Loss: 10.740797 - Test Loss: 2.230654\n",
      "\n",
      "\n",
      "Epoch 192/750 - Train Cd Loss: 0.126475 - Test Loss: 0.037084\n",
      "Epoch 192/750 - Train pg Loss: 10.866220 - Test Loss: 2.457705\n",
      "\n",
      "\n",
      "Epoch 193/750 - Train Cd Loss: 0.107094 - Test Loss: 0.037724\n",
      "Epoch 193/750 - Train pg Loss: 9.845200 - Test Loss: 2.414748\n",
      "\n",
      "\n",
      "Epoch 194/750 - Train Cd Loss: 0.102963 - Test Loss: 0.035810\n",
      "Epoch 194/750 - Train pg Loss: 9.803851 - Test Loss: 2.379643\n",
      "\n",
      "\n",
      "Epoch 195/750 - Train Cd Loss: 0.098427 - Test Loss: 0.035665\n",
      "Epoch 195/750 - Train pg Loss: 9.925153 - Test Loss: 2.187975\n",
      "\n",
      "\n",
      "Epoch 196/750 - Train Cd Loss: 0.101649 - Test Loss: 0.038363\n",
      "Epoch 196/750 - Train pg Loss: 9.303211 - Test Loss: 2.388292\n",
      "\n",
      "\n",
      "Epoch 197/750 - Train Cd Loss: 0.102103 - Test Loss: 0.038551\n",
      "Epoch 197/750 - Train pg Loss: 9.855217 - Test Loss: 2.422942\n",
      "\n",
      "\n",
      "Epoch 198/750 - Train Cd Loss: 0.100163 - Test Loss: 0.038045\n",
      "Epoch 198/750 - Train pg Loss: 9.349554 - Test Loss: 2.179837\n",
      "\n",
      "\n",
      "Epoch 199/750 - Train Cd Loss: 0.099445 - Test Loss: 0.037853\n",
      "Epoch 199/750 - Train pg Loss: 9.549210 - Test Loss: 2.270844\n",
      "\n",
      "\n",
      "Epoch 200/750 - Train Cd Loss: 0.108627 - Test Loss: 0.036235\n",
      "Epoch 200/750 - Train pg Loss: 9.865403 - Test Loss: 2.228435\n",
      "\n",
      "\n",
      "Epoch 201/750 - Train Cd Loss: 0.119766 - Test Loss: 0.039336\n",
      "Epoch 201/750 - Train pg Loss: 10.833645 - Test Loss: 2.377588\n",
      "\n",
      "\n",
      "Epoch 202/750 - Train Cd Loss: 0.102174 - Test Loss: 0.036570\n",
      "Epoch 202/750 - Train pg Loss: 8.964681 - Test Loss: 2.080736\n",
      "\n",
      "\n",
      "Epoch 203/750 - Train Cd Loss: 0.103988 - Test Loss: 0.036268\n",
      "Epoch 203/750 - Train pg Loss: 8.654587 - Test Loss: 2.323625\n",
      "\n",
      "\n",
      "Epoch 204/750 - Train Cd Loss: 0.098677 - Test Loss: 0.035921\n",
      "Epoch 204/750 - Train pg Loss: 10.340930 - Test Loss: 2.535652\n",
      "\n",
      "\n",
      "Epoch 205/750 - Train Cd Loss: 0.097979 - Test Loss: 0.036133\n",
      "Epoch 205/750 - Train pg Loss: 9.741989 - Test Loss: 2.433617\n",
      "\n",
      "\n",
      "Epoch 206/750 - Train Cd Loss: 0.105067 - Test Loss: 0.037894\n",
      "Epoch 206/750 - Train pg Loss: 8.615829 - Test Loss: 1.899706\n",
      "\n",
      "\n",
      "Epoch 207/750 - Train Cd Loss: 0.104130 - Test Loss: 0.037789\n",
      "Epoch 207/750 - Train pg Loss: 8.505769 - Test Loss: 2.347267\n",
      "\n",
      "\n",
      "Epoch 208/750 - Train Cd Loss: 0.102840 - Test Loss: 0.037637\n",
      "Epoch 208/750 - Train pg Loss: 10.177032 - Test Loss: 2.599991\n",
      "\n",
      "\n",
      "Epoch 209/750 - Train Cd Loss: 0.109978 - Test Loss: 0.036440\n",
      "Epoch 209/750 - Train pg Loss: 11.186265 - Test Loss: 2.825577\n",
      "\n",
      "\n",
      "Epoch 210/750 - Train Cd Loss: 0.104474 - Test Loss: 0.037504\n",
      "Epoch 210/750 - Train pg Loss: 12.505073 - Test Loss: 2.729739\n",
      "\n",
      "\n",
      "Epoch 211/750 - Train Cd Loss: 0.093019 - Test Loss: 0.035748\n",
      "Epoch 211/750 - Train pg Loss: 10.621952 - Test Loss: 2.266496\n",
      "\n",
      "\n",
      "Epoch 212/750 - Train Cd Loss: 0.098689 - Test Loss: 0.037511\n",
      "Epoch 212/750 - Train pg Loss: 9.520475 - Test Loss: 2.481892\n",
      "\n",
      "\n",
      "Epoch 213/750 - Train Cd Loss: 0.093586 - Test Loss: 0.037802\n",
      "Epoch 213/750 - Train pg Loss: 10.491072 - Test Loss: 2.633833\n",
      "\n",
      "\n",
      "Epoch 214/750 - Train Cd Loss: 0.105228 - Test Loss: 0.037104\n",
      "Epoch 214/750 - Train pg Loss: 11.396000 - Test Loss: 2.331977\n",
      "\n",
      "\n",
      "Epoch 215/750 - Train Cd Loss: 0.091218 - Test Loss: 0.039089\n",
      "Epoch 215/750 - Train pg Loss: 9.291643 - Test Loss: 2.378775\n",
      "\n",
      "\n",
      "Epoch 216/750 - Train Cd Loss: 0.092316 - Test Loss: 0.040103\n",
      "Epoch 216/750 - Train pg Loss: 9.386843 - Test Loss: 2.645923\n",
      "\n",
      "\n",
      "Epoch 217/750 - Train Cd Loss: 0.097618 - Test Loss: 0.036781\n",
      "Epoch 217/750 - Train pg Loss: 10.769196 - Test Loss: 2.654693\n",
      "\n",
      "\n",
      "Epoch 218/750 - Train Cd Loss: 0.124187 - Test Loss: 0.037708\n",
      "Epoch 218/750 - Train pg Loss: 11.027906 - Test Loss: 2.639953\n",
      "\n",
      "\n",
      "Epoch 219/750 - Train Cd Loss: 0.100365 - Test Loss: 0.038439\n",
      "Epoch 219/750 - Train pg Loss: 10.880874 - Test Loss: 2.573156\n",
      "\n",
      "\n",
      "Epoch 220/750 - Train Cd Loss: 0.097025 - Test Loss: 0.035999\n",
      "Epoch 220/750 - Train pg Loss: 10.628486 - Test Loss: 2.586145\n",
      "\n",
      "\n",
      "Epoch 221/750 - Train Cd Loss: 0.089304 - Test Loss: 0.037515\n",
      "Epoch 221/750 - Train pg Loss: 9.547128 - Test Loss: 2.406319\n",
      "\n",
      "\n",
      "Epoch 222/750 - Train Cd Loss: 0.111979 - Test Loss: 0.039503\n",
      "Epoch 222/750 - Train pg Loss: 12.489327 - Test Loss: 2.707778\n",
      "\n",
      "\n",
      "Epoch 223/750 - Train Cd Loss: 0.093435 - Test Loss: 0.035315\n",
      "Epoch 223/750 - Train pg Loss: 11.205568 - Test Loss: 2.584742\n",
      "\n",
      "\n",
      "Epoch 224/750 - Train Cd Loss: 0.091990 - Test Loss: 0.037350\n",
      "Epoch 224/750 - Train pg Loss: 12.171198 - Test Loss: 2.980433\n",
      "\n",
      "\n",
      "Epoch 225/750 - Train Cd Loss: 0.096993 - Test Loss: 0.038370\n",
      "Epoch 225/750 - Train pg Loss: 12.519427 - Test Loss: 3.023625\n",
      "\n",
      "\n",
      "Epoch 226/750 - Train Cd Loss: 0.094972 - Test Loss: 0.037960\n",
      "Epoch 226/750 - Train pg Loss: 12.680447 - Test Loss: 3.196414\n",
      "\n",
      "\n",
      "Epoch 227/750 - Train Cd Loss: 0.094111 - Test Loss: 0.038534\n",
      "Epoch 227/750 - Train pg Loss: 13.197063 - Test Loss: 3.438360\n",
      "\n",
      "\n",
      "Epoch 228/750 - Train Cd Loss: 0.092522 - Test Loss: 0.035985\n",
      "Epoch 228/750 - Train pg Loss: 14.716590 - Test Loss: 3.408403\n",
      "\n",
      "\n",
      "Epoch 229/750 - Train Cd Loss: 0.097989 - Test Loss: 0.038290\n",
      "Epoch 229/750 - Train pg Loss: 15.057794 - Test Loss: 3.477287\n",
      "\n",
      "\n",
      "Epoch 230/750 - Train Cd Loss: 0.093984 - Test Loss: 0.037749\n",
      "Epoch 230/750 - Train pg Loss: 16.669971 - Test Loss: 3.439995\n",
      "\n",
      "\n",
      "Epoch 231/750 - Train Cd Loss: 0.094104 - Test Loss: 0.038344\n",
      "Epoch 231/750 - Train pg Loss: 12.691309 - Test Loss: 2.609317\n",
      "\n",
      "\n",
      "Epoch 232/750 - Train Cd Loss: 0.092941 - Test Loss: 0.038961\n",
      "Epoch 232/750 - Train pg Loss: 13.512058 - Test Loss: 3.603415\n",
      "\n",
      "\n",
      "Epoch 233/750 - Train Cd Loss: 0.090089 - Test Loss: 0.037019\n",
      "Epoch 233/750 - Train pg Loss: 14.002313 - Test Loss: 3.219674\n",
      "\n",
      "\n",
      "Epoch 234/750 - Train Cd Loss: 0.097782 - Test Loss: 0.038202\n",
      "Epoch 234/750 - Train pg Loss: 15.177798 - Test Loss: 2.962657\n",
      "\n",
      "\n",
      "Epoch 235/750 - Train Cd Loss: 0.097538 - Test Loss: 0.038557\n",
      "Epoch 235/750 - Train pg Loss: 12.734133 - Test Loss: 3.309479\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/750 - Train Cd Loss: 0.096754 - Test Loss: 0.036698\n",
      "Epoch 236/750 - Train pg Loss: 14.415836 - Test Loss: 3.002162\n",
      "\n",
      "\n",
      "Epoch 237/750 - Train Cd Loss: 0.093821 - Test Loss: 0.036547\n",
      "Epoch 237/750 - Train pg Loss: 11.422570 - Test Loss: 2.917413\n",
      "\n",
      "\n",
      "Epoch 238/750 - Train Cd Loss: 0.089029 - Test Loss: 0.037947\n",
      "Epoch 238/750 - Train pg Loss: 12.007955 - Test Loss: 2.823884\n",
      "\n",
      "\n",
      "Epoch 239/750 - Train Cd Loss: 0.091561 - Test Loss: 0.038700\n",
      "Epoch 239/750 - Train pg Loss: 13.833025 - Test Loss: 3.442944\n",
      "\n",
      "\n",
      "Epoch 240/750 - Train Cd Loss: 0.085992 - Test Loss: 0.039297\n",
      "Epoch 240/750 - Train pg Loss: 14.688438 - Test Loss: 3.533086\n",
      "\n",
      "\n",
      "Epoch 241/750 - Train Cd Loss: 0.085463 - Test Loss: 0.039056\n",
      "Epoch 241/750 - Train pg Loss: 11.579391 - Test Loss: 3.102416\n",
      "\n",
      "\n",
      "Epoch 242/750 - Train Cd Loss: 0.089237 - Test Loss: 0.039147\n",
      "Epoch 242/750 - Train pg Loss: 11.552039 - Test Loss: 3.195463\n",
      "\n",
      "\n",
      "Epoch 243/750 - Train Cd Loss: 0.089274 - Test Loss: 0.038945\n",
      "Epoch 243/750 - Train pg Loss: 16.022532 - Test Loss: 3.729686\n",
      "\n",
      "\n",
      "Epoch 244/750 - Train Cd Loss: 0.092288 - Test Loss: 0.037904\n",
      "Epoch 244/750 - Train pg Loss: 13.021937 - Test Loss: 3.315629\n",
      "\n",
      "\n",
      "Epoch 245/750 - Train Cd Loss: 0.084101 - Test Loss: 0.037989\n",
      "Epoch 245/750 - Train pg Loss: 12.106804 - Test Loss: 2.975002\n",
      "\n",
      "\n",
      "Epoch 246/750 - Train Cd Loss: 0.081527 - Test Loss: 0.039572\n",
      "Epoch 246/750 - Train pg Loss: 12.746080 - Test Loss: 3.498245\n",
      "\n",
      "\n",
      "Epoch 247/750 - Train Cd Loss: 0.095034 - Test Loss: 0.039544\n",
      "Epoch 247/750 - Train pg Loss: 13.256548 - Test Loss: 3.454789\n",
      "\n",
      "\n",
      "Epoch 248/750 - Train Cd Loss: 0.085970 - Test Loss: 0.039283\n",
      "Epoch 248/750 - Train pg Loss: 14.972621 - Test Loss: 3.561604\n",
      "\n",
      "\n",
      "Epoch 249/750 - Train Cd Loss: 0.085283 - Test Loss: 0.038741\n",
      "Epoch 249/750 - Train pg Loss: 11.787020 - Test Loss: 3.439599\n",
      "\n",
      "\n",
      "Epoch 250/750 - Train Cd Loss: 0.088276 - Test Loss: 0.038327\n",
      "Epoch 250/750 - Train pg Loss: 15.980493 - Test Loss: 4.086629\n",
      "\n",
      "\n",
      "Epoch 251/750 - Train Cd Loss: 0.087082 - Test Loss: 0.038945\n",
      "Epoch 251/750 - Train pg Loss: 16.567696 - Test Loss: 3.960868\n",
      "\n",
      "\n",
      "Epoch 252/750 - Train Cd Loss: 0.081024 - Test Loss: 0.038522\n",
      "Epoch 252/750 - Train pg Loss: 17.235153 - Test Loss: 3.901220\n",
      "\n",
      "\n",
      "Epoch 253/750 - Train Cd Loss: 0.085978 - Test Loss: 0.038395\n",
      "Epoch 253/750 - Train pg Loss: 14.953374 - Test Loss: 3.681974\n",
      "\n",
      "\n",
      "Epoch 254/750 - Train Cd Loss: 0.078526 - Test Loss: 0.037648\n",
      "Epoch 254/750 - Train pg Loss: 15.060699 - Test Loss: 3.824767\n",
      "\n",
      "\n",
      "Epoch 255/750 - Train Cd Loss: 0.076291 - Test Loss: 0.041125\n",
      "Epoch 255/750 - Train pg Loss: 16.379187 - Test Loss: 4.246492\n",
      "\n",
      "\n",
      "Epoch 256/750 - Train Cd Loss: 0.091495 - Test Loss: 0.038182\n",
      "Epoch 256/750 - Train pg Loss: 16.708128 - Test Loss: 4.050711\n",
      "\n",
      "\n",
      "Epoch 257/750 - Train Cd Loss: 0.098332 - Test Loss: 0.038271\n",
      "Epoch 257/750 - Train pg Loss: 18.011393 - Test Loss: 4.264514\n",
      "\n",
      "\n",
      "Epoch 258/750 - Train Cd Loss: 0.082538 - Test Loss: 0.038206\n",
      "Epoch 258/750 - Train pg Loss: 19.070116 - Test Loss: 4.511040\n",
      "\n",
      "\n",
      "Epoch 259/750 - Train Cd Loss: 0.078786 - Test Loss: 0.040776\n",
      "Epoch 259/750 - Train pg Loss: 19.012432 - Test Loss: 4.420397\n",
      "\n",
      "\n",
      "Epoch 260/750 - Train Cd Loss: 0.079590 - Test Loss: 0.038603\n",
      "Epoch 260/750 - Train pg Loss: 17.703531 - Test Loss: 4.572702\n",
      "\n",
      "\n",
      "Epoch 261/750 - Train Cd Loss: 0.082619 - Test Loss: 0.036499\n",
      "Epoch 261/750 - Train pg Loss: 18.322208 - Test Loss: 4.943213\n",
      "\n",
      "\n",
      "Epoch 262/750 - Train Cd Loss: 0.085734 - Test Loss: 0.038809\n",
      "Epoch 262/750 - Train pg Loss: 19.932178 - Test Loss: 5.136983\n",
      "\n",
      "\n",
      "Epoch 263/750 - Train Cd Loss: 0.085964 - Test Loss: 0.038746\n",
      "Epoch 263/750 - Train pg Loss: 24.588112 - Test Loss: 5.347135\n",
      "\n",
      "\n",
      "Epoch 264/750 - Train Cd Loss: 0.081460 - Test Loss: 0.039059\n",
      "Epoch 264/750 - Train pg Loss: 21.476192 - Test Loss: 5.971917\n",
      "\n",
      "\n",
      "Epoch 265/750 - Train Cd Loss: 0.088883 - Test Loss: 0.041642\n",
      "Epoch 265/750 - Train pg Loss: 22.180529 - Test Loss: 5.178607\n",
      "\n",
      "\n",
      "Epoch 266/750 - Train Cd Loss: 0.077451 - Test Loss: 0.038111\n",
      "Epoch 266/750 - Train pg Loss: 18.494316 - Test Loss: 5.001099\n",
      "\n",
      "\n",
      "Epoch 267/750 - Train Cd Loss: 0.086166 - Test Loss: 0.040093\n",
      "Epoch 267/750 - Train pg Loss: 21.804003 - Test Loss: 5.078909\n",
      "\n",
      "\n",
      "Epoch 268/750 - Train Cd Loss: 0.081033 - Test Loss: 0.038826\n",
      "Epoch 268/750 - Train pg Loss: 20.126963 - Test Loss: 4.085634\n",
      "\n",
      "\n",
      "Epoch 269/750 - Train Cd Loss: 0.076320 - Test Loss: 0.040591\n",
      "Epoch 269/750 - Train pg Loss: 17.163750 - Test Loss: 4.292539\n",
      "\n",
      "\n",
      "Epoch 270/750 - Train Cd Loss: 0.078113 - Test Loss: 0.038650\n",
      "Epoch 270/750 - Train pg Loss: 18.118477 - Test Loss: 4.377794\n",
      "\n",
      "\n",
      "Epoch 271/750 - Train Cd Loss: 0.080162 - Test Loss: 0.041165\n",
      "Epoch 271/750 - Train pg Loss: 17.536991 - Test Loss: 5.023721\n",
      "\n",
      "\n",
      "Epoch 272/750 - Train Cd Loss: 0.084289 - Test Loss: 0.038070\n",
      "Epoch 272/750 - Train pg Loss: 21.907362 - Test Loss: 4.933840\n",
      "\n",
      "\n",
      "Epoch 273/750 - Train Cd Loss: 0.072444 - Test Loss: 0.040033\n",
      "Epoch 273/750 - Train pg Loss: 20.853254 - Test Loss: 5.231385\n",
      "\n",
      "\n",
      "Epoch 274/750 - Train Cd Loss: 0.075708 - Test Loss: 0.038598\n",
      "Epoch 274/750 - Train pg Loss: 21.541903 - Test Loss: 5.917271\n",
      "\n",
      "\n",
      "Epoch 275/750 - Train Cd Loss: 0.074520 - Test Loss: 0.037488\n",
      "Epoch 275/750 - Train pg Loss: 21.611910 - Test Loss: 5.725345\n",
      "\n",
      "\n",
      "Epoch 276/750 - Train Cd Loss: 0.080456 - Test Loss: 0.038876\n",
      "Epoch 276/750 - Train pg Loss: 25.599461 - Test Loss: 6.256123\n",
      "\n",
      "\n",
      "Epoch 277/750 - Train Cd Loss: 0.070768 - Test Loss: 0.039640\n",
      "Epoch 277/750 - Train pg Loss: 26.785242 - Test Loss: 6.391080\n",
      "\n",
      "\n",
      "Epoch 278/750 - Train Cd Loss: 0.073917 - Test Loss: 0.037733\n",
      "Epoch 278/750 - Train pg Loss: 26.924362 - Test Loss: 6.017169\n",
      "\n",
      "\n",
      "Epoch 279/750 - Train Cd Loss: 0.073441 - Test Loss: 0.037579\n",
      "Epoch 279/750 - Train pg Loss: 25.427891 - Test Loss: 4.950792\n",
      "\n",
      "\n",
      "Epoch 280/750 - Train Cd Loss: 0.068347 - Test Loss: 0.039124\n",
      "Epoch 280/750 - Train pg Loss: 25.401218 - Test Loss: 6.384026\n",
      "\n",
      "\n",
      "Epoch 281/750 - Train Cd Loss: 0.084136 - Test Loss: 0.040388\n",
      "Epoch 281/750 - Train pg Loss: 27.251532 - Test Loss: 5.634206\n",
      "\n",
      "\n",
      "Epoch 282/750 - Train Cd Loss: 0.075396 - Test Loss: 0.038751\n",
      "Epoch 282/750 - Train pg Loss: 23.205837 - Test Loss: 6.057431\n",
      "\n",
      "\n",
      "Epoch 283/750 - Train Cd Loss: 0.074116 - Test Loss: 0.040428\n",
      "Epoch 283/750 - Train pg Loss: 25.577988 - Test Loss: 5.597753\n",
      "\n",
      "\n",
      "Epoch 284/750 - Train Cd Loss: 0.081674 - Test Loss: 0.040656\n",
      "Epoch 284/750 - Train pg Loss: 22.166752 - Test Loss: 6.147836\n",
      "\n",
      "\n",
      "Epoch 285/750 - Train Cd Loss: 0.073134 - Test Loss: 0.039172\n",
      "Epoch 285/750 - Train pg Loss: 23.736345 - Test Loss: 6.101239\n",
      "\n",
      "\n",
      "Epoch 286/750 - Train Cd Loss: 0.069679 - Test Loss: 0.038770\n",
      "Epoch 286/750 - Train pg Loss: 22.834820 - Test Loss: 5.528642\n",
      "\n",
      "\n",
      "Epoch 287/750 - Train Cd Loss: 0.086317 - Test Loss: 0.036148\n",
      "Epoch 287/750 - Train pg Loss: 26.865780 - Test Loss: 5.531597\n",
      "\n",
      "\n",
      "Epoch 288/750 - Train Cd Loss: 0.069745 - Test Loss: 0.037106\n",
      "Epoch 288/750 - Train pg Loss: 23.349880 - Test Loss: 5.614608\n",
      "\n",
      "\n",
      "Epoch 289/750 - Train Cd Loss: 0.069291 - Test Loss: 0.038836\n",
      "Epoch 289/750 - Train pg Loss: 25.977459 - Test Loss: 6.911457\n",
      "\n",
      "\n",
      "Epoch 290/750 - Train Cd Loss: 0.075761 - Test Loss: 0.038244\n",
      "Epoch 290/750 - Train pg Loss: 27.862144 - Test Loss: 7.477219\n",
      "\n",
      "\n",
      "Epoch 291/750 - Train Cd Loss: 0.072642 - Test Loss: 0.039428\n",
      "Epoch 291/750 - Train pg Loss: 31.503592 - Test Loss: 7.784104\n",
      "\n",
      "\n",
      "Epoch 292/750 - Train Cd Loss: 0.067717 - Test Loss: 0.041670\n",
      "Epoch 292/750 - Train pg Loss: 31.015255 - Test Loss: 7.726285\n",
      "\n",
      "\n",
      "Epoch 293/750 - Train Cd Loss: 0.080778 - Test Loss: 0.038674\n",
      "Epoch 293/750 - Train pg Loss: 37.953972 - Test Loss: 8.606037\n",
      "\n",
      "\n",
      "Epoch 294/750 - Train Cd Loss: 0.069012 - Test Loss: 0.036878\n",
      "Epoch 294/750 - Train pg Loss: 35.481323 - Test Loss: 7.893130\n",
      "\n",
      "\n",
      "Epoch 295/750 - Train Cd Loss: 0.062130 - Test Loss: 0.040945\n",
      "Epoch 295/750 - Train pg Loss: 32.153244 - Test Loss: 8.030557\n",
      "\n",
      "\n",
      "Epoch 296/750 - Train Cd Loss: 0.082413 - Test Loss: 0.039083\n",
      "Epoch 296/750 - Train pg Loss: 34.768082 - Test Loss: 8.174260\n",
      "\n",
      "\n",
      "Epoch 297/750 - Train Cd Loss: 0.073362 - Test Loss: 0.040645\n",
      "Epoch 297/750 - Train pg Loss: 29.512119 - Test Loss: 8.444950\n",
      "\n",
      "\n",
      "Epoch 298/750 - Train Cd Loss: 0.069788 - Test Loss: 0.043185\n",
      "Epoch 298/750 - Train pg Loss: 34.719234 - Test Loss: 7.351366\n",
      "\n",
      "\n",
      "Epoch 299/750 - Train Cd Loss: 0.062479 - Test Loss: 0.040844\n",
      "Epoch 299/750 - Train pg Loss: 30.576096 - Test Loss: 8.008319\n",
      "\n",
      "\n",
      "Epoch 300/750 - Train Cd Loss: 0.066016 - Test Loss: 0.040436\n",
      "Epoch 300/750 - Train pg Loss: 34.660603 - Test Loss: 9.246146\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/750 - Train Cd Loss: 0.092828 - Test Loss: 0.039525\n",
      "Epoch 301/750 - Train pg Loss: 38.390751 - Test Loss: 7.636857\n",
      "\n",
      "\n",
      "Epoch 302/750 - Train Cd Loss: 0.062351 - Test Loss: 0.039419\n",
      "Epoch 302/750 - Train pg Loss: 32.340313 - Test Loss: 7.309453\n",
      "\n",
      "\n",
      "Epoch 303/750 - Train Cd Loss: 0.074242 - Test Loss: 0.039576\n",
      "Epoch 303/750 - Train pg Loss: 28.625237 - Test Loss: 7.082373\n",
      "\n",
      "\n",
      "Epoch 304/750 - Train Cd Loss: 0.068233 - Test Loss: 0.037765\n",
      "Epoch 304/750 - Train pg Loss: 32.227718 - Test Loss: 7.950774\n",
      "\n",
      "\n",
      "Epoch 305/750 - Train Cd Loss: 0.068268 - Test Loss: 0.040718\n",
      "Epoch 305/750 - Train pg Loss: 35.396904 - Test Loss: 8.923365\n",
      "\n",
      "\n",
      "Epoch 306/750 - Train Cd Loss: 0.064799 - Test Loss: 0.042268\n",
      "Epoch 306/750 - Train pg Loss: 39.020020 - Test Loss: 8.673857\n",
      "\n",
      "\n",
      "Epoch 307/750 - Train Cd Loss: 0.069350 - Test Loss: 0.041852\n",
      "Epoch 307/750 - Train pg Loss: 40.631409 - Test Loss: 8.334072\n",
      "\n",
      "\n",
      "Epoch 308/750 - Train Cd Loss: 0.066524 - Test Loss: 0.039142\n",
      "Epoch 308/750 - Train pg Loss: 31.679365 - Test Loss: 7.312182\n",
      "\n",
      "\n",
      "Epoch 309/750 - Train Cd Loss: 0.083235 - Test Loss: 0.037949\n",
      "Epoch 309/750 - Train pg Loss: 30.581221 - Test Loss: 7.285098\n",
      "\n",
      "\n",
      "Epoch 310/750 - Train Cd Loss: 0.062430 - Test Loss: 0.039145\n",
      "Epoch 310/750 - Train pg Loss: 31.400942 - Test Loss: 8.159238\n",
      "\n",
      "\n",
      "Epoch 311/750 - Train Cd Loss: 0.063940 - Test Loss: 0.040413\n",
      "Epoch 311/750 - Train pg Loss: 33.520603 - Test Loss: 8.591830\n",
      "\n",
      "\n",
      "Epoch 312/750 - Train Cd Loss: 0.063095 - Test Loss: 0.043920\n",
      "Epoch 312/750 - Train pg Loss: 34.510120 - Test Loss: 7.894857\n",
      "\n",
      "\n",
      "Epoch 313/750 - Train Cd Loss: 0.076275 - Test Loss: 0.039723\n",
      "Epoch 313/750 - Train pg Loss: 32.370884 - Test Loss: 8.432878\n",
      "\n",
      "\n",
      "Epoch 314/750 - Train Cd Loss: 0.066210 - Test Loss: 0.042629\n",
      "Epoch 314/750 - Train pg Loss: 36.839600 - Test Loss: 8.406993\n",
      "\n",
      "\n",
      "Epoch 315/750 - Train Cd Loss: 0.070951 - Test Loss: 0.042013\n",
      "Epoch 315/750 - Train pg Loss: 40.245754 - Test Loss: 8.328056\n",
      "\n",
      "\n",
      "Epoch 316/750 - Train Cd Loss: 0.062340 - Test Loss: 0.039596\n",
      "Epoch 316/750 - Train pg Loss: 30.049538 - Test Loss: 7.596865\n",
      "\n",
      "\n",
      "Epoch 317/750 - Train Cd Loss: 0.079687 - Test Loss: 0.040471\n",
      "Epoch 317/750 - Train pg Loss: 30.994820 - Test Loss: 7.998671\n",
      "\n",
      "\n",
      "Epoch 318/750 - Train Cd Loss: 0.062938 - Test Loss: 0.040293\n",
      "Epoch 318/750 - Train pg Loss: 28.685131 - Test Loss: 7.185112\n",
      "\n",
      "\n",
      "Epoch 319/750 - Train Cd Loss: 0.076777 - Test Loss: 0.041718\n",
      "Epoch 319/750 - Train pg Loss: 29.510826 - Test Loss: 7.635227\n",
      "\n",
      "\n",
      "Epoch 320/750 - Train Cd Loss: 0.065887 - Test Loss: 0.039485\n",
      "Epoch 320/750 - Train pg Loss: 30.313992 - Test Loss: 7.306630\n",
      "\n",
      "\n",
      "Epoch 321/750 - Train Cd Loss: 0.067540 - Test Loss: 0.039833\n",
      "Epoch 321/750 - Train pg Loss: 27.708183 - Test Loss: 6.812161\n",
      "\n",
      "\n",
      "Epoch 322/750 - Train Cd Loss: 0.061271 - Test Loss: 0.043646\n",
      "Epoch 322/750 - Train pg Loss: 28.453651 - Test Loss: 7.113489\n",
      "\n",
      "\n",
      "Epoch 323/750 - Train Cd Loss: 0.068147 - Test Loss: 0.041442\n",
      "Epoch 323/750 - Train pg Loss: 31.027977 - Test Loss: 8.011112\n",
      "\n",
      "\n",
      "Epoch 324/750 - Train Cd Loss: 0.053395 - Test Loss: 0.042366\n",
      "Epoch 324/750 - Train pg Loss: 31.270746 - Test Loss: 7.771431\n",
      "\n",
      "\n",
      "Epoch 325/750 - Train Cd Loss: 0.065255 - Test Loss: 0.039393\n",
      "Epoch 325/750 - Train pg Loss: 28.905962 - Test Loss: 7.771749\n",
      "\n",
      "\n",
      "Epoch 326/750 - Train Cd Loss: 0.058783 - Test Loss: 0.041761\n",
      "Epoch 326/750 - Train pg Loss: 28.739794 - Test Loss: 7.676511\n",
      "\n",
      "\n",
      "Epoch 327/750 - Train Cd Loss: 0.066860 - Test Loss: 0.043083\n",
      "Epoch 327/750 - Train pg Loss: 33.943058 - Test Loss: 7.359630\n",
      "\n",
      "\n",
      "Epoch 328/750 - Train Cd Loss: 0.059939 - Test Loss: 0.042769\n",
      "Epoch 328/750 - Train pg Loss: 29.615122 - Test Loss: 7.854079\n",
      "\n",
      "\n",
      "Epoch 329/750 - Train Cd Loss: 0.072888 - Test Loss: 0.044434\n",
      "Epoch 329/750 - Train pg Loss: 36.698097 - Test Loss: 8.261375\n",
      "\n",
      "\n",
      "Epoch 330/750 - Train Cd Loss: 0.058135 - Test Loss: 0.041412\n",
      "Epoch 330/750 - Train pg Loss: 32.563183 - Test Loss: 8.365447\n",
      "\n",
      "\n",
      "Epoch 331/750 - Train Cd Loss: 0.057457 - Test Loss: 0.040450\n",
      "Epoch 331/750 - Train pg Loss: 33.743759 - Test Loss: 9.166166\n",
      "\n",
      "\n",
      "Epoch 332/750 - Train Cd Loss: 0.066914 - Test Loss: 0.037586\n",
      "Epoch 332/750 - Train pg Loss: 33.474606 - Test Loss: 7.228420\n",
      "\n",
      "\n",
      "Epoch 333/750 - Train Cd Loss: 0.058525 - Test Loss: 0.043110\n",
      "Epoch 333/750 - Train pg Loss: 34.883770 - Test Loss: 8.505515\n",
      "\n",
      "\n",
      "Epoch 334/750 - Train Cd Loss: 0.054208 - Test Loss: 0.042791\n",
      "Epoch 334/750 - Train pg Loss: 34.767097 - Test Loss: 9.189043\n",
      "\n",
      "\n",
      "Epoch 335/750 - Train Cd Loss: 0.053250 - Test Loss: 0.043619\n",
      "Epoch 335/750 - Train pg Loss: 34.911293 - Test Loss: 9.694422\n",
      "\n",
      "\n",
      "Epoch 336/750 - Train Cd Loss: 0.079278 - Test Loss: 0.041459\n",
      "Epoch 336/750 - Train pg Loss: 36.759018 - Test Loss: 8.583315\n",
      "\n",
      "\n",
      "Epoch 337/750 - Train Cd Loss: 0.063224 - Test Loss: 0.042447\n",
      "Epoch 337/750 - Train pg Loss: 31.905645 - Test Loss: 8.624545\n",
      "\n",
      "\n",
      "Epoch 338/750 - Train Cd Loss: 0.052528 - Test Loss: 0.040251\n",
      "Epoch 338/750 - Train pg Loss: 31.215481 - Test Loss: 7.893350\n",
      "\n",
      "\n",
      "Epoch 339/750 - Train Cd Loss: 0.070690 - Test Loss: 0.043366\n",
      "Epoch 339/750 - Train pg Loss: 37.146420 - Test Loss: 9.850198\n",
      "\n",
      "\n",
      "Epoch 340/750 - Train Cd Loss: 0.057823 - Test Loss: 0.042371\n",
      "Epoch 340/750 - Train pg Loss: 38.155029 - Test Loss: 8.965249\n",
      "\n",
      "\n",
      "Epoch 341/750 - Train Cd Loss: 0.059488 - Test Loss: 0.043911\n",
      "Epoch 341/750 - Train pg Loss: 39.436211 - Test Loss: 9.138183\n",
      "\n",
      "\n",
      "Epoch 342/750 - Train Cd Loss: 0.060573 - Test Loss: 0.042875\n",
      "Epoch 342/750 - Train pg Loss: 37.385117 - Test Loss: 9.195349\n",
      "\n",
      "\n",
      "Epoch 343/750 - Train Cd Loss: 0.053059 - Test Loss: 0.040114\n",
      "Epoch 343/750 - Train pg Loss: 39.718002 - Test Loss: 10.508547\n",
      "\n",
      "\n",
      "Epoch 344/750 - Train Cd Loss: 0.068819 - Test Loss: 0.042619\n",
      "Epoch 344/750 - Train pg Loss: 40.866470 - Test Loss: 10.169958\n",
      "\n",
      "\n",
      "Epoch 345/750 - Train Cd Loss: 0.049897 - Test Loss: 0.043234\n",
      "Epoch 345/750 - Train pg Loss: 34.106632 - Test Loss: 10.252643\n",
      "\n",
      "\n",
      "Epoch 346/750 - Train Cd Loss: 0.070686 - Test Loss: 0.042764\n",
      "Epoch 346/750 - Train pg Loss: 41.684090 - Test Loss: 9.072587\n",
      "\n",
      "\n",
      "Epoch 347/750 - Train Cd Loss: 0.053488 - Test Loss: 0.044965\n",
      "Epoch 347/750 - Train pg Loss: 39.098598 - Test Loss: 9.770468\n",
      "\n",
      "\n",
      "Epoch 348/750 - Train Cd Loss: 0.052268 - Test Loss: 0.041231\n",
      "Epoch 348/750 - Train pg Loss: 39.524033 - Test Loss: 9.737261\n",
      "\n",
      "\n",
      "Epoch 349/750 - Train Cd Loss: 0.069799 - Test Loss: 0.041370\n",
      "Epoch 349/750 - Train pg Loss: 45.931187 - Test Loss: 10.372379\n",
      "\n",
      "\n",
      "Epoch 350/750 - Train Cd Loss: 0.067250 - Test Loss: 0.043196\n",
      "Epoch 350/750 - Train pg Loss: 39.811954 - Test Loss: 10.613710\n",
      "\n",
      "\n",
      "Epoch 351/750 - Train Cd Loss: 0.054160 - Test Loss: 0.042742\n",
      "Epoch 351/750 - Train pg Loss: 39.395470 - Test Loss: 9.415414\n",
      "\n",
      "\n",
      "Epoch 352/750 - Train Cd Loss: 0.057495 - Test Loss: 0.042190\n",
      "Epoch 352/750 - Train pg Loss: 34.881733 - Test Loss: 10.474317\n",
      "\n",
      "\n",
      "Epoch 353/750 - Train Cd Loss: 0.054632 - Test Loss: 0.043187\n",
      "Epoch 353/750 - Train pg Loss: 41.251564 - Test Loss: 10.821931\n",
      "\n",
      "\n",
      "Epoch 354/750 - Train Cd Loss: 0.067404 - Test Loss: 0.041682\n",
      "Epoch 354/750 - Train pg Loss: 45.127991 - Test Loss: 10.502222\n",
      "\n",
      "\n",
      "Epoch 355/750 - Train Cd Loss: 0.061744 - Test Loss: 0.044471\n",
      "Epoch 355/750 - Train pg Loss: 41.046715 - Test Loss: 10.212293\n",
      "\n",
      "\n",
      "Epoch 356/750 - Train Cd Loss: 0.060214 - Test Loss: 0.044616\n",
      "Epoch 356/750 - Train pg Loss: 43.068417 - Test Loss: 11.483075\n",
      "\n",
      "\n",
      "Epoch 357/750 - Train Cd Loss: 0.065355 - Test Loss: 0.043529\n",
      "Epoch 357/750 - Train pg Loss: 45.459354 - Test Loss: 12.381529\n",
      "\n",
      "\n",
      "Epoch 358/750 - Train Cd Loss: 0.071631 - Test Loss: 0.043635\n",
      "Epoch 358/750 - Train pg Loss: 51.214588 - Test Loss: 10.159455\n",
      "\n",
      "\n",
      "Epoch 359/750 - Train Cd Loss: 0.051791 - Test Loss: 0.043949\n",
      "Epoch 359/750 - Train pg Loss: 42.037613 - Test Loss: 9.973303\n",
      "\n",
      "\n",
      "Epoch 360/750 - Train Cd Loss: 0.050905 - Test Loss: 0.044186\n",
      "Epoch 360/750 - Train pg Loss: 42.658958 - Test Loss: 10.631425\n",
      "\n",
      "\n",
      "Epoch 361/750 - Train Cd Loss: 0.053753 - Test Loss: 0.044318\n",
      "Epoch 361/750 - Train pg Loss: 38.121490 - Test Loss: 10.922202\n",
      "\n",
      "\n",
      "Epoch 362/750 - Train Cd Loss: 0.072611 - Test Loss: 0.045824\n",
      "Epoch 362/750 - Train pg Loss: 48.678463 - Test Loss: 12.175990\n",
      "\n",
      "\n",
      "Epoch 363/750 - Train Cd Loss: 0.057481 - Test Loss: 0.043945\n",
      "Epoch 363/750 - Train pg Loss: 46.977249 - Test Loss: 10.274831\n",
      "\n",
      "\n",
      "Epoch 364/750 - Train Cd Loss: 0.049099 - Test Loss: 0.043033\n",
      "Epoch 364/750 - Train pg Loss: 35.829754 - Test Loss: 9.951029\n",
      "\n",
      "\n",
      "Epoch 365/750 - Train Cd Loss: 0.053255 - Test Loss: 0.046074\n",
      "Epoch 365/750 - Train pg Loss: 40.695713 - Test Loss: 11.173446\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 366/750 - Train Cd Loss: 0.051237 - Test Loss: 0.044357\n",
      "Epoch 366/750 - Train pg Loss: 45.392414 - Test Loss: 11.417290\n",
      "\n",
      "\n",
      "Epoch 367/750 - Train Cd Loss: 0.051770 - Test Loss: 0.043436\n",
      "Epoch 367/750 - Train pg Loss: 50.854534 - Test Loss: 11.881978\n",
      "\n",
      "\n",
      "Epoch 368/750 - Train Cd Loss: 0.049951 - Test Loss: 0.045783\n",
      "Epoch 368/750 - Train pg Loss: 47.085472 - Test Loss: 12.361772\n",
      "\n",
      "\n",
      "Epoch 369/750 - Train Cd Loss: 0.060537 - Test Loss: 0.042905\n",
      "Epoch 369/750 - Train pg Loss: 52.899593 - Test Loss: 12.188836\n",
      "\n",
      "\n",
      "Epoch 370/750 - Train Cd Loss: 0.053821 - Test Loss: 0.045132\n",
      "Epoch 370/750 - Train pg Loss: 49.151390 - Test Loss: 11.169729\n",
      "\n",
      "\n",
      "Epoch 371/750 - Train Cd Loss: 0.056573 - Test Loss: 0.047031\n",
      "Epoch 371/750 - Train pg Loss: 42.032703 - Test Loss: 10.909647\n",
      "\n",
      "\n",
      "Epoch 372/750 - Train Cd Loss: 0.067745 - Test Loss: 0.045460\n",
      "Epoch 372/750 - Train pg Loss: 42.068649 - Test Loss: 9.332849\n",
      "\n",
      "\n",
      "Epoch 373/750 - Train Cd Loss: 0.064555 - Test Loss: 0.041278\n",
      "Epoch 373/750 - Train pg Loss: 34.561119 - Test Loss: 8.039907\n",
      "\n",
      "\n",
      "Epoch 374/750 - Train Cd Loss: 0.058275 - Test Loss: 0.043181\n",
      "Epoch 374/750 - Train pg Loss: 33.925293 - Test Loss: 8.118919\n",
      "\n",
      "\n",
      "Epoch 375/750 - Train Cd Loss: 0.052764 - Test Loss: 0.044217\n",
      "Epoch 375/750 - Train pg Loss: 33.636097 - Test Loss: 8.579329\n",
      "\n",
      "\n",
      "Epoch 376/750 - Train Cd Loss: 0.067430 - Test Loss: 0.042891\n",
      "Epoch 376/750 - Train pg Loss: 37.417725 - Test Loss: 8.822855\n",
      "\n",
      "\n",
      "Epoch 377/750 - Train Cd Loss: 0.054784 - Test Loss: 0.043648\n",
      "Epoch 377/750 - Train pg Loss: 42.796928 - Test Loss: 10.406531\n",
      "\n",
      "\n",
      "Epoch 378/750 - Train Cd Loss: 0.064114 - Test Loss: 0.040929\n",
      "Epoch 378/750 - Train pg Loss: 39.477852 - Test Loss: 9.792855\n",
      "\n",
      "\n",
      "Epoch 379/750 - Train Cd Loss: 0.056708 - Test Loss: 0.042947\n",
      "Epoch 379/750 - Train pg Loss: 44.031467 - Test Loss: 9.051555\n",
      "\n",
      "\n",
      "Epoch 380/750 - Train Cd Loss: 0.056499 - Test Loss: 0.046421\n",
      "Epoch 380/750 - Train pg Loss: 39.469814 - Test Loss: 9.292377\n",
      "\n",
      "\n",
      "Epoch 381/750 - Train Cd Loss: 0.050711 - Test Loss: 0.042384\n",
      "Epoch 381/750 - Train pg Loss: 32.101784 - Test Loss: 7.531441\n",
      "\n",
      "\n",
      "Epoch 382/750 - Train Cd Loss: 0.052598 - Test Loss: 0.045452\n",
      "Epoch 382/750 - Train pg Loss: 33.128399 - Test Loss: 8.601119\n",
      "\n",
      "\n",
      "Epoch 383/750 - Train Cd Loss: 0.063649 - Test Loss: 0.043626\n",
      "Epoch 383/750 - Train pg Loss: 36.402660 - Test Loss: 8.102546\n",
      "\n",
      "\n",
      "Epoch 384/750 - Train Cd Loss: 0.054150 - Test Loss: 0.044136\n",
      "Epoch 384/750 - Train pg Loss: 35.650444 - Test Loss: 8.691677\n",
      "\n",
      "\n",
      "Epoch 385/750 - Train Cd Loss: 0.053242 - Test Loss: 0.039880\n",
      "Epoch 385/750 - Train pg Loss: 32.654892 - Test Loss: 9.337397\n",
      "\n",
      "\n",
      "Epoch 386/750 - Train Cd Loss: 0.050615 - Test Loss: 0.042560\n",
      "Epoch 386/750 - Train pg Loss: 36.461548 - Test Loss: 9.107265\n",
      "\n",
      "\n",
      "Epoch 387/750 - Train Cd Loss: 0.049769 - Test Loss: 0.044152\n",
      "Epoch 387/750 - Train pg Loss: 39.578293 - Test Loss: 10.016303\n",
      "\n",
      "\n",
      "Epoch 388/750 - Train Cd Loss: 0.055915 - Test Loss: 0.044597\n",
      "Epoch 388/750 - Train pg Loss: 42.857773 - Test Loss: 9.952052\n",
      "\n",
      "\n",
      "Epoch 389/750 - Train Cd Loss: 0.053927 - Test Loss: 0.042962\n",
      "Epoch 389/750 - Train pg Loss: 43.870190 - Test Loss: 10.418770\n",
      "\n",
      "\n",
      "Epoch 390/750 - Train Cd Loss: 0.052581 - Test Loss: 0.047269\n",
      "Epoch 390/750 - Train pg Loss: 39.332493 - Test Loss: 9.781586\n",
      "\n",
      "\n",
      "Epoch 391/750 - Train Cd Loss: 0.058457 - Test Loss: 0.045019\n",
      "Epoch 391/750 - Train pg Loss: 36.324406 - Test Loss: 9.582459\n",
      "\n",
      "\n",
      "Epoch 392/750 - Train Cd Loss: 0.046541 - Test Loss: 0.046062\n",
      "Epoch 392/750 - Train pg Loss: 38.928726 - Test Loss: 9.424726\n",
      "\n",
      "\n",
      "Epoch 393/750 - Train Cd Loss: 0.045166 - Test Loss: 0.044637\n",
      "Epoch 393/750 - Train pg Loss: 37.106400 - Test Loss: 10.065011\n",
      "\n",
      "\n",
      "Epoch 394/750 - Train Cd Loss: 0.058762 - Test Loss: 0.044555\n",
      "Epoch 394/750 - Train pg Loss: 46.998753 - Test Loss: 10.527281\n",
      "\n",
      "\n",
      "Epoch 395/750 - Train Cd Loss: 0.052603 - Test Loss: 0.044334\n",
      "Epoch 395/750 - Train pg Loss: 35.782936 - Test Loss: 9.956212\n",
      "\n",
      "\n",
      "Epoch 396/750 - Train Cd Loss: 0.060750 - Test Loss: 0.042086\n",
      "Epoch 396/750 - Train pg Loss: 40.682762 - Test Loss: 10.006392\n",
      "\n",
      "\n",
      "Epoch 397/750 - Train Cd Loss: 0.046643 - Test Loss: 0.043476\n",
      "Epoch 397/750 - Train pg Loss: 39.131733 - Test Loss: 10.139178\n",
      "\n",
      "\n",
      "Epoch 398/750 - Train Cd Loss: 0.055395 - Test Loss: 0.043186\n",
      "Epoch 398/750 - Train pg Loss: 43.540119 - Test Loss: 9.964978\n",
      "\n",
      "\n",
      "Epoch 399/750 - Train Cd Loss: 0.056827 - Test Loss: 0.042373\n",
      "Epoch 399/750 - Train pg Loss: 43.271629 - Test Loss: 9.164830\n",
      "\n",
      "\n",
      "Epoch 400/750 - Train Cd Loss: 0.050841 - Test Loss: 0.044074\n",
      "Epoch 400/750 - Train pg Loss: 39.442127 - Test Loss: 9.744099\n",
      "\n",
      "\n",
      "Epoch 401/750 - Train Cd Loss: 0.046589 - Test Loss: 0.045339\n",
      "Epoch 401/750 - Train pg Loss: 43.695240 - Test Loss: 11.371998\n",
      "\n",
      "\n",
      "Epoch 402/750 - Train Cd Loss: 0.060821 - Test Loss: 0.047363\n",
      "Epoch 402/750 - Train pg Loss: 46.977512 - Test Loss: 10.719324\n",
      "\n",
      "\n",
      "Epoch 403/750 - Train Cd Loss: 0.046110 - Test Loss: 0.048083\n",
      "Epoch 403/750 - Train pg Loss: 42.946159 - Test Loss: 10.835545\n",
      "\n",
      "\n",
      "Epoch 404/750 - Train Cd Loss: 0.050028 - Test Loss: 0.045588\n",
      "Epoch 404/750 - Train pg Loss: 47.482376 - Test Loss: 13.216238\n",
      "\n",
      "\n",
      "Epoch 405/750 - Train Cd Loss: 0.043403 - Test Loss: 0.048514\n",
      "Epoch 405/750 - Train pg Loss: 62.054218 - Test Loss: 13.803966\n",
      "\n",
      "\n",
      "Epoch 406/750 - Train Cd Loss: 0.057029 - Test Loss: 0.043832\n",
      "Epoch 406/750 - Train pg Loss: 45.308918 - Test Loss: 11.965395\n",
      "\n",
      "\n",
      "Epoch 407/750 - Train Cd Loss: 0.048123 - Test Loss: 0.041584\n",
      "Epoch 407/750 - Train pg Loss: 46.477150 - Test Loss: 11.467889\n",
      "\n",
      "\n",
      "Epoch 408/750 - Train Cd Loss: 0.049632 - Test Loss: 0.044758\n",
      "Epoch 408/750 - Train pg Loss: 47.517632 - Test Loss: 11.054869\n",
      "\n",
      "\n",
      "Epoch 409/750 - Train Cd Loss: 0.049074 - Test Loss: 0.047181\n",
      "Epoch 409/750 - Train pg Loss: 44.788471 - Test Loss: 13.050719\n",
      "\n",
      "\n",
      "Epoch 410/750 - Train Cd Loss: 0.060677 - Test Loss: 0.044893\n",
      "Epoch 410/750 - Train pg Loss: 52.008785 - Test Loss: 12.260283\n",
      "\n",
      "\n",
      "Epoch 411/750 - Train Cd Loss: 0.045183 - Test Loss: 0.046924\n",
      "Epoch 411/750 - Train pg Loss: 51.235447 - Test Loss: 12.887671\n",
      "\n",
      "\n",
      "Epoch 412/750 - Train Cd Loss: 0.039585 - Test Loss: 0.048855\n",
      "Epoch 412/750 - Train pg Loss: 47.240696 - Test Loss: 12.673916\n",
      "\n",
      "\n",
      "Epoch 413/750 - Train Cd Loss: 0.072346 - Test Loss: 0.047309\n",
      "Epoch 413/750 - Train pg Loss: 53.439812 - Test Loss: 12.527106\n",
      "\n",
      "\n",
      "Epoch 414/750 - Train Cd Loss: 0.049889 - Test Loss: 0.050601\n",
      "Epoch 414/750 - Train pg Loss: 48.535282 - Test Loss: 13.201395\n",
      "\n",
      "\n",
      "Epoch 415/750 - Train Cd Loss: 0.058190 - Test Loss: 0.043676\n",
      "Epoch 415/750 - Train pg Loss: 46.681702 - Test Loss: 11.419558\n",
      "\n",
      "\n",
      "Epoch 416/750 - Train Cd Loss: 0.054691 - Test Loss: 0.046924\n",
      "Epoch 416/750 - Train pg Loss: 43.249439 - Test Loss: 10.181360\n",
      "\n",
      "\n",
      "Epoch 417/750 - Train Cd Loss: 0.045838 - Test Loss: 0.046665\n",
      "Epoch 417/750 - Train pg Loss: 42.767651 - Test Loss: 12.675394\n",
      "\n",
      "\n",
      "Epoch 418/750 - Train Cd Loss: 0.051691 - Test Loss: 0.046566\n",
      "Epoch 418/750 - Train pg Loss: 47.545757 - Test Loss: 11.682388\n",
      "\n",
      "\n",
      "Epoch 419/750 - Train Cd Loss: 0.049046 - Test Loss: 0.046058\n",
      "Epoch 419/750 - Train pg Loss: 51.251667 - Test Loss: 12.380830\n",
      "\n",
      "\n",
      "Epoch 420/750 - Train Cd Loss: 0.042781 - Test Loss: 0.046731\n",
      "Epoch 420/750 - Train pg Loss: 48.306801 - Test Loss: 12.395596\n",
      "\n",
      "\n",
      "Epoch 421/750 - Train Cd Loss: 0.062127 - Test Loss: 0.044000\n",
      "Epoch 421/750 - Train pg Loss: 48.083553 - Test Loss: 10.563793\n",
      "\n",
      "\n",
      "Epoch 422/750 - Train Cd Loss: 0.051520 - Test Loss: 0.047296\n",
      "Epoch 422/750 - Train pg Loss: 41.921608 - Test Loss: 10.631575\n",
      "\n",
      "\n",
      "Epoch 423/750 - Train Cd Loss: 0.057185 - Test Loss: 0.043436\n",
      "Epoch 423/750 - Train pg Loss: 42.115467 - Test Loss: 10.922281\n",
      "\n",
      "\n",
      "Epoch 424/750 - Train Cd Loss: 0.049221 - Test Loss: 0.041302\n",
      "Epoch 424/750 - Train pg Loss: 43.722481 - Test Loss: 11.917259\n",
      "\n",
      "\n",
      "Epoch 425/750 - Train Cd Loss: 0.044189 - Test Loss: 0.045565\n",
      "Epoch 425/750 - Train pg Loss: 49.970211 - Test Loss: 11.891454\n",
      "\n",
      "\n",
      "Epoch 426/750 - Train Cd Loss: 0.039802 - Test Loss: 0.045988\n",
      "Epoch 426/750 - Train pg Loss: 49.477833 - Test Loss: 12.580349\n",
      "\n",
      "\n",
      "Epoch 427/750 - Train Cd Loss: 0.044998 - Test Loss: 0.048365\n",
      "Epoch 427/750 - Train pg Loss: 46.463261 - Test Loss: 12.069711\n",
      "\n",
      "\n",
      "Epoch 428/750 - Train Cd Loss: 0.045583 - Test Loss: 0.046643\n",
      "Epoch 428/750 - Train pg Loss: 49.509159 - Test Loss: 13.311162\n",
      "\n",
      "\n",
      "Epoch 429/750 - Train Cd Loss: 0.058528 - Test Loss: 0.044625\n",
      "Epoch 429/750 - Train pg Loss: 58.157452 - Test Loss: 13.817699\n",
      "\n",
      "\n",
      "Epoch 430/750 - Train Cd Loss: 0.044456 - Test Loss: 0.046985\n",
      "Epoch 430/750 - Train pg Loss: 45.748444 - Test Loss: 13.776599\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 431/750 - Train Cd Loss: 0.050571 - Test Loss: 0.045170\n",
      "Epoch 431/750 - Train pg Loss: 48.194164 - Test Loss: 12.428012\n",
      "\n",
      "\n",
      "Epoch 432/750 - Train Cd Loss: 0.052939 - Test Loss: 0.042176\n",
      "Epoch 432/750 - Train pg Loss: 45.772774 - Test Loss: 11.479119\n",
      "\n",
      "\n",
      "Epoch 433/750 - Train Cd Loss: 0.051189 - Test Loss: 0.044081\n",
      "Epoch 433/750 - Train pg Loss: 45.258579 - Test Loss: 11.108377\n",
      "\n",
      "\n",
      "Epoch 434/750 - Train Cd Loss: 0.038221 - Test Loss: 0.045834\n",
      "Epoch 434/750 - Train pg Loss: 44.273945 - Test Loss: 11.724199\n",
      "\n",
      "\n",
      "Epoch 435/750 - Train Cd Loss: 0.058817 - Test Loss: 0.046368\n",
      "Epoch 435/750 - Train pg Loss: 48.116634 - Test Loss: 11.703771\n",
      "\n",
      "\n",
      "Epoch 436/750 - Train Cd Loss: 0.049327 - Test Loss: 0.044116\n",
      "Epoch 436/750 - Train pg Loss: 47.471596 - Test Loss: 13.893107\n",
      "\n",
      "\n",
      "Epoch 437/750 - Train Cd Loss: 0.061980 - Test Loss: 0.042369\n",
      "Epoch 437/750 - Train pg Loss: 51.174290 - Test Loss: 11.910156\n",
      "\n",
      "\n",
      "Epoch 438/750 - Train Cd Loss: 0.044286 - Test Loss: 0.042652\n",
      "Epoch 438/750 - Train pg Loss: 44.024956 - Test Loss: 12.474290\n",
      "\n",
      "\n",
      "Epoch 439/750 - Train Cd Loss: 0.053849 - Test Loss: 0.044402\n",
      "Epoch 439/750 - Train pg Loss: 55.134880 - Test Loss: 13.384188\n",
      "\n",
      "\n",
      "Epoch 440/750 - Train Cd Loss: 0.048997 - Test Loss: 0.044183\n",
      "Epoch 440/750 - Train pg Loss: 52.258759 - Test Loss: 13.099772\n",
      "\n",
      "\n",
      "Epoch 441/750 - Train Cd Loss: 0.044026 - Test Loss: 0.043421\n",
      "Epoch 441/750 - Train pg Loss: 46.178242 - Test Loss: 13.233156\n",
      "\n",
      "\n",
      "Epoch 442/750 - Train Cd Loss: 0.041972 - Test Loss: 0.048183\n",
      "Epoch 442/750 - Train pg Loss: 46.864048 - Test Loss: 13.304889\n",
      "\n",
      "\n",
      "Epoch 443/750 - Train Cd Loss: 0.055475 - Test Loss: 0.045461\n",
      "Epoch 443/750 - Train pg Loss: 51.039295 - Test Loss: 13.125999\n",
      "\n",
      "\n",
      "Epoch 444/750 - Train Cd Loss: 0.043623 - Test Loss: 0.046866\n",
      "Epoch 444/750 - Train pg Loss: 54.002789 - Test Loss: 13.973625\n",
      "\n",
      "\n",
      "Epoch 445/750 - Train Cd Loss: 0.042490 - Test Loss: 0.050751\n",
      "Epoch 445/750 - Train pg Loss: 58.243416 - Test Loss: 15.008844\n",
      "\n",
      "\n",
      "Epoch 446/750 - Train Cd Loss: 0.048331 - Test Loss: 0.046458\n",
      "Epoch 446/750 - Train pg Loss: 62.918045 - Test Loss: 14.218271\n",
      "\n",
      "\n",
      "Epoch 447/750 - Train Cd Loss: 0.048519 - Test Loss: 0.046206\n",
      "Epoch 447/750 - Train pg Loss: 50.549469 - Test Loss: 11.227793\n",
      "\n",
      "\n",
      "Epoch 448/750 - Train Cd Loss: 0.041626 - Test Loss: 0.048600\n",
      "Epoch 448/750 - Train pg Loss: 43.396755 - Test Loss: 13.239603\n",
      "\n",
      "\n",
      "Epoch 449/750 - Train Cd Loss: 0.038879 - Test Loss: 0.049225\n",
      "Epoch 449/750 - Train pg Loss: 57.948132 - Test Loss: 15.059001\n",
      "\n",
      "\n",
      "Epoch 450/750 - Train Cd Loss: 0.042909 - Test Loss: 0.049623\n",
      "Epoch 450/750 - Train pg Loss: 59.185925 - Test Loss: 15.751492\n",
      "\n",
      "\n",
      "Epoch 451/750 - Train Cd Loss: 0.052201 - Test Loss: 0.049250\n",
      "Epoch 451/750 - Train pg Loss: 61.222027 - Test Loss: 15.054107\n",
      "\n",
      "\n",
      "Epoch 452/750 - Train Cd Loss: 0.053599 - Test Loss: 0.044699\n",
      "Epoch 452/750 - Train pg Loss: 56.494396 - Test Loss: 13.916636\n",
      "\n",
      "\n",
      "Epoch 453/750 - Train Cd Loss: 0.037702 - Test Loss: 0.046607\n",
      "Epoch 453/750 - Train pg Loss: 59.458393 - Test Loss: 15.432956\n",
      "\n",
      "\n",
      "Epoch 454/750 - Train Cd Loss: 0.044727 - Test Loss: 0.044896\n",
      "Epoch 454/750 - Train pg Loss: 63.183376 - Test Loss: 15.981977\n",
      "\n",
      "\n",
      "Epoch 455/750 - Train Cd Loss: 0.041268 - Test Loss: 0.046932\n",
      "Epoch 455/750 - Train pg Loss: 55.350082 - Test Loss: 15.086950\n",
      "\n",
      "\n",
      "Epoch 456/750 - Train Cd Loss: 0.044590 - Test Loss: 0.045137\n",
      "Epoch 456/750 - Train pg Loss: 54.430092 - Test Loss: 12.699392\n",
      "\n",
      "\n",
      "Epoch 457/750 - Train Cd Loss: 0.038191 - Test Loss: 0.047323\n",
      "Epoch 457/750 - Train pg Loss: 52.358517 - Test Loss: 14.988407\n",
      "\n",
      "\n",
      "Epoch 458/750 - Train Cd Loss: 0.036147 - Test Loss: 0.046315\n",
      "Epoch 458/750 - Train pg Loss: 58.394672 - Test Loss: 14.447789\n",
      "\n",
      "\n",
      "Epoch 459/750 - Train Cd Loss: 0.056259 - Test Loss: 0.047719\n",
      "Epoch 459/750 - Train pg Loss: 48.795456 - Test Loss: 13.168797\n",
      "\n",
      "\n",
      "Epoch 460/750 - Train Cd Loss: 0.039396 - Test Loss: 0.045347\n",
      "Epoch 460/750 - Train pg Loss: 54.240726 - Test Loss: 13.441729\n",
      "\n",
      "\n",
      "Epoch 461/750 - Train Cd Loss: 0.036172 - Test Loss: 0.048279\n",
      "Epoch 461/750 - Train pg Loss: 48.141716 - Test Loss: 13.890504\n",
      "\n",
      "\n",
      "Epoch 462/750 - Train Cd Loss: 0.047279 - Test Loss: 0.046845\n",
      "Epoch 462/750 - Train pg Loss: 60.648426 - Test Loss: 13.895042\n",
      "\n",
      "\n",
      "Epoch 463/750 - Train Cd Loss: 0.045097 - Test Loss: 0.048034\n",
      "Epoch 463/750 - Train pg Loss: 56.718082 - Test Loss: 14.602052\n",
      "\n",
      "\n",
      "Epoch 464/750 - Train Cd Loss: 0.035805 - Test Loss: 0.046162\n",
      "Epoch 464/750 - Train pg Loss: 60.401787 - Test Loss: 14.640330\n",
      "\n",
      "\n",
      "Epoch 465/750 - Train Cd Loss: 0.042400 - Test Loss: 0.045314\n",
      "Epoch 465/750 - Train pg Loss: 53.969856 - Test Loss: 15.753999\n",
      "\n",
      "\n",
      "Epoch 466/750 - Train Cd Loss: 0.051140 - Test Loss: 0.043668\n",
      "Epoch 466/750 - Train pg Loss: 57.093300 - Test Loss: 14.910293\n",
      "\n",
      "\n",
      "Epoch 467/750 - Train Cd Loss: 0.035957 - Test Loss: 0.048702\n",
      "Epoch 467/750 - Train pg Loss: 58.211643 - Test Loss: 16.766632\n",
      "\n",
      "\n",
      "Epoch 468/750 - Train Cd Loss: 0.051116 - Test Loss: 0.047770\n",
      "Epoch 468/750 - Train pg Loss: 63.923466 - Test Loss: 16.733534\n",
      "\n",
      "\n",
      "Epoch 469/750 - Train Cd Loss: 0.036810 - Test Loss: 0.047187\n",
      "Epoch 469/750 - Train pg Loss: 75.001144 - Test Loss: 18.891766\n",
      "\n",
      "\n",
      "Epoch 470/750 - Train Cd Loss: 0.034697 - Test Loss: 0.046966\n",
      "Epoch 470/750 - Train pg Loss: 76.086357 - Test Loss: 17.895643\n",
      "\n",
      "\n",
      "Epoch 471/750 - Train Cd Loss: 0.035344 - Test Loss: 0.051293\n",
      "Epoch 471/750 - Train pg Loss: 64.970009 - Test Loss: 19.785084\n",
      "\n",
      "\n",
      "Epoch 472/750 - Train Cd Loss: 0.036930 - Test Loss: 0.049659\n",
      "Epoch 472/750 - Train pg Loss: 77.163445 - Test Loss: 19.420059\n",
      "\n",
      "\n",
      "Epoch 473/750 - Train Cd Loss: 0.064554 - Test Loss: 0.047583\n",
      "Epoch 473/750 - Train pg Loss: 71.929062 - Test Loss: 15.563333\n",
      "\n",
      "\n",
      "Epoch 474/750 - Train Cd Loss: 0.034441 - Test Loss: 0.048816\n",
      "Epoch 474/750 - Train pg Loss: 58.944389 - Test Loss: 15.545487\n",
      "\n",
      "\n",
      "Epoch 475/750 - Train Cd Loss: 0.034358 - Test Loss: 0.049517\n",
      "Epoch 475/750 - Train pg Loss: 60.169559 - Test Loss: 15.998934\n",
      "\n",
      "\n",
      "Epoch 476/750 - Train Cd Loss: 0.031866 - Test Loss: 0.046671\n",
      "Epoch 476/750 - Train pg Loss: 57.684883 - Test Loss: 17.642368\n",
      "\n",
      "\n",
      "Epoch 477/750 - Train Cd Loss: 0.036549 - Test Loss: 0.048880\n",
      "Epoch 477/750 - Train pg Loss: 70.751945 - Test Loss: 17.385677\n",
      "\n",
      "\n",
      "Epoch 478/750 - Train Cd Loss: 0.033505 - Test Loss: 0.051225\n",
      "Epoch 478/750 - Train pg Loss: 65.032379 - Test Loss: 18.392139\n",
      "\n",
      "\n",
      "Epoch 479/750 - Train Cd Loss: 0.064140 - Test Loss: 0.046752\n",
      "Epoch 479/750 - Train pg Loss: 72.194710 - Test Loss: 17.408373\n",
      "\n",
      "\n",
      "Epoch 480/750 - Train Cd Loss: 0.040209 - Test Loss: 0.048520\n",
      "Epoch 480/750 - Train pg Loss: 81.487900 - Test Loss: 18.173428\n",
      "\n",
      "\n",
      "Epoch 481/750 - Train Cd Loss: 0.035434 - Test Loss: 0.051020\n",
      "Epoch 481/750 - Train pg Loss: 82.772995 - Test Loss: 19.433475\n",
      "\n",
      "\n",
      "Epoch 482/750 - Train Cd Loss: 0.048866 - Test Loss: 0.047000\n",
      "Epoch 482/750 - Train pg Loss: 67.838379 - Test Loss: 20.062077\n",
      "\n",
      "\n",
      "Epoch 483/750 - Train Cd Loss: 0.035892 - Test Loss: 0.048292\n",
      "Epoch 483/750 - Train pg Loss: 80.216072 - Test Loss: 20.738632\n",
      "\n",
      "\n",
      "Epoch 484/750 - Train Cd Loss: 0.054733 - Test Loss: 0.047572\n",
      "Epoch 484/750 - Train pg Loss: 77.720795 - Test Loss: 18.423840\n",
      "\n",
      "\n",
      "Epoch 485/750 - Train Cd Loss: 0.035307 - Test Loss: 0.046958\n",
      "Epoch 485/750 - Train pg Loss: 75.304855 - Test Loss: 20.722275\n",
      "\n",
      "\n",
      "Epoch 486/750 - Train Cd Loss: 0.033868 - Test Loss: 0.051598\n",
      "Epoch 486/750 - Train pg Loss: 68.841537 - Test Loss: 21.899023\n",
      "\n",
      "\n",
      "Epoch 487/750 - Train Cd Loss: 0.047011 - Test Loss: 0.050794\n",
      "Epoch 487/750 - Train pg Loss: 66.478477 - Test Loss: 19.555845\n",
      "\n",
      "\n",
      "Epoch 488/750 - Train Cd Loss: 0.050316 - Test Loss: 0.045033\n",
      "Epoch 488/750 - Train pg Loss: 61.711685 - Test Loss: 19.169697\n",
      "\n",
      "\n",
      "Epoch 489/750 - Train Cd Loss: 0.048877 - Test Loss: 0.045837\n",
      "Epoch 489/750 - Train pg Loss: 74.162354 - Test Loss: 18.546988\n",
      "\n",
      "\n",
      "Epoch 490/750 - Train Cd Loss: 0.035317 - Test Loss: 0.048213\n",
      "Epoch 490/750 - Train pg Loss: 84.563812 - Test Loss: 19.949203\n",
      "\n",
      "\n",
      "Epoch 491/750 - Train Cd Loss: 0.030724 - Test Loss: 0.049637\n",
      "Epoch 491/750 - Train pg Loss: 75.399483 - Test Loss: 22.176184\n",
      "\n",
      "\n",
      "Epoch 492/750 - Train Cd Loss: 0.056348 - Test Loss: 0.050434\n",
      "Epoch 492/750 - Train pg Loss: 87.283821 - Test Loss: 21.653566\n",
      "\n",
      "\n",
      "Epoch 493/750 - Train Cd Loss: 0.034862 - Test Loss: 0.046150\n",
      "Epoch 493/750 - Train pg Loss: 76.442726 - Test Loss: 18.668062\n",
      "\n",
      "\n",
      "Epoch 494/750 - Train Cd Loss: 0.033114 - Test Loss: 0.049553\n",
      "Epoch 494/750 - Train pg Loss: 79.467957 - Test Loss: 20.892830\n",
      "\n",
      "\n",
      "Epoch 495/750 - Train Cd Loss: 0.041776 - Test Loss: 0.050605\n",
      "Epoch 495/750 - Train pg Loss: 81.980682 - Test Loss: 22.411440\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/750 - Train Cd Loss: 0.045672 - Test Loss: 0.048267\n",
      "Epoch 496/750 - Train pg Loss: 83.932686 - Test Loss: 21.399101\n",
      "\n",
      "\n",
      "Epoch 497/750 - Train Cd Loss: 0.036706 - Test Loss: 0.046717\n",
      "Epoch 497/750 - Train pg Loss: 76.999130 - Test Loss: 18.700676\n",
      "\n",
      "\n",
      "Epoch 498/750 - Train Cd Loss: 0.044053 - Test Loss: 0.046280\n",
      "Epoch 498/750 - Train pg Loss: 64.270218 - Test Loss: 18.190819\n",
      "\n",
      "\n",
      "Epoch 499/750 - Train Cd Loss: 0.034474 - Test Loss: 0.047431\n",
      "Epoch 499/750 - Train pg Loss: 63.396233 - Test Loss: 18.951485\n",
      "\n",
      "\n",
      "Epoch 500/750 - Train Cd Loss: 0.057973 - Test Loss: 0.047470\n",
      "Epoch 500/750 - Train pg Loss: 71.975975 - Test Loss: 15.790945\n",
      "\n",
      "\n",
      "Epoch 501/750 - Train Cd Loss: 0.030666 - Test Loss: 0.046541\n",
      "Epoch 501/750 - Train pg Loss: 67.345581 - Test Loss: 18.134176\n",
      "\n",
      "\n",
      "Epoch 502/750 - Train Cd Loss: 0.029581 - Test Loss: 0.047867\n",
      "Epoch 502/750 - Train pg Loss: 74.309311 - Test Loss: 20.032230\n",
      "\n",
      "\n",
      "Epoch 503/750 - Train Cd Loss: 0.063562 - Test Loss: 0.047562\n",
      "Epoch 503/750 - Train pg Loss: 78.853149 - Test Loss: 22.506283\n",
      "\n",
      "\n",
      "Epoch 504/750 - Train Cd Loss: 0.035094 - Test Loss: 0.043298\n",
      "Epoch 504/750 - Train pg Loss: 79.032936 - Test Loss: 19.006939\n",
      "\n",
      "\n",
      "Epoch 505/750 - Train Cd Loss: 0.036835 - Test Loss: 0.046766\n",
      "Epoch 505/750 - Train pg Loss: 70.996193 - Test Loss: 18.622374\n",
      "\n",
      "\n",
      "Epoch 506/750 - Train Cd Loss: 0.034467 - Test Loss: 0.049503\n",
      "Epoch 506/750 - Train pg Loss: 71.724808 - Test Loss: 19.829060\n",
      "\n",
      "\n",
      "Epoch 507/750 - Train Cd Loss: 0.032148 - Test Loss: 0.051546\n",
      "Epoch 507/750 - Train pg Loss: 82.327972 - Test Loss: 21.252396\n",
      "\n",
      "\n",
      "Epoch 508/750 - Train Cd Loss: 0.067279 - Test Loss: 0.045380\n",
      "Epoch 508/750 - Train pg Loss: 69.551155 - Test Loss: 17.331261\n",
      "\n",
      "\n",
      "Epoch 509/750 - Train Cd Loss: 0.040744 - Test Loss: 0.046699\n",
      "Epoch 509/750 - Train pg Loss: 67.109665 - Test Loss: 16.684315\n",
      "\n",
      "\n",
      "Epoch 510/750 - Train Cd Loss: 0.032515 - Test Loss: 0.048642\n",
      "Epoch 510/750 - Train pg Loss: 54.352596 - Test Loss: 15.519779\n",
      "\n",
      "\n",
      "Epoch 511/750 - Train Cd Loss: 0.035847 - Test Loss: 0.048252\n",
      "Epoch 511/750 - Train pg Loss: 62.521629 - Test Loss: 17.444176\n",
      "\n",
      "\n",
      "Epoch 512/750 - Train Cd Loss: 0.056829 - Test Loss: 0.046194\n",
      "Epoch 512/750 - Train pg Loss: 61.898510 - Test Loss: 16.537134\n",
      "\n",
      "\n",
      "Epoch 513/750 - Train Cd Loss: 0.037006 - Test Loss: 0.048579\n",
      "Epoch 513/750 - Train pg Loss: 60.932533 - Test Loss: 16.247902\n",
      "\n",
      "\n",
      "Epoch 514/750 - Train Cd Loss: 0.029875 - Test Loss: 0.047240\n",
      "Epoch 514/750 - Train pg Loss: 58.042534 - Test Loss: 16.287928\n",
      "\n",
      "\n",
      "Epoch 515/750 - Train Cd Loss: 0.049666 - Test Loss: 0.046288\n",
      "Epoch 515/750 - Train pg Loss: 60.742626 - Test Loss: 16.915968\n",
      "\n",
      "\n",
      "Epoch 516/750 - Train Cd Loss: 0.029923 - Test Loss: 0.049072\n",
      "Epoch 516/750 - Train pg Loss: 61.273582 - Test Loss: 15.747262\n",
      "\n",
      "\n",
      "Epoch 517/750 - Train Cd Loss: 0.033857 - Test Loss: 0.053243\n",
      "Epoch 517/750 - Train pg Loss: 57.562340 - Test Loss: 15.470146\n",
      "\n",
      "\n",
      "Epoch 518/750 - Train Cd Loss: 0.043600 - Test Loss: 0.048760\n",
      "Epoch 518/750 - Train pg Loss: 53.104801 - Test Loss: 14.782636\n",
      "\n",
      "\n",
      "Epoch 519/750 - Train Cd Loss: 0.029987 - Test Loss: 0.049251\n",
      "Epoch 519/750 - Train pg Loss: 59.240551 - Test Loss: 15.974693\n",
      "\n",
      "\n",
      "Epoch 520/750 - Train Cd Loss: 0.047535 - Test Loss: 0.047883\n",
      "Epoch 520/750 - Train pg Loss: 54.709164 - Test Loss: 16.237871\n",
      "\n",
      "\n",
      "Epoch 521/750 - Train Cd Loss: 0.042932 - Test Loss: 0.044507\n",
      "Epoch 521/750 - Train pg Loss: 58.333855 - Test Loss: 14.533101\n",
      "\n",
      "\n",
      "Epoch 522/750 - Train Cd Loss: 0.032209 - Test Loss: 0.046493\n",
      "Epoch 522/750 - Train pg Loss: 52.955769 - Test Loss: 14.184452\n",
      "\n",
      "\n",
      "Epoch 523/750 - Train Cd Loss: 0.047281 - Test Loss: 0.047529\n",
      "Epoch 523/750 - Train pg Loss: 50.868950 - Test Loss: 14.770317\n",
      "\n",
      "\n",
      "Epoch 524/750 - Train Cd Loss: 0.047208 - Test Loss: 0.045792\n",
      "Epoch 524/750 - Train pg Loss: 61.257732 - Test Loss: 14.115047\n",
      "\n",
      "\n",
      "Epoch 525/750 - Train Cd Loss: 0.035000 - Test Loss: 0.046512\n",
      "Epoch 525/750 - Train pg Loss: 55.943466 - Test Loss: 13.506725\n",
      "\n",
      "\n",
      "Epoch 526/750 - Train Cd Loss: 0.033892 - Test Loss: 0.049784\n",
      "Epoch 526/750 - Train pg Loss: 48.323238 - Test Loss: 14.110634\n",
      "\n",
      "\n",
      "Epoch 527/750 - Train Cd Loss: 0.033513 - Test Loss: 0.049930\n",
      "Epoch 527/750 - Train pg Loss: 51.497505 - Test Loss: 14.167009\n",
      "\n",
      "\n",
      "Epoch 528/750 - Train Cd Loss: 0.032817 - Test Loss: 0.049636\n",
      "Epoch 528/750 - Train pg Loss: 49.886028 - Test Loss: 15.640694\n",
      "\n",
      "\n",
      "Epoch 529/750 - Train Cd Loss: 0.044717 - Test Loss: 0.049391\n",
      "Epoch 529/750 - Train pg Loss: 56.471325 - Test Loss: 16.279346\n",
      "\n",
      "\n",
      "Epoch 530/750 - Train Cd Loss: 0.035821 - Test Loss: 0.047179\n",
      "Epoch 530/750 - Train pg Loss: 53.509811 - Test Loss: 15.183013\n",
      "\n",
      "\n",
      "Epoch 531/750 - Train Cd Loss: 0.037469 - Test Loss: 0.049135\n",
      "Epoch 531/750 - Train pg Loss: 53.014629 - Test Loss: 15.209423\n",
      "\n",
      "\n",
      "Epoch 532/750 - Train Cd Loss: 0.040012 - Test Loss: 0.051398\n",
      "Epoch 532/750 - Train pg Loss: 50.932571 - Test Loss: 15.835505\n",
      "\n",
      "\n",
      "Epoch 533/750 - Train Cd Loss: 0.040599 - Test Loss: 0.047457\n",
      "Epoch 533/750 - Train pg Loss: 60.009838 - Test Loss: 14.919741\n",
      "\n",
      "\n",
      "Epoch 534/750 - Train Cd Loss: 0.031757 - Test Loss: 0.049176\n",
      "Epoch 534/750 - Train pg Loss: 51.733162 - Test Loss: 15.815581\n",
      "\n",
      "\n",
      "Epoch 535/750 - Train Cd Loss: 0.049044 - Test Loss: 0.047466\n",
      "Epoch 535/750 - Train pg Loss: 55.464016 - Test Loss: 15.789297\n",
      "\n",
      "\n",
      "Epoch 536/750 - Train Cd Loss: 0.030874 - Test Loss: 0.049933\n",
      "Epoch 536/750 - Train pg Loss: 62.009979 - Test Loss: 18.346897\n",
      "\n",
      "\n",
      "Epoch 537/750 - Train Cd Loss: 0.043819 - Test Loss: 0.047100\n",
      "Epoch 537/750 - Train pg Loss: 64.822693 - Test Loss: 16.010870\n",
      "\n",
      "\n",
      "Epoch 538/750 - Train Cd Loss: 0.033536 - Test Loss: 0.048598\n",
      "Epoch 538/750 - Train pg Loss: 55.285618 - Test Loss: 16.452051\n",
      "\n",
      "\n",
      "Epoch 539/750 - Train Cd Loss: 0.029111 - Test Loss: 0.049802\n",
      "Epoch 539/750 - Train pg Loss: 61.326580 - Test Loss: 17.720646\n",
      "\n",
      "\n",
      "Epoch 540/750 - Train Cd Loss: 0.038413 - Test Loss: 0.049291\n",
      "Epoch 540/750 - Train pg Loss: 62.151249 - Test Loss: 16.713627\n",
      "\n",
      "\n",
      "Epoch 541/750 - Train Cd Loss: 0.035130 - Test Loss: 0.050411\n",
      "Epoch 541/750 - Train pg Loss: 57.366932 - Test Loss: 17.468605\n",
      "\n",
      "\n",
      "Epoch 542/750 - Train Cd Loss: 0.033533 - Test Loss: 0.048274\n",
      "Epoch 542/750 - Train pg Loss: 56.362087 - Test Loss: 17.112318\n",
      "\n",
      "\n",
      "Epoch 543/750 - Train Cd Loss: 0.041961 - Test Loss: 0.045905\n",
      "Epoch 543/750 - Train pg Loss: 65.009537 - Test Loss: 15.012525\n",
      "\n",
      "\n",
      "Epoch 544/750 - Train Cd Loss: 0.034736 - Test Loss: 0.048832\n",
      "Epoch 544/750 - Train pg Loss: 48.215591 - Test Loss: 15.135834\n",
      "\n",
      "\n",
      "Epoch 545/750 - Train Cd Loss: 0.026547 - Test Loss: 0.049558\n",
      "Epoch 545/750 - Train pg Loss: 50.664444 - Test Loss: 13.820024\n",
      "\n",
      "\n",
      "Epoch 546/750 - Train Cd Loss: 0.032447 - Test Loss: 0.049264\n",
      "Epoch 546/750 - Train pg Loss: 51.469807 - Test Loss: 15.464511\n",
      "\n",
      "\n",
      "Epoch 547/750 - Train Cd Loss: 0.026360 - Test Loss: 0.051555\n",
      "Epoch 547/750 - Train pg Loss: 64.024124 - Test Loss: 19.159979\n",
      "\n",
      "\n",
      "Epoch 548/750 - Train Cd Loss: 0.040732 - Test Loss: 0.047478\n",
      "Epoch 548/750 - Train pg Loss: 72.657570 - Test Loss: 17.418066\n",
      "\n",
      "\n",
      "Epoch 549/750 - Train Cd Loss: 0.026241 - Test Loss: 0.049205\n",
      "Epoch 549/750 - Train pg Loss: 66.787910 - Test Loss: 19.278959\n",
      "\n",
      "\n",
      "Epoch 550/750 - Train Cd Loss: 0.031678 - Test Loss: 0.049145\n",
      "Epoch 550/750 - Train pg Loss: 66.621635 - Test Loss: 18.905792\n",
      "\n",
      "\n",
      "Epoch 551/750 - Train Cd Loss: 0.031905 - Test Loss: 0.054081\n",
      "Epoch 551/750 - Train pg Loss: 65.509094 - Test Loss: 19.458305\n",
      "\n",
      "\n",
      "Epoch 552/750 - Train Cd Loss: 0.041727 - Test Loss: 0.047435\n",
      "Epoch 552/750 - Train pg Loss: 59.932392 - Test Loss: 17.975399\n",
      "\n",
      "\n",
      "Epoch 553/750 - Train Cd Loss: 0.028660 - Test Loss: 0.049940\n",
      "Epoch 553/750 - Train pg Loss: 61.691952 - Test Loss: 18.010616\n",
      "\n",
      "\n",
      "Epoch 554/750 - Train Cd Loss: 0.030876 - Test Loss: 0.050619\n",
      "Epoch 554/750 - Train pg Loss: 59.388653 - Test Loss: 19.292337\n",
      "\n",
      "\n",
      "Epoch 555/750 - Train Cd Loss: 0.042270 - Test Loss: 0.050533\n",
      "Epoch 555/750 - Train pg Loss: 66.201813 - Test Loss: 19.737339\n",
      "\n",
      "\n",
      "Epoch 556/750 - Train Cd Loss: 0.030739 - Test Loss: 0.052929\n",
      "Epoch 556/750 - Train pg Loss: 72.402023 - Test Loss: 19.958288\n",
      "\n",
      "\n",
      "Epoch 557/750 - Train Cd Loss: 0.040002 - Test Loss: 0.052530\n",
      "Epoch 557/750 - Train pg Loss: 61.520679 - Test Loss: 21.002605\n",
      "\n",
      "\n",
      "Epoch 558/750 - Train Cd Loss: 0.028479 - Test Loss: 0.047643\n",
      "Epoch 558/750 - Train pg Loss: 86.834778 - Test Loss: 20.035595\n",
      "\n",
      "\n",
      "Epoch 559/750 - Train Cd Loss: 0.027238 - Test Loss: 0.047977\n",
      "Epoch 559/750 - Train pg Loss: 75.810562 - Test Loss: 22.514719\n",
      "\n",
      "\n",
      "Epoch 560/750 - Train Cd Loss: 0.047896 - Test Loss: 0.048645\n",
      "Epoch 560/750 - Train pg Loss: 73.739052 - Test Loss: 22.074938\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561/750 - Train Cd Loss: 0.031451 - Test Loss: 0.044057\n",
      "Epoch 561/750 - Train pg Loss: 78.052956 - Test Loss: 20.093760\n",
      "\n",
      "\n",
      "Epoch 562/750 - Train Cd Loss: 0.027572 - Test Loss: 0.050429\n",
      "Epoch 562/750 - Train pg Loss: 78.437202 - Test Loss: 20.668362\n",
      "\n",
      "\n",
      "Epoch 563/750 - Train Cd Loss: 0.036253 - Test Loss: 0.051723\n",
      "Epoch 563/750 - Train pg Loss: 73.298531 - Test Loss: 20.927944\n",
      "\n",
      "\n",
      "Epoch 564/750 - Train Cd Loss: 0.028326 - Test Loss: 0.051815\n",
      "Epoch 564/750 - Train pg Loss: 78.478294 - Test Loss: 24.245968\n",
      "\n",
      "\n",
      "Epoch 565/750 - Train Cd Loss: 0.026526 - Test Loss: 0.049462\n",
      "Epoch 565/750 - Train pg Loss: 89.229546 - Test Loss: 25.122042\n",
      "\n",
      "\n",
      "Epoch 566/750 - Train Cd Loss: 0.044094 - Test Loss: 0.047777\n",
      "Epoch 566/750 - Train pg Loss: 81.567902 - Test Loss: 23.031580\n",
      "\n",
      "\n",
      "Epoch 567/750 - Train Cd Loss: 0.026011 - Test Loss: 0.048982\n",
      "Epoch 567/750 - Train pg Loss: 74.423050 - Test Loss: 22.757645\n",
      "\n",
      "\n",
      "Epoch 568/750 - Train Cd Loss: 0.056738 - Test Loss: 0.046404\n",
      "Epoch 568/750 - Train pg Loss: 75.894676 - Test Loss: 19.020697\n",
      "\n",
      "\n",
      "Epoch 569/750 - Train Cd Loss: 0.028879 - Test Loss: 0.046823\n",
      "Epoch 569/750 - Train pg Loss: 71.992981 - Test Loss: 21.683285\n",
      "\n",
      "\n",
      "Epoch 570/750 - Train Cd Loss: 0.039535 - Test Loss: 0.046021\n",
      "Epoch 570/750 - Train pg Loss: 86.843864 - Test Loss: 21.064190\n",
      "\n",
      "\n",
      "Epoch 571/750 - Train Cd Loss: 0.028382 - Test Loss: 0.049627\n",
      "Epoch 571/750 - Train pg Loss: 77.579056 - Test Loss: 21.590017\n",
      "\n",
      "\n",
      "Epoch 572/750 - Train Cd Loss: 0.032709 - Test Loss: 0.050332\n",
      "Epoch 572/750 - Train pg Loss: 83.615135 - Test Loss: 20.413673\n",
      "\n",
      "\n",
      "Epoch 573/750 - Train Cd Loss: 0.031989 - Test Loss: 0.052031\n",
      "Epoch 573/750 - Train pg Loss: 74.138084 - Test Loss: 19.940916\n",
      "\n",
      "\n",
      "Epoch 574/750 - Train Cd Loss: 0.046169 - Test Loss: 0.051168\n",
      "Epoch 574/750 - Train pg Loss: 63.024982 - Test Loss: 17.573666\n",
      "\n",
      "\n",
      "Epoch 575/750 - Train Cd Loss: 0.028234 - Test Loss: 0.051522\n",
      "Epoch 575/750 - Train pg Loss: 64.848541 - Test Loss: 17.844925\n",
      "\n",
      "\n",
      "Epoch 576/750 - Train Cd Loss: 0.029703 - Test Loss: 0.050619\n",
      "Epoch 576/750 - Train pg Loss: 52.136292 - Test Loss: 18.935003\n",
      "\n",
      "\n",
      "Epoch 577/750 - Train Cd Loss: 0.028207 - Test Loss: 0.053496\n",
      "Epoch 577/750 - Train pg Loss: 68.491676 - Test Loss: 21.747297\n",
      "\n",
      "\n",
      "Epoch 578/750 - Train Cd Loss: 0.043482 - Test Loss: 0.050881\n",
      "Epoch 578/750 - Train pg Loss: 61.852131 - Test Loss: 18.915924\n",
      "\n",
      "\n",
      "Epoch 579/750 - Train Cd Loss: 0.042839 - Test Loss: 0.049020\n",
      "Epoch 579/750 - Train pg Loss: 58.261112 - Test Loss: 16.290092\n",
      "\n",
      "\n",
      "Epoch 580/750 - Train Cd Loss: 0.029550 - Test Loss: 0.052343\n",
      "Epoch 580/750 - Train pg Loss: 52.773399 - Test Loss: 16.927532\n",
      "\n",
      "\n",
      "Epoch 581/750 - Train Cd Loss: 0.038541 - Test Loss: 0.048907\n",
      "Epoch 581/750 - Train pg Loss: 56.742466 - Test Loss: 16.481432\n",
      "\n",
      "\n",
      "Epoch 582/750 - Train Cd Loss: 0.039960 - Test Loss: 0.048091\n",
      "Epoch 582/750 - Train pg Loss: 51.386272 - Test Loss: 14.663538\n",
      "\n",
      "\n",
      "Epoch 583/750 - Train Cd Loss: 0.029066 - Test Loss: 0.049278\n",
      "Epoch 583/750 - Train pg Loss: 43.442062 - Test Loss: 15.247794\n",
      "\n",
      "\n",
      "Epoch 584/750 - Train Cd Loss: 0.042348 - Test Loss: 0.049244\n",
      "Epoch 584/750 - Train pg Loss: 58.294395 - Test Loss: 15.158101\n",
      "\n",
      "\n",
      "Epoch 585/750 - Train Cd Loss: 0.029759 - Test Loss: 0.048748\n",
      "Epoch 585/750 - Train pg Loss: 53.452644 - Test Loss: 16.901937\n",
      "\n",
      "\n",
      "Epoch 586/750 - Train Cd Loss: 0.034036 - Test Loss: 0.050426\n",
      "Epoch 586/750 - Train pg Loss: 58.536114 - Test Loss: 18.210943\n",
      "\n",
      "\n",
      "Epoch 587/750 - Train Cd Loss: 0.025770 - Test Loss: 0.051188\n",
      "Epoch 587/750 - Train pg Loss: 66.607452 - Test Loss: 19.740004\n",
      "\n",
      "\n",
      "Epoch 588/750 - Train Cd Loss: 0.057299 - Test Loss: 0.045282\n",
      "Epoch 588/750 - Train pg Loss: 56.235077 - Test Loss: 16.818913\n",
      "\n",
      "\n",
      "Epoch 589/750 - Train Cd Loss: 0.029358 - Test Loss: 0.049947\n",
      "Epoch 589/750 - Train pg Loss: 50.429443 - Test Loss: 16.503675\n",
      "\n",
      "\n",
      "Epoch 590/750 - Train Cd Loss: 0.027738 - Test Loss: 0.054280\n",
      "Epoch 590/750 - Train pg Loss: 48.861542 - Test Loss: 20.164852\n",
      "\n",
      "\n",
      "Epoch 591/750 - Train Cd Loss: 0.038980 - Test Loss: 0.053390\n",
      "Epoch 591/750 - Train pg Loss: 67.117386 - Test Loss: 19.053690\n",
      "\n",
      "\n",
      "Epoch 592/750 - Train Cd Loss: 0.023347 - Test Loss: 0.050892\n",
      "Epoch 592/750 - Train pg Loss: 70.301605 - Test Loss: 21.425718\n",
      "\n",
      "\n",
      "Epoch 593/750 - Train Cd Loss: 0.050696 - Test Loss: 0.047826\n",
      "Epoch 593/750 - Train pg Loss: 74.631783 - Test Loss: 21.613367\n",
      "\n",
      "\n",
      "Epoch 594/750 - Train Cd Loss: 0.024106 - Test Loss: 0.049232\n",
      "Epoch 594/750 - Train pg Loss: 71.772217 - Test Loss: 21.950403\n",
      "\n",
      "\n",
      "Epoch 595/750 - Train Cd Loss: 0.030267 - Test Loss: 0.047868\n",
      "Epoch 595/750 - Train pg Loss: 77.716812 - Test Loss: 22.300104\n",
      "\n",
      "\n",
      "Epoch 596/750 - Train Cd Loss: 0.027442 - Test Loss: 0.049240\n",
      "Epoch 596/750 - Train pg Loss: 85.327682 - Test Loss: 22.169329\n",
      "\n",
      "\n",
      "Epoch 597/750 - Train Cd Loss: 0.022660 - Test Loss: 0.050925\n",
      "Epoch 597/750 - Train pg Loss: 87.150429 - Test Loss: 23.993238\n",
      "\n",
      "\n",
      "Epoch 598/750 - Train Cd Loss: 0.036190 - Test Loss: 0.049715\n",
      "Epoch 598/750 - Train pg Loss: 103.615570 - Test Loss: 25.103128\n",
      "\n",
      "\n",
      "Epoch 599/750 - Train Cd Loss: 0.026454 - Test Loss: 0.050028\n",
      "Epoch 599/750 - Train pg Loss: 81.255676 - Test Loss: 23.761944\n",
      "\n",
      "\n",
      "Epoch 600/750 - Train Cd Loss: 0.028372 - Test Loss: 0.053167\n",
      "Epoch 600/750 - Train pg Loss: 86.280060 - Test Loss: 25.820566\n",
      "\n",
      "\n",
      "Epoch 601/750 - Train Cd Loss: 0.045807 - Test Loss: 0.051489\n",
      "Epoch 601/750 - Train pg Loss: 86.075920 - Test Loss: 24.823751\n",
      "\n",
      "\n",
      "Epoch 602/750 - Train Cd Loss: 0.038660 - Test Loss: 0.045414\n",
      "Epoch 602/750 - Train pg Loss: 76.174461 - Test Loss: 21.818823\n",
      "\n",
      "\n",
      "Epoch 603/750 - Train Cd Loss: 0.041832 - Test Loss: 0.050855\n",
      "Epoch 603/750 - Train pg Loss: 72.713341 - Test Loss: 23.610905\n",
      "\n",
      "\n",
      "Epoch 604/750 - Train Cd Loss: 0.025852 - Test Loss: 0.049433\n",
      "Epoch 604/750 - Train pg Loss: 81.979393 - Test Loss: 25.208576\n",
      "\n",
      "\n",
      "Epoch 605/750 - Train Cd Loss: 0.024029 - Test Loss: 0.053678\n",
      "Epoch 605/750 - Train pg Loss: 90.567757 - Test Loss: 30.051949\n",
      "\n",
      "\n",
      "Epoch 606/750 - Train Cd Loss: 0.037111 - Test Loss: 0.050408\n",
      "Epoch 606/750 - Train pg Loss: 93.316978 - Test Loss: 26.461674\n",
      "\n",
      "\n",
      "Epoch 607/750 - Train Cd Loss: 0.021867 - Test Loss: 0.053570\n",
      "Epoch 607/750 - Train pg Loss: 96.837418 - Test Loss: 27.454746\n",
      "\n",
      "\n",
      "Epoch 608/750 - Train Cd Loss: 0.050498 - Test Loss: 0.047804\n",
      "Epoch 608/750 - Train pg Loss: 95.995453 - Test Loss: 28.002323\n",
      "\n",
      "\n",
      "Epoch 609/750 - Train Cd Loss: 0.023420 - Test Loss: 0.049998\n",
      "Epoch 609/750 - Train pg Loss: 105.616791 - Test Loss: 26.233995\n",
      "\n",
      "\n",
      "Epoch 610/750 - Train Cd Loss: 0.026349 - Test Loss: 0.051528\n",
      "Epoch 610/750 - Train pg Loss: 86.234703 - Test Loss: 26.202587\n",
      "\n",
      "\n",
      "Epoch 611/750 - Train Cd Loss: 0.052831 - Test Loss: 0.047881\n",
      "Epoch 611/750 - Train pg Loss: 83.889214 - Test Loss: 25.584658\n",
      "\n",
      "\n",
      "Epoch 612/750 - Train Cd Loss: 0.039289 - Test Loss: 0.044594\n",
      "Epoch 612/750 - Train pg Loss: 88.868896 - Test Loss: 25.898481\n",
      "\n",
      "\n",
      "Epoch 613/750 - Train Cd Loss: 0.027395 - Test Loss: 0.051328\n",
      "Epoch 613/750 - Train pg Loss: 90.816498 - Test Loss: 26.217989\n",
      "\n",
      "\n",
      "Epoch 614/750 - Train Cd Loss: 0.039453 - Test Loss: 0.052632\n",
      "Epoch 614/750 - Train pg Loss: 95.723869 - Test Loss: 28.954149\n",
      "\n",
      "\n",
      "Epoch 615/750 - Train Cd Loss: 0.038322 - Test Loss: 0.049765\n",
      "Epoch 615/750 - Train pg Loss: 89.970421 - Test Loss: 23.305220\n",
      "\n",
      "\n",
      "Epoch 616/750 - Train Cd Loss: 0.024235 - Test Loss: 0.050437\n",
      "Epoch 616/750 - Train pg Loss: 86.400299 - Test Loss: 26.617178\n",
      "\n",
      "\n",
      "Epoch 617/750 - Train Cd Loss: 0.030853 - Test Loss: 0.050367\n",
      "Epoch 617/750 - Train pg Loss: 94.011879 - Test Loss: 27.942734\n",
      "\n",
      "\n",
      "Epoch 618/750 - Train Cd Loss: 0.026183 - Test Loss: 0.053286\n",
      "Epoch 618/750 - Train pg Loss: 97.892174 - Test Loss: 28.297215\n",
      "\n",
      "\n",
      "Epoch 619/750 - Train Cd Loss: 0.034891 - Test Loss: 0.053004\n",
      "Epoch 619/750 - Train pg Loss: 99.911766 - Test Loss: 26.303640\n",
      "\n",
      "\n",
      "Epoch 620/750 - Train Cd Loss: 0.028878 - Test Loss: 0.048647\n",
      "Epoch 620/750 - Train pg Loss: 95.069016 - Test Loss: 24.761322\n",
      "\n",
      "\n",
      "Epoch 621/750 - Train Cd Loss: 0.025059 - Test Loss: 0.052282\n",
      "Epoch 621/750 - Train pg Loss: 92.221352 - Test Loss: 26.930153\n",
      "\n",
      "\n",
      "Epoch 622/750 - Train Cd Loss: 0.025113 - Test Loss: 0.050233\n",
      "Epoch 622/750 - Train pg Loss: 90.583076 - Test Loss: 28.058237\n",
      "\n",
      "\n",
      "Epoch 623/750 - Train Cd Loss: 0.024890 - Test Loss: 0.049456\n",
      "Epoch 623/750 - Train pg Loss: 95.598175 - Test Loss: 26.862806\n",
      "\n",
      "\n",
      "Epoch 624/750 - Train Cd Loss: 0.037806 - Test Loss: 0.049691\n",
      "Epoch 624/750 - Train pg Loss: 89.314926 - Test Loss: 29.005678\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 625/750 - Train Cd Loss: 0.034220 - Test Loss: 0.047603\n",
      "Epoch 625/750 - Train pg Loss: 94.406883 - Test Loss: 27.117062\n",
      "\n",
      "\n",
      "Epoch 626/750 - Train Cd Loss: 0.022698 - Test Loss: 0.049522\n",
      "Epoch 626/750 - Train pg Loss: 90.993286 - Test Loss: 27.408449\n",
      "\n",
      "\n",
      "Epoch 627/750 - Train Cd Loss: 0.038455 - Test Loss: 0.048906\n",
      "Epoch 627/750 - Train pg Loss: 93.229286 - Test Loss: 24.703245\n",
      "\n",
      "\n",
      "Epoch 628/750 - Train Cd Loss: 0.027618 - Test Loss: 0.051076\n",
      "Epoch 628/750 - Train pg Loss: 76.768845 - Test Loss: 26.494505\n",
      "\n",
      "\n",
      "Epoch 629/750 - Train Cd Loss: 0.027191 - Test Loss: 0.052153\n",
      "Epoch 629/750 - Train pg Loss: 86.242096 - Test Loss: 27.205959\n",
      "\n",
      "\n",
      "Epoch 630/750 - Train Cd Loss: 0.026672 - Test Loss: 0.053429\n",
      "Epoch 630/750 - Train pg Loss: 82.648300 - Test Loss: 31.059921\n",
      "\n",
      "\n",
      "Epoch 631/750 - Train Cd Loss: 0.035717 - Test Loss: 0.049819\n",
      "Epoch 631/750 - Train pg Loss: 101.857254 - Test Loss: 28.739737\n",
      "\n",
      "\n",
      "Epoch 632/750 - Train Cd Loss: 0.022637 - Test Loss: 0.048906\n",
      "Epoch 632/750 - Train pg Loss: 110.144112 - Test Loss: 31.280172\n",
      "\n",
      "\n",
      "Epoch 633/750 - Train Cd Loss: 0.027533 - Test Loss: 0.049617\n",
      "Epoch 633/750 - Train pg Loss: 103.776054 - Test Loss: 30.555647\n",
      "\n",
      "\n",
      "Epoch 634/750 - Train Cd Loss: 0.037795 - Test Loss: 0.049733\n",
      "Epoch 634/750 - Train pg Loss: 102.691589 - Test Loss: 31.331339\n",
      "\n",
      "\n",
      "Epoch 635/750 - Train Cd Loss: 0.031615 - Test Loss: 0.050506\n",
      "Epoch 635/750 - Train pg Loss: 97.571228 - Test Loss: 28.663748\n",
      "\n",
      "\n",
      "Epoch 636/750 - Train Cd Loss: 0.023326 - Test Loss: 0.051176\n",
      "Epoch 636/750 - Train pg Loss: 90.635254 - Test Loss: 27.804520\n",
      "\n",
      "\n",
      "Epoch 637/750 - Train Cd Loss: 0.022905 - Test Loss: 0.051532\n",
      "Epoch 637/750 - Train pg Loss: 96.227501 - Test Loss: 30.621983\n",
      "\n",
      "\n",
      "Epoch 638/750 - Train Cd Loss: 0.059088 - Test Loss: 0.053342\n",
      "Epoch 638/750 - Train pg Loss: 92.381226 - Test Loss: 30.626406\n",
      "\n",
      "\n",
      "Epoch 639/750 - Train Cd Loss: 0.021694 - Test Loss: 0.047778\n",
      "Epoch 639/750 - Train pg Loss: 92.826439 - Test Loss: 31.279001\n",
      "\n",
      "\n",
      "Epoch 640/750 - Train Cd Loss: 0.026472 - Test Loss: 0.051199\n",
      "Epoch 640/750 - Train pg Loss: 102.041718 - Test Loss: 32.526497\n",
      "\n",
      "\n",
      "Epoch 641/750 - Train Cd Loss: 0.049303 - Test Loss: 0.049371\n",
      "Epoch 641/750 - Train pg Loss: 94.312622 - Test Loss: 29.375248\n",
      "\n",
      "\n",
      "Epoch 642/750 - Train Cd Loss: 0.024850 - Test Loss: 0.050271\n",
      "Epoch 642/750 - Train pg Loss: 102.985092 - Test Loss: 27.456078\n",
      "\n",
      "\n",
      "Epoch 643/750 - Train Cd Loss: 0.024321 - Test Loss: 0.055732\n",
      "Epoch 643/750 - Train pg Loss: 102.242706 - Test Loss: 28.153437\n",
      "\n",
      "\n",
      "Epoch 644/750 - Train Cd Loss: 0.038003 - Test Loss: 0.053023\n",
      "Epoch 644/750 - Train pg Loss: 83.371872 - Test Loss: 26.117521\n",
      "\n",
      "\n",
      "Epoch 645/750 - Train Cd Loss: 0.025096 - Test Loss: 0.051221\n",
      "Epoch 645/750 - Train pg Loss: 78.758858 - Test Loss: 27.486210\n",
      "\n",
      "\n",
      "Epoch 646/750 - Train Cd Loss: 0.024432 - Test Loss: 0.049148\n",
      "Epoch 646/750 - Train pg Loss: 95.632515 - Test Loss: 28.250532\n",
      "\n",
      "\n",
      "Epoch 647/750 - Train Cd Loss: 0.032750 - Test Loss: 0.050364\n",
      "Epoch 647/750 - Train pg Loss: 97.979561 - Test Loss: 30.264038\n",
      "\n",
      "\n",
      "Epoch 648/750 - Train Cd Loss: 0.036899 - Test Loss: 0.047681\n",
      "Epoch 648/750 - Train pg Loss: 106.664238 - Test Loss: 27.812553\n",
      "\n",
      "\n",
      "Epoch 649/750 - Train Cd Loss: 0.028582 - Test Loss: 0.049782\n",
      "Epoch 649/750 - Train pg Loss: 87.728447 - Test Loss: 26.916306\n",
      "\n",
      "\n",
      "Epoch 650/750 - Train Cd Loss: 0.023790 - Test Loss: 0.053621\n",
      "Epoch 650/750 - Train pg Loss: 86.016640 - Test Loss: 29.969902\n",
      "\n",
      "\n",
      "Epoch 651/750 - Train Cd Loss: 0.041693 - Test Loss: 0.050740\n",
      "Epoch 651/750 - Train pg Loss: 95.592880 - Test Loss: 29.680790\n",
      "\n",
      "\n",
      "Epoch 652/750 - Train Cd Loss: 0.023796 - Test Loss: 0.053706\n",
      "Epoch 652/750 - Train pg Loss: 91.236992 - Test Loss: 28.623268\n",
      "\n",
      "\n",
      "Epoch 653/750 - Train Cd Loss: 0.025730 - Test Loss: 0.053937\n",
      "Epoch 653/750 - Train pg Loss: 86.207764 - Test Loss: 28.154543\n",
      "\n",
      "\n",
      "Epoch 654/750 - Train Cd Loss: 0.022738 - Test Loss: 0.055979\n",
      "Epoch 654/750 - Train pg Loss: 106.676079 - Test Loss: 32.470665\n",
      "\n",
      "\n",
      "Epoch 655/750 - Train Cd Loss: 0.044055 - Test Loss: 0.051975\n",
      "Epoch 655/750 - Train pg Loss: 92.319847 - Test Loss: 27.435429\n",
      "\n",
      "\n",
      "Epoch 656/750 - Train Cd Loss: 0.027454 - Test Loss: 0.048298\n",
      "Epoch 656/750 - Train pg Loss: 84.632195 - Test Loss: 24.623856\n",
      "\n",
      "\n",
      "Epoch 657/750 - Train Cd Loss: 0.023878 - Test Loss: 0.051338\n",
      "Epoch 657/750 - Train pg Loss: 85.422829 - Test Loss: 27.002491\n",
      "\n",
      "\n",
      "Epoch 658/750 - Train Cd Loss: 0.022344 - Test Loss: 0.051755\n",
      "Epoch 658/750 - Train pg Loss: 87.795143 - Test Loss: 27.707504\n",
      "\n",
      "\n",
      "Epoch 659/750 - Train Cd Loss: 0.025171 - Test Loss: 0.056277\n",
      "Epoch 659/750 - Train pg Loss: 97.706047 - Test Loss: 30.855471\n",
      "\n",
      "\n",
      "Epoch 660/750 - Train Cd Loss: 0.037818 - Test Loss: 0.053743\n",
      "Epoch 660/750 - Train pg Loss: 82.519035 - Test Loss: 28.510698\n",
      "\n",
      "\n",
      "Epoch 661/750 - Train Cd Loss: 0.038488 - Test Loss: 0.051953\n",
      "Epoch 661/750 - Train pg Loss: 85.653931 - Test Loss: 25.456255\n",
      "\n",
      "\n",
      "Epoch 662/750 - Train Cd Loss: 0.022548 - Test Loss: 0.053871\n",
      "Epoch 662/750 - Train pg Loss: 87.229614 - Test Loss: 28.154013\n",
      "\n",
      "\n",
      "Epoch 663/750 - Train Cd Loss: 0.021618 - Test Loss: 0.054005\n",
      "Epoch 663/750 - Train pg Loss: 91.469307 - Test Loss: 32.384781\n",
      "\n",
      "\n",
      "Epoch 664/750 - Train Cd Loss: 0.037480 - Test Loss: 0.052188\n",
      "Epoch 664/750 - Train pg Loss: 112.197983 - Test Loss: 33.407200\n",
      "\n",
      "\n",
      "Epoch 665/750 - Train Cd Loss: 0.022512 - Test Loss: 0.051702\n",
      "Epoch 665/750 - Train pg Loss: 106.135002 - Test Loss: 28.111158\n",
      "\n",
      "\n",
      "Epoch 666/750 - Train Cd Loss: 0.038010 - Test Loss: 0.050278\n",
      "Epoch 666/750 - Train pg Loss: 83.190323 - Test Loss: 24.860088\n",
      "\n",
      "\n",
      "Epoch 667/750 - Train Cd Loss: 0.020521 - Test Loss: 0.051188\n",
      "Epoch 667/750 - Train pg Loss: 94.555702 - Test Loss: 31.653709\n",
      "\n",
      "\n",
      "Epoch 668/750 - Train Cd Loss: 0.017705 - Test Loss: 0.052805\n",
      "Epoch 668/750 - Train pg Loss: 99.308899 - Test Loss: 31.336092\n",
      "\n",
      "\n",
      "Epoch 669/750 - Train Cd Loss: 0.017335 - Test Loss: 0.055883\n",
      "Epoch 669/750 - Train pg Loss: 98.943626 - Test Loss: 32.501221\n",
      "\n",
      "\n",
      "Epoch 670/750 - Train Cd Loss: 0.021180 - Test Loss: 0.055692\n",
      "Epoch 670/750 - Train pg Loss: 118.585388 - Test Loss: 35.255592\n",
      "\n",
      "\n",
      "Epoch 671/750 - Train Cd Loss: 0.039435 - Test Loss: 0.050607\n",
      "Epoch 671/750 - Train pg Loss: 105.755966 - Test Loss: 30.588861\n",
      "\n",
      "\n",
      "Epoch 672/750 - Train Cd Loss: 0.029230 - Test Loss: 0.048964\n",
      "Epoch 672/750 - Train pg Loss: 90.988464 - Test Loss: 32.373001\n",
      "\n",
      "\n",
      "Epoch 673/750 - Train Cd Loss: 0.025756 - Test Loss: 0.051646\n",
      "Epoch 673/750 - Train pg Loss: 117.232498 - Test Loss: 33.542515\n",
      "\n",
      "\n",
      "Epoch 674/750 - Train Cd Loss: 0.044526 - Test Loss: 0.052781\n",
      "Epoch 674/750 - Train pg Loss: 105.029526 - Test Loss: 28.100996\n",
      "\n",
      "\n",
      "Epoch 675/750 - Train Cd Loss: 0.045749 - Test Loss: 0.049750\n",
      "Epoch 675/750 - Train pg Loss: 90.416931 - Test Loss: 25.451605\n",
      "\n",
      "\n",
      "Epoch 676/750 - Train Cd Loss: 0.021029 - Test Loss: 0.053749\n",
      "Epoch 676/750 - Train pg Loss: 91.152824 - Test Loss: 27.700258\n",
      "\n",
      "\n",
      "Epoch 677/750 - Train Cd Loss: 0.019364 - Test Loss: 0.055176\n",
      "Epoch 677/750 - Train pg Loss: 97.551659 - Test Loss: 30.454321\n",
      "\n",
      "\n",
      "Epoch 678/750 - Train Cd Loss: 0.034033 - Test Loss: 0.051819\n",
      "Epoch 678/750 - Train pg Loss: 90.822563 - Test Loss: 27.959692\n",
      "\n",
      "\n",
      "Epoch 679/750 - Train Cd Loss: 0.021745 - Test Loss: 0.055686\n",
      "Epoch 679/750 - Train pg Loss: 99.876190 - Test Loss: 29.284536\n",
      "\n",
      "\n",
      "Epoch 680/750 - Train Cd Loss: 0.055364 - Test Loss: 0.050943\n",
      "Epoch 680/750 - Train pg Loss: 99.628403 - Test Loss: 27.613571\n",
      "\n",
      "\n",
      "Epoch 681/750 - Train Cd Loss: 0.025990 - Test Loss: 0.050764\n",
      "Epoch 681/750 - Train pg Loss: 83.360725 - Test Loss: 29.930677\n",
      "\n",
      "\n",
      "Epoch 682/750 - Train Cd Loss: 0.025816 - Test Loss: 0.054115\n",
      "Epoch 682/750 - Train pg Loss: 85.666466 - Test Loss: 30.145807\n",
      "\n",
      "\n",
      "Epoch 683/750 - Train Cd Loss: 0.047012 - Test Loss: 0.050599\n",
      "Epoch 683/750 - Train pg Loss: 92.083115 - Test Loss: 28.880823\n",
      "\n",
      "\n",
      "Epoch 684/750 - Train Cd Loss: 0.023400 - Test Loss: 0.051200\n",
      "Epoch 684/750 - Train pg Loss: 97.277603 - Test Loss: 26.831797\n",
      "\n",
      "\n",
      "Epoch 685/750 - Train Cd Loss: 0.019770 - Test Loss: 0.054503\n",
      "Epoch 685/750 - Train pg Loss: 91.404739 - Test Loss: 28.976547\n",
      "\n",
      "\n",
      "Epoch 686/750 - Train Cd Loss: 0.032216 - Test Loss: 0.051980\n",
      "Epoch 686/750 - Train pg Loss: 103.092766 - Test Loss: 31.218904\n",
      "\n",
      "\n",
      "Epoch 687/750 - Train Cd Loss: 0.024195 - Test Loss: 0.051694\n",
      "Epoch 687/750 - Train pg Loss: 102.780655 - Test Loss: 31.265900\n",
      "\n",
      "\n",
      "Epoch 688/750 - Train Cd Loss: 0.037451 - Test Loss: 0.053643\n",
      "Epoch 688/750 - Train pg Loss: 96.611832 - Test Loss: 29.184967\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 689/750 - Train Cd Loss: 0.018192 - Test Loss: 0.053215\n",
      "Epoch 689/750 - Train pg Loss: 96.323875 - Test Loss: 30.070633\n",
      "\n",
      "\n",
      "Epoch 690/750 - Train Cd Loss: 0.041689 - Test Loss: 0.051258\n",
      "Epoch 690/750 - Train pg Loss: 92.633553 - Test Loss: 28.710915\n",
      "\n",
      "\n",
      "Epoch 691/750 - Train Cd Loss: 0.022852 - Test Loss: 0.054119\n",
      "Epoch 691/750 - Train pg Loss: 105.034706 - Test Loss: 29.649141\n",
      "\n",
      "\n",
      "Epoch 692/750 - Train Cd Loss: 0.024333 - Test Loss: 0.054032\n",
      "Epoch 692/750 - Train pg Loss: 94.494736 - Test Loss: 30.094429\n",
      "\n",
      "\n",
      "Epoch 693/750 - Train Cd Loss: 0.036433 - Test Loss: 0.049948\n",
      "Epoch 693/750 - Train pg Loss: 101.954247 - Test Loss: 32.250576\n",
      "\n",
      "\n",
      "Epoch 694/750 - Train Cd Loss: 0.022315 - Test Loss: 0.054186\n",
      "Epoch 694/750 - Train pg Loss: 114.495193 - Test Loss: 34.933861\n",
      "\n",
      "\n",
      "Epoch 695/750 - Train Cd Loss: 0.034722 - Test Loss: 0.051637\n",
      "Epoch 695/750 - Train pg Loss: 118.255554 - Test Loss: 33.580166\n",
      "\n",
      "\n",
      "Epoch 696/750 - Train Cd Loss: 0.024431 - Test Loss: 0.050636\n",
      "Epoch 696/750 - Train pg Loss: 102.772606 - Test Loss: 29.865343\n",
      "\n",
      "\n",
      "Epoch 697/750 - Train Cd Loss: 0.019212 - Test Loss: 0.056292\n",
      "Epoch 697/750 - Train pg Loss: 113.377380 - Test Loss: 33.676643\n",
      "\n",
      "\n",
      "Epoch 698/750 - Train Cd Loss: 0.019966 - Test Loss: 0.060907\n",
      "Epoch 698/750 - Train pg Loss: 114.257210 - Test Loss: 38.940361\n",
      "\n",
      "\n",
      "Epoch 699/750 - Train Cd Loss: 0.031392 - Test Loss: 0.055279\n",
      "Epoch 699/750 - Train pg Loss: 119.182365 - Test Loss: 34.986645\n",
      "\n",
      "\n",
      "Epoch 700/750 - Train Cd Loss: 0.020363 - Test Loss: 0.057923\n",
      "Epoch 700/750 - Train pg Loss: 132.737549 - Test Loss: 35.590931\n",
      "\n",
      "\n",
      "Epoch 701/750 - Train Cd Loss: 0.039427 - Test Loss: 0.056450\n",
      "Epoch 701/750 - Train pg Loss: 106.057625 - Test Loss: 34.535275\n",
      "\n",
      "\n",
      "Epoch 702/750 - Train Cd Loss: 0.022509 - Test Loss: 0.055128\n",
      "Epoch 702/750 - Train pg Loss: 111.467766 - Test Loss: 35.750679\n",
      "\n",
      "\n",
      "Epoch 703/750 - Train Cd Loss: 0.035724 - Test Loss: 0.052077\n",
      "Epoch 703/750 - Train pg Loss: 100.779747 - Test Loss: 30.800665\n",
      "\n",
      "\n",
      "Epoch 704/750 - Train Cd Loss: 0.023095 - Test Loss: 0.051351\n",
      "Epoch 704/750 - Train pg Loss: 105.850800 - Test Loss: 30.784628\n",
      "\n",
      "\n",
      "Epoch 705/750 - Train Cd Loss: 0.019921 - Test Loss: 0.052690\n",
      "Epoch 705/750 - Train pg Loss: 109.062828 - Test Loss: 33.841652\n",
      "\n",
      "\n",
      "Epoch 706/750 - Train Cd Loss: 0.018797 - Test Loss: 0.057857\n",
      "Epoch 706/750 - Train pg Loss: 119.590225 - Test Loss: 38.544144\n",
      "\n",
      "\n",
      "Epoch 707/750 - Train Cd Loss: 0.044457 - Test Loss: 0.051252\n",
      "Epoch 707/750 - Train pg Loss: 139.528564 - Test Loss: 40.842739\n",
      "\n",
      "\n",
      "Epoch 708/750 - Train Cd Loss: 0.021617 - Test Loss: 0.051795\n",
      "Epoch 708/750 - Train pg Loss: 122.641380 - Test Loss: 36.827515\n",
      "\n",
      "\n",
      "Epoch 709/750 - Train Cd Loss: 0.025720 - Test Loss: 0.054313\n",
      "Epoch 709/750 - Train pg Loss: 125.027771 - Test Loss: 36.396683\n",
      "\n",
      "\n",
      "Epoch 710/750 - Train Cd Loss: 0.019204 - Test Loss: 0.049488\n",
      "Epoch 710/750 - Train pg Loss: 97.156868 - Test Loss: 33.329208\n",
      "\n",
      "\n",
      "Epoch 711/750 - Train Cd Loss: 0.037589 - Test Loss: 0.052710\n",
      "Epoch 711/750 - Train pg Loss: 107.721649 - Test Loss: 33.848774\n",
      "\n",
      "\n",
      "Epoch 712/750 - Train Cd Loss: 0.017520 - Test Loss: 0.051499\n",
      "Epoch 712/750 - Train pg Loss: 109.728653 - Test Loss: 38.359158\n",
      "\n",
      "\n",
      "Epoch 713/750 - Train Cd Loss: 0.024736 - Test Loss: 0.053025\n",
      "Epoch 713/750 - Train pg Loss: 116.821579 - Test Loss: 39.389454\n",
      "\n",
      "\n",
      "Epoch 714/750 - Train Cd Loss: 0.032258 - Test Loss: 0.050105\n",
      "Epoch 714/750 - Train pg Loss: 119.184906 - Test Loss: 36.836170\n",
      "\n",
      "\n",
      "Epoch 715/750 - Train Cd Loss: 0.020201 - Test Loss: 0.051977\n",
      "Epoch 715/750 - Train pg Loss: 131.898743 - Test Loss: 37.587543\n",
      "\n",
      "\n",
      "Epoch 716/750 - Train Cd Loss: 0.019351 - Test Loss: 0.055954\n",
      "Epoch 716/750 - Train pg Loss: 135.313339 - Test Loss: 40.193924\n",
      "\n",
      "\n",
      "Epoch 717/750 - Train Cd Loss: 0.018707 - Test Loss: 0.053812\n",
      "Epoch 717/750 - Train pg Loss: 120.954765 - Test Loss: 39.976643\n",
      "\n",
      "\n",
      "Epoch 718/750 - Train Cd Loss: 0.019170 - Test Loss: 0.053541\n",
      "Epoch 718/750 - Train pg Loss: 134.276062 - Test Loss: 42.801315\n",
      "\n",
      "\n",
      "Epoch 719/750 - Train Cd Loss: 0.034777 - Test Loss: 0.052678\n",
      "Epoch 719/750 - Train pg Loss: 118.491066 - Test Loss: 40.175880\n",
      "\n",
      "\n",
      "Epoch 720/750 - Train Cd Loss: 0.022853 - Test Loss: 0.052547\n",
      "Epoch 720/750 - Train pg Loss: 128.953400 - Test Loss: 38.463390\n",
      "\n",
      "\n",
      "Epoch 721/750 - Train Cd Loss: 0.031176 - Test Loss: 0.055041\n",
      "Epoch 721/750 - Train pg Loss: 122.759010 - Test Loss: 40.151581\n",
      "\n",
      "\n",
      "Epoch 722/750 - Train Cd Loss: 0.039365 - Test Loss: 0.051156\n",
      "Epoch 722/750 - Train pg Loss: 142.616028 - Test Loss: 41.789120\n",
      "\n",
      "\n",
      "Epoch 723/750 - Train Cd Loss: 0.021181 - Test Loss: 0.053915\n",
      "Epoch 723/750 - Train pg Loss: 138.659409 - Test Loss: 45.475445\n",
      "\n",
      "\n",
      "Epoch 724/750 - Train Cd Loss: 0.046156 - Test Loss: 0.053739\n",
      "Epoch 724/750 - Train pg Loss: 135.551620 - Test Loss: 42.348755\n",
      "\n",
      "\n",
      "Epoch 725/750 - Train Cd Loss: 0.026684 - Test Loss: 0.050272\n",
      "Epoch 725/750 - Train pg Loss: 120.975334 - Test Loss: 37.356930\n",
      "\n",
      "\n",
      "Epoch 726/750 - Train Cd Loss: 0.016700 - Test Loss: 0.052861\n",
      "Epoch 726/750 - Train pg Loss: 114.897980 - Test Loss: 42.393055\n",
      "\n",
      "\n",
      "Epoch 727/750 - Train Cd Loss: 0.016915 - Test Loss: 0.054284\n",
      "Epoch 727/750 - Train pg Loss: 133.322479 - Test Loss: 42.114765\n",
      "\n",
      "\n",
      "Epoch 728/750 - Train Cd Loss: 0.032834 - Test Loss: 0.053130\n",
      "Epoch 728/750 - Train pg Loss: 136.768448 - Test Loss: 40.550617\n",
      "\n",
      "\n",
      "Epoch 729/750 - Train Cd Loss: 0.021886 - Test Loss: 0.051312\n",
      "Epoch 729/750 - Train pg Loss: 147.567871 - Test Loss: 45.476227\n",
      "\n",
      "\n",
      "Epoch 730/750 - Train Cd Loss: 0.039417 - Test Loss: 0.055317\n",
      "Epoch 730/750 - Train pg Loss: 158.664948 - Test Loss: 44.938187\n",
      "\n",
      "\n",
      "Epoch 731/750 - Train Cd Loss: 0.040296 - Test Loss: 0.050679\n",
      "Epoch 731/750 - Train pg Loss: 149.608032 - Test Loss: 44.801140\n",
      "\n",
      "\n",
      "Epoch 732/750 - Train Cd Loss: 0.037393 - Test Loss: 0.052569\n",
      "Epoch 732/750 - Train pg Loss: 135.618759 - Test Loss: 45.208084\n",
      "\n",
      "\n",
      "Epoch 733/750 - Train Cd Loss: 0.024030 - Test Loss: 0.053560\n",
      "Epoch 733/750 - Train pg Loss: 139.211792 - Test Loss: 46.786411\n",
      "\n",
      "\n",
      "Epoch 734/750 - Train Cd Loss: 0.015019 - Test Loss: 0.057205\n",
      "Epoch 734/750 - Train pg Loss: 167.732666 - Test Loss: 47.512737\n",
      "\n",
      "\n",
      "Epoch 735/750 - Train Cd Loss: 0.033950 - Test Loss: 0.052624\n",
      "Epoch 735/750 - Train pg Loss: 136.918823 - Test Loss: 40.727493\n",
      "\n",
      "\n",
      "Epoch 736/750 - Train Cd Loss: 0.018166 - Test Loss: 0.054619\n",
      "Epoch 736/750 - Train pg Loss: 134.393082 - Test Loss: 43.798759\n",
      "\n",
      "\n",
      "Epoch 737/750 - Train Cd Loss: 0.032600 - Test Loss: 0.053224\n",
      "Epoch 737/750 - Train pg Loss: 131.460175 - Test Loss: 41.456295\n",
      "\n",
      "\n",
      "Epoch 738/750 - Train Cd Loss: 0.022286 - Test Loss: 0.055804\n",
      "Epoch 738/750 - Train pg Loss: 140.645523 - Test Loss: 41.943073\n",
      "\n",
      "\n",
      "Epoch 739/750 - Train Cd Loss: 0.038414 - Test Loss: 0.054007\n",
      "Epoch 739/750 - Train pg Loss: 120.769623 - Test Loss: 38.296417\n",
      "\n",
      "\n",
      "Epoch 740/750 - Train Cd Loss: 0.019520 - Test Loss: 0.053225\n",
      "Epoch 740/750 - Train pg Loss: 118.322525 - Test Loss: 37.470623\n",
      "\n",
      "\n",
      "Epoch 741/750 - Train Cd Loss: 0.023375 - Test Loss: 0.055537\n",
      "Epoch 741/750 - Train pg Loss: 110.719017 - Test Loss: 39.836975\n",
      "\n",
      "\n",
      "Epoch 742/750 - Train Cd Loss: 0.045563 - Test Loss: 0.052334\n",
      "Epoch 742/750 - Train pg Loss: 104.696373 - Test Loss: 33.637268\n",
      "\n",
      "\n",
      "Epoch 743/750 - Train Cd Loss: 0.018645 - Test Loss: 0.051500\n",
      "Epoch 743/750 - Train pg Loss: 108.578552 - Test Loss: 34.710865\n",
      "\n",
      "\n",
      "Epoch 744/750 - Train Cd Loss: 0.032945 - Test Loss: 0.051597\n",
      "Epoch 744/750 - Train pg Loss: 111.733360 - Test Loss: 39.174297\n",
      "\n",
      "\n",
      "Epoch 745/750 - Train Cd Loss: 0.017727 - Test Loss: 0.053599\n",
      "Epoch 745/750 - Train pg Loss: 147.487793 - Test Loss: 38.802284\n",
      "\n",
      "\n",
      "Epoch 746/750 - Train Cd Loss: 0.023124 - Test Loss: 0.055581\n",
      "Epoch 746/750 - Train pg Loss: 111.805893 - Test Loss: 34.405472\n",
      "\n",
      "\n",
      "Epoch 747/750 - Train Cd Loss: 0.051971 - Test Loss: 0.053634\n",
      "Epoch 747/750 - Train pg Loss: 112.072968 - Test Loss: 33.969933\n",
      "\n",
      "\n",
      "Epoch 748/750 - Train Cd Loss: 0.025434 - Test Loss: 0.051137\n",
      "Epoch 748/750 - Train pg Loss: 116.973495 - Test Loss: 35.041023\n",
      "\n",
      "\n",
      "Epoch 749/750 - Train Cd Loss: 0.021945 - Test Loss: 0.051707\n",
      "Epoch 749/750 - Train pg Loss: 108.560745 - Test Loss: 35.215450\n",
      "\n",
      "\n",
      "Epoch 750/750 - Train Cd Loss: 0.017114 - Test Loss: 0.054914\n",
      "Epoch 750/750 - Train pg Loss: 119.638496 - Test Loss: 40.354702\n",
      "\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch 1/750 - Train Cd Loss: 0.169413 - Test Loss: 0.038016\n",
      "Epoch 1/750 - Train pg Loss: 3.870826 - Test Loss: 0.939127\n",
      "\n",
      "\n",
      "Epoch 2/750 - Train Cd Loss: 0.168446 - Test Loss: 0.038017\n",
      "Epoch 2/750 - Train pg Loss: 3.784231 - Test Loss: 0.930402\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/750 - Train Cd Loss: 0.167824 - Test Loss: 0.037792\n",
      "Epoch 3/750 - Train pg Loss: 3.722778 - Test Loss: 0.909373\n",
      "\n",
      "\n",
      "Epoch 4/750 - Train Cd Loss: 0.167307 - Test Loss: 0.037293\n",
      "Epoch 4/750 - Train pg Loss: 3.627721 - Test Loss: 0.888996\n",
      "\n",
      "\n",
      "Epoch 5/750 - Train Cd Loss: 0.165910 - Test Loss: 0.037538\n",
      "Epoch 5/750 - Train pg Loss: 3.533969 - Test Loss: 0.868164\n",
      "\n",
      "\n",
      "Epoch 6/750 - Train Cd Loss: 0.165132 - Test Loss: 0.036696\n",
      "Epoch 6/750 - Train pg Loss: 3.473875 - Test Loss: 0.837176\n",
      "\n",
      "\n",
      "Epoch 7/750 - Train Cd Loss: 0.165214 - Test Loss: 0.036940\n",
      "Epoch 7/750 - Train pg Loss: 3.332709 - Test Loss: 0.809014\n",
      "\n",
      "\n",
      "Epoch 8/750 - Train Cd Loss: 0.164687 - Test Loss: 0.037331\n",
      "Epoch 8/750 - Train pg Loss: 3.257977 - Test Loss: 0.803561\n",
      "\n",
      "\n",
      "Epoch 9/750 - Train Cd Loss: 0.163154 - Test Loss: 0.036942\n",
      "Epoch 9/750 - Train pg Loss: 3.175430 - Test Loss: 0.777296\n",
      "\n",
      "\n",
      "Epoch 10/750 - Train Cd Loss: 0.163453 - Test Loss: 0.036980\n",
      "Epoch 10/750 - Train pg Loss: 3.129778 - Test Loss: 0.784444\n",
      "\n",
      "\n",
      "Epoch 11/750 - Train Cd Loss: 0.164461 - Test Loss: 0.036790\n",
      "Epoch 11/750 - Train pg Loss: 3.115789 - Test Loss: 0.787212\n",
      "\n",
      "\n",
      "Epoch 12/750 - Train Cd Loss: 0.162983 - Test Loss: 0.036086\n",
      "Epoch 12/750 - Train pg Loss: 3.135228 - Test Loss: 0.776471\n",
      "\n",
      "\n",
      "Epoch 13/750 - Train Cd Loss: 0.162515 - Test Loss: 0.036650\n",
      "Epoch 13/750 - Train pg Loss: 3.171017 - Test Loss: 0.770368\n",
      "\n",
      "\n",
      "Epoch 14/750 - Train Cd Loss: 0.161266 - Test Loss: 0.035153\n",
      "Epoch 14/750 - Train pg Loss: 3.051986 - Test Loss: 0.743536\n",
      "\n",
      "\n",
      "Epoch 15/750 - Train Cd Loss: 0.161031 - Test Loss: 0.035344\n",
      "Epoch 15/750 - Train pg Loss: 3.025170 - Test Loss: 0.740564\n",
      "\n",
      "\n",
      "Epoch 16/750 - Train Cd Loss: 0.164052 - Test Loss: 0.037685\n",
      "Epoch 16/750 - Train pg Loss: 2.992370 - Test Loss: 0.761062\n",
      "\n",
      "\n",
      "Epoch 17/750 - Train Cd Loss: 0.162217 - Test Loss: 0.036508\n",
      "Epoch 17/750 - Train pg Loss: 3.092003 - Test Loss: 0.763130\n",
      "\n",
      "\n",
      "Epoch 18/750 - Train Cd Loss: 0.165487 - Test Loss: 0.036755\n",
      "Epoch 18/750 - Train pg Loss: 3.120283 - Test Loss: 0.772456\n",
      "\n",
      "\n",
      "Epoch 19/750 - Train Cd Loss: 0.161897 - Test Loss: 0.036341\n",
      "Epoch 19/750 - Train pg Loss: 3.148422 - Test Loss: 0.783898\n",
      "\n",
      "\n",
      "Epoch 20/750 - Train Cd Loss: 0.162512 - Test Loss: 0.037274\n",
      "Epoch 20/750 - Train pg Loss: 3.125617 - Test Loss: 0.763355\n",
      "\n",
      "\n",
      "Epoch 21/750 - Train Cd Loss: 0.162991 - Test Loss: 0.036586\n",
      "Epoch 21/750 - Train pg Loss: 3.100580 - Test Loss: 0.755698\n",
      "\n",
      "\n",
      "Epoch 22/750 - Train Cd Loss: 0.161297 - Test Loss: 0.036155\n",
      "Epoch 22/750 - Train pg Loss: 3.145404 - Test Loss: 0.773742\n",
      "\n",
      "\n",
      "Epoch 23/750 - Train Cd Loss: 0.165749 - Test Loss: 0.036160\n",
      "Epoch 23/750 - Train pg Loss: 3.173226 - Test Loss: 0.769494\n",
      "\n",
      "\n",
      "Epoch 24/750 - Train Cd Loss: 0.161976 - Test Loss: 0.036499\n",
      "Epoch 24/750 - Train pg Loss: 3.234091 - Test Loss: 0.788563\n",
      "\n",
      "\n",
      "Epoch 25/750 - Train Cd Loss: 0.164411 - Test Loss: 0.036991\n",
      "Epoch 25/750 - Train pg Loss: 3.252934 - Test Loss: 0.807631\n",
      "\n",
      "\n",
      "Epoch 26/750 - Train Cd Loss: 0.162362 - Test Loss: 0.036008\n",
      "Epoch 26/750 - Train pg Loss: 3.198461 - Test Loss: 0.791561\n",
      "\n",
      "\n",
      "Epoch 27/750 - Train Cd Loss: 0.164337 - Test Loss: 0.036611\n",
      "Epoch 27/750 - Train pg Loss: 3.327257 - Test Loss: 0.805306\n",
      "\n",
      "\n",
      "Epoch 28/750 - Train Cd Loss: 0.164109 - Test Loss: 0.036989\n",
      "Epoch 28/750 - Train pg Loss: 3.325160 - Test Loss: 0.818495\n",
      "\n",
      "\n",
      "Epoch 29/750 - Train Cd Loss: 0.164340 - Test Loss: 0.037381\n",
      "Epoch 29/750 - Train pg Loss: 3.229451 - Test Loss: 0.814818\n",
      "\n",
      "\n",
      "Epoch 30/750 - Train Cd Loss: 0.162858 - Test Loss: 0.036406\n",
      "Epoch 30/750 - Train pg Loss: 3.379492 - Test Loss: 0.831272\n",
      "\n",
      "\n",
      "Epoch 31/750 - Train Cd Loss: 0.161926 - Test Loss: 0.037040\n",
      "Epoch 31/750 - Train pg Loss: 3.305355 - Test Loss: 0.823475\n",
      "\n",
      "\n",
      "Epoch 32/750 - Train Cd Loss: 0.163862 - Test Loss: 0.035472\n",
      "Epoch 32/750 - Train pg Loss: 3.296694 - Test Loss: 0.815696\n",
      "\n",
      "\n",
      "Epoch 33/750 - Train Cd Loss: 0.162909 - Test Loss: 0.037159\n",
      "Epoch 33/750 - Train pg Loss: 3.338762 - Test Loss: 0.835541\n",
      "\n",
      "\n",
      "Epoch 34/750 - Train Cd Loss: 0.161595 - Test Loss: 0.037164\n",
      "Epoch 34/750 - Train pg Loss: 3.402230 - Test Loss: 0.828965\n",
      "\n",
      "\n",
      "Epoch 35/750 - Train Cd Loss: 0.163551 - Test Loss: 0.036841\n",
      "Epoch 35/750 - Train pg Loss: 3.339284 - Test Loss: 0.823934\n",
      "\n",
      "\n",
      "Epoch 36/750 - Train Cd Loss: 0.161278 - Test Loss: 0.036621\n",
      "Epoch 36/750 - Train pg Loss: 3.367314 - Test Loss: 0.820455\n",
      "\n",
      "\n",
      "Epoch 37/750 - Train Cd Loss: 0.163668 - Test Loss: 0.036722\n",
      "Epoch 37/750 - Train pg Loss: 3.307153 - Test Loss: 0.808895\n",
      "\n",
      "\n",
      "Epoch 38/750 - Train Cd Loss: 0.162737 - Test Loss: 0.036814\n",
      "Epoch 38/750 - Train pg Loss: 3.307994 - Test Loss: 0.805822\n",
      "\n",
      "\n",
      "Epoch 39/750 - Train Cd Loss: 0.162413 - Test Loss: 0.036789\n",
      "Epoch 39/750 - Train pg Loss: 3.328284 - Test Loss: 0.816942\n",
      "\n",
      "\n",
      "Epoch 40/750 - Train Cd Loss: 0.161637 - Test Loss: 0.036994\n",
      "Epoch 40/750 - Train pg Loss: 3.329903 - Test Loss: 0.801142\n",
      "\n",
      "\n",
      "Epoch 41/750 - Train Cd Loss: 0.160517 - Test Loss: 0.036869\n",
      "Epoch 41/750 - Train pg Loss: 3.229465 - Test Loss: 0.806590\n",
      "\n",
      "\n",
      "Epoch 42/750 - Train Cd Loss: 0.160659 - Test Loss: 0.036815\n",
      "Epoch 42/750 - Train pg Loss: 3.290267 - Test Loss: 0.809218\n",
      "\n",
      "\n",
      "Epoch 43/750 - Train Cd Loss: 0.162345 - Test Loss: 0.037003\n",
      "Epoch 43/750 - Train pg Loss: 3.312888 - Test Loss: 0.812202\n",
      "\n",
      "\n",
      "Epoch 44/750 - Train Cd Loss: 0.161274 - Test Loss: 0.036885\n",
      "Epoch 44/750 - Train pg Loss: 3.336955 - Test Loss: 0.808874\n",
      "\n",
      "\n",
      "Epoch 45/750 - Train Cd Loss: 0.159562 - Test Loss: 0.036931\n",
      "Epoch 45/750 - Train pg Loss: 3.302854 - Test Loss: 0.791282\n",
      "\n",
      "\n",
      "Epoch 46/750 - Train Cd Loss: 0.161588 - Test Loss: 0.036980\n",
      "Epoch 46/750 - Train pg Loss: 3.203856 - Test Loss: 0.803825\n",
      "\n",
      "\n",
      "Epoch 47/750 - Train Cd Loss: 0.160081 - Test Loss: 0.037074\n",
      "Epoch 47/750 - Train pg Loss: 3.228307 - Test Loss: 0.805379\n",
      "\n",
      "\n",
      "Epoch 48/750 - Train Cd Loss: 0.161505 - Test Loss: 0.037075\n",
      "Epoch 48/750 - Train pg Loss: 3.332799 - Test Loss: 0.810919\n",
      "\n",
      "\n",
      "Epoch 49/750 - Train Cd Loss: 0.162718 - Test Loss: 0.037212\n",
      "Epoch 49/750 - Train pg Loss: 3.294200 - Test Loss: 0.821356\n",
      "\n",
      "\n",
      "Epoch 50/750 - Train Cd Loss: 0.161898 - Test Loss: 0.036981\n",
      "Epoch 50/750 - Train pg Loss: 3.305146 - Test Loss: 0.811987\n",
      "\n",
      "\n",
      "Epoch 51/750 - Train Cd Loss: 0.159439 - Test Loss: 0.037247\n",
      "Epoch 51/750 - Train pg Loss: 3.260988 - Test Loss: 0.810286\n",
      "\n",
      "\n",
      "Epoch 52/750 - Train Cd Loss: 0.162746 - Test Loss: 0.037028\n",
      "Epoch 52/750 - Train pg Loss: 3.256517 - Test Loss: 0.810508\n",
      "\n",
      "\n",
      "Epoch 53/750 - Train Cd Loss: 0.162523 - Test Loss: 0.036523\n",
      "Epoch 53/750 - Train pg Loss: 3.366273 - Test Loss: 0.826334\n",
      "\n",
      "\n",
      "Epoch 54/750 - Train Cd Loss: 0.160133 - Test Loss: 0.036862\n",
      "Epoch 54/750 - Train pg Loss: 3.403560 - Test Loss: 0.829892\n",
      "\n",
      "\n",
      "Epoch 55/750 - Train Cd Loss: 0.160787 - Test Loss: 0.037478\n",
      "Epoch 55/750 - Train pg Loss: 3.418625 - Test Loss: 0.828028\n",
      "\n",
      "\n",
      "Epoch 56/750 - Train Cd Loss: 0.163708 - Test Loss: 0.036806\n",
      "Epoch 56/750 - Train pg Loss: 3.323170 - Test Loss: 0.816545\n",
      "\n",
      "\n",
      "Epoch 57/750 - Train Cd Loss: 0.161084 - Test Loss: 0.037170\n",
      "Epoch 57/750 - Train pg Loss: 3.375447 - Test Loss: 0.826515\n",
      "\n",
      "\n",
      "Epoch 58/750 - Train Cd Loss: 0.159501 - Test Loss: 0.037061\n",
      "Epoch 58/750 - Train pg Loss: 3.333269 - Test Loss: 0.822231\n",
      "\n",
      "\n",
      "Epoch 59/750 - Train Cd Loss: 0.161460 - Test Loss: 0.037028\n",
      "Epoch 59/750 - Train pg Loss: 3.307205 - Test Loss: 0.818293\n",
      "\n",
      "\n",
      "Epoch 60/750 - Train Cd Loss: 0.160150 - Test Loss: 0.037004\n",
      "Epoch 60/750 - Train pg Loss: 3.123134 - Test Loss: 0.797072\n",
      "\n",
      "\n",
      "Epoch 61/750 - Train Cd Loss: 0.160623 - Test Loss: 0.037066\n",
      "Epoch 61/750 - Train pg Loss: 3.257252 - Test Loss: 0.802376\n",
      "\n",
      "\n",
      "Epoch 62/750 - Train Cd Loss: 0.162437 - Test Loss: 0.037034\n",
      "Epoch 62/750 - Train pg Loss: 3.274531 - Test Loss: 0.800340\n",
      "\n",
      "\n",
      "Epoch 63/750 - Train Cd Loss: 0.162627 - Test Loss: 0.037119\n",
      "Epoch 63/750 - Train pg Loss: 3.254102 - Test Loss: 0.819840\n",
      "\n",
      "\n",
      "Epoch 64/750 - Train Cd Loss: 0.160602 - Test Loss: 0.036288\n",
      "Epoch 64/750 - Train pg Loss: 3.351485 - Test Loss: 0.818219\n",
      "\n",
      "\n",
      "Epoch 65/750 - Train Cd Loss: 0.161066 - Test Loss: 0.037582\n",
      "Epoch 65/750 - Train pg Loss: 3.353270 - Test Loss: 0.818007\n",
      "\n",
      "\n",
      "Epoch 66/750 - Train Cd Loss: 0.161274 - Test Loss: 0.037663\n",
      "Epoch 66/750 - Train pg Loss: 3.301863 - Test Loss: 0.821996\n",
      "\n",
      "\n",
      "Epoch 67/750 - Train Cd Loss: 0.160197 - Test Loss: 0.037452\n",
      "Epoch 67/750 - Train pg Loss: 3.256890 - Test Loss: 0.808102\n",
      "\n",
      "\n",
      "Epoch 68/750 - Train Cd Loss: 0.161289 - Test Loss: 0.036948\n",
      "Epoch 68/750 - Train pg Loss: 3.268132 - Test Loss: 0.813222\n",
      "\n",
      "\n",
      "Epoch 69/750 - Train Cd Loss: 0.160301 - Test Loss: 0.036763\n",
      "Epoch 69/750 - Train pg Loss: 3.353199 - Test Loss: 0.821504\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/750 - Train Cd Loss: 0.161741 - Test Loss: 0.037764\n",
      "Epoch 70/750 - Train pg Loss: 3.226279 - Test Loss: 0.816374\n",
      "\n",
      "\n",
      "Epoch 71/750 - Train Cd Loss: 0.161587 - Test Loss: 0.037216\n",
      "Epoch 71/750 - Train pg Loss: 3.213445 - Test Loss: 0.808979\n",
      "\n",
      "\n",
      "Epoch 72/750 - Train Cd Loss: 0.160963 - Test Loss: 0.037473\n",
      "Epoch 72/750 - Train pg Loss: 3.336414 - Test Loss: 0.806255\n",
      "\n",
      "\n",
      "Epoch 73/750 - Train Cd Loss: 0.160817 - Test Loss: 0.037596\n",
      "Epoch 73/750 - Train pg Loss: 3.256524 - Test Loss: 0.814713\n",
      "\n",
      "\n",
      "Epoch 74/750 - Train Cd Loss: 0.160028 - Test Loss: 0.037208\n",
      "Epoch 74/750 - Train pg Loss: 3.335887 - Test Loss: 0.828267\n",
      "\n",
      "\n",
      "Epoch 75/750 - Train Cd Loss: 0.160789 - Test Loss: 0.037329\n",
      "Epoch 75/750 - Train pg Loss: 3.426250 - Test Loss: 0.838068\n",
      "\n",
      "\n",
      "Epoch 76/750 - Train Cd Loss: 0.158325 - Test Loss: 0.037141\n",
      "Epoch 76/750 - Train pg Loss: 3.449736 - Test Loss: 0.832932\n",
      "\n",
      "\n",
      "Epoch 77/750 - Train Cd Loss: 0.160155 - Test Loss: 0.037614\n",
      "Epoch 77/750 - Train pg Loss: 3.331070 - Test Loss: 0.806528\n",
      "\n",
      "\n",
      "Epoch 78/750 - Train Cd Loss: 0.159301 - Test Loss: 0.037511\n",
      "Epoch 78/750 - Train pg Loss: 3.247174 - Test Loss: 0.788448\n",
      "\n",
      "\n",
      "Epoch 79/750 - Train Cd Loss: 0.161233 - Test Loss: 0.037273\n",
      "Epoch 79/750 - Train pg Loss: 3.229816 - Test Loss: 0.805308\n",
      "\n",
      "\n",
      "Epoch 80/750 - Train Cd Loss: 0.160228 - Test Loss: 0.037211\n",
      "Epoch 80/750 - Train pg Loss: 3.240672 - Test Loss: 0.799843\n",
      "\n",
      "\n",
      "Epoch 81/750 - Train Cd Loss: 0.158438 - Test Loss: 0.037322\n",
      "Epoch 81/750 - Train pg Loss: 3.398807 - Test Loss: 0.834114\n",
      "\n",
      "\n",
      "Epoch 82/750 - Train Cd Loss: 0.161849 - Test Loss: 0.037735\n",
      "Epoch 82/750 - Train pg Loss: 3.375890 - Test Loss: 0.826046\n",
      "\n",
      "\n",
      "Epoch 83/750 - Train Cd Loss: 0.158687 - Test Loss: 0.037487\n",
      "Epoch 83/750 - Train pg Loss: 3.470504 - Test Loss: 0.858277\n",
      "\n",
      "\n",
      "Epoch 84/750 - Train Cd Loss: 0.159470 - Test Loss: 0.036852\n",
      "Epoch 84/750 - Train pg Loss: 3.441564 - Test Loss: 0.842472\n",
      "\n",
      "\n",
      "Epoch 85/750 - Train Cd Loss: 0.157273 - Test Loss: 0.037180\n",
      "Epoch 85/750 - Train pg Loss: 3.324664 - Test Loss: 0.828047\n",
      "\n",
      "\n",
      "Epoch 86/750 - Train Cd Loss: 0.159709 - Test Loss: 0.037261\n",
      "Epoch 86/750 - Train pg Loss: 3.457209 - Test Loss: 0.856816\n",
      "\n",
      "\n",
      "Epoch 87/750 - Train Cd Loss: 0.159946 - Test Loss: 0.037447\n",
      "Epoch 87/750 - Train pg Loss: 3.351235 - Test Loss: 0.845222\n",
      "\n",
      "\n",
      "Epoch 88/750 - Train Cd Loss: 0.157931 - Test Loss: 0.037335\n",
      "Epoch 88/750 - Train pg Loss: 3.492932 - Test Loss: 0.837244\n",
      "\n",
      "\n",
      "Epoch 89/750 - Train Cd Loss: 0.158896 - Test Loss: 0.037779\n",
      "Epoch 89/750 - Train pg Loss: 3.268324 - Test Loss: 0.839104\n",
      "\n",
      "\n",
      "Epoch 90/750 - Train Cd Loss: 0.159696 - Test Loss: 0.037704\n",
      "Epoch 90/750 - Train pg Loss: 3.310959 - Test Loss: 0.832897\n",
      "\n",
      "\n",
      "Epoch 91/750 - Train Cd Loss: 0.160009 - Test Loss: 0.037936\n",
      "Epoch 91/750 - Train pg Loss: 3.283445 - Test Loss: 0.809160\n",
      "\n",
      "\n",
      "Epoch 92/750 - Train Cd Loss: 0.157375 - Test Loss: 0.038089\n",
      "Epoch 92/750 - Train pg Loss: 3.308913 - Test Loss: 0.780917\n",
      "\n",
      "\n",
      "Epoch 93/750 - Train Cd Loss: 0.158474 - Test Loss: 0.037194\n",
      "Epoch 93/750 - Train pg Loss: 3.249244 - Test Loss: 0.787488\n",
      "\n",
      "\n",
      "Epoch 94/750 - Train Cd Loss: 0.158084 - Test Loss: 0.037284\n",
      "Epoch 94/750 - Train pg Loss: 3.285332 - Test Loss: 0.821205\n",
      "\n",
      "\n",
      "Epoch 95/750 - Train Cd Loss: 0.157180 - Test Loss: 0.037596\n",
      "Epoch 95/750 - Train pg Loss: 3.210376 - Test Loss: 0.784365\n",
      "\n",
      "\n",
      "Epoch 96/750 - Train Cd Loss: 0.158069 - Test Loss: 0.037358\n",
      "Epoch 96/750 - Train pg Loss: 3.184872 - Test Loss: 0.802612\n",
      "\n",
      "\n",
      "Epoch 97/750 - Train Cd Loss: 0.159679 - Test Loss: 0.037488\n",
      "Epoch 97/750 - Train pg Loss: 3.226977 - Test Loss: 0.788075\n",
      "\n",
      "\n",
      "Epoch 98/750 - Train Cd Loss: 0.156910 - Test Loss: 0.037612\n",
      "Epoch 98/750 - Train pg Loss: 3.286923 - Test Loss: 0.788602\n",
      "\n",
      "\n",
      "Epoch 99/750 - Train Cd Loss: 0.159010 - Test Loss: 0.037906\n",
      "Epoch 99/750 - Train pg Loss: 3.154299 - Test Loss: 0.789657\n",
      "\n",
      "\n",
      "Epoch 100/750 - Train Cd Loss: 0.157826 - Test Loss: 0.037941\n",
      "Epoch 100/750 - Train pg Loss: 3.236434 - Test Loss: 0.809782\n",
      "\n",
      "\n",
      "Epoch 101/750 - Train Cd Loss: 0.157454 - Test Loss: 0.037787\n",
      "Epoch 101/750 - Train pg Loss: 3.246372 - Test Loss: 0.813479\n",
      "\n",
      "\n",
      "Epoch 102/750 - Train Cd Loss: 0.153190 - Test Loss: 0.038081\n",
      "Epoch 102/750 - Train pg Loss: 3.225097 - Test Loss: 0.801596\n",
      "\n",
      "\n",
      "Epoch 103/750 - Train Cd Loss: 0.155459 - Test Loss: 0.038360\n",
      "Epoch 103/750 - Train pg Loss: 3.311863 - Test Loss: 0.816677\n",
      "\n",
      "\n",
      "Epoch 104/750 - Train Cd Loss: 0.156300 - Test Loss: 0.037793\n",
      "Epoch 104/750 - Train pg Loss: 3.363333 - Test Loss: 0.804195\n",
      "\n",
      "\n",
      "Epoch 105/750 - Train Cd Loss: 0.152361 - Test Loss: 0.039250\n",
      "Epoch 105/750 - Train pg Loss: 3.244909 - Test Loss: 0.801159\n",
      "\n",
      "\n",
      "Epoch 106/750 - Train Cd Loss: 0.154371 - Test Loss: 0.037618\n",
      "Epoch 106/750 - Train pg Loss: 3.276122 - Test Loss: 0.810136\n",
      "\n",
      "\n",
      "Epoch 107/750 - Train Cd Loss: 0.152161 - Test Loss: 0.038602\n",
      "Epoch 107/750 - Train pg Loss: 3.236898 - Test Loss: 0.795198\n",
      "\n",
      "\n",
      "Epoch 108/750 - Train Cd Loss: 0.155073 - Test Loss: 0.037419\n",
      "Epoch 108/750 - Train pg Loss: 3.242943 - Test Loss: 0.802995\n",
      "\n",
      "\n",
      "Epoch 109/750 - Train Cd Loss: 0.152275 - Test Loss: 0.038430\n",
      "Epoch 109/750 - Train pg Loss: 3.342880 - Test Loss: 0.814245\n",
      "\n",
      "\n",
      "Epoch 110/750 - Train Cd Loss: 0.157062 - Test Loss: 0.036542\n",
      "Epoch 110/750 - Train pg Loss: 3.358625 - Test Loss: 0.851159\n",
      "\n",
      "\n",
      "Epoch 111/750 - Train Cd Loss: 0.149625 - Test Loss: 0.040791\n",
      "Epoch 111/750 - Train pg Loss: 3.539494 - Test Loss: 0.857121\n",
      "\n",
      "\n",
      "Epoch 112/750 - Train Cd Loss: 0.160107 - Test Loss: 0.039598\n",
      "Epoch 112/750 - Train pg Loss: 3.418489 - Test Loss: 0.834523\n",
      "\n",
      "\n",
      "Epoch 113/750 - Train Cd Loss: 0.158027 - Test Loss: 0.038814\n",
      "Epoch 113/750 - Train pg Loss: 3.439702 - Test Loss: 0.826514\n",
      "\n",
      "\n",
      "Epoch 114/750 - Train Cd Loss: 0.154590 - Test Loss: 0.037967\n",
      "Epoch 114/750 - Train pg Loss: 3.407862 - Test Loss: 0.848323\n",
      "\n",
      "\n",
      "Epoch 115/750 - Train Cd Loss: 0.154241 - Test Loss: 0.037763\n",
      "Epoch 115/750 - Train pg Loss: 3.320699 - Test Loss: 0.857237\n",
      "\n",
      "\n",
      "Epoch 116/750 - Train Cd Loss: 0.153714 - Test Loss: 0.038250\n",
      "Epoch 116/750 - Train pg Loss: 3.390619 - Test Loss: 0.863189\n",
      "\n",
      "\n",
      "Epoch 117/750 - Train Cd Loss: 0.155535 - Test Loss: 0.039248\n",
      "Epoch 117/750 - Train pg Loss: 3.424002 - Test Loss: 0.842952\n",
      "\n",
      "\n",
      "Epoch 118/750 - Train Cd Loss: 0.153211 - Test Loss: 0.037928\n",
      "Epoch 118/750 - Train pg Loss: 3.414543 - Test Loss: 0.870376\n",
      "\n",
      "\n",
      "Epoch 119/750 - Train Cd Loss: 0.150950 - Test Loss: 0.037869\n",
      "Epoch 119/750 - Train pg Loss: 3.365863 - Test Loss: 0.830429\n",
      "\n",
      "\n",
      "Epoch 120/750 - Train Cd Loss: 0.152782 - Test Loss: 0.037786\n",
      "Epoch 120/750 - Train pg Loss: 3.308275 - Test Loss: 0.816354\n",
      "\n",
      "\n",
      "Epoch 121/750 - Train Cd Loss: 0.152916 - Test Loss: 0.037702\n",
      "Epoch 121/750 - Train pg Loss: 3.152997 - Test Loss: 0.806896\n",
      "\n",
      "\n",
      "Epoch 122/750 - Train Cd Loss: 0.149428 - Test Loss: 0.037647\n",
      "Epoch 122/750 - Train pg Loss: 3.365772 - Test Loss: 0.841670\n",
      "\n",
      "\n",
      "Epoch 123/750 - Train Cd Loss: 0.151145 - Test Loss: 0.037479\n",
      "Epoch 123/750 - Train pg Loss: 3.533985 - Test Loss: 0.887038\n",
      "\n",
      "\n",
      "Epoch 124/750 - Train Cd Loss: 0.149389 - Test Loss: 0.038764\n",
      "Epoch 124/750 - Train pg Loss: 3.472546 - Test Loss: 0.863910\n",
      "\n",
      "\n",
      "Epoch 125/750 - Train Cd Loss: 0.154095 - Test Loss: 0.037972\n",
      "Epoch 125/750 - Train pg Loss: 3.536598 - Test Loss: 0.889400\n",
      "\n",
      "\n",
      "Epoch 126/750 - Train Cd Loss: 0.150897 - Test Loss: 0.038392\n",
      "Epoch 126/750 - Train pg Loss: 3.738485 - Test Loss: 0.937269\n",
      "\n",
      "\n",
      "Epoch 127/750 - Train Cd Loss: 0.152856 - Test Loss: 0.037935\n",
      "Epoch 127/750 - Train pg Loss: 3.723333 - Test Loss: 0.955070\n",
      "\n",
      "\n",
      "Epoch 128/750 - Train Cd Loss: 0.149809 - Test Loss: 0.037745\n",
      "Epoch 128/750 - Train pg Loss: 3.848459 - Test Loss: 0.943138\n",
      "\n",
      "\n",
      "Epoch 129/750 - Train Cd Loss: 0.150486 - Test Loss: 0.038116\n",
      "Epoch 129/750 - Train pg Loss: 3.809703 - Test Loss: 0.908078\n",
      "\n",
      "\n",
      "Epoch 130/750 - Train Cd Loss: 0.150744 - Test Loss: 0.038132\n",
      "Epoch 130/750 - Train pg Loss: 3.533097 - Test Loss: 0.862284\n",
      "\n",
      "\n",
      "Epoch 131/750 - Train Cd Loss: 0.150762 - Test Loss: 0.038938\n",
      "Epoch 131/750 - Train pg Loss: 3.361331 - Test Loss: 0.859328\n",
      "\n",
      "\n",
      "Epoch 132/750 - Train Cd Loss: 0.147515 - Test Loss: 0.038405\n",
      "Epoch 132/750 - Train pg Loss: 3.570575 - Test Loss: 0.902379\n",
      "\n",
      "\n",
      "Epoch 133/750 - Train Cd Loss: 0.148865 - Test Loss: 0.037950\n",
      "Epoch 133/750 - Train pg Loss: 3.680127 - Test Loss: 0.901027\n",
      "\n",
      "\n",
      "Epoch 134/750 - Train Cd Loss: 0.146220 - Test Loss: 0.038812\n",
      "Epoch 134/750 - Train pg Loss: 3.583030 - Test Loss: 0.856381\n",
      "\n",
      "\n",
      "Epoch 135/750 - Train Cd Loss: 0.144220 - Test Loss: 0.038743\n",
      "Epoch 135/750 - Train pg Loss: 3.431546 - Test Loss: 0.823463\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/750 - Train Cd Loss: 0.147406 - Test Loss: 0.037923\n",
      "Epoch 136/750 - Train pg Loss: 3.439767 - Test Loss: 0.845035\n",
      "\n",
      "\n",
      "Epoch 137/750 - Train Cd Loss: 0.146192 - Test Loss: 0.037944\n",
      "Epoch 137/750 - Train pg Loss: 3.467959 - Test Loss: 0.867053\n",
      "\n",
      "\n",
      "Epoch 138/750 - Train Cd Loss: 0.148982 - Test Loss: 0.038336\n",
      "Epoch 138/750 - Train pg Loss: 3.404649 - Test Loss: 0.840095\n",
      "\n",
      "\n",
      "Epoch 139/750 - Train Cd Loss: 0.143521 - Test Loss: 0.038043\n",
      "Epoch 139/750 - Train pg Loss: 3.501802 - Test Loss: 0.834410\n",
      "\n",
      "\n",
      "Epoch 140/750 - Train Cd Loss: 0.143370 - Test Loss: 0.038498\n",
      "Epoch 140/750 - Train pg Loss: 3.376251 - Test Loss: 0.832014\n",
      "\n",
      "\n",
      "Epoch 141/750 - Train Cd Loss: 0.143881 - Test Loss: 0.038553\n",
      "Epoch 141/750 - Train pg Loss: 3.347347 - Test Loss: 0.811005\n",
      "\n",
      "\n",
      "Epoch 142/750 - Train Cd Loss: 0.139945 - Test Loss: 0.038668\n",
      "Epoch 142/750 - Train pg Loss: 3.268103 - Test Loss: 0.835383\n",
      "\n",
      "\n",
      "Epoch 143/750 - Train Cd Loss: 0.142607 - Test Loss: 0.038656\n",
      "Epoch 143/750 - Train pg Loss: 3.314281 - Test Loss: 0.856581\n",
      "\n",
      "\n",
      "Epoch 144/750 - Train Cd Loss: 0.144289 - Test Loss: 0.038400\n",
      "Epoch 144/750 - Train pg Loss: 3.309322 - Test Loss: 0.809075\n",
      "\n",
      "\n",
      "Epoch 145/750 - Train Cd Loss: 0.146934 - Test Loss: 0.039116\n",
      "Epoch 145/750 - Train pg Loss: 3.289386 - Test Loss: 0.823222\n",
      "\n",
      "\n",
      "Epoch 146/750 - Train Cd Loss: 0.141236 - Test Loss: 0.037810\n",
      "Epoch 146/750 - Train pg Loss: 3.356456 - Test Loss: 0.793921\n",
      "\n",
      "\n",
      "Epoch 147/750 - Train Cd Loss: 0.143556 - Test Loss: 0.037520\n",
      "Epoch 147/750 - Train pg Loss: 3.260754 - Test Loss: 0.777429\n",
      "\n",
      "\n",
      "Epoch 148/750 - Train Cd Loss: 0.139844 - Test Loss: 0.040075\n",
      "Epoch 148/750 - Train pg Loss: 3.069274 - Test Loss: 0.726500\n",
      "\n",
      "\n",
      "Epoch 149/750 - Train Cd Loss: 0.144366 - Test Loss: 0.039094\n",
      "Epoch 149/750 - Train pg Loss: 2.738479 - Test Loss: 0.689826\n",
      "\n",
      "\n",
      "Epoch 150/750 - Train Cd Loss: 0.139620 - Test Loss: 0.039232\n",
      "Epoch 150/750 - Train pg Loss: 2.873313 - Test Loss: 0.712943\n",
      "\n",
      "\n",
      "Epoch 151/750 - Train Cd Loss: 0.136160 - Test Loss: 0.039728\n",
      "Epoch 151/750 - Train pg Loss: 2.861664 - Test Loss: 0.689004\n",
      "\n",
      "\n",
      "Epoch 152/750 - Train Cd Loss: 0.141929 - Test Loss: 0.037001\n",
      "Epoch 152/750 - Train pg Loss: 2.652677 - Test Loss: 0.671518\n",
      "\n",
      "\n",
      "Epoch 153/750 - Train Cd Loss: 0.141436 - Test Loss: 0.038009\n",
      "Epoch 153/750 - Train pg Loss: 2.821510 - Test Loss: 0.674395\n",
      "\n",
      "\n",
      "Epoch 154/750 - Train Cd Loss: 0.141355 - Test Loss: 0.037868\n",
      "Epoch 154/750 - Train pg Loss: 2.677497 - Test Loss: 0.702201\n",
      "\n",
      "\n",
      "Epoch 155/750 - Train Cd Loss: 0.139522 - Test Loss: 0.040167\n",
      "Epoch 155/750 - Train pg Loss: 2.745888 - Test Loss: 0.693087\n",
      "\n",
      "\n",
      "Epoch 156/750 - Train Cd Loss: 0.138426 - Test Loss: 0.038636\n",
      "Epoch 156/750 - Train pg Loss: 2.792621 - Test Loss: 0.682939\n",
      "\n",
      "\n",
      "Epoch 157/750 - Train Cd Loss: 0.141936 - Test Loss: 0.038553\n",
      "Epoch 157/750 - Train pg Loss: 2.706899 - Test Loss: 0.628018\n",
      "\n",
      "\n",
      "Epoch 158/750 - Train Cd Loss: 0.134830 - Test Loss: 0.038166\n",
      "Epoch 158/750 - Train pg Loss: 2.519078 - Test Loss: 0.661777\n",
      "\n",
      "\n",
      "Epoch 159/750 - Train Cd Loss: 0.138974 - Test Loss: 0.038864\n",
      "Epoch 159/750 - Train pg Loss: 2.600257 - Test Loss: 0.629839\n",
      "\n",
      "\n",
      "Epoch 160/750 - Train Cd Loss: 0.136983 - Test Loss: 0.038680\n",
      "Epoch 160/750 - Train pg Loss: 2.701763 - Test Loss: 0.680056\n",
      "\n",
      "\n",
      "Epoch 161/750 - Train Cd Loss: 0.136068 - Test Loss: 0.039333\n",
      "Epoch 161/750 - Train pg Loss: 2.706292 - Test Loss: 0.632927\n",
      "\n",
      "\n",
      "Epoch 162/750 - Train Cd Loss: 0.137187 - Test Loss: 0.039290\n",
      "Epoch 162/750 - Train pg Loss: 2.630725 - Test Loss: 0.643307\n",
      "\n",
      "\n",
      "Epoch 163/750 - Train Cd Loss: 0.136810 - Test Loss: 0.039090\n",
      "Epoch 163/750 - Train pg Loss: 2.715335 - Test Loss: 0.683787\n",
      "\n",
      "\n",
      "Epoch 164/750 - Train Cd Loss: 0.135374 - Test Loss: 0.040385\n",
      "Epoch 164/750 - Train pg Loss: 2.592888 - Test Loss: 0.624872\n",
      "\n",
      "\n",
      "Epoch 165/750 - Train Cd Loss: 0.138626 - Test Loss: 0.039206\n",
      "Epoch 165/750 - Train pg Loss: 2.658297 - Test Loss: 0.619000\n",
      "\n",
      "\n",
      "Epoch 166/750 - Train Cd Loss: 0.138529 - Test Loss: 0.038684\n",
      "Epoch 166/750 - Train pg Loss: 2.565240 - Test Loss: 0.627156\n",
      "\n",
      "\n",
      "Epoch 167/750 - Train Cd Loss: 0.134327 - Test Loss: 0.040070\n",
      "Epoch 167/750 - Train pg Loss: 2.507903 - Test Loss: 0.589910\n",
      "\n",
      "\n",
      "Epoch 168/750 - Train Cd Loss: 0.130587 - Test Loss: 0.039610\n",
      "Epoch 168/750 - Train pg Loss: 2.428318 - Test Loss: 0.619652\n",
      "\n",
      "\n",
      "Epoch 169/750 - Train Cd Loss: 0.135532 - Test Loss: 0.037097\n",
      "Epoch 169/750 - Train pg Loss: 2.434694 - Test Loss: 0.632868\n",
      "\n",
      "\n",
      "Epoch 170/750 - Train Cd Loss: 0.135284 - Test Loss: 0.039931\n",
      "Epoch 170/750 - Train pg Loss: 2.426002 - Test Loss: 0.594238\n",
      "\n",
      "\n",
      "Epoch 171/750 - Train Cd Loss: 0.134634 - Test Loss: 0.039486\n",
      "Epoch 171/750 - Train pg Loss: 2.420779 - Test Loss: 0.615512\n",
      "\n",
      "\n",
      "Epoch 172/750 - Train Cd Loss: 0.128356 - Test Loss: 0.039714\n",
      "Epoch 172/750 - Train pg Loss: 2.351708 - Test Loss: 0.539174\n",
      "\n",
      "\n",
      "Epoch 173/750 - Train Cd Loss: 0.127394 - Test Loss: 0.040258\n",
      "Epoch 173/750 - Train pg Loss: 2.185082 - Test Loss: 0.529119\n",
      "\n",
      "\n",
      "Epoch 174/750 - Train Cd Loss: 0.139038 - Test Loss: 0.039386\n",
      "Epoch 174/750 - Train pg Loss: 2.212687 - Test Loss: 0.528807\n",
      "\n",
      "\n",
      "Epoch 175/750 - Train Cd Loss: 0.136376 - Test Loss: 0.040037\n",
      "Epoch 175/750 - Train pg Loss: 2.161048 - Test Loss: 0.541439\n",
      "\n",
      "\n",
      "Epoch 176/750 - Train Cd Loss: 0.139519 - Test Loss: 0.039622\n",
      "Epoch 176/750 - Train pg Loss: 2.099982 - Test Loss: 0.513595\n",
      "\n",
      "\n",
      "Epoch 177/750 - Train Cd Loss: 0.128683 - Test Loss: 0.039456\n",
      "Epoch 177/750 - Train pg Loss: 2.336297 - Test Loss: 0.566653\n",
      "\n",
      "\n",
      "Epoch 178/750 - Train Cd Loss: 0.135147 - Test Loss: 0.039571\n",
      "Epoch 178/750 - Train pg Loss: 2.217282 - Test Loss: 0.515812\n",
      "\n",
      "\n",
      "Epoch 179/750 - Train Cd Loss: 0.126522 - Test Loss: 0.039939\n",
      "Epoch 179/750 - Train pg Loss: 2.016231 - Test Loss: 0.493806\n",
      "\n",
      "\n",
      "Epoch 180/750 - Train Cd Loss: 0.140850 - Test Loss: 0.038912\n",
      "Epoch 180/750 - Train pg Loss: 2.052655 - Test Loss: 0.512218\n",
      "\n",
      "\n",
      "Epoch 181/750 - Train Cd Loss: 0.132595 - Test Loss: 0.039196\n",
      "Epoch 181/750 - Train pg Loss: 2.027298 - Test Loss: 0.531612\n",
      "\n",
      "\n",
      "Epoch 182/750 - Train Cd Loss: 0.133484 - Test Loss: 0.039475\n",
      "Epoch 182/750 - Train pg Loss: 2.037697 - Test Loss: 0.520195\n",
      "\n",
      "\n",
      "Epoch 183/750 - Train Cd Loss: 0.128478 - Test Loss: 0.039160\n",
      "Epoch 183/750 - Train pg Loss: 2.027168 - Test Loss: 0.529872\n",
      "\n",
      "\n",
      "Epoch 184/750 - Train Cd Loss: 0.134963 - Test Loss: 0.040074\n",
      "Epoch 184/750 - Train pg Loss: 2.331248 - Test Loss: 0.579315\n",
      "\n",
      "\n",
      "Epoch 185/750 - Train Cd Loss: 0.127184 - Test Loss: 0.038224\n",
      "Epoch 185/750 - Train pg Loss: 2.321727 - Test Loss: 0.532655\n",
      "\n",
      "\n",
      "Epoch 186/750 - Train Cd Loss: 0.140482 - Test Loss: 0.040081\n",
      "Epoch 186/750 - Train pg Loss: 2.754889 - Test Loss: 0.565147\n",
      "\n",
      "\n",
      "Epoch 187/750 - Train Cd Loss: 0.126597 - Test Loss: 0.038782\n",
      "Epoch 187/750 - Train pg Loss: 2.384440 - Test Loss: 0.582909\n",
      "\n",
      "\n",
      "Epoch 188/750 - Train Cd Loss: 0.124430 - Test Loss: 0.039234\n",
      "Epoch 188/750 - Train pg Loss: 2.433229 - Test Loss: 0.551125\n",
      "\n",
      "\n",
      "Epoch 189/750 - Train Cd Loss: 0.124981 - Test Loss: 0.039852\n",
      "Epoch 189/750 - Train pg Loss: 2.334284 - Test Loss: 0.596154\n",
      "\n",
      "\n",
      "Epoch 190/750 - Train Cd Loss: 0.134932 - Test Loss: 0.039494\n",
      "Epoch 190/750 - Train pg Loss: 2.200544 - Test Loss: 0.531847\n",
      "\n",
      "\n",
      "Epoch 191/750 - Train Cd Loss: 0.130553 - Test Loss: 0.040117\n",
      "Epoch 191/750 - Train pg Loss: 2.203643 - Test Loss: 0.535495\n",
      "\n",
      "\n",
      "Epoch 192/750 - Train Cd Loss: 0.125922 - Test Loss: 0.039119\n",
      "Epoch 192/750 - Train pg Loss: 2.201306 - Test Loss: 0.517208\n",
      "\n",
      "\n",
      "Epoch 193/750 - Train Cd Loss: 0.126297 - Test Loss: 0.039875\n",
      "Epoch 193/750 - Train pg Loss: 2.152396 - Test Loss: 0.511877\n",
      "\n",
      "\n",
      "Epoch 194/750 - Train Cd Loss: 0.121888 - Test Loss: 0.041076\n",
      "Epoch 194/750 - Train pg Loss: 2.225476 - Test Loss: 0.504924\n",
      "\n",
      "\n",
      "Epoch 195/750 - Train Cd Loss: 0.125721 - Test Loss: 0.040844\n",
      "Epoch 195/750 - Train pg Loss: 2.242132 - Test Loss: 0.532676\n",
      "\n",
      "\n",
      "Epoch 196/750 - Train Cd Loss: 0.123351 - Test Loss: 0.038998\n",
      "Epoch 196/750 - Train pg Loss: 2.092563 - Test Loss: 0.459992\n",
      "\n",
      "\n",
      "Epoch 197/750 - Train Cd Loss: 0.130717 - Test Loss: 0.039286\n",
      "Epoch 197/750 - Train pg Loss: 1.819873 - Test Loss: 0.428003\n",
      "\n",
      "\n",
      "Epoch 198/750 - Train Cd Loss: 0.131217 - Test Loss: 0.040777\n",
      "Epoch 198/750 - Train pg Loss: 2.215991 - Test Loss: 0.504364\n",
      "\n",
      "\n",
      "Epoch 199/750 - Train Cd Loss: 0.127820 - Test Loss: 0.040064\n",
      "Epoch 199/750 - Train pg Loss: 1.976488 - Test Loss: 0.476952\n",
      "\n",
      "\n",
      "Epoch 200/750 - Train Cd Loss: 0.121551 - Test Loss: 0.041108\n",
      "Epoch 200/750 - Train pg Loss: 1.822236 - Test Loss: 0.406535\n",
      "\n",
      "\n",
      "Epoch 201/750 - Train Cd Loss: 0.130814 - Test Loss: 0.040073\n",
      "Epoch 201/750 - Train pg Loss: 1.792021 - Test Loss: 0.417389\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202/750 - Train Cd Loss: 0.131637 - Test Loss: 0.041089\n",
      "Epoch 202/750 - Train pg Loss: 1.912493 - Test Loss: 0.427107\n",
      "\n",
      "\n",
      "Epoch 203/750 - Train Cd Loss: 0.124484 - Test Loss: 0.039394\n",
      "Epoch 203/750 - Train pg Loss: 1.850093 - Test Loss: 0.456392\n",
      "\n",
      "\n",
      "Epoch 204/750 - Train Cd Loss: 0.125301 - Test Loss: 0.041129\n",
      "Epoch 204/750 - Train pg Loss: 2.249130 - Test Loss: 0.541355\n",
      "\n",
      "\n",
      "Epoch 205/750 - Train Cd Loss: 0.127085 - Test Loss: 0.039889\n",
      "Epoch 205/750 - Train pg Loss: 2.313798 - Test Loss: 0.540455\n",
      "\n",
      "\n",
      "Epoch 206/750 - Train Cd Loss: 0.127130 - Test Loss: 0.040325\n",
      "Epoch 206/750 - Train pg Loss: 2.309836 - Test Loss: 0.530074\n",
      "\n",
      "\n",
      "Epoch 207/750 - Train Cd Loss: 0.130176 - Test Loss: 0.040850\n",
      "Epoch 207/750 - Train pg Loss: 3.276269 - Test Loss: 0.611088\n",
      "\n",
      "\n",
      "Epoch 208/750 - Train Cd Loss: 0.122723 - Test Loss: 0.040377\n",
      "Epoch 208/750 - Train pg Loss: 2.621227 - Test Loss: 0.609530\n",
      "\n",
      "\n",
      "Epoch 209/750 - Train Cd Loss: 0.121392 - Test Loss: 0.039774\n",
      "Epoch 209/750 - Train pg Loss: 2.557010 - Test Loss: 0.592047\n",
      "\n",
      "\n",
      "Epoch 210/750 - Train Cd Loss: 0.128061 - Test Loss: 0.040458\n",
      "Epoch 210/750 - Train pg Loss: 2.460460 - Test Loss: 0.577665\n",
      "\n",
      "\n",
      "Epoch 211/750 - Train Cd Loss: 0.124695 - Test Loss: 0.041043\n",
      "Epoch 211/750 - Train pg Loss: 2.429481 - Test Loss: 0.566500\n",
      "\n",
      "\n",
      "Epoch 212/750 - Train Cd Loss: 0.122568 - Test Loss: 0.040973\n",
      "Epoch 212/750 - Train pg Loss: 2.419300 - Test Loss: 0.528131\n",
      "\n",
      "\n",
      "Epoch 213/750 - Train Cd Loss: 0.122150 - Test Loss: 0.040341\n",
      "Epoch 213/750 - Train pg Loss: 2.613440 - Test Loss: 0.592700\n",
      "\n",
      "\n",
      "Epoch 214/750 - Train Cd Loss: 0.117834 - Test Loss: 0.039934\n",
      "Epoch 214/750 - Train pg Loss: 2.471364 - Test Loss: 0.580805\n",
      "\n",
      "\n",
      "Epoch 215/750 - Train Cd Loss: 0.124913 - Test Loss: 0.039968\n",
      "Epoch 215/750 - Train pg Loss: 2.300097 - Test Loss: 0.525876\n",
      "\n",
      "\n",
      "Epoch 216/750 - Train Cd Loss: 0.120933 - Test Loss: 0.039655\n",
      "Epoch 216/750 - Train pg Loss: 2.290109 - Test Loss: 0.528554\n",
      "\n",
      "\n",
      "Epoch 217/750 - Train Cd Loss: 0.126207 - Test Loss: 0.040148\n",
      "Epoch 217/750 - Train pg Loss: 2.287855 - Test Loss: 0.540263\n",
      "\n",
      "\n",
      "Epoch 218/750 - Train Cd Loss: 0.119782 - Test Loss: 0.040911\n",
      "Epoch 218/750 - Train pg Loss: 2.453527 - Test Loss: 0.551460\n",
      "\n",
      "\n",
      "Epoch 219/750 - Train Cd Loss: 0.118125 - Test Loss: 0.041148\n",
      "Epoch 219/750 - Train pg Loss: 2.341910 - Test Loss: 0.498156\n",
      "\n",
      "\n",
      "Epoch 220/750 - Train Cd Loss: 0.113982 - Test Loss: 0.040252\n",
      "Epoch 220/750 - Train pg Loss: 2.285896 - Test Loss: 0.482221\n",
      "\n",
      "\n",
      "Epoch 221/750 - Train Cd Loss: 0.126342 - Test Loss: 0.040052\n",
      "Epoch 221/750 - Train pg Loss: 2.169224 - Test Loss: 0.510173\n",
      "\n",
      "\n",
      "Epoch 222/750 - Train Cd Loss: 0.116528 - Test Loss: 0.040119\n",
      "Epoch 222/750 - Train pg Loss: 2.216059 - Test Loss: 0.489040\n",
      "\n",
      "\n",
      "Epoch 223/750 - Train Cd Loss: 0.132588 - Test Loss: 0.040948\n",
      "Epoch 223/750 - Train pg Loss: 2.679256 - Test Loss: 0.498442\n",
      "\n",
      "\n",
      "Epoch 224/750 - Train Cd Loss: 0.141557 - Test Loss: 0.040068\n",
      "Epoch 224/750 - Train pg Loss: 3.061879 - Test Loss: 0.565995\n",
      "\n",
      "\n",
      "Epoch 225/750 - Train Cd Loss: 0.120650 - Test Loss: 0.039349\n",
      "Epoch 225/750 - Train pg Loss: 2.486408 - Test Loss: 0.568970\n",
      "\n",
      "\n",
      "Epoch 226/750 - Train Cd Loss: 0.124224 - Test Loss: 0.041994\n",
      "Epoch 226/750 - Train pg Loss: 2.239519 - Test Loss: 0.492861\n",
      "\n",
      "\n",
      "Epoch 227/750 - Train Cd Loss: 0.119575 - Test Loss: 0.039896\n",
      "Epoch 227/750 - Train pg Loss: 2.179502 - Test Loss: 0.502998\n",
      "\n",
      "\n",
      "Epoch 228/750 - Train Cd Loss: 0.120906 - Test Loss: 0.040644\n",
      "Epoch 228/750 - Train pg Loss: 2.375824 - Test Loss: 0.529819\n",
      "\n",
      "\n",
      "Epoch 229/750 - Train Cd Loss: 0.117371 - Test Loss: 0.040000\n",
      "Epoch 229/750 - Train pg Loss: 2.342629 - Test Loss: 0.520281\n",
      "\n",
      "\n",
      "Epoch 230/750 - Train Cd Loss: 0.113972 - Test Loss: 0.041236\n",
      "Epoch 230/750 - Train pg Loss: 2.052354 - Test Loss: 0.448478\n",
      "\n",
      "\n",
      "Epoch 231/750 - Train Cd Loss: 0.118333 - Test Loss: 0.041370\n",
      "Epoch 231/750 - Train pg Loss: 2.002759 - Test Loss: 0.434397\n",
      "\n",
      "\n",
      "Epoch 232/750 - Train Cd Loss: 0.122765 - Test Loss: 0.041389\n",
      "Epoch 232/750 - Train pg Loss: 1.923081 - Test Loss: 0.465360\n",
      "\n",
      "\n",
      "Epoch 233/750 - Train Cd Loss: 0.122969 - Test Loss: 0.041351\n",
      "Epoch 233/750 - Train pg Loss: 2.202527 - Test Loss: 0.491922\n",
      "\n",
      "\n",
      "Epoch 234/750 - Train Cd Loss: 0.113621 - Test Loss: 0.040419\n",
      "Epoch 234/750 - Train pg Loss: 2.056599 - Test Loss: 0.439309\n",
      "\n",
      "\n",
      "Epoch 235/750 - Train Cd Loss: 0.113818 - Test Loss: 0.040048\n",
      "Epoch 235/750 - Train pg Loss: 2.000479 - Test Loss: 0.458785\n",
      "\n",
      "\n",
      "Epoch 236/750 - Train Cd Loss: 0.116895 - Test Loss: 0.040205\n",
      "Epoch 236/750 - Train pg Loss: 1.927456 - Test Loss: 0.435767\n",
      "\n",
      "\n",
      "Epoch 237/750 - Train Cd Loss: 0.115593 - Test Loss: 0.041775\n",
      "Epoch 237/750 - Train pg Loss: 1.953168 - Test Loss: 0.431153\n",
      "\n",
      "\n",
      "Epoch 238/750 - Train Cd Loss: 0.117180 - Test Loss: 0.040599\n",
      "Epoch 238/750 - Train pg Loss: 2.032181 - Test Loss: 0.444254\n",
      "\n",
      "\n",
      "Epoch 239/750 - Train Cd Loss: 0.118488 - Test Loss: 0.040363\n",
      "Epoch 239/750 - Train pg Loss: 2.032593 - Test Loss: 0.397489\n",
      "\n",
      "\n",
      "Epoch 240/750 - Train Cd Loss: 0.118800 - Test Loss: 0.041489\n",
      "Epoch 240/750 - Train pg Loss: 2.061676 - Test Loss: 0.427500\n",
      "\n",
      "\n",
      "Epoch 241/750 - Train Cd Loss: 0.121485 - Test Loss: 0.040588\n",
      "Epoch 241/750 - Train pg Loss: 2.588924 - Test Loss: 0.542794\n",
      "\n",
      "\n",
      "Epoch 242/750 - Train Cd Loss: 0.113330 - Test Loss: 0.039960\n",
      "Epoch 242/750 - Train pg Loss: 2.364093 - Test Loss: 0.513971\n",
      "\n",
      "\n",
      "Epoch 243/750 - Train Cd Loss: 0.119262 - Test Loss: 0.040937\n",
      "Epoch 243/750 - Train pg Loss: 2.437737 - Test Loss: 0.547020\n",
      "\n",
      "\n",
      "Epoch 244/750 - Train Cd Loss: 0.115950 - Test Loss: 0.039586\n",
      "Epoch 244/750 - Train pg Loss: 2.567034 - Test Loss: 0.593316\n",
      "\n",
      "\n",
      "Epoch 245/750 - Train Cd Loss: 0.109949 - Test Loss: 0.041801\n",
      "Epoch 245/750 - Train pg Loss: 2.500765 - Test Loss: 0.568837\n",
      "\n",
      "\n",
      "Epoch 246/750 - Train Cd Loss: 0.114015 - Test Loss: 0.041730\n",
      "Epoch 246/750 - Train pg Loss: 2.628254 - Test Loss: 0.569094\n",
      "\n",
      "\n",
      "Epoch 247/750 - Train Cd Loss: 0.117345 - Test Loss: 0.042031\n",
      "Epoch 247/750 - Train pg Loss: 2.561005 - Test Loss: 0.554203\n",
      "\n",
      "\n",
      "Epoch 248/750 - Train Cd Loss: 0.108197 - Test Loss: 0.040494\n",
      "Epoch 248/750 - Train pg Loss: 2.411680 - Test Loss: 0.495803\n",
      "\n",
      "\n",
      "Epoch 249/750 - Train Cd Loss: 0.114013 - Test Loss: 0.040583\n",
      "Epoch 249/750 - Train pg Loss: 2.278086 - Test Loss: 0.491515\n",
      "\n",
      "\n",
      "Epoch 250/750 - Train Cd Loss: 0.109961 - Test Loss: 0.042374\n",
      "Epoch 250/750 - Train pg Loss: 2.246485 - Test Loss: 0.468812\n",
      "\n",
      "\n",
      "Epoch 251/750 - Train Cd Loss: 0.105993 - Test Loss: 0.040512\n",
      "Epoch 251/750 - Train pg Loss: 2.260057 - Test Loss: 0.423628\n",
      "\n",
      "\n",
      "Epoch 252/750 - Train Cd Loss: 0.129475 - Test Loss: 0.042456\n",
      "Epoch 252/750 - Train pg Loss: 2.602549 - Test Loss: 0.440927\n",
      "\n",
      "\n",
      "Epoch 253/750 - Train Cd Loss: 0.113427 - Test Loss: 0.041377\n",
      "Epoch 253/750 - Train pg Loss: 2.219879 - Test Loss: 0.474977\n",
      "\n",
      "\n",
      "Epoch 254/750 - Train Cd Loss: 0.115780 - Test Loss: 0.041881\n",
      "Epoch 254/750 - Train pg Loss: 2.926185 - Test Loss: 0.484822\n",
      "\n",
      "\n",
      "Epoch 255/750 - Train Cd Loss: 0.112165 - Test Loss: 0.041574\n",
      "Epoch 255/750 - Train pg Loss: 2.386387 - Test Loss: 0.538205\n",
      "\n",
      "\n",
      "Epoch 256/750 - Train Cd Loss: 0.115517 - Test Loss: 0.042088\n",
      "Epoch 256/750 - Train pg Loss: 2.335951 - Test Loss: 0.490874\n",
      "\n",
      "\n",
      "Epoch 257/750 - Train Cd Loss: 0.116242 - Test Loss: 0.040491\n",
      "Epoch 257/750 - Train pg Loss: 2.282518 - Test Loss: 0.538195\n",
      "\n",
      "\n",
      "Epoch 258/750 - Train Cd Loss: 0.110514 - Test Loss: 0.040613\n",
      "Epoch 258/750 - Train pg Loss: 2.475538 - Test Loss: 0.536083\n",
      "\n",
      "\n",
      "Epoch 259/750 - Train Cd Loss: 0.112635 - Test Loss: 0.040976\n",
      "Epoch 259/750 - Train pg Loss: 2.521219 - Test Loss: 0.516956\n",
      "\n",
      "\n",
      "Epoch 260/750 - Train Cd Loss: 0.106591 - Test Loss: 0.042773\n",
      "Epoch 260/750 - Train pg Loss: 2.399740 - Test Loss: 0.492823\n",
      "\n",
      "\n",
      "Epoch 261/750 - Train Cd Loss: 0.109832 - Test Loss: 0.039693\n",
      "Epoch 261/750 - Train pg Loss: 2.195638 - Test Loss: 0.466238\n",
      "\n",
      "\n",
      "Epoch 262/750 - Train Cd Loss: 0.106924 - Test Loss: 0.041281\n",
      "Epoch 262/750 - Train pg Loss: 2.196872 - Test Loss: 0.504586\n",
      "\n",
      "\n",
      "Epoch 263/750 - Train Cd Loss: 0.112098 - Test Loss: 0.041000\n",
      "Epoch 263/750 - Train pg Loss: 2.270051 - Test Loss: 0.478433\n",
      "\n",
      "\n",
      "Epoch 264/750 - Train Cd Loss: 0.107973 - Test Loss: 0.040814\n",
      "Epoch 264/750 - Train pg Loss: 2.078285 - Test Loss: 0.466415\n",
      "\n",
      "\n",
      "Epoch 265/750 - Train Cd Loss: 0.120960 - Test Loss: 0.042369\n",
      "Epoch 265/750 - Train pg Loss: 2.877453 - Test Loss: 0.494843\n",
      "\n",
      "\n",
      "Epoch 266/750 - Train Cd Loss: 0.112335 - Test Loss: 0.043325\n",
      "Epoch 266/750 - Train pg Loss: 2.216476 - Test Loss: 0.458795\n",
      "\n",
      "\n",
      "Epoch 267/750 - Train Cd Loss: 0.110491 - Test Loss: 0.041679\n",
      "Epoch 267/750 - Train pg Loss: 2.279838 - Test Loss: 0.457442\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 268/750 - Train Cd Loss: 0.109150 - Test Loss: 0.042389\n",
      "Epoch 268/750 - Train pg Loss: 2.153474 - Test Loss: 0.454817\n",
      "\n",
      "\n",
      "Epoch 269/750 - Train Cd Loss: 0.105694 - Test Loss: 0.041431\n",
      "Epoch 269/750 - Train pg Loss: 2.467554 - Test Loss: 0.530914\n",
      "\n",
      "\n",
      "Epoch 270/750 - Train Cd Loss: 0.112035 - Test Loss: 0.041011\n",
      "Epoch 270/750 - Train pg Loss: 2.389691 - Test Loss: 0.525751\n",
      "\n",
      "\n",
      "Epoch 271/750 - Train Cd Loss: 0.114441 - Test Loss: 0.040937\n",
      "Epoch 271/750 - Train pg Loss: 2.320625 - Test Loss: 0.508446\n",
      "\n",
      "\n",
      "Epoch 272/750 - Train Cd Loss: 0.110649 - Test Loss: 0.043050\n",
      "Epoch 272/750 - Train pg Loss: 2.623437 - Test Loss: 0.558287\n",
      "\n",
      "\n",
      "Epoch 273/750 - Train Cd Loss: 0.113412 - Test Loss: 0.040668\n",
      "Epoch 273/750 - Train pg Loss: 2.508923 - Test Loss: 0.539209\n",
      "\n",
      "\n",
      "Epoch 274/750 - Train Cd Loss: 0.106633 - Test Loss: 0.042152\n",
      "Epoch 274/750 - Train pg Loss: 2.384399 - Test Loss: 0.518283\n",
      "\n",
      "\n",
      "Epoch 275/750 - Train Cd Loss: 0.108182 - Test Loss: 0.040832\n",
      "Epoch 275/750 - Train pg Loss: 2.437850 - Test Loss: 0.524987\n",
      "\n",
      "\n",
      "Epoch 276/750 - Train Cd Loss: 0.108751 - Test Loss: 0.042295\n",
      "Epoch 276/750 - Train pg Loss: 2.437768 - Test Loss: 0.504817\n",
      "\n",
      "\n",
      "Epoch 277/750 - Train Cd Loss: 0.095964 - Test Loss: 0.041372\n",
      "Epoch 277/750 - Train pg Loss: 2.384633 - Test Loss: 0.491929\n",
      "\n",
      "\n",
      "Epoch 278/750 - Train Cd Loss: 0.104153 - Test Loss: 0.042013\n",
      "Epoch 278/750 - Train pg Loss: 2.467544 - Test Loss: 0.540387\n",
      "\n",
      "\n",
      "Epoch 279/750 - Train Cd Loss: 0.112974 - Test Loss: 0.041169\n",
      "Epoch 279/750 - Train pg Loss: 3.308886 - Test Loss: 0.627490\n",
      "\n",
      "\n",
      "Epoch 280/750 - Train Cd Loss: 0.104868 - Test Loss: 0.041601\n",
      "Epoch 280/750 - Train pg Loss: 3.151899 - Test Loss: 0.689717\n",
      "\n",
      "\n",
      "Epoch 281/750 - Train Cd Loss: 0.104941 - Test Loss: 0.043140\n",
      "Epoch 281/750 - Train pg Loss: 3.307819 - Test Loss: 0.648771\n",
      "\n",
      "\n",
      "Epoch 282/750 - Train Cd Loss: 0.107049 - Test Loss: 0.042142\n",
      "Epoch 282/750 - Train pg Loss: 2.921784 - Test Loss: 0.571988\n",
      "\n",
      "\n",
      "Epoch 283/750 - Train Cd Loss: 0.103394 - Test Loss: 0.041557\n",
      "Epoch 283/750 - Train pg Loss: 2.554944 - Test Loss: 0.517315\n",
      "\n",
      "\n",
      "Epoch 284/750 - Train Cd Loss: 0.105345 - Test Loss: 0.040985\n",
      "Epoch 284/750 - Train pg Loss: 2.599222 - Test Loss: 0.545735\n",
      "\n",
      "\n",
      "Epoch 285/750 - Train Cd Loss: 0.103722 - Test Loss: 0.042346\n",
      "Epoch 285/750 - Train pg Loss: 2.556860 - Test Loss: 0.543516\n",
      "\n",
      "\n",
      "Epoch 286/750 - Train Cd Loss: 0.105818 - Test Loss: 0.042562\n",
      "Epoch 286/750 - Train pg Loss: 2.553814 - Test Loss: 0.549866\n",
      "\n",
      "\n",
      "Epoch 287/750 - Train Cd Loss: 0.107757 - Test Loss: 0.041666\n",
      "Epoch 287/750 - Train pg Loss: 2.654820 - Test Loss: 0.555511\n",
      "\n",
      "\n",
      "Epoch 288/750 - Train Cd Loss: 0.100602 - Test Loss: 0.042479\n",
      "Epoch 288/750 - Train pg Loss: 2.448893 - Test Loss: 0.514866\n",
      "\n",
      "\n",
      "Epoch 289/750 - Train Cd Loss: 0.104489 - Test Loss: 0.040970\n",
      "Epoch 289/750 - Train pg Loss: 2.671924 - Test Loss: 0.535490\n",
      "\n",
      "\n",
      "Epoch 290/750 - Train Cd Loss: 0.101346 - Test Loss: 0.042007\n",
      "Epoch 290/750 - Train pg Loss: 2.716132 - Test Loss: 0.492264\n",
      "\n",
      "\n",
      "Epoch 291/750 - Train Cd Loss: 0.102734 - Test Loss: 0.041338\n",
      "Epoch 291/750 - Train pg Loss: 2.589879 - Test Loss: 0.557135\n",
      "\n",
      "\n",
      "Epoch 292/750 - Train Cd Loss: 0.101629 - Test Loss: 0.041279\n",
      "Epoch 292/750 - Train pg Loss: 2.538928 - Test Loss: 0.508150\n",
      "\n",
      "\n",
      "Epoch 293/750 - Train Cd Loss: 0.093979 - Test Loss: 0.043480\n",
      "Epoch 293/750 - Train pg Loss: 2.347324 - Test Loss: 0.469018\n",
      "\n",
      "\n",
      "Epoch 294/750 - Train Cd Loss: 0.102342 - Test Loss: 0.041447\n",
      "Epoch 294/750 - Train pg Loss: 2.552333 - Test Loss: 0.547395\n",
      "\n",
      "\n",
      "Epoch 295/750 - Train Cd Loss: 0.098160 - Test Loss: 0.040816\n",
      "Epoch 295/750 - Train pg Loss: 2.634753 - Test Loss: 0.486989\n",
      "\n",
      "\n",
      "Epoch 296/750 - Train Cd Loss: 0.111423 - Test Loss: 0.040888\n",
      "Epoch 296/750 - Train pg Loss: 3.215839 - Test Loss: 0.519187\n",
      "\n",
      "\n",
      "Epoch 297/750 - Train Cd Loss: 0.094846 - Test Loss: 0.043522\n",
      "Epoch 297/750 - Train pg Loss: 2.447977 - Test Loss: 0.516447\n",
      "\n",
      "\n",
      "Epoch 298/750 - Train Cd Loss: 0.098408 - Test Loss: 0.043432\n",
      "Epoch 298/750 - Train pg Loss: 2.548048 - Test Loss: 0.473558\n",
      "\n",
      "\n",
      "Epoch 299/750 - Train Cd Loss: 0.099435 - Test Loss: 0.040833\n",
      "Epoch 299/750 - Train pg Loss: 3.007798 - Test Loss: 0.450213\n",
      "\n",
      "\n",
      "Epoch 300/750 - Train Cd Loss: 0.103138 - Test Loss: 0.042822\n",
      "Epoch 300/750 - Train pg Loss: 2.021867 - Test Loss: 0.407622\n",
      "\n",
      "\n",
      "Epoch 301/750 - Train Cd Loss: 0.112949 - Test Loss: 0.043563\n",
      "Epoch 301/750 - Train pg Loss: 3.061034 - Test Loss: 0.473197\n",
      "\n",
      "\n",
      "Epoch 302/750 - Train Cd Loss: 0.104381 - Test Loss: 0.040901\n",
      "Epoch 302/750 - Train pg Loss: 2.391703 - Test Loss: 0.498145\n",
      "\n",
      "\n",
      "Epoch 303/750 - Train Cd Loss: 0.103281 - Test Loss: 0.042325\n",
      "Epoch 303/750 - Train pg Loss: 2.273547 - Test Loss: 0.400762\n",
      "\n",
      "\n",
      "Epoch 304/750 - Train Cd Loss: 0.101399 - Test Loss: 0.040443\n",
      "Epoch 304/750 - Train pg Loss: 2.007018 - Test Loss: 0.412127\n",
      "\n",
      "\n",
      "Epoch 305/750 - Train Cd Loss: 0.101872 - Test Loss: 0.043204\n",
      "Epoch 305/750 - Train pg Loss: 2.183915 - Test Loss: 0.448558\n",
      "\n",
      "\n",
      "Epoch 306/750 - Train Cd Loss: 0.099384 - Test Loss: 0.040927\n",
      "Epoch 306/750 - Train pg Loss: 2.261291 - Test Loss: 0.486074\n",
      "\n",
      "\n",
      "Epoch 307/750 - Train Cd Loss: 0.122791 - Test Loss: 0.043961\n",
      "Epoch 307/750 - Train pg Loss: 3.577803 - Test Loss: 0.505726\n",
      "\n",
      "\n",
      "Epoch 308/750 - Train Cd Loss: 0.095808 - Test Loss: 0.041615\n",
      "Epoch 308/750 - Train pg Loss: 2.629260 - Test Loss: 0.546970\n",
      "\n",
      "\n",
      "Epoch 309/750 - Train Cd Loss: 0.101042 - Test Loss: 0.042128\n",
      "Epoch 309/750 - Train pg Loss: 2.388727 - Test Loss: 0.514731\n",
      "\n",
      "\n",
      "Epoch 310/750 - Train Cd Loss: 0.098550 - Test Loss: 0.041608\n",
      "Epoch 310/750 - Train pg Loss: 2.626432 - Test Loss: 0.537132\n",
      "\n",
      "\n",
      "Epoch 311/750 - Train Cd Loss: 0.101430 - Test Loss: 0.041531\n",
      "Epoch 311/750 - Train pg Loss: 2.448781 - Test Loss: 0.486586\n",
      "\n",
      "\n",
      "Epoch 312/750 - Train Cd Loss: 0.092544 - Test Loss: 0.041170\n",
      "Epoch 312/750 - Train pg Loss: 2.313388 - Test Loss: 0.467097\n",
      "\n",
      "\n",
      "Epoch 313/750 - Train Cd Loss: 0.099801 - Test Loss: 0.043922\n",
      "Epoch 313/750 - Train pg Loss: 2.450591 - Test Loss: 0.436983\n",
      "\n",
      "\n",
      "Epoch 314/750 - Train Cd Loss: 0.090998 - Test Loss: 0.041922\n",
      "Epoch 314/750 - Train pg Loss: 2.274863 - Test Loss: 0.407451\n",
      "\n",
      "\n",
      "Epoch 315/750 - Train Cd Loss: 0.103071 - Test Loss: 0.041674\n",
      "Epoch 315/750 - Train pg Loss: 2.907252 - Test Loss: 0.455684\n",
      "\n",
      "\n",
      "Epoch 316/750 - Train Cd Loss: 0.101305 - Test Loss: 0.046189\n",
      "Epoch 316/750 - Train pg Loss: 2.291802 - Test Loss: 0.420797\n",
      "\n",
      "\n",
      "Epoch 317/750 - Train Cd Loss: 0.096935 - Test Loss: 0.040540\n",
      "Epoch 317/750 - Train pg Loss: 2.073449 - Test Loss: 0.435459\n",
      "\n",
      "\n",
      "Epoch 318/750 - Train Cd Loss: 0.092323 - Test Loss: 0.041724\n",
      "Epoch 318/750 - Train pg Loss: 2.435814 - Test Loss: 0.430628\n",
      "\n",
      "\n",
      "Epoch 319/750 - Train Cd Loss: 0.096228 - Test Loss: 0.043614\n",
      "Epoch 319/750 - Train pg Loss: 2.218452 - Test Loss: 0.457698\n",
      "\n",
      "\n",
      "Epoch 320/750 - Train Cd Loss: 0.102956 - Test Loss: 0.041548\n",
      "Epoch 320/750 - Train pg Loss: 3.436660 - Test Loss: 0.513989\n",
      "\n",
      "\n",
      "Epoch 321/750 - Train Cd Loss: 0.098970 - Test Loss: 0.041909\n",
      "Epoch 321/750 - Train pg Loss: 2.641258 - Test Loss: 0.529605\n",
      "\n",
      "\n",
      "Epoch 322/750 - Train Cd Loss: 0.090319 - Test Loss: 0.042740\n",
      "Epoch 322/750 - Train pg Loss: 2.421351 - Test Loss: 0.462336\n",
      "\n",
      "\n",
      "Epoch 323/750 - Train Cd Loss: 0.092838 - Test Loss: 0.041216\n",
      "Epoch 323/750 - Train pg Loss: 3.356076 - Test Loss: 0.411476\n",
      "\n",
      "\n",
      "Epoch 324/750 - Train Cd Loss: 0.104184 - Test Loss: 0.041337\n",
      "Epoch 324/750 - Train pg Loss: 2.090767 - Test Loss: 0.424135\n",
      "\n",
      "\n",
      "Epoch 325/750 - Train Cd Loss: 0.097574 - Test Loss: 0.043998\n",
      "Epoch 325/750 - Train pg Loss: 2.352854 - Test Loss: 0.478980\n",
      "\n",
      "\n",
      "Epoch 326/750 - Train Cd Loss: 0.093723 - Test Loss: 0.043985\n",
      "Epoch 326/750 - Train pg Loss: 2.348381 - Test Loss: 0.441741\n",
      "\n",
      "\n",
      "Epoch 327/750 - Train Cd Loss: 0.092699 - Test Loss: 0.041433\n",
      "Epoch 327/750 - Train pg Loss: 1.973161 - Test Loss: 0.342770\n",
      "\n",
      "\n",
      "Epoch 328/750 - Train Cd Loss: 0.089906 - Test Loss: 0.041672\n",
      "Epoch 328/750 - Train pg Loss: 1.816289 - Test Loss: 0.361412\n",
      "\n",
      "\n",
      "Epoch 329/750 - Train Cd Loss: 0.099311 - Test Loss: 0.042512\n",
      "Epoch 329/750 - Train pg Loss: 2.066134 - Test Loss: 0.382077\n",
      "\n",
      "\n",
      "Epoch 330/750 - Train Cd Loss: 0.109060 - Test Loss: 0.041292\n",
      "Epoch 330/750 - Train pg Loss: 3.365862 - Test Loss: 0.329007\n",
      "\n",
      "\n",
      "Epoch 331/750 - Train Cd Loss: 0.093273 - Test Loss: 0.041432\n",
      "Epoch 331/750 - Train pg Loss: 1.808551 - Test Loss: 0.397743\n",
      "\n",
      "\n",
      "Epoch 332/750 - Train Cd Loss: 0.095049 - Test Loss: 0.040097\n",
      "Epoch 332/750 - Train pg Loss: 1.943310 - Test Loss: 0.374034\n",
      "\n",
      "\n",
      "Epoch 333/750 - Train Cd Loss: 0.109621 - Test Loss: 0.042782\n",
      "Epoch 333/750 - Train pg Loss: 2.964468 - Test Loss: 0.321834\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334/750 - Train Cd Loss: 0.089780 - Test Loss: 0.042778\n",
      "Epoch 334/750 - Train pg Loss: 2.164061 - Test Loss: 0.343455\n",
      "\n",
      "\n",
      "Epoch 335/750 - Train Cd Loss: 0.100042 - Test Loss: 0.040110\n",
      "Epoch 335/750 - Train pg Loss: 1.674844 - Test Loss: 0.325824\n",
      "\n",
      "\n",
      "Epoch 336/750 - Train Cd Loss: 0.090568 - Test Loss: 0.042035\n",
      "Epoch 336/750 - Train pg Loss: 1.842467 - Test Loss: 0.355551\n",
      "\n",
      "\n",
      "Epoch 337/750 - Train Cd Loss: 0.098558 - Test Loss: 0.041449\n",
      "Epoch 337/750 - Train pg Loss: 1.873142 - Test Loss: 0.341080\n",
      "\n",
      "\n",
      "Epoch 338/750 - Train Cd Loss: 0.093007 - Test Loss: 0.041966\n",
      "Epoch 338/750 - Train pg Loss: 2.108000 - Test Loss: 0.343533\n",
      "\n",
      "\n",
      "Epoch 339/750 - Train Cd Loss: 0.093610 - Test Loss: 0.043467\n",
      "Epoch 339/750 - Train pg Loss: 1.900857 - Test Loss: 0.358246\n",
      "\n",
      "\n",
      "Epoch 340/750 - Train Cd Loss: 0.095370 - Test Loss: 0.042027\n",
      "Epoch 340/750 - Train pg Loss: 1.989703 - Test Loss: 0.421011\n",
      "\n",
      "\n",
      "Epoch 341/750 - Train Cd Loss: 0.086860 - Test Loss: 0.044211\n",
      "Epoch 341/750 - Train pg Loss: 1.993965 - Test Loss: 0.373683\n",
      "\n",
      "\n",
      "Epoch 342/750 - Train Cd Loss: 0.092036 - Test Loss: 0.042978\n",
      "Epoch 342/750 - Train pg Loss: 2.063615 - Test Loss: 0.383977\n",
      "\n",
      "\n",
      "Epoch 343/750 - Train Cd Loss: 0.086141 - Test Loss: 0.041305\n",
      "Epoch 343/750 - Train pg Loss: 2.086610 - Test Loss: 0.400393\n",
      "\n",
      "\n",
      "Epoch 344/750 - Train Cd Loss: 0.089386 - Test Loss: 0.044150\n",
      "Epoch 344/750 - Train pg Loss: 1.898814 - Test Loss: 0.369308\n",
      "\n",
      "\n",
      "Epoch 345/750 - Train Cd Loss: 0.084753 - Test Loss: 0.041158\n",
      "Epoch 345/750 - Train pg Loss: 2.582534 - Test Loss: 0.396023\n",
      "\n",
      "\n",
      "Epoch 346/750 - Train Cd Loss: 0.077889 - Test Loss: 0.042678\n",
      "Epoch 346/750 - Train pg Loss: 1.994739 - Test Loss: 0.352678\n",
      "\n",
      "\n",
      "Epoch 347/750 - Train Cd Loss: 0.087948 - Test Loss: 0.043152\n",
      "Epoch 347/750 - Train pg Loss: 2.005516 - Test Loss: 0.360830\n",
      "\n",
      "\n",
      "Epoch 348/750 - Train Cd Loss: 0.086438 - Test Loss: 0.043328\n",
      "Epoch 348/750 - Train pg Loss: 1.989981 - Test Loss: 0.400300\n",
      "\n",
      "\n",
      "Epoch 349/750 - Train Cd Loss: 0.079584 - Test Loss: 0.044722\n",
      "Epoch 349/750 - Train pg Loss: 2.067140 - Test Loss: 0.387415\n",
      "\n",
      "\n",
      "Epoch 350/750 - Train Cd Loss: 0.107210 - Test Loss: 0.042000\n",
      "Epoch 350/750 - Train pg Loss: 3.192982 - Test Loss: 0.408125\n",
      "\n",
      "\n",
      "Epoch 351/750 - Train Cd Loss: 0.087712 - Test Loss: 0.043853\n",
      "Epoch 351/750 - Train pg Loss: 2.102970 - Test Loss: 0.380203\n",
      "\n",
      "\n",
      "Epoch 352/750 - Train Cd Loss: 0.091486 - Test Loss: 0.041133\n",
      "Epoch 352/750 - Train pg Loss: 2.355763 - Test Loss: 0.469197\n",
      "\n",
      "\n",
      "Epoch 353/750 - Train Cd Loss: 0.085087 - Test Loss: 0.043873\n",
      "Epoch 353/750 - Train pg Loss: 2.301251 - Test Loss: 0.439342\n",
      "\n",
      "\n",
      "Epoch 354/750 - Train Cd Loss: 0.086003 - Test Loss: 0.040533\n",
      "Epoch 354/750 - Train pg Loss: 2.215242 - Test Loss: 0.358872\n",
      "\n",
      "\n",
      "Epoch 355/750 - Train Cd Loss: 0.087622 - Test Loss: 0.042557\n",
      "Epoch 355/750 - Train pg Loss: 1.787972 - Test Loss: 0.353863\n",
      "\n",
      "\n",
      "Epoch 356/750 - Train Cd Loss: 0.099592 - Test Loss: 0.042179\n",
      "Epoch 356/750 - Train pg Loss: 2.756340 - Test Loss: 0.436974\n",
      "\n",
      "\n",
      "Epoch 357/750 - Train Cd Loss: 0.094792 - Test Loss: 0.042280\n",
      "Epoch 357/750 - Train pg Loss: 2.163743 - Test Loss: 0.395860\n",
      "\n",
      "\n",
      "Epoch 358/750 - Train Cd Loss: 0.089225 - Test Loss: 0.041213\n",
      "Epoch 358/750 - Train pg Loss: 2.093179 - Test Loss: 0.411998\n",
      "\n",
      "\n",
      "Epoch 359/750 - Train Cd Loss: 0.086145 - Test Loss: 0.042233\n",
      "Epoch 359/750 - Train pg Loss: 2.297180 - Test Loss: 0.432693\n",
      "\n",
      "\n",
      "Epoch 360/750 - Train Cd Loss: 0.087782 - Test Loss: 0.041518\n",
      "Epoch 360/750 - Train pg Loss: 2.108640 - Test Loss: 0.407970\n",
      "\n",
      "\n",
      "Epoch 361/750 - Train Cd Loss: 0.083450 - Test Loss: 0.045216\n",
      "Epoch 361/750 - Train pg Loss: 1.946057 - Test Loss: 0.358967\n",
      "\n",
      "\n",
      "Epoch 362/750 - Train Cd Loss: 0.085699 - Test Loss: 0.043970\n",
      "Epoch 362/750 - Train pg Loss: 1.832305 - Test Loss: 0.354436\n",
      "\n",
      "\n",
      "Epoch 363/750 - Train Cd Loss: 0.100275 - Test Loss: 0.040742\n",
      "Epoch 363/750 - Train pg Loss: 3.064306 - Test Loss: 0.422405\n",
      "\n",
      "\n",
      "Epoch 364/750 - Train Cd Loss: 0.089490 - Test Loss: 0.041432\n",
      "Epoch 364/750 - Train pg Loss: 2.256790 - Test Loss: 0.382309\n",
      "\n",
      "\n",
      "Epoch 365/750 - Train Cd Loss: 0.087841 - Test Loss: 0.040549\n",
      "Epoch 365/750 - Train pg Loss: 1.930565 - Test Loss: 0.372815\n",
      "\n",
      "\n",
      "Epoch 366/750 - Train Cd Loss: 0.091680 - Test Loss: 0.040619\n",
      "Epoch 366/750 - Train pg Loss: 2.252338 - Test Loss: 0.376834\n",
      "\n",
      "\n",
      "Epoch 367/750 - Train Cd Loss: 0.078631 - Test Loss: 0.043394\n",
      "Epoch 367/750 - Train pg Loss: 1.802427 - Test Loss: 0.343780\n",
      "\n",
      "\n",
      "Epoch 368/750 - Train Cd Loss: 0.085293 - Test Loss: 0.042403\n",
      "Epoch 368/750 - Train pg Loss: 2.019875 - Test Loss: 0.390305\n",
      "\n",
      "\n",
      "Epoch 369/750 - Train Cd Loss: 0.093935 - Test Loss: 0.042614\n",
      "Epoch 369/750 - Train pg Loss: 2.727942 - Test Loss: 0.383694\n",
      "\n",
      "\n",
      "Epoch 370/750 - Train Cd Loss: 0.087363 - Test Loss: 0.041748\n",
      "Epoch 370/750 - Train pg Loss: 2.207527 - Test Loss: 0.374664\n",
      "\n",
      "\n",
      "Epoch 371/750 - Train Cd Loss: 0.083152 - Test Loss: 0.043263\n",
      "Epoch 371/750 - Train pg Loss: 2.383793 - Test Loss: 0.336446\n",
      "\n",
      "\n",
      "Epoch 372/750 - Train Cd Loss: 0.079964 - Test Loss: 0.041673\n",
      "Epoch 372/750 - Train pg Loss: 1.882390 - Test Loss: 0.345886\n",
      "\n",
      "\n",
      "Epoch 373/750 - Train Cd Loss: 0.091437 - Test Loss: 0.042419\n",
      "Epoch 373/750 - Train pg Loss: 3.244423 - Test Loss: 0.381667\n",
      "\n",
      "\n",
      "Epoch 374/750 - Train Cd Loss: 0.084914 - Test Loss: 0.045620\n",
      "Epoch 374/750 - Train pg Loss: 1.970305 - Test Loss: 0.373929\n",
      "\n",
      "\n",
      "Epoch 375/750 - Train Cd Loss: 0.084499 - Test Loss: 0.041905\n",
      "Epoch 375/750 - Train pg Loss: 2.169108 - Test Loss: 0.425925\n",
      "\n",
      "\n",
      "Epoch 376/750 - Train Cd Loss: 0.085824 - Test Loss: 0.043484\n",
      "Epoch 376/750 - Train pg Loss: 2.210137 - Test Loss: 0.430224\n",
      "\n",
      "\n",
      "Epoch 377/750 - Train Cd Loss: 0.084926 - Test Loss: 0.042234\n",
      "Epoch 377/750 - Train pg Loss: 2.440998 - Test Loss: 0.465909\n",
      "\n",
      "\n",
      "Epoch 378/750 - Train Cd Loss: 0.079721 - Test Loss: 0.044343\n",
      "Epoch 378/750 - Train pg Loss: 2.705628 - Test Loss: 0.335009\n",
      "\n",
      "\n",
      "Epoch 379/750 - Train Cd Loss: 0.081624 - Test Loss: 0.044826\n",
      "Epoch 379/750 - Train pg Loss: 2.039750 - Test Loss: 0.378437\n",
      "\n",
      "\n",
      "Epoch 380/750 - Train Cd Loss: 0.082493 - Test Loss: 0.042258\n",
      "Epoch 380/750 - Train pg Loss: 2.088773 - Test Loss: 0.373194\n",
      "\n",
      "\n",
      "Epoch 381/750 - Train Cd Loss: 0.080713 - Test Loss: 0.044952\n",
      "Epoch 381/750 - Train pg Loss: 2.147263 - Test Loss: 0.376348\n",
      "\n",
      "\n",
      "Epoch 382/750 - Train Cd Loss: 0.077012 - Test Loss: 0.044704\n",
      "Epoch 382/750 - Train pg Loss: 2.094431 - Test Loss: 0.357183\n",
      "\n",
      "\n",
      "Epoch 383/750 - Train Cd Loss: 0.085529 - Test Loss: 0.044482\n",
      "Epoch 383/750 - Train pg Loss: 2.329489 - Test Loss: 0.385115\n",
      "\n",
      "\n",
      "Epoch 384/750 - Train Cd Loss: 0.079117 - Test Loss: 0.044944\n",
      "Epoch 384/750 - Train pg Loss: 2.280103 - Test Loss: 0.376814\n",
      "\n",
      "\n",
      "Epoch 385/750 - Train Cd Loss: 0.081828 - Test Loss: 0.043488\n",
      "Epoch 385/750 - Train pg Loss: 2.228412 - Test Loss: 0.381032\n",
      "\n",
      "\n",
      "Epoch 386/750 - Train Cd Loss: 0.084867 - Test Loss: 0.046538\n",
      "Epoch 386/750 - Train pg Loss: 2.319726 - Test Loss: 0.336136\n",
      "\n",
      "\n",
      "Epoch 387/750 - Train Cd Loss: 0.082451 - Test Loss: 0.042625\n",
      "Epoch 387/750 - Train pg Loss: 2.231021 - Test Loss: 0.422598\n",
      "\n",
      "\n",
      "Epoch 388/750 - Train Cd Loss: 0.078943 - Test Loss: 0.041425\n",
      "Epoch 388/750 - Train pg Loss: 2.353873 - Test Loss: 0.415668\n",
      "\n",
      "\n",
      "Epoch 389/750 - Train Cd Loss: 0.082247 - Test Loss: 0.041555\n",
      "Epoch 389/750 - Train pg Loss: 2.072680 - Test Loss: 0.363022\n",
      "\n",
      "\n",
      "Epoch 390/750 - Train Cd Loss: 0.076253 - Test Loss: 0.040519\n",
      "Epoch 390/750 - Train pg Loss: 2.126642 - Test Loss: 0.383981\n",
      "\n",
      "\n",
      "Epoch 391/750 - Train Cd Loss: 0.071987 - Test Loss: 0.044476\n",
      "Epoch 391/750 - Train pg Loss: 2.330911 - Test Loss: 0.345461\n",
      "\n",
      "\n",
      "Epoch 392/750 - Train Cd Loss: 0.077239 - Test Loss: 0.041605\n",
      "Epoch 392/750 - Train pg Loss: 1.994100 - Test Loss: 0.361293\n",
      "\n",
      "\n",
      "Epoch 393/750 - Train Cd Loss: 0.088684 - Test Loss: 0.044623\n",
      "Epoch 393/750 - Train pg Loss: 3.710533 - Test Loss: 0.546402\n",
      "\n",
      "\n",
      "Epoch 394/750 - Train Cd Loss: 0.087276 - Test Loss: 0.045169\n",
      "Epoch 394/750 - Train pg Loss: 2.775801 - Test Loss: 0.479325\n",
      "\n",
      "\n",
      "Epoch 395/750 - Train Cd Loss: 0.080184 - Test Loss: 0.042757\n",
      "Epoch 395/750 - Train pg Loss: 2.516040 - Test Loss: 0.428558\n",
      "\n",
      "\n",
      "Epoch 396/750 - Train Cd Loss: 0.075453 - Test Loss: 0.043400\n",
      "Epoch 396/750 - Train pg Loss: 2.500987 - Test Loss: 0.391319\n",
      "\n",
      "\n",
      "Epoch 397/750 - Train Cd Loss: 0.081242 - Test Loss: 0.043685\n",
      "Epoch 397/750 - Train pg Loss: 2.061254 - Test Loss: 0.353891\n",
      "\n",
      "\n",
      "Epoch 398/750 - Train Cd Loss: 0.073597 - Test Loss: 0.041661\n",
      "Epoch 398/750 - Train pg Loss: 2.218290 - Test Loss: 0.418684\n",
      "\n",
      "\n",
      "Epoch 399/750 - Train Cd Loss: 0.078279 - Test Loss: 0.044161\n",
      "Epoch 399/750 - Train pg Loss: 2.160495 - Test Loss: 0.384865\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/750 - Train Cd Loss: 0.100871 - Test Loss: 0.042172\n",
      "Epoch 400/750 - Train pg Loss: 3.465703 - Test Loss: 0.388943\n",
      "\n",
      "\n",
      "Epoch 401/750 - Train Cd Loss: 0.076171 - Test Loss: 0.045868\n",
      "Epoch 401/750 - Train pg Loss: 2.180088 - Test Loss: 0.428443\n",
      "\n",
      "\n",
      "Epoch 402/750 - Train Cd Loss: 0.082085 - Test Loss: 0.045022\n",
      "Epoch 402/750 - Train pg Loss: 2.322282 - Test Loss: 0.379822\n",
      "\n",
      "\n",
      "Epoch 403/750 - Train Cd Loss: 0.074117 - Test Loss: 0.044731\n",
      "Epoch 403/750 - Train pg Loss: 2.152801 - Test Loss: 0.350448\n",
      "\n",
      "\n",
      "Epoch 404/750 - Train Cd Loss: 0.076001 - Test Loss: 0.042590\n",
      "Epoch 404/750 - Train pg Loss: 1.986208 - Test Loss: 0.360344\n",
      "\n",
      "\n",
      "Epoch 405/750 - Train Cd Loss: 0.077086 - Test Loss: 0.044382\n",
      "Epoch 405/750 - Train pg Loss: 2.057922 - Test Loss: 0.353405\n",
      "\n",
      "\n",
      "Epoch 406/750 - Train Cd Loss: 0.073605 - Test Loss: 0.046835\n",
      "Epoch 406/750 - Train pg Loss: 2.123335 - Test Loss: 0.378862\n",
      "\n",
      "\n",
      "Epoch 407/750 - Train Cd Loss: 0.076190 - Test Loss: 0.041895\n",
      "Epoch 407/750 - Train pg Loss: 2.180217 - Test Loss: 0.347892\n",
      "\n",
      "\n",
      "Epoch 408/750 - Train Cd Loss: 0.083284 - Test Loss: 0.042763\n",
      "Epoch 408/750 - Train pg Loss: 2.036890 - Test Loss: 0.358008\n",
      "\n",
      "\n",
      "Epoch 409/750 - Train Cd Loss: 0.071398 - Test Loss: 0.046305\n",
      "Epoch 409/750 - Train pg Loss: 2.239725 - Test Loss: 0.343978\n",
      "\n",
      "\n",
      "Epoch 410/750 - Train Cd Loss: 0.074454 - Test Loss: 0.043097\n",
      "Epoch 410/750 - Train pg Loss: 2.294662 - Test Loss: 0.384696\n",
      "\n",
      "\n",
      "Epoch 411/750 - Train Cd Loss: 0.079316 - Test Loss: 0.041607\n",
      "Epoch 411/750 - Train pg Loss: 2.105364 - Test Loss: 0.338755\n",
      "\n",
      "\n",
      "Epoch 412/750 - Train Cd Loss: 0.079125 - Test Loss: 0.042393\n",
      "Epoch 412/750 - Train pg Loss: 2.065850 - Test Loss: 0.414671\n",
      "\n",
      "\n",
      "Epoch 413/750 - Train Cd Loss: 0.075795 - Test Loss: 0.041531\n",
      "Epoch 413/750 - Train pg Loss: 2.516538 - Test Loss: 0.412513\n",
      "\n",
      "\n",
      "Epoch 414/750 - Train Cd Loss: 0.074448 - Test Loss: 0.041908\n",
      "Epoch 414/750 - Train pg Loss: 2.353248 - Test Loss: 0.383273\n",
      "\n",
      "\n",
      "Epoch 415/750 - Train Cd Loss: 0.077779 - Test Loss: 0.041415\n",
      "Epoch 415/750 - Train pg Loss: 2.081502 - Test Loss: 0.377587\n",
      "\n",
      "\n",
      "Epoch 416/750 - Train Cd Loss: 0.087572 - Test Loss: 0.044418\n",
      "Epoch 416/750 - Train pg Loss: 3.329700 - Test Loss: 0.395039\n",
      "\n",
      "\n",
      "Epoch 417/750 - Train Cd Loss: 0.069704 - Test Loss: 0.043112\n",
      "Epoch 417/750 - Train pg Loss: 2.341275 - Test Loss: 0.405114\n",
      "\n",
      "\n",
      "Epoch 418/750 - Train Cd Loss: 0.074614 - Test Loss: 0.044713\n",
      "Epoch 418/750 - Train pg Loss: 1.944641 - Test Loss: 0.361173\n",
      "\n",
      "\n",
      "Epoch 419/750 - Train Cd Loss: 0.074627 - Test Loss: 0.042546\n",
      "Epoch 419/750 - Train pg Loss: 2.236304 - Test Loss: 0.381516\n",
      "\n",
      "\n",
      "Epoch 420/750 - Train Cd Loss: 0.089607 - Test Loss: 0.047270\n",
      "Epoch 420/750 - Train pg Loss: 3.251506 - Test Loss: 0.315987\n",
      "\n",
      "\n",
      "Epoch 421/750 - Train Cd Loss: 0.076530 - Test Loss: 0.045290\n",
      "Epoch 421/750 - Train pg Loss: 1.880466 - Test Loss: 0.358507\n",
      "\n",
      "\n",
      "Epoch 422/750 - Train Cd Loss: 0.081570 - Test Loss: 0.041631\n",
      "Epoch 422/750 - Train pg Loss: 2.384439 - Test Loss: 0.479978\n",
      "\n",
      "\n",
      "Epoch 423/750 - Train Cd Loss: 0.069612 - Test Loss: 0.042916\n",
      "Epoch 423/750 - Train pg Loss: 2.570016 - Test Loss: 0.438736\n",
      "\n",
      "\n",
      "Epoch 424/750 - Train Cd Loss: 0.077554 - Test Loss: 0.043026\n",
      "Epoch 424/750 - Train pg Loss: 2.560301 - Test Loss: 0.357121\n",
      "\n",
      "\n",
      "Epoch 425/750 - Train Cd Loss: 0.064822 - Test Loss: 0.041947\n",
      "Epoch 425/750 - Train pg Loss: 2.056954 - Test Loss: 0.342547\n",
      "\n",
      "\n",
      "Epoch 426/750 - Train Cd Loss: 0.074762 - Test Loss: 0.043164\n",
      "Epoch 426/750 - Train pg Loss: 1.769460 - Test Loss: 0.316876\n",
      "\n",
      "\n",
      "Epoch 427/750 - Train Cd Loss: 0.072653 - Test Loss: 0.042271\n",
      "Epoch 427/750 - Train pg Loss: 2.217622 - Test Loss: 0.375136\n",
      "\n",
      "\n",
      "Epoch 428/750 - Train Cd Loss: 0.065783 - Test Loss: 0.047703\n",
      "Epoch 428/750 - Train pg Loss: 2.060844 - Test Loss: 0.306744\n",
      "\n",
      "\n",
      "Epoch 429/750 - Train Cd Loss: 0.069072 - Test Loss: 0.043475\n",
      "Epoch 429/750 - Train pg Loss: 2.145562 - Test Loss: 0.372795\n",
      "\n",
      "\n",
      "Epoch 430/750 - Train Cd Loss: 0.068193 - Test Loss: 0.045185\n",
      "Epoch 430/750 - Train pg Loss: 2.159076 - Test Loss: 0.345401\n",
      "\n",
      "\n",
      "Epoch 431/750 - Train Cd Loss: 0.068384 - Test Loss: 0.043641\n",
      "Epoch 431/750 - Train pg Loss: 2.747382 - Test Loss: 0.313967\n",
      "\n",
      "\n",
      "Epoch 432/750 - Train Cd Loss: 0.077198 - Test Loss: 0.044565\n",
      "Epoch 432/750 - Train pg Loss: 2.291604 - Test Loss: 0.288446\n",
      "\n",
      "\n",
      "Epoch 433/750 - Train Cd Loss: 0.071460 - Test Loss: 0.044229\n",
      "Epoch 433/750 - Train pg Loss: 2.760373 - Test Loss: 0.322081\n",
      "\n",
      "\n",
      "Epoch 434/750 - Train Cd Loss: 0.069144 - Test Loss: 0.044254\n",
      "Epoch 434/750 - Train pg Loss: 2.196061 - Test Loss: 0.343690\n",
      "\n",
      "\n",
      "Epoch 435/750 - Train Cd Loss: 0.068240 - Test Loss: 0.042430\n",
      "Epoch 435/750 - Train pg Loss: 2.329123 - Test Loss: 0.372497\n",
      "\n",
      "\n",
      "Epoch 436/750 - Train Cd Loss: 0.072250 - Test Loss: 0.043901\n",
      "Epoch 436/750 - Train pg Loss: 2.146945 - Test Loss: 0.328928\n",
      "\n",
      "\n",
      "Epoch 437/750 - Train Cd Loss: 0.074935 - Test Loss: 0.043306\n",
      "Epoch 437/750 - Train pg Loss: 3.012704 - Test Loss: 0.360504\n",
      "\n",
      "\n",
      "Epoch 438/750 - Train Cd Loss: 0.060833 - Test Loss: 0.046316\n",
      "Epoch 438/750 - Train pg Loss: 2.321345 - Test Loss: 0.344074\n",
      "\n",
      "\n",
      "Epoch 439/750 - Train Cd Loss: 0.067775 - Test Loss: 0.043308\n",
      "Epoch 439/750 - Train pg Loss: 2.172599 - Test Loss: 0.379219\n",
      "\n",
      "\n",
      "Epoch 440/750 - Train Cd Loss: 0.067949 - Test Loss: 0.042916\n",
      "Epoch 440/750 - Train pg Loss: 2.433086 - Test Loss: 0.383664\n",
      "\n",
      "\n",
      "Epoch 441/750 - Train Cd Loss: 0.069249 - Test Loss: 0.045602\n",
      "Epoch 441/750 - Train pg Loss: 2.165563 - Test Loss: 0.354091\n",
      "\n",
      "\n",
      "Epoch 442/750 - Train Cd Loss: 0.074477 - Test Loss: 0.045135\n",
      "Epoch 442/750 - Train pg Loss: 2.806444 - Test Loss: 0.353604\n",
      "\n",
      "\n",
      "Epoch 443/750 - Train Cd Loss: 0.065586 - Test Loss: 0.045056\n",
      "Epoch 443/750 - Train pg Loss: 2.271683 - Test Loss: 0.324336\n",
      "\n",
      "\n",
      "Epoch 444/750 - Train Cd Loss: 0.066134 - Test Loss: 0.045010\n",
      "Epoch 444/750 - Train pg Loss: 1.791264 - Test Loss: 0.337489\n",
      "\n",
      "\n",
      "Epoch 445/750 - Train Cd Loss: 0.069677 - Test Loss: 0.046173\n",
      "Epoch 445/750 - Train pg Loss: 2.041474 - Test Loss: 0.351888\n",
      "\n",
      "\n",
      "Epoch 446/750 - Train Cd Loss: 0.061612 - Test Loss: 0.047489\n",
      "Epoch 446/750 - Train pg Loss: 2.240670 - Test Loss: 0.354715\n",
      "\n",
      "\n",
      "Epoch 447/750 - Train Cd Loss: 0.069259 - Test Loss: 0.045299\n",
      "Epoch 447/750 - Train pg Loss: 2.414912 - Test Loss: 0.305405\n",
      "\n",
      "\n",
      "Epoch 448/750 - Train Cd Loss: 0.075033 - Test Loss: 0.042839\n",
      "Epoch 448/750 - Train pg Loss: 3.470863 - Test Loss: 0.352745\n",
      "\n",
      "\n",
      "Epoch 449/750 - Train Cd Loss: 0.071784 - Test Loss: 0.045733\n",
      "Epoch 449/750 - Train pg Loss: 2.798572 - Test Loss: 0.333060\n",
      "\n",
      "\n",
      "Epoch 450/750 - Train Cd Loss: 0.062179 - Test Loss: 0.043683\n",
      "Epoch 450/750 - Train pg Loss: 2.144684 - Test Loss: 0.357548\n",
      "\n",
      "\n",
      "Epoch 451/750 - Train Cd Loss: 0.069663 - Test Loss: 0.045354\n",
      "Epoch 451/750 - Train pg Loss: 2.035313 - Test Loss: 0.325526\n",
      "\n",
      "\n",
      "Epoch 452/750 - Train Cd Loss: 0.069017 - Test Loss: 0.043481\n",
      "Epoch 452/750 - Train pg Loss: 2.607094 - Test Loss: 0.335188\n",
      "\n",
      "\n",
      "Epoch 453/750 - Train Cd Loss: 0.096687 - Test Loss: 0.043355\n",
      "Epoch 453/750 - Train pg Loss: 3.533274 - Test Loss: 0.332887\n",
      "\n",
      "\n",
      "Epoch 454/750 - Train Cd Loss: 0.065723 - Test Loss: 0.047000\n",
      "Epoch 454/750 - Train pg Loss: 2.135854 - Test Loss: 0.308888\n",
      "\n",
      "\n",
      "Epoch 455/750 - Train Cd Loss: 0.066423 - Test Loss: 0.045923\n",
      "Epoch 455/750 - Train pg Loss: 1.881946 - Test Loss: 0.350717\n",
      "\n",
      "\n",
      "Epoch 456/750 - Train Cd Loss: 0.065655 - Test Loss: 0.045739\n",
      "Epoch 456/750 - Train pg Loss: 2.315551 - Test Loss: 0.358112\n",
      "\n",
      "\n",
      "Epoch 457/750 - Train Cd Loss: 0.064103 - Test Loss: 0.046032\n",
      "Epoch 457/750 - Train pg Loss: 2.246165 - Test Loss: 0.359035\n",
      "\n",
      "\n",
      "Epoch 458/750 - Train Cd Loss: 0.064584 - Test Loss: 0.044264\n",
      "Epoch 458/750 - Train pg Loss: 2.835328 - Test Loss: 0.379212\n",
      "\n",
      "\n",
      "Epoch 459/750 - Train Cd Loss: 0.061708 - Test Loss: 0.044483\n",
      "Epoch 459/750 - Train pg Loss: 2.501158 - Test Loss: 0.289375\n",
      "\n",
      "\n",
      "Epoch 460/750 - Train Cd Loss: 0.066289 - Test Loss: 0.045224\n",
      "Epoch 460/750 - Train pg Loss: 1.760595 - Test Loss: 0.235794\n",
      "\n",
      "\n",
      "Epoch 461/750 - Train Cd Loss: 0.073553 - Test Loss: 0.047607\n",
      "Epoch 461/750 - Train pg Loss: 2.770309 - Test Loss: 0.274707\n",
      "\n",
      "\n",
      "Epoch 462/750 - Train Cd Loss: 0.062443 - Test Loss: 0.042583\n",
      "Epoch 462/750 - Train pg Loss: 1.967843 - Test Loss: 0.351597\n",
      "\n",
      "\n",
      "Epoch 463/750 - Train Cd Loss: 0.061746 - Test Loss: 0.043677\n",
      "Epoch 463/750 - Train pg Loss: 1.897234 - Test Loss: 0.335148\n",
      "\n",
      "\n",
      "Epoch 464/750 - Train Cd Loss: 0.063938 - Test Loss: 0.046774\n",
      "Epoch 464/750 - Train pg Loss: 2.068753 - Test Loss: 0.363302\n",
      "\n",
      "\n",
      "Epoch 465/750 - Train Cd Loss: 0.069771 - Test Loss: 0.044996\n",
      "Epoch 465/750 - Train pg Loss: 2.033819 - Test Loss: 0.323803\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466/750 - Train Cd Loss: 0.060029 - Test Loss: 0.049686\n",
      "Epoch 466/750 - Train pg Loss: 1.912445 - Test Loss: 0.260861\n",
      "\n",
      "\n",
      "Epoch 467/750 - Train Cd Loss: 0.059227 - Test Loss: 0.044584\n",
      "Epoch 467/750 - Train pg Loss: 1.812777 - Test Loss: 0.349706\n",
      "\n",
      "\n",
      "Epoch 468/750 - Train Cd Loss: 0.056500 - Test Loss: 0.043193\n",
      "Epoch 468/750 - Train pg Loss: 2.114674 - Test Loss: 0.306018\n",
      "\n",
      "\n",
      "Epoch 469/750 - Train Cd Loss: 0.053213 - Test Loss: 0.043698\n",
      "Epoch 469/750 - Train pg Loss: 2.426852 - Test Loss: 0.299664\n",
      "\n",
      "\n",
      "Epoch 470/750 - Train Cd Loss: 0.074525 - Test Loss: 0.047477\n",
      "Epoch 470/750 - Train pg Loss: 2.840497 - Test Loss: 0.337111\n",
      "\n",
      "\n",
      "Epoch 471/750 - Train Cd Loss: 0.066502 - Test Loss: 0.045086\n",
      "Epoch 471/750 - Train pg Loss: 2.318768 - Test Loss: 0.370731\n",
      "\n",
      "\n",
      "Epoch 472/750 - Train Cd Loss: 0.064159 - Test Loss: 0.044010\n",
      "Epoch 472/750 - Train pg Loss: 3.848356 - Test Loss: 0.365240\n",
      "\n",
      "\n",
      "Epoch 473/750 - Train Cd Loss: 0.062815 - Test Loss: 0.044496\n",
      "Epoch 473/750 - Train pg Loss: 3.489413 - Test Loss: 0.434135\n",
      "\n",
      "\n",
      "Epoch 474/750 - Train Cd Loss: 0.062091 - Test Loss: 0.045460\n",
      "Epoch 474/750 - Train pg Loss: 2.567574 - Test Loss: 0.362621\n",
      "\n",
      "\n",
      "Epoch 475/750 - Train Cd Loss: 0.066717 - Test Loss: 0.043607\n",
      "Epoch 475/750 - Train pg Loss: 2.444421 - Test Loss: 0.347865\n",
      "\n",
      "\n",
      "Epoch 476/750 - Train Cd Loss: 0.067232 - Test Loss: 0.049446\n",
      "Epoch 476/750 - Train pg Loss: 2.090093 - Test Loss: 0.233993\n",
      "\n",
      "\n",
      "Epoch 477/750 - Train Cd Loss: 0.058567 - Test Loss: 0.042110\n",
      "Epoch 477/750 - Train pg Loss: 1.788582 - Test Loss: 0.308628\n",
      "\n",
      "\n",
      "Epoch 478/750 - Train Cd Loss: 0.082839 - Test Loss: 0.047772\n",
      "Epoch 478/750 - Train pg Loss: 3.501549 - Test Loss: 0.283620\n",
      "\n",
      "\n",
      "Epoch 479/750 - Train Cd Loss: 0.061008 - Test Loss: 0.045002\n",
      "Epoch 479/750 - Train pg Loss: 2.170984 - Test Loss: 0.277585\n",
      "\n",
      "\n",
      "Epoch 480/750 - Train Cd Loss: 0.058506 - Test Loss: 0.047122\n",
      "Epoch 480/750 - Train pg Loss: 2.024213 - Test Loss: 0.267079\n",
      "\n",
      "\n",
      "Epoch 481/750 - Train Cd Loss: 0.072741 - Test Loss: 0.045011\n",
      "Epoch 481/750 - Train pg Loss: 2.396956 - Test Loss: 0.306361\n",
      "\n",
      "\n",
      "Epoch 482/750 - Train Cd Loss: 0.059806 - Test Loss: 0.043079\n",
      "Epoch 482/750 - Train pg Loss: 2.185767 - Test Loss: 0.333647\n",
      "\n",
      "\n",
      "Epoch 483/750 - Train Cd Loss: 0.056713 - Test Loss: 0.045235\n",
      "Epoch 483/750 - Train pg Loss: 2.118408 - Test Loss: 0.295491\n",
      "\n",
      "\n",
      "Epoch 484/750 - Train Cd Loss: 0.067994 - Test Loss: 0.046364\n",
      "Epoch 484/750 - Train pg Loss: 2.532972 - Test Loss: 0.314894\n",
      "\n",
      "\n",
      "Epoch 485/750 - Train Cd Loss: 0.061292 - Test Loss: 0.046075\n",
      "Epoch 485/750 - Train pg Loss: 2.212109 - Test Loss: 0.372391\n",
      "\n",
      "\n",
      "Epoch 486/750 - Train Cd Loss: 0.056190 - Test Loss: 0.043725\n",
      "Epoch 486/750 - Train pg Loss: 2.241457 - Test Loss: 0.350896\n",
      "\n",
      "\n",
      "Epoch 487/750 - Train Cd Loss: 0.051988 - Test Loss: 0.046282\n",
      "Epoch 487/750 - Train pg Loss: 2.649625 - Test Loss: 0.308215\n",
      "\n",
      "\n",
      "Epoch 488/750 - Train Cd Loss: 0.067032 - Test Loss: 0.042308\n",
      "Epoch 488/750 - Train pg Loss: 3.519024 - Test Loss: 0.321436\n",
      "\n",
      "\n",
      "Epoch 489/750 - Train Cd Loss: 0.062017 - Test Loss: 0.045178\n",
      "Epoch 489/750 - Train pg Loss: 1.917662 - Test Loss: 0.283683\n",
      "\n",
      "\n",
      "Epoch 490/750 - Train Cd Loss: 0.057219 - Test Loss: 0.046676\n",
      "Epoch 490/750 - Train pg Loss: 2.485322 - Test Loss: 0.305235\n",
      "\n",
      "\n",
      "Epoch 491/750 - Train Cd Loss: 0.057914 - Test Loss: 0.043984\n",
      "Epoch 491/750 - Train pg Loss: 2.528305 - Test Loss: 0.287558\n",
      "\n",
      "\n",
      "Epoch 492/750 - Train Cd Loss: 0.074541 - Test Loss: 0.048106\n",
      "Epoch 492/750 - Train pg Loss: 3.804091 - Test Loss: 0.272519\n",
      "\n",
      "\n",
      "Epoch 493/750 - Train Cd Loss: 0.059932 - Test Loss: 0.043542\n",
      "Epoch 493/750 - Train pg Loss: 2.381548 - Test Loss: 0.356107\n",
      "\n",
      "\n",
      "Epoch 494/750 - Train Cd Loss: 0.056653 - Test Loss: 0.045349\n",
      "Epoch 494/750 - Train pg Loss: 2.186787 - Test Loss: 0.328133\n",
      "\n",
      "\n",
      "Epoch 495/750 - Train Cd Loss: 0.058073 - Test Loss: 0.044065\n",
      "Epoch 495/750 - Train pg Loss: 2.347842 - Test Loss: 0.304458\n",
      "\n",
      "\n",
      "Epoch 496/750 - Train Cd Loss: 0.058404 - Test Loss: 0.045113\n",
      "Epoch 496/750 - Train pg Loss: 3.666918 - Test Loss: 0.316185\n",
      "\n",
      "\n",
      "Epoch 497/750 - Train Cd Loss: 0.065122 - Test Loss: 0.043503\n",
      "Epoch 497/750 - Train pg Loss: 2.859735 - Test Loss: 0.259866\n",
      "\n",
      "\n",
      "Epoch 498/750 - Train Cd Loss: 0.050263 - Test Loss: 0.044043\n",
      "Epoch 498/750 - Train pg Loss: 1.903389 - Test Loss: 0.262768\n",
      "\n",
      "\n",
      "Epoch 499/750 - Train Cd Loss: 0.087388 - Test Loss: 0.044818\n",
      "Epoch 499/750 - Train pg Loss: 3.819546 - Test Loss: 0.251952\n",
      "\n",
      "\n",
      "Epoch 500/750 - Train Cd Loss: 0.058595 - Test Loss: 0.041944\n",
      "Epoch 500/750 - Train pg Loss: 2.045889 - Test Loss: 0.272571\n",
      "\n",
      "\n",
      "Epoch 501/750 - Train Cd Loss: 0.055212 - Test Loss: 0.044450\n",
      "Epoch 501/750 - Train pg Loss: 2.597995 - Test Loss: 0.242000\n",
      "\n",
      "\n",
      "Epoch 502/750 - Train Cd Loss: 0.062868 - Test Loss: 0.044303\n",
      "Epoch 502/750 - Train pg Loss: 3.961992 - Test Loss: 0.305129\n",
      "\n",
      "\n",
      "Epoch 503/750 - Train Cd Loss: 0.054176 - Test Loss: 0.045923\n",
      "Epoch 503/750 - Train pg Loss: 3.694656 - Test Loss: 0.319990\n",
      "\n",
      "\n",
      "Epoch 504/750 - Train Cd Loss: 0.056136 - Test Loss: 0.044527\n",
      "Epoch 504/750 - Train pg Loss: 2.104407 - Test Loss: 0.305129\n",
      "\n",
      "\n",
      "Epoch 505/750 - Train Cd Loss: 0.050955 - Test Loss: 0.044814\n",
      "Epoch 505/750 - Train pg Loss: 2.190273 - Test Loss: 0.316600\n",
      "\n",
      "\n",
      "Epoch 506/750 - Train Cd Loss: 0.053597 - Test Loss: 0.045040\n",
      "Epoch 506/750 - Train pg Loss: 2.299238 - Test Loss: 0.273952\n",
      "\n",
      "\n",
      "Epoch 507/750 - Train Cd Loss: 0.059011 - Test Loss: 0.043958\n",
      "Epoch 507/750 - Train pg Loss: 2.909748 - Test Loss: 0.290571\n",
      "\n",
      "\n",
      "Epoch 508/750 - Train Cd Loss: 0.052773 - Test Loss: 0.043117\n",
      "Epoch 508/750 - Train pg Loss: 3.116400 - Test Loss: 0.289277\n",
      "\n",
      "\n",
      "Epoch 509/750 - Train Cd Loss: 0.049180 - Test Loss: 0.044170\n",
      "Epoch 509/750 - Train pg Loss: 2.555155 - Test Loss: 0.287301\n",
      "\n",
      "\n",
      "Epoch 510/750 - Train Cd Loss: 0.050448 - Test Loss: 0.045587\n",
      "Epoch 510/750 - Train pg Loss: 3.147596 - Test Loss: 0.268246\n",
      "\n",
      "\n",
      "Epoch 511/750 - Train Cd Loss: 0.048673 - Test Loss: 0.047094\n",
      "Epoch 511/750 - Train pg Loss: 1.825845 - Test Loss: 0.253979\n",
      "\n",
      "\n",
      "Epoch 512/750 - Train Cd Loss: 0.053264 - Test Loss: 0.045057\n",
      "Epoch 512/750 - Train pg Loss: 2.190812 - Test Loss: 0.258186\n",
      "\n",
      "\n",
      "Epoch 513/750 - Train Cd Loss: 0.048570 - Test Loss: 0.045809\n",
      "Epoch 513/750 - Train pg Loss: 1.788150 - Test Loss: 0.256257\n",
      "\n",
      "\n",
      "Epoch 514/750 - Train Cd Loss: 0.063475 - Test Loss: 0.047896\n",
      "Epoch 514/750 - Train pg Loss: 2.757442 - Test Loss: 0.227857\n",
      "\n",
      "\n",
      "Epoch 515/750 - Train Cd Loss: 0.053078 - Test Loss: 0.050179\n",
      "Epoch 515/750 - Train pg Loss: 2.546894 - Test Loss: 0.260122\n",
      "\n",
      "\n",
      "Epoch 516/750 - Train Cd Loss: 0.068382 - Test Loss: 0.044810\n",
      "Epoch 516/750 - Train pg Loss: 2.398330 - Test Loss: 0.295615\n",
      "\n",
      "\n",
      "Epoch 517/750 - Train Cd Loss: 0.057640 - Test Loss: 0.045463\n",
      "Epoch 517/750 - Train pg Loss: 2.116823 - Test Loss: 0.333963\n",
      "\n",
      "\n",
      "Epoch 518/750 - Train Cd Loss: 0.051644 - Test Loss: 0.047106\n",
      "Epoch 518/750 - Train pg Loss: 2.290312 - Test Loss: 0.301016\n",
      "\n",
      "\n",
      "Epoch 519/750 - Train Cd Loss: 0.060005 - Test Loss: 0.041997\n",
      "Epoch 519/750 - Train pg Loss: 3.072084 - Test Loss: 0.355276\n",
      "\n",
      "\n",
      "Epoch 520/750 - Train Cd Loss: 0.065090 - Test Loss: 0.048691\n",
      "Epoch 520/750 - Train pg Loss: 2.600527 - Test Loss: 0.292452\n",
      "\n",
      "\n",
      "Epoch 521/750 - Train Cd Loss: 0.057717 - Test Loss: 0.043622\n",
      "Epoch 521/750 - Train pg Loss: 2.721469 - Test Loss: 0.350321\n",
      "\n",
      "\n",
      "Epoch 522/750 - Train Cd Loss: 0.059646 - Test Loss: 0.043883\n",
      "Epoch 522/750 - Train pg Loss: 4.049998 - Test Loss: 0.322313\n",
      "\n",
      "\n",
      "Epoch 523/750 - Train Cd Loss: 0.054793 - Test Loss: 0.044047\n",
      "Epoch 523/750 - Train pg Loss: 2.775646 - Test Loss: 0.289580\n",
      "\n",
      "\n",
      "Epoch 524/750 - Train Cd Loss: 0.064610 - Test Loss: 0.046997\n",
      "Epoch 524/750 - Train pg Loss: 3.895065 - Test Loss: 0.283238\n",
      "\n",
      "\n",
      "Epoch 525/750 - Train Cd Loss: 0.051852 - Test Loss: 0.048899\n",
      "Epoch 525/750 - Train pg Loss: 2.274151 - Test Loss: 0.261932\n",
      "\n",
      "\n",
      "Epoch 526/750 - Train Cd Loss: 0.057551 - Test Loss: 0.045296\n",
      "Epoch 526/750 - Train pg Loss: 3.525856 - Test Loss: 0.304984\n",
      "\n",
      "\n",
      "Epoch 527/750 - Train Cd Loss: 0.049884 - Test Loss: 0.045455\n",
      "Epoch 527/750 - Train pg Loss: 3.952953 - Test Loss: 0.297818\n",
      "\n",
      "\n",
      "Epoch 528/750 - Train Cd Loss: 0.054322 - Test Loss: 0.046474\n",
      "Epoch 528/750 - Train pg Loss: 2.330252 - Test Loss: 0.322511\n",
      "\n",
      "\n",
      "Epoch 529/750 - Train Cd Loss: 0.065874 - Test Loss: 0.047067\n",
      "Epoch 529/750 - Train pg Loss: 3.126221 - Test Loss: 0.333216\n",
      "\n",
      "\n",
      "Epoch 530/750 - Train Cd Loss: 0.049643 - Test Loss: 0.045851\n",
      "Epoch 530/750 - Train pg Loss: 2.478635 - Test Loss: 0.307584\n",
      "\n",
      "\n",
      "Epoch 531/750 - Train Cd Loss: 0.048778 - Test Loss: 0.043382\n",
      "Epoch 531/750 - Train pg Loss: 2.328789 - Test Loss: 0.293966\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 532/750 - Train Cd Loss: 0.058668 - Test Loss: 0.049758\n",
      "Epoch 532/750 - Train pg Loss: 3.019293 - Test Loss: 0.236106\n",
      "\n",
      "\n",
      "Epoch 533/750 - Train Cd Loss: 0.060826 - Test Loss: 0.044726\n",
      "Epoch 533/750 - Train pg Loss: 3.838339 - Test Loss: 0.238721\n",
      "\n",
      "\n",
      "Epoch 534/750 - Train Cd Loss: 0.049770 - Test Loss: 0.045129\n",
      "Epoch 534/750 - Train pg Loss: 2.441844 - Test Loss: 0.258913\n",
      "\n",
      "\n",
      "Epoch 535/750 - Train Cd Loss: 0.046090 - Test Loss: 0.046719\n",
      "Epoch 535/750 - Train pg Loss: 1.787121 - Test Loss: 0.237471\n",
      "\n",
      "\n",
      "Epoch 536/750 - Train Cd Loss: 0.045228 - Test Loss: 0.047050\n",
      "Epoch 536/750 - Train pg Loss: 3.554582 - Test Loss: 0.221380\n",
      "\n",
      "\n",
      "Epoch 537/750 - Train Cd Loss: 0.080345 - Test Loss: 0.048722\n",
      "Epoch 537/750 - Train pg Loss: 4.859646 - Test Loss: 0.237160\n",
      "\n",
      "\n",
      "Epoch 538/750 - Train Cd Loss: 0.050914 - Test Loss: 0.044641\n",
      "Epoch 538/750 - Train pg Loss: 3.148510 - Test Loss: 0.274158\n",
      "\n",
      "\n",
      "Epoch 539/750 - Train Cd Loss: 0.046974 - Test Loss: 0.045860\n",
      "Epoch 539/750 - Train pg Loss: 2.072959 - Test Loss: 0.288228\n",
      "\n",
      "\n",
      "Epoch 540/750 - Train Cd Loss: 0.061920 - Test Loss: 0.043506\n",
      "Epoch 540/750 - Train pg Loss: 2.879624 - Test Loss: 0.299640\n",
      "\n",
      "\n",
      "Epoch 541/750 - Train Cd Loss: 0.045800 - Test Loss: 0.048605\n",
      "Epoch 541/750 - Train pg Loss: 2.184480 - Test Loss: 0.319245\n",
      "\n",
      "\n",
      "Epoch 542/750 - Train Cd Loss: 0.048805 - Test Loss: 0.043677\n",
      "Epoch 542/750 - Train pg Loss: 2.447476 - Test Loss: 0.322721\n",
      "\n",
      "\n",
      "Epoch 543/750 - Train Cd Loss: 0.064811 - Test Loss: 0.049773\n",
      "Epoch 543/750 - Train pg Loss: 4.439611 - Test Loss: 0.277043\n",
      "\n",
      "\n",
      "Epoch 544/750 - Train Cd Loss: 0.048823 - Test Loss: 0.046269\n",
      "Epoch 544/750 - Train pg Loss: 1.893805 - Test Loss: 0.279654\n",
      "\n",
      "\n",
      "Epoch 545/750 - Train Cd Loss: 0.049276 - Test Loss: 0.046653\n",
      "Epoch 545/750 - Train pg Loss: 2.414162 - Test Loss: 0.281223\n",
      "\n",
      "\n",
      "Epoch 546/750 - Train Cd Loss: 0.066236 - Test Loss: 0.048701\n",
      "Epoch 546/750 - Train pg Loss: 3.716320 - Test Loss: 0.305197\n",
      "\n",
      "\n",
      "Epoch 547/750 - Train Cd Loss: 0.070036 - Test Loss: 0.044640\n",
      "Epoch 547/750 - Train pg Loss: 3.822388 - Test Loss: 0.343427\n",
      "\n",
      "\n",
      "Epoch 548/750 - Train Cd Loss: 0.059710 - Test Loss: 0.043675\n",
      "Epoch 548/750 - Train pg Loss: 3.447572 - Test Loss: 0.292613\n",
      "\n",
      "\n",
      "Epoch 549/750 - Train Cd Loss: 0.052849 - Test Loss: 0.047903\n",
      "Epoch 549/750 - Train pg Loss: 2.097565 - Test Loss: 0.242982\n",
      "\n",
      "\n",
      "Epoch 550/750 - Train Cd Loss: 0.060910 - Test Loss: 0.044367\n",
      "Epoch 550/750 - Train pg Loss: 2.677214 - Test Loss: 0.262952\n",
      "\n",
      "\n",
      "Epoch 551/750 - Train Cd Loss: 0.044897 - Test Loss: 0.048719\n",
      "Epoch 551/750 - Train pg Loss: 2.120005 - Test Loss: 0.235447\n",
      "\n",
      "\n",
      "Epoch 552/750 - Train Cd Loss: 0.052324 - Test Loss: 0.043573\n",
      "Epoch 552/750 - Train pg Loss: 3.096717 - Test Loss: 0.257975\n",
      "\n",
      "\n",
      "Epoch 553/750 - Train Cd Loss: 0.043893 - Test Loss: 0.046371\n",
      "Epoch 553/750 - Train pg Loss: 1.702420 - Test Loss: 0.238452\n",
      "\n",
      "\n",
      "Epoch 554/750 - Train Cd Loss: 0.050128 - Test Loss: 0.044898\n",
      "Epoch 554/750 - Train pg Loss: 3.082039 - Test Loss: 0.233013\n",
      "\n",
      "\n",
      "Epoch 555/750 - Train Cd Loss: 0.072143 - Test Loss: 0.047524\n",
      "Epoch 555/750 - Train pg Loss: 4.684177 - Test Loss: 0.266678\n",
      "\n",
      "\n",
      "Epoch 556/750 - Train Cd Loss: 0.049318 - Test Loss: 0.047384\n",
      "Epoch 556/750 - Train pg Loss: 2.347458 - Test Loss: 0.263540\n",
      "\n",
      "\n",
      "Epoch 557/750 - Train Cd Loss: 0.054044 - Test Loss: 0.044667\n",
      "Epoch 557/750 - Train pg Loss: 3.044725 - Test Loss: 0.275956\n",
      "\n",
      "\n",
      "Epoch 558/750 - Train Cd Loss: 0.045695 - Test Loss: 0.044954\n",
      "Epoch 558/750 - Train pg Loss: 2.455363 - Test Loss: 0.273395\n",
      "\n",
      "\n",
      "Epoch 559/750 - Train Cd Loss: 0.040267 - Test Loss: 0.048907\n",
      "Epoch 559/750 - Train pg Loss: 2.126158 - Test Loss: 0.236076\n",
      "\n",
      "\n",
      "Epoch 560/750 - Train Cd Loss: 0.041737 - Test Loss: 0.044600\n",
      "Epoch 560/750 - Train pg Loss: 1.576995 - Test Loss: 0.247882\n",
      "\n",
      "\n",
      "Epoch 561/750 - Train Cd Loss: 0.045638 - Test Loss: 0.048450\n",
      "Epoch 561/750 - Train pg Loss: 2.512489 - Test Loss: 0.215808\n",
      "\n",
      "\n",
      "Epoch 562/750 - Train Cd Loss: 0.054342 - Test Loss: 0.049459\n",
      "Epoch 562/750 - Train pg Loss: 2.402036 - Test Loss: 0.187576\n",
      "\n",
      "\n",
      "Epoch 563/750 - Train Cd Loss: 0.051167 - Test Loss: 0.047550\n",
      "Epoch 563/750 - Train pg Loss: 2.175243 - Test Loss: 0.219906\n",
      "\n",
      "\n",
      "Epoch 564/750 - Train Cd Loss: 0.050563 - Test Loss: 0.049147\n",
      "Epoch 564/750 - Train pg Loss: 2.397025 - Test Loss: 0.279638\n",
      "\n",
      "\n",
      "Epoch 565/750 - Train Cd Loss: 0.044420 - Test Loss: 0.048193\n",
      "Epoch 565/750 - Train pg Loss: 2.090951 - Test Loss: 0.213775\n",
      "\n",
      "\n",
      "Epoch 566/750 - Train Cd Loss: 0.051754 - Test Loss: 0.053557\n",
      "Epoch 566/750 - Train pg Loss: 3.301447 - Test Loss: 0.233562\n",
      "\n",
      "\n",
      "Epoch 567/750 - Train Cd Loss: 0.041420 - Test Loss: 0.044647\n",
      "Epoch 567/750 - Train pg Loss: 1.895643 - Test Loss: 0.205519\n",
      "\n",
      "\n",
      "Epoch 568/750 - Train Cd Loss: 0.053426 - Test Loss: 0.051014\n",
      "Epoch 568/750 - Train pg Loss: 3.239960 - Test Loss: 0.252821\n",
      "\n",
      "\n",
      "Epoch 569/750 - Train Cd Loss: 0.040364 - Test Loss: 0.044397\n",
      "Epoch 569/750 - Train pg Loss: 2.269874 - Test Loss: 0.241398\n",
      "\n",
      "\n",
      "Epoch 570/750 - Train Cd Loss: 0.038132 - Test Loss: 0.050200\n",
      "Epoch 570/750 - Train pg Loss: 2.244604 - Test Loss: 0.281224\n",
      "\n",
      "\n",
      "Epoch 571/750 - Train Cd Loss: 0.049704 - Test Loss: 0.047689\n",
      "Epoch 571/750 - Train pg Loss: 1.783753 - Test Loss: 0.253046\n",
      "\n",
      "\n",
      "Epoch 572/750 - Train Cd Loss: 0.062500 - Test Loss: 0.049183\n",
      "Epoch 572/750 - Train pg Loss: 2.419452 - Test Loss: 0.255354\n",
      "\n",
      "\n",
      "Epoch 573/750 - Train Cd Loss: 0.042949 - Test Loss: 0.045158\n",
      "Epoch 573/750 - Train pg Loss: 2.314221 - Test Loss: 0.308703\n",
      "\n",
      "\n",
      "Epoch 574/750 - Train Cd Loss: 0.045276 - Test Loss: 0.048547\n",
      "Epoch 574/750 - Train pg Loss: 2.044810 - Test Loss: 0.226206\n",
      "\n",
      "\n",
      "Epoch 575/750 - Train Cd Loss: 0.042257 - Test Loss: 0.052145\n",
      "Epoch 575/750 - Train pg Loss: 2.657911 - Test Loss: 0.240440\n",
      "\n",
      "\n",
      "Epoch 576/750 - Train Cd Loss: 0.042388 - Test Loss: 0.048440\n",
      "Epoch 576/750 - Train pg Loss: 2.569854 - Test Loss: 0.600439\n",
      "\n",
      "\n",
      "Epoch 577/750 - Train Cd Loss: 0.044536 - Test Loss: 0.047668\n",
      "Epoch 577/750 - Train pg Loss: 3.049894 - Test Loss: 0.294259\n",
      "\n",
      "\n",
      "Epoch 578/750 - Train Cd Loss: 0.042812 - Test Loss: 0.044985\n",
      "Epoch 578/750 - Train pg Loss: 3.501366 - Test Loss: 0.329479\n",
      "\n",
      "\n",
      "Epoch 579/750 - Train Cd Loss: 0.054201 - Test Loss: 0.050365\n",
      "Epoch 579/750 - Train pg Loss: 3.311625 - Test Loss: 0.289177\n",
      "\n",
      "\n",
      "Epoch 580/750 - Train Cd Loss: 0.045244 - Test Loss: 0.046685\n",
      "Epoch 580/750 - Train pg Loss: 2.758232 - Test Loss: 0.293929\n",
      "\n",
      "\n",
      "Epoch 581/750 - Train Cd Loss: 0.044366 - Test Loss: 0.045312\n",
      "Epoch 581/750 - Train pg Loss: 2.538534 - Test Loss: 0.318455\n",
      "\n",
      "\n",
      "Epoch 582/750 - Train Cd Loss: 0.054457 - Test Loss: 0.049278\n",
      "Epoch 582/750 - Train pg Loss: 2.922326 - Test Loss: 0.321355\n",
      "\n",
      "\n",
      "Epoch 583/750 - Train Cd Loss: 0.039968 - Test Loss: 0.045498\n",
      "Epoch 583/750 - Train pg Loss: 2.214085 - Test Loss: 0.314924\n",
      "\n",
      "\n",
      "Epoch 584/750 - Train Cd Loss: 0.041459 - Test Loss: 0.049858\n",
      "Epoch 584/750 - Train pg Loss: 2.766628 - Test Loss: 0.276404\n",
      "\n",
      "\n",
      "Epoch 585/750 - Train Cd Loss: 0.040490 - Test Loss: 0.051076\n",
      "Epoch 585/750 - Train pg Loss: 2.067889 - Test Loss: 0.259602\n",
      "\n",
      "\n",
      "Epoch 586/750 - Train Cd Loss: 0.039125 - Test Loss: 0.046357\n",
      "Epoch 586/750 - Train pg Loss: 2.580310 - Test Loss: 0.284073\n",
      "\n",
      "\n",
      "Epoch 587/750 - Train Cd Loss: 0.041680 - Test Loss: 0.045669\n",
      "Epoch 587/750 - Train pg Loss: 2.626398 - Test Loss: 0.286259\n",
      "\n",
      "\n",
      "Epoch 588/750 - Train Cd Loss: 0.061532 - Test Loss: 0.049675\n",
      "Epoch 588/750 - Train pg Loss: 3.387537 - Test Loss: 0.335191\n",
      "\n",
      "\n",
      "Epoch 589/750 - Train Cd Loss: 0.039913 - Test Loss: 0.043282\n",
      "Epoch 589/750 - Train pg Loss: 2.790337 - Test Loss: 0.287751\n",
      "\n",
      "\n",
      "Epoch 590/750 - Train Cd Loss: 0.053016 - Test Loss: 0.046131\n",
      "Epoch 590/750 - Train pg Loss: 2.545278 - Test Loss: 0.394508\n",
      "\n",
      "\n",
      "Epoch 591/750 - Train Cd Loss: 0.043639 - Test Loss: 0.047083\n",
      "Epoch 591/750 - Train pg Loss: 2.272452 - Test Loss: 0.252079\n",
      "\n",
      "\n",
      "Epoch 592/750 - Train Cd Loss: 0.034357 - Test Loss: 0.044429\n",
      "Epoch 592/750 - Train pg Loss: 1.631647 - Test Loss: 0.326385\n",
      "\n",
      "\n",
      "Epoch 593/750 - Train Cd Loss: 0.040331 - Test Loss: 0.048885\n",
      "Epoch 593/750 - Train pg Loss: 3.082480 - Test Loss: 0.276217\n",
      "\n",
      "\n",
      "Epoch 594/750 - Train Cd Loss: 0.039333 - Test Loss: 0.047972\n",
      "Epoch 594/750 - Train pg Loss: 1.964061 - Test Loss: 0.313405\n",
      "\n",
      "\n",
      "Epoch 595/750 - Train Cd Loss: 0.047213 - Test Loss: 0.047195\n",
      "Epoch 595/750 - Train pg Loss: 3.361865 - Test Loss: 0.296186\n",
      "\n",
      "\n",
      "Epoch 596/750 - Train Cd Loss: 0.042893 - Test Loss: 0.049751\n",
      "Epoch 596/750 - Train pg Loss: 3.050655 - Test Loss: 0.270665\n",
      "\n",
      "\n",
      "Epoch 597/750 - Train Cd Loss: 0.046789 - Test Loss: 0.051874\n",
      "Epoch 597/750 - Train pg Loss: 2.726181 - Test Loss: 0.285308\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 598/750 - Train Cd Loss: 0.042890 - Test Loss: 0.048225\n",
      "Epoch 598/750 - Train pg Loss: 2.415554 - Test Loss: 0.300053\n",
      "\n",
      "\n",
      "Epoch 599/750 - Train Cd Loss: 0.039235 - Test Loss: 0.048152\n",
      "Epoch 599/750 - Train pg Loss: 2.544026 - Test Loss: 0.639617\n",
      "\n",
      "\n",
      "Epoch 600/750 - Train Cd Loss: 0.070725 - Test Loss: 0.044136\n",
      "Epoch 600/750 - Train pg Loss: 4.230341 - Test Loss: 0.774009\n",
      "\n",
      "\n",
      "Epoch 601/750 - Train Cd Loss: 0.044811 - Test Loss: 0.050562\n",
      "Epoch 601/750 - Train pg Loss: 2.078172 - Test Loss: 0.350037\n",
      "\n",
      "\n",
      "Epoch 602/750 - Train Cd Loss: 0.057827 - Test Loss: 0.048429\n",
      "Epoch 602/750 - Train pg Loss: 3.717182 - Test Loss: 0.298284\n",
      "\n",
      "\n",
      "Epoch 603/750 - Train Cd Loss: 0.043803 - Test Loss: 0.047028\n",
      "Epoch 603/750 - Train pg Loss: 3.413249 - Test Loss: 0.319276\n",
      "\n",
      "\n",
      "Epoch 604/750 - Train Cd Loss: 0.050756 - Test Loss: 0.045184\n",
      "Epoch 604/750 - Train pg Loss: 2.346412 - Test Loss: 0.344953\n",
      "\n",
      "\n",
      "Epoch 605/750 - Train Cd Loss: 0.058536 - Test Loss: 0.050298\n",
      "Epoch 605/750 - Train pg Loss: 4.369391 - Test Loss: 0.626486\n",
      "\n",
      "\n",
      "Epoch 606/750 - Train Cd Loss: 0.041809 - Test Loss: 0.048105\n",
      "Epoch 606/750 - Train pg Loss: 2.933273 - Test Loss: 0.533665\n",
      "\n",
      "\n",
      "Epoch 607/750 - Train Cd Loss: 0.049799 - Test Loss: 0.047635\n",
      "Epoch 607/750 - Train pg Loss: 3.775822 - Test Loss: 0.377961\n",
      "\n",
      "\n",
      "Epoch 608/750 - Train Cd Loss: 0.042483 - Test Loss: 0.047925\n",
      "Epoch 608/750 - Train pg Loss: 2.699527 - Test Loss: 0.393181\n",
      "\n",
      "\n",
      "Epoch 609/750 - Train Cd Loss: 0.050639 - Test Loss: 0.053313\n",
      "Epoch 609/750 - Train pg Loss: 2.807706 - Test Loss: 0.496257\n",
      "\n",
      "\n",
      "Epoch 610/750 - Train Cd Loss: 0.037248 - Test Loss: 0.050121\n",
      "Epoch 610/750 - Train pg Loss: 3.223696 - Test Loss: 0.473815\n",
      "\n",
      "\n",
      "Epoch 611/750 - Train Cd Loss: 0.034998 - Test Loss: 0.054626\n",
      "Epoch 611/750 - Train pg Loss: 1.949657 - Test Loss: 0.568855\n",
      "\n",
      "\n",
      "Epoch 612/750 - Train Cd Loss: 0.034678 - Test Loss: 0.046044\n",
      "Epoch 612/750 - Train pg Loss: 1.987521 - Test Loss: 0.642678\n",
      "\n",
      "\n",
      "Epoch 613/750 - Train Cd Loss: 0.069870 - Test Loss: 0.053979\n",
      "Epoch 613/750 - Train pg Loss: 4.063937 - Test Loss: 0.548801\n",
      "\n",
      "\n",
      "Epoch 614/750 - Train Cd Loss: 0.043517 - Test Loss: 0.046204\n",
      "Epoch 614/750 - Train pg Loss: 2.979728 - Test Loss: 0.316306\n",
      "\n",
      "\n",
      "Epoch 615/750 - Train Cd Loss: 0.041583 - Test Loss: 0.054155\n",
      "Epoch 615/750 - Train pg Loss: 2.420779 - Test Loss: 0.523387\n",
      "\n",
      "\n",
      "Epoch 616/750 - Train Cd Loss: 0.038777 - Test Loss: 0.049810\n",
      "Epoch 616/750 - Train pg Loss: 2.232109 - Test Loss: 0.313958\n",
      "\n",
      "\n",
      "Epoch 617/750 - Train Cd Loss: 0.036154 - Test Loss: 0.047784\n",
      "Epoch 617/750 - Train pg Loss: 1.938593 - Test Loss: 0.491716\n",
      "\n",
      "\n",
      "Epoch 618/750 - Train Cd Loss: 0.038761 - Test Loss: 0.047766\n",
      "Epoch 618/750 - Train pg Loss: 2.717717 - Test Loss: 0.810813\n",
      "\n",
      "\n",
      "Epoch 619/750 - Train Cd Loss: 0.050110 - Test Loss: 0.045555\n",
      "Epoch 619/750 - Train pg Loss: 2.522487 - Test Loss: 0.595637\n",
      "\n",
      "\n",
      "Epoch 620/750 - Train Cd Loss: 0.042642 - Test Loss: 0.047857\n",
      "Epoch 620/750 - Train pg Loss: 2.596694 - Test Loss: 0.538530\n",
      "\n",
      "\n",
      "Epoch 621/750 - Train Cd Loss: 0.054153 - Test Loss: 0.044932\n",
      "Epoch 621/750 - Train pg Loss: 4.213313 - Test Loss: 0.569895\n",
      "\n",
      "\n",
      "Epoch 622/750 - Train Cd Loss: 0.052942 - Test Loss: 0.047521\n",
      "Epoch 622/750 - Train pg Loss: 5.590260 - Test Loss: 0.721499\n",
      "\n",
      "\n",
      "Epoch 623/750 - Train Cd Loss: 0.046918 - Test Loss: 0.052896\n",
      "Epoch 623/750 - Train pg Loss: 2.691599 - Test Loss: 0.598563\n",
      "\n",
      "\n",
      "Epoch 624/750 - Train Cd Loss: 0.035946 - Test Loss: 0.049910\n",
      "Epoch 624/750 - Train pg Loss: 1.740434 - Test Loss: 0.642908\n",
      "\n",
      "\n",
      "Epoch 625/750 - Train Cd Loss: 0.054760 - Test Loss: 0.047405\n",
      "Epoch 625/750 - Train pg Loss: 4.429359 - Test Loss: 0.641765\n",
      "\n",
      "\n",
      "Epoch 626/750 - Train Cd Loss: 0.038856 - Test Loss: 0.050390\n",
      "Epoch 626/750 - Train pg Loss: 2.368796 - Test Loss: 0.577549\n",
      "\n",
      "\n",
      "Epoch 627/750 - Train Cd Loss: 0.044438 - Test Loss: 0.048846\n",
      "Epoch 627/750 - Train pg Loss: 2.425491 - Test Loss: 0.483392\n",
      "\n",
      "\n",
      "Epoch 628/750 - Train Cd Loss: 0.038925 - Test Loss: 0.050917\n",
      "Epoch 628/750 - Train pg Loss: 2.260928 - Test Loss: 0.661482\n",
      "\n",
      "\n",
      "Epoch 629/750 - Train Cd Loss: 0.034786 - Test Loss: 0.049199\n",
      "Epoch 629/750 - Train pg Loss: 2.691847 - Test Loss: 0.559255\n",
      "\n",
      "\n",
      "Epoch 630/750 - Train Cd Loss: 0.038218 - Test Loss: 0.046414\n",
      "Epoch 630/750 - Train pg Loss: 2.515486 - Test Loss: 0.644582\n",
      "\n",
      "\n",
      "Epoch 631/750 - Train Cd Loss: 0.034717 - Test Loss: 0.051501\n",
      "Epoch 631/750 - Train pg Loss: 3.319947 - Test Loss: 0.782612\n",
      "\n",
      "\n",
      "Epoch 632/750 - Train Cd Loss: 0.049165 - Test Loss: 0.045743\n",
      "Epoch 632/750 - Train pg Loss: 2.353070 - Test Loss: 0.589219\n",
      "\n",
      "\n",
      "Epoch 633/750 - Train Cd Loss: 0.042287 - Test Loss: 0.052127\n",
      "Epoch 633/750 - Train pg Loss: 4.482641 - Test Loss: 0.688336\n",
      "\n",
      "\n",
      "Epoch 634/750 - Train Cd Loss: 0.055993 - Test Loss: 0.048632\n",
      "Epoch 634/750 - Train pg Loss: 4.303195 - Test Loss: 0.583602\n",
      "\n",
      "\n",
      "Epoch 635/750 - Train Cd Loss: 0.038915 - Test Loss: 0.047779\n",
      "Epoch 635/750 - Train pg Loss: 2.506961 - Test Loss: 0.703800\n",
      "\n",
      "\n",
      "Epoch 636/750 - Train Cd Loss: 0.064443 - Test Loss: 0.058759\n",
      "Epoch 636/750 - Train pg Loss: 5.521627 - Test Loss: 0.501297\n",
      "\n",
      "\n",
      "Epoch 637/750 - Train Cd Loss: 0.034254 - Test Loss: 0.046244\n",
      "Epoch 637/750 - Train pg Loss: 2.945071 - Test Loss: 0.502462\n",
      "\n",
      "\n",
      "Epoch 638/750 - Train Cd Loss: 0.038272 - Test Loss: 0.049447\n",
      "Epoch 638/750 - Train pg Loss: 2.526586 - Test Loss: 0.501942\n",
      "\n",
      "\n",
      "Epoch 639/750 - Train Cd Loss: 0.051924 - Test Loss: 0.047022\n",
      "Epoch 639/750 - Train pg Loss: 3.638728 - Test Loss: 0.683794\n",
      "\n",
      "\n",
      "Epoch 640/750 - Train Cd Loss: 0.039038 - Test Loss: 0.052194\n",
      "Epoch 640/750 - Train pg Loss: 3.583226 - Test Loss: 0.442901\n",
      "\n",
      "\n",
      "Epoch 641/750 - Train Cd Loss: 0.028854 - Test Loss: 0.047252\n",
      "Epoch 641/750 - Train pg Loss: 2.109514 - Test Loss: 0.723034\n",
      "\n",
      "\n",
      "Epoch 642/750 - Train Cd Loss: 0.034101 - Test Loss: 0.050683\n",
      "Epoch 642/750 - Train pg Loss: 1.705606 - Test Loss: 0.635203\n",
      "\n",
      "\n",
      "Epoch 643/750 - Train Cd Loss: 0.038184 - Test Loss: 0.048134\n",
      "Epoch 643/750 - Train pg Loss: 4.180951 - Test Loss: 0.383984\n",
      "\n",
      "\n",
      "Epoch 644/750 - Train Cd Loss: 0.057263 - Test Loss: 0.044477\n",
      "Epoch 644/750 - Train pg Loss: 3.890748 - Test Loss: 0.733994\n",
      "\n",
      "\n",
      "Epoch 645/750 - Train Cd Loss: 0.053001 - Test Loss: 0.051805\n",
      "Epoch 645/750 - Train pg Loss: 3.773642 - Test Loss: 0.688464\n",
      "\n",
      "\n",
      "Epoch 646/750 - Train Cd Loss: 0.048179 - Test Loss: 0.047005\n",
      "Epoch 646/750 - Train pg Loss: 4.060637 - Test Loss: 0.756328\n",
      "\n",
      "\n",
      "Epoch 647/750 - Train Cd Loss: 0.043239 - Test Loss: 0.054985\n",
      "Epoch 647/750 - Train pg Loss: 3.464034 - Test Loss: 0.552879\n",
      "\n",
      "\n",
      "Epoch 648/750 - Train Cd Loss: 0.050762 - Test Loss: 0.051110\n",
      "Epoch 648/750 - Train pg Loss: 3.599902 - Test Loss: 0.813255\n",
      "\n",
      "\n",
      "Epoch 649/750 - Train Cd Loss: 0.031409 - Test Loss: 0.048595\n",
      "Epoch 649/750 - Train pg Loss: 2.712520 - Test Loss: 0.633624\n",
      "\n",
      "\n",
      "Epoch 650/750 - Train Cd Loss: 0.032880 - Test Loss: 0.049471\n",
      "Epoch 650/750 - Train pg Loss: 2.318751 - Test Loss: 0.592842\n",
      "\n",
      "\n",
      "Epoch 651/750 - Train Cd Loss: 0.087062 - Test Loss: 0.053240\n",
      "Epoch 651/750 - Train pg Loss: 4.967845 - Test Loss: 0.621065\n",
      "\n",
      "\n",
      "Epoch 652/750 - Train Cd Loss: 0.034872 - Test Loss: 0.051099\n",
      "Epoch 652/750 - Train pg Loss: 2.654111 - Test Loss: 0.515259\n",
      "\n",
      "\n",
      "Epoch 653/750 - Train Cd Loss: 0.048141 - Test Loss: 0.053223\n",
      "Epoch 653/750 - Train pg Loss: 3.870304 - Test Loss: 0.529435\n",
      "\n",
      "\n",
      "Epoch 654/750 - Train Cd Loss: 0.043091 - Test Loss: 0.054736\n",
      "Epoch 654/750 - Train pg Loss: 3.393898 - Test Loss: 0.521703\n",
      "\n",
      "\n",
      "Epoch 655/750 - Train Cd Loss: 0.034828 - Test Loss: 0.046854\n",
      "Epoch 655/750 - Train pg Loss: 3.190728 - Test Loss: 0.569404\n",
      "\n",
      "\n",
      "Epoch 656/750 - Train Cd Loss: 0.043175 - Test Loss: 0.051695\n",
      "Epoch 656/750 - Train pg Loss: 2.792846 - Test Loss: 0.739193\n",
      "\n",
      "\n",
      "Epoch 657/750 - Train Cd Loss: 0.055170 - Test Loss: 0.053226\n",
      "Epoch 657/750 - Train pg Loss: 3.362011 - Test Loss: 0.608648\n",
      "\n",
      "\n",
      "Epoch 658/750 - Train Cd Loss: 0.034601 - Test Loss: 0.046911\n",
      "Epoch 658/750 - Train pg Loss: 3.136542 - Test Loss: 1.016207\n",
      "\n",
      "\n",
      "Epoch 659/750 - Train Cd Loss: 0.037350 - Test Loss: 0.050815\n",
      "Epoch 659/750 - Train pg Loss: 2.366125 - Test Loss: 0.606318\n",
      "\n",
      "\n",
      "Epoch 660/750 - Train Cd Loss: 0.033139 - Test Loss: 0.052148\n",
      "Epoch 660/750 - Train pg Loss: 2.690561 - Test Loss: 0.649649\n",
      "\n",
      "\n",
      "Epoch 661/750 - Train Cd Loss: 0.033643 - Test Loss: 0.047170\n",
      "Epoch 661/750 - Train pg Loss: 2.918561 - Test Loss: 0.741093\n",
      "\n",
      "\n",
      "Epoch 662/750 - Train Cd Loss: 0.053791 - Test Loss: 0.049077\n",
      "Epoch 662/750 - Train pg Loss: 4.701241 - Test Loss: 0.744185\n",
      "\n",
      "\n",
      "Epoch 663/750 - Train Cd Loss: 0.050617 - Test Loss: 0.052300\n",
      "Epoch 663/750 - Train pg Loss: 4.132157 - Test Loss: 0.583287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 664/750 - Train Cd Loss: 0.033998 - Test Loss: 0.053788\n",
      "Epoch 664/750 - Train pg Loss: 3.529382 - Test Loss: 0.675835\n",
      "\n",
      "\n",
      "Epoch 665/750 - Train Cd Loss: 0.055839 - Test Loss: 0.054728\n",
      "Epoch 665/750 - Train pg Loss: 3.772229 - Test Loss: 0.485604\n",
      "\n",
      "\n",
      "Epoch 666/750 - Train Cd Loss: 0.079395 - Test Loss: 0.047001\n",
      "Epoch 666/750 - Train pg Loss: 5.135520 - Test Loss: 0.588945\n",
      "\n",
      "\n",
      "Epoch 667/750 - Train Cd Loss: 0.037473 - Test Loss: 0.050801\n",
      "Epoch 667/750 - Train pg Loss: 2.644169 - Test Loss: 0.509993\n",
      "\n",
      "\n",
      "Epoch 668/750 - Train Cd Loss: 0.036555 - Test Loss: 0.046835\n",
      "Epoch 668/750 - Train pg Loss: 2.477569 - Test Loss: 0.600012\n",
      "\n",
      "\n",
      "Epoch 669/750 - Train Cd Loss: 0.038127 - Test Loss: 0.051041\n",
      "Epoch 669/750 - Train pg Loss: 2.762889 - Test Loss: 0.724048\n",
      "\n",
      "\n",
      "Epoch 670/750 - Train Cd Loss: 0.035729 - Test Loss: 0.051867\n",
      "Epoch 670/750 - Train pg Loss: 1.664447 - Test Loss: 0.685532\n",
      "\n",
      "\n",
      "Epoch 671/750 - Train Cd Loss: 0.049106 - Test Loss: 0.053695\n",
      "Epoch 671/750 - Train pg Loss: 4.125805 - Test Loss: 0.398539\n",
      "\n",
      "\n",
      "Epoch 672/750 - Train Cd Loss: 0.032116 - Test Loss: 0.048534\n",
      "Epoch 672/750 - Train pg Loss: 2.571982 - Test Loss: 0.524134\n",
      "\n",
      "\n",
      "Epoch 673/750 - Train Cd Loss: 0.034769 - Test Loss: 0.049239\n",
      "Epoch 673/750 - Train pg Loss: 2.729778 - Test Loss: 0.741691\n",
      "\n",
      "\n",
      "Epoch 674/750 - Train Cd Loss: 0.032058 - Test Loss: 0.051478\n",
      "Epoch 674/750 - Train pg Loss: 3.369743 - Test Loss: 0.424483\n",
      "\n",
      "\n",
      "Epoch 675/750 - Train Cd Loss: 0.043270 - Test Loss: 0.049696\n",
      "Epoch 675/750 - Train pg Loss: 4.120384 - Test Loss: 0.492600\n",
      "\n",
      "\n",
      "Epoch 676/750 - Train Cd Loss: 0.031468 - Test Loss: 0.048694\n",
      "Epoch 676/750 - Train pg Loss: 3.878860 - Test Loss: 0.495878\n",
      "\n",
      "\n",
      "Epoch 677/750 - Train Cd Loss: 0.039434 - Test Loss: 0.056248\n",
      "Epoch 677/750 - Train pg Loss: 3.257458 - Test Loss: 0.766786\n",
      "\n",
      "\n",
      "Epoch 678/750 - Train Cd Loss: 0.029046 - Test Loss: 0.048632\n",
      "Epoch 678/750 - Train pg Loss: 2.914459 - Test Loss: 0.331537\n",
      "\n",
      "\n",
      "Epoch 679/750 - Train Cd Loss: 0.033430 - Test Loss: 0.052653\n",
      "Epoch 679/750 - Train pg Loss: 2.253548 - Test Loss: 0.643933\n",
      "\n",
      "\n",
      "Epoch 680/750 - Train Cd Loss: 0.042420 - Test Loss: 0.048043\n",
      "Epoch 680/750 - Train pg Loss: 3.560746 - Test Loss: 0.571768\n",
      "\n",
      "\n",
      "Epoch 681/750 - Train Cd Loss: 0.049727 - Test Loss: 0.052002\n",
      "Epoch 681/750 - Train pg Loss: 3.812195 - Test Loss: 0.665667\n",
      "\n",
      "\n",
      "Epoch 682/750 - Train Cd Loss: 0.055485 - Test Loss: 0.051012\n",
      "Epoch 682/750 - Train pg Loss: 6.194613 - Test Loss: 0.542969\n",
      "\n",
      "\n",
      "Epoch 683/750 - Train Cd Loss: 0.037565 - Test Loss: 0.046205\n",
      "Epoch 683/750 - Train pg Loss: 2.751613 - Test Loss: 0.860485\n",
      "\n",
      "\n",
      "Epoch 684/750 - Train Cd Loss: 0.038248 - Test Loss: 0.055261\n",
      "Epoch 684/750 - Train pg Loss: 3.236817 - Test Loss: 0.774478\n",
      "\n",
      "\n",
      "Epoch 685/750 - Train Cd Loss: 0.034432 - Test Loss: 0.049016\n",
      "Epoch 685/750 - Train pg Loss: 3.713266 - Test Loss: 0.761240\n",
      "\n",
      "\n",
      "Epoch 686/750 - Train Cd Loss: 0.044927 - Test Loss: 0.052465\n",
      "Epoch 686/750 - Train pg Loss: 3.949857 - Test Loss: 0.686309\n",
      "\n",
      "\n",
      "Epoch 687/750 - Train Cd Loss: 0.029533 - Test Loss: 0.049354\n",
      "Epoch 687/750 - Train pg Loss: 3.424989 - Test Loss: 0.645432\n",
      "\n",
      "\n",
      "Epoch 688/750 - Train Cd Loss: 0.049252 - Test Loss: 0.052944\n",
      "Epoch 688/750 - Train pg Loss: 2.964457 - Test Loss: 0.493547\n",
      "\n",
      "\n",
      "Epoch 689/750 - Train Cd Loss: 0.037718 - Test Loss: 0.048870\n",
      "Epoch 689/750 - Train pg Loss: 3.059238 - Test Loss: 0.681599\n",
      "\n",
      "\n",
      "Epoch 690/750 - Train Cd Loss: 0.032938 - Test Loss: 0.050439\n",
      "Epoch 690/750 - Train pg Loss: 2.078932 - Test Loss: 0.602692\n",
      "\n",
      "\n",
      "Epoch 691/750 - Train Cd Loss: 0.051933 - Test Loss: 0.053251\n",
      "Epoch 691/750 - Train pg Loss: 3.240308 - Test Loss: 0.709463\n",
      "\n",
      "\n",
      "Epoch 692/750 - Train Cd Loss: 0.031797 - Test Loss: 0.053976\n",
      "Epoch 692/750 - Train pg Loss: 2.625429 - Test Loss: 0.587864\n",
      "\n",
      "\n",
      "Epoch 693/750 - Train Cd Loss: 0.035275 - Test Loss: 0.048328\n",
      "Epoch 693/750 - Train pg Loss: 2.739351 - Test Loss: 0.740166\n",
      "\n",
      "\n",
      "Epoch 694/750 - Train Cd Loss: 0.060446 - Test Loss: 0.051193\n",
      "Epoch 694/750 - Train pg Loss: 4.618923 - Test Loss: 0.723125\n",
      "\n",
      "\n",
      "Epoch 695/750 - Train Cd Loss: 0.038192 - Test Loss: 0.050563\n",
      "Epoch 695/750 - Train pg Loss: 3.570680 - Test Loss: 0.705855\n",
      "\n",
      "\n",
      "Epoch 696/750 - Train Cd Loss: 0.029579 - Test Loss: 0.051342\n",
      "Epoch 696/750 - Train pg Loss: 3.120084 - Test Loss: 0.603566\n",
      "\n",
      "\n",
      "Epoch 697/750 - Train Cd Loss: 0.046643 - Test Loss: 0.053842\n",
      "Epoch 697/750 - Train pg Loss: 3.354890 - Test Loss: 0.709787\n",
      "\n",
      "\n",
      "Epoch 698/750 - Train Cd Loss: 0.039692 - Test Loss: 0.049057\n",
      "Epoch 698/750 - Train pg Loss: 2.351962 - Test Loss: 0.767855\n",
      "\n",
      "\n",
      "Epoch 699/750 - Train Cd Loss: 0.035810 - Test Loss: 0.055028\n",
      "Epoch 699/750 - Train pg Loss: 2.308350 - Test Loss: 0.768008\n",
      "\n",
      "\n",
      "Epoch 700/750 - Train Cd Loss: 0.034753 - Test Loss: 0.048057\n",
      "Epoch 700/750 - Train pg Loss: 2.067117 - Test Loss: 0.652387\n",
      "\n",
      "\n",
      "Epoch 701/750 - Train Cd Loss: 0.057663 - Test Loss: 0.051425\n",
      "Epoch 701/750 - Train pg Loss: 3.634011 - Test Loss: 0.766848\n",
      "\n",
      "\n",
      "Epoch 702/750 - Train Cd Loss: 0.047610 - Test Loss: 0.051062\n",
      "Epoch 702/750 - Train pg Loss: 3.039531 - Test Loss: 0.683475\n",
      "\n",
      "\n",
      "Epoch 703/750 - Train Cd Loss: 0.036085 - Test Loss: 0.049110\n",
      "Epoch 703/750 - Train pg Loss: 2.767292 - Test Loss: 0.709729\n",
      "\n",
      "\n",
      "Epoch 704/750 - Train Cd Loss: 0.032057 - Test Loss: 0.056178\n",
      "Epoch 704/750 - Train pg Loss: 2.491249 - Test Loss: 0.420977\n",
      "\n",
      "\n",
      "Epoch 705/750 - Train Cd Loss: 0.028135 - Test Loss: 0.048844\n",
      "Epoch 705/750 - Train pg Loss: 2.809730 - Test Loss: 0.829123\n",
      "\n",
      "\n",
      "Epoch 706/750 - Train Cd Loss: 0.032091 - Test Loss: 0.059433\n",
      "Epoch 706/750 - Train pg Loss: 2.997547 - Test Loss: 0.647019\n",
      "\n",
      "\n",
      "Epoch 707/750 - Train Cd Loss: 0.067818 - Test Loss: 0.047448\n",
      "Epoch 707/750 - Train pg Loss: 4.495552 - Test Loss: 0.492458\n",
      "\n",
      "\n",
      "Epoch 708/750 - Train Cd Loss: 0.044751 - Test Loss: 0.054613\n",
      "Epoch 708/750 - Train pg Loss: 3.404461 - Test Loss: 0.782170\n",
      "\n",
      "\n",
      "Epoch 709/750 - Train Cd Loss: 0.033360 - Test Loss: 0.057968\n",
      "Epoch 709/750 - Train pg Loss: 4.100815 - Test Loss: 0.712315\n",
      "\n",
      "\n",
      "Epoch 710/750 - Train Cd Loss: 0.026299 - Test Loss: 0.052734\n",
      "Epoch 710/750 - Train pg Loss: 2.659723 - Test Loss: 0.669037\n",
      "\n",
      "\n",
      "Epoch 711/750 - Train Cd Loss: 0.057351 - Test Loss: 0.056023\n",
      "Epoch 711/750 - Train pg Loss: 5.519922 - Test Loss: 0.759199\n",
      "\n",
      "\n",
      "Epoch 712/750 - Train Cd Loss: 0.030832 - Test Loss: 0.050552\n",
      "Epoch 712/750 - Train pg Loss: 2.473309 - Test Loss: 0.482573\n",
      "\n",
      "\n",
      "Epoch 713/750 - Train Cd Loss: 0.025578 - Test Loss: 0.050057\n",
      "Epoch 713/750 - Train pg Loss: 2.328893 - Test Loss: 0.510637\n",
      "\n",
      "\n",
      "Epoch 714/750 - Train Cd Loss: 0.046423 - Test Loss: 0.058604\n",
      "Epoch 714/750 - Train pg Loss: 3.330773 - Test Loss: 0.901436\n",
      "\n",
      "\n",
      "Epoch 715/750 - Train Cd Loss: 0.038065 - Test Loss: 0.051261\n",
      "Epoch 715/750 - Train pg Loss: 3.873909 - Test Loss: 0.633476\n",
      "\n",
      "\n",
      "Epoch 716/750 - Train Cd Loss: 0.031893 - Test Loss: 0.051606\n",
      "Epoch 716/750 - Train pg Loss: 4.493766 - Test Loss: 0.677549\n",
      "\n",
      "\n",
      "Epoch 717/750 - Train Cd Loss: 0.041224 - Test Loss: 0.052449\n",
      "Epoch 717/750 - Train pg Loss: 2.689579 - Test Loss: 0.784211\n",
      "\n",
      "\n",
      "Epoch 718/750 - Train Cd Loss: 0.030324 - Test Loss: 0.053660\n",
      "Epoch 718/750 - Train pg Loss: 3.107717 - Test Loss: 0.638116\n",
      "\n",
      "\n",
      "Epoch 719/750 - Train Cd Loss: 0.049272 - Test Loss: 0.050146\n",
      "Epoch 719/750 - Train pg Loss: 5.370809 - Test Loss: 0.521388\n",
      "\n",
      "\n",
      "Epoch 720/750 - Train Cd Loss: 0.040226 - Test Loss: 0.053892\n",
      "Epoch 720/750 - Train pg Loss: 2.577597 - Test Loss: 0.774434\n",
      "\n",
      "\n",
      "Epoch 721/750 - Train Cd Loss: 0.028861 - Test Loss: 0.058604\n",
      "Epoch 721/750 - Train pg Loss: 2.273466 - Test Loss: 0.804031\n",
      "\n",
      "\n",
      "Epoch 722/750 - Train Cd Loss: 0.025449 - Test Loss: 0.052597\n",
      "Epoch 722/750 - Train pg Loss: 2.903466 - Test Loss: 0.782259\n",
      "\n",
      "\n",
      "Epoch 723/750 - Train Cd Loss: 0.040212 - Test Loss: 0.053187\n",
      "Epoch 723/750 - Train pg Loss: 4.255272 - Test Loss: 0.628998\n",
      "\n",
      "\n",
      "Epoch 724/750 - Train Cd Loss: 0.030868 - Test Loss: 0.059394\n",
      "Epoch 724/750 - Train pg Loss: 3.355471 - Test Loss: 0.849395\n",
      "\n",
      "\n",
      "Epoch 725/750 - Train Cd Loss: 0.045938 - Test Loss: 0.052913\n",
      "Epoch 725/750 - Train pg Loss: 4.071362 - Test Loss: 0.540091\n",
      "\n",
      "\n",
      "Epoch 726/750 - Train Cd Loss: 0.029130 - Test Loss: 0.051169\n",
      "Epoch 726/750 - Train pg Loss: 1.934106 - Test Loss: 0.768084\n",
      "\n",
      "\n",
      "Epoch 727/750 - Train Cd Loss: 0.044317 - Test Loss: 0.049467\n",
      "Epoch 727/750 - Train pg Loss: 4.974873 - Test Loss: 0.622333\n",
      "\n",
      "\n",
      "Epoch 728/750 - Train Cd Loss: 0.031274 - Test Loss: 0.054150\n",
      "Epoch 728/750 - Train pg Loss: 2.622728 - Test Loss: 0.534739\n",
      "\n",
      "\n",
      "Epoch 729/750 - Train Cd Loss: 0.027289 - Test Loss: 0.050368\n",
      "Epoch 729/750 - Train pg Loss: 2.360319 - Test Loss: 0.792009\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 730/750 - Train Cd Loss: 0.046659 - Test Loss: 0.053382\n",
      "Epoch 730/750 - Train pg Loss: 4.195514 - Test Loss: 0.816896\n",
      "\n",
      "\n",
      "Epoch 731/750 - Train Cd Loss: 0.029257 - Test Loss: 0.054832\n",
      "Epoch 731/750 - Train pg Loss: 2.181449 - Test Loss: 0.757171\n",
      "\n",
      "\n",
      "Epoch 732/750 - Train Cd Loss: 0.044928 - Test Loss: 0.049629\n",
      "Epoch 732/750 - Train pg Loss: 4.410928 - Test Loss: 0.667739\n",
      "\n",
      "\n",
      "Epoch 733/750 - Train Cd Loss: 0.029904 - Test Loss: 0.058078\n",
      "Epoch 733/750 - Train pg Loss: 3.876305 - Test Loss: 0.772529\n",
      "\n",
      "\n",
      "Epoch 734/750 - Train Cd Loss: 0.036197 - Test Loss: 0.051736\n",
      "Epoch 734/750 - Train pg Loss: 3.292682 - Test Loss: 0.432570\n",
      "\n",
      "\n",
      "Epoch 735/750 - Train Cd Loss: 0.025682 - Test Loss: 0.052110\n",
      "Epoch 735/750 - Train pg Loss: 2.068331 - Test Loss: 0.489613\n",
      "\n",
      "\n",
      "Epoch 736/750 - Train Cd Loss: 0.028281 - Test Loss: 0.058500\n",
      "Epoch 736/750 - Train pg Loss: 3.356818 - Test Loss: 0.569534\n",
      "\n",
      "\n",
      "Epoch 737/750 - Train Cd Loss: 0.044393 - Test Loss: 0.063535\n",
      "Epoch 737/750 - Train pg Loss: 4.148399 - Test Loss: 0.605438\n",
      "\n",
      "\n",
      "Epoch 738/750 - Train Cd Loss: 0.028375 - Test Loss: 0.050094\n",
      "Epoch 738/750 - Train pg Loss: 2.112103 - Test Loss: 0.781510\n",
      "\n",
      "\n",
      "Epoch 739/750 - Train Cd Loss: 0.041742 - Test Loss: 0.053615\n",
      "Epoch 739/750 - Train pg Loss: 3.544744 - Test Loss: 0.611588\n",
      "\n",
      "\n",
      "Epoch 740/750 - Train Cd Loss: 0.030529 - Test Loss: 0.055630\n",
      "Epoch 740/750 - Train pg Loss: 3.141028 - Test Loss: 0.738926\n",
      "\n",
      "\n",
      "Epoch 741/750 - Train Cd Loss: 0.040168 - Test Loss: 0.055459\n",
      "Epoch 741/750 - Train pg Loss: 3.605598 - Test Loss: 0.545230\n",
      "\n",
      "\n",
      "Epoch 742/750 - Train Cd Loss: 0.031318 - Test Loss: 0.048392\n",
      "Epoch 742/750 - Train pg Loss: 2.091976 - Test Loss: 0.745139\n",
      "\n",
      "\n",
      "Epoch 743/750 - Train Cd Loss: 0.050498 - Test Loss: 0.050031\n",
      "Epoch 743/750 - Train pg Loss: 2.997206 - Test Loss: 0.748235\n",
      "\n",
      "\n",
      "Epoch 744/750 - Train Cd Loss: 0.044265 - Test Loss: 0.055080\n",
      "Epoch 744/750 - Train pg Loss: 3.596058 - Test Loss: 0.672165\n",
      "\n",
      "\n",
      "Epoch 745/750 - Train Cd Loss: 0.032050 - Test Loss: 0.051107\n",
      "Epoch 745/750 - Train pg Loss: 2.464361 - Test Loss: 0.757320\n",
      "\n",
      "\n",
      "Epoch 746/750 - Train Cd Loss: 0.025592 - Test Loss: 0.048603\n",
      "Epoch 746/750 - Train pg Loss: 2.152597 - Test Loss: 0.711592\n",
      "\n",
      "\n",
      "Epoch 747/750 - Train Cd Loss: 0.030240 - Test Loss: 0.058942\n",
      "Epoch 747/750 - Train pg Loss: 1.736090 - Test Loss: 0.684000\n",
      "\n",
      "\n",
      "Epoch 748/750 - Train Cd Loss: 0.041005 - Test Loss: 0.053145\n",
      "Epoch 748/750 - Train pg Loss: 3.605113 - Test Loss: 0.715812\n",
      "\n",
      "\n",
      "Epoch 749/750 - Train Cd Loss: 0.028381 - Test Loss: 0.059055\n",
      "Epoch 749/750 - Train pg Loss: 2.652689 - Test Loss: 0.617006\n",
      "\n",
      "\n",
      "Epoch 750/750 - Train Cd Loss: 0.044058 - Test Loss: 0.051992\n",
      "Epoch 750/750 - Train pg Loss: 4.869698 - Test Loss: 0.524284\n",
      "\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch 1/750 - Train Cd Loss: 0.152230 - Test Loss: 0.050404\n",
      "Epoch 1/750 - Train pg Loss: 4.520742 - Test Loss: 1.102157\n",
      "\n",
      "\n",
      "Epoch 2/750 - Train Cd Loss: 0.151512 - Test Loss: 0.050262\n",
      "Epoch 2/750 - Train pg Loss: 4.393247 - Test Loss: 1.072707\n",
      "\n",
      "\n",
      "Epoch 3/750 - Train Cd Loss: 0.150947 - Test Loss: 0.050107\n",
      "Epoch 3/750 - Train pg Loss: 4.341765 - Test Loss: 1.059687\n",
      "\n",
      "\n",
      "Epoch 4/750 - Train Cd Loss: 0.150435 - Test Loss: 0.050068\n",
      "Epoch 4/750 - Train pg Loss: 4.277102 - Test Loss: 1.052597\n",
      "\n",
      "\n",
      "Epoch 5/750 - Train Cd Loss: 0.150067 - Test Loss: 0.050015\n",
      "Epoch 5/750 - Train pg Loss: 4.210306 - Test Loss: 1.032756\n",
      "\n",
      "\n",
      "Epoch 6/750 - Train Cd Loss: 0.149993 - Test Loss: 0.049878\n",
      "Epoch 6/750 - Train pg Loss: 4.151177 - Test Loss: 1.017287\n",
      "\n",
      "\n",
      "Epoch 7/750 - Train Cd Loss: 0.149630 - Test Loss: 0.049954\n",
      "Epoch 7/750 - Train pg Loss: 4.094338 - Test Loss: 0.999303\n",
      "\n",
      "\n",
      "Epoch 8/750 - Train Cd Loss: 0.149508 - Test Loss: 0.049611\n",
      "Epoch 8/750 - Train pg Loss: 4.091646 - Test Loss: 1.007041\n",
      "\n",
      "\n",
      "Epoch 9/750 - Train Cd Loss: 0.148434 - Test Loss: 0.050058\n",
      "Epoch 9/750 - Train pg Loss: 4.040270 - Test Loss: 0.981153\n",
      "\n",
      "\n",
      "Epoch 10/750 - Train Cd Loss: 0.150022 - Test Loss: 0.049659\n",
      "Epoch 10/750 - Train pg Loss: 3.952824 - Test Loss: 0.966790\n",
      "\n",
      "\n",
      "Epoch 11/750 - Train Cd Loss: 0.149076 - Test Loss: 0.050141\n",
      "Epoch 11/750 - Train pg Loss: 3.923852 - Test Loss: 0.960383\n",
      "\n",
      "\n",
      "Epoch 12/750 - Train Cd Loss: 0.149912 - Test Loss: 0.050100\n",
      "Epoch 12/750 - Train pg Loss: 3.915891 - Test Loss: 0.968700\n",
      "\n",
      "\n",
      "Epoch 13/750 - Train Cd Loss: 0.149814 - Test Loss: 0.050182\n",
      "Epoch 13/750 - Train pg Loss: 3.970859 - Test Loss: 0.978601\n",
      "\n",
      "\n",
      "Epoch 14/750 - Train Cd Loss: 0.148770 - Test Loss: 0.049971\n",
      "Epoch 14/750 - Train pg Loss: 4.019016 - Test Loss: 0.985833\n",
      "\n",
      "\n",
      "Epoch 15/750 - Train Cd Loss: 0.148794 - Test Loss: 0.049897\n",
      "Epoch 15/750 - Train pg Loss: 3.989845 - Test Loss: 0.971581\n",
      "\n",
      "\n",
      "Epoch 16/750 - Train Cd Loss: 0.149483 - Test Loss: 0.050214\n",
      "Epoch 16/750 - Train pg Loss: 3.946674 - Test Loss: 0.970004\n",
      "\n",
      "\n",
      "Epoch 17/750 - Train Cd Loss: 0.148378 - Test Loss: 0.049687\n",
      "Epoch 17/750 - Train pg Loss: 3.939408 - Test Loss: 0.976185\n",
      "\n",
      "\n",
      "Epoch 18/750 - Train Cd Loss: 0.149705 - Test Loss: 0.049851\n",
      "Epoch 18/750 - Train pg Loss: 3.938307 - Test Loss: 0.967121\n",
      "\n",
      "\n",
      "Epoch 19/750 - Train Cd Loss: 0.149623 - Test Loss: 0.050145\n",
      "Epoch 19/750 - Train pg Loss: 3.972625 - Test Loss: 0.979814\n",
      "\n",
      "\n",
      "Epoch 20/750 - Train Cd Loss: 0.149175 - Test Loss: 0.050175\n",
      "Epoch 20/750 - Train pg Loss: 4.037843 - Test Loss: 0.983810\n",
      "\n",
      "\n",
      "Epoch 21/750 - Train Cd Loss: 0.148846 - Test Loss: 0.049950\n",
      "Epoch 21/750 - Train pg Loss: 4.000317 - Test Loss: 0.985228\n",
      "\n",
      "\n",
      "Epoch 22/750 - Train Cd Loss: 0.148959 - Test Loss: 0.050069\n",
      "Epoch 22/750 - Train pg Loss: 3.978083 - Test Loss: 0.987133\n",
      "\n",
      "\n",
      "Epoch 23/750 - Train Cd Loss: 0.149501 - Test Loss: 0.049651\n",
      "Epoch 23/750 - Train pg Loss: 4.043218 - Test Loss: 0.986197\n",
      "\n",
      "\n",
      "Epoch 24/750 - Train Cd Loss: 0.150574 - Test Loss: 0.049789\n",
      "Epoch 24/750 - Train pg Loss: 4.023356 - Test Loss: 0.997532\n",
      "\n",
      "\n",
      "Epoch 25/750 - Train Cd Loss: 0.148503 - Test Loss: 0.049903\n",
      "Epoch 25/750 - Train pg Loss: 4.062632 - Test Loss: 0.995542\n",
      "\n",
      "\n",
      "Epoch 26/750 - Train Cd Loss: 0.147944 - Test Loss: 0.049696\n",
      "Epoch 26/750 - Train pg Loss: 4.042507 - Test Loss: 0.996030\n",
      "\n",
      "\n",
      "Epoch 27/750 - Train Cd Loss: 0.148945 - Test Loss: 0.050616\n",
      "Epoch 27/750 - Train pg Loss: 4.002851 - Test Loss: 0.991852\n",
      "\n",
      "\n",
      "Epoch 28/750 - Train Cd Loss: 0.150657 - Test Loss: 0.050369\n",
      "Epoch 28/750 - Train pg Loss: 4.056500 - Test Loss: 0.992783\n",
      "\n",
      "\n",
      "Epoch 29/750 - Train Cd Loss: 0.148541 - Test Loss: 0.050331\n",
      "Epoch 29/750 - Train pg Loss: 3.985687 - Test Loss: 0.980046\n",
      "\n",
      "\n",
      "Epoch 30/750 - Train Cd Loss: 0.146354 - Test Loss: 0.050371\n",
      "Epoch 30/750 - Train pg Loss: 3.963761 - Test Loss: 0.984296\n",
      "\n",
      "\n",
      "Epoch 31/750 - Train Cd Loss: 0.147095 - Test Loss: 0.049721\n",
      "Epoch 31/750 - Train pg Loss: 4.020874 - Test Loss: 0.988738\n",
      "\n",
      "\n",
      "Epoch 32/750 - Train Cd Loss: 0.146921 - Test Loss: 0.048930\n",
      "Epoch 32/750 - Train pg Loss: 4.003065 - Test Loss: 0.984241\n",
      "\n",
      "\n",
      "Epoch 33/750 - Train Cd Loss: 0.149174 - Test Loss: 0.050243\n",
      "Epoch 33/750 - Train pg Loss: 4.009438 - Test Loss: 0.988352\n",
      "\n",
      "\n",
      "Epoch 34/750 - Train Cd Loss: 0.147640 - Test Loss: 0.050624\n",
      "Epoch 34/750 - Train pg Loss: 4.019780 - Test Loss: 0.986903\n",
      "\n",
      "\n",
      "Epoch 35/750 - Train Cd Loss: 0.147731 - Test Loss: 0.049958\n",
      "Epoch 35/750 - Train pg Loss: 4.029852 - Test Loss: 0.978687\n",
      "\n",
      "\n",
      "Epoch 36/750 - Train Cd Loss: 0.148818 - Test Loss: 0.049771\n",
      "Epoch 36/750 - Train pg Loss: 4.024739 - Test Loss: 1.004317\n",
      "\n",
      "\n",
      "Epoch 37/750 - Train Cd Loss: 0.150598 - Test Loss: 0.049781\n",
      "Epoch 37/750 - Train pg Loss: 4.066830 - Test Loss: 1.004936\n",
      "\n",
      "\n",
      "Epoch 38/750 - Train Cd Loss: 0.148858 - Test Loss: 0.049988\n",
      "Epoch 38/750 - Train pg Loss: 4.144770 - Test Loss: 1.013773\n",
      "\n",
      "\n",
      "Epoch 39/750 - Train Cd Loss: 0.150247 - Test Loss: 0.049970\n",
      "Epoch 39/750 - Train pg Loss: 4.205982 - Test Loss: 1.039849\n",
      "\n",
      "\n",
      "Epoch 40/750 - Train Cd Loss: 0.148640 - Test Loss: 0.050057\n",
      "Epoch 40/750 - Train pg Loss: 4.191602 - Test Loss: 1.023690\n",
      "\n",
      "\n",
      "Epoch 41/750 - Train Cd Loss: 0.146997 - Test Loss: 0.050241\n",
      "Epoch 41/750 - Train pg Loss: 4.101241 - Test Loss: 0.998743\n",
      "\n",
      "\n",
      "Epoch 42/750 - Train Cd Loss: 0.148420 - Test Loss: 0.050441\n",
      "Epoch 42/750 - Train pg Loss: 4.072372 - Test Loss: 1.001957\n",
      "\n",
      "\n",
      "Epoch 43/750 - Train Cd Loss: 0.147085 - Test Loss: 0.050219\n",
      "Epoch 43/750 - Train pg Loss: 4.074051 - Test Loss: 0.992759\n",
      "\n",
      "\n",
      "Epoch 44/750 - Train Cd Loss: 0.148263 - Test Loss: 0.050198\n",
      "Epoch 44/750 - Train pg Loss: 4.091415 - Test Loss: 1.030083\n",
      "\n",
      "\n",
      "Epoch 45/750 - Train Cd Loss: 0.149590 - Test Loss: 0.050113\n",
      "Epoch 45/750 - Train pg Loss: 4.156577 - Test Loss: 1.025824\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/750 - Train Cd Loss: 0.148195 - Test Loss: 0.050395\n",
      "Epoch 46/750 - Train pg Loss: 4.166637 - Test Loss: 1.019253\n",
      "\n",
      "\n",
      "Epoch 47/750 - Train Cd Loss: 0.146474 - Test Loss: 0.050983\n",
      "Epoch 47/750 - Train pg Loss: 4.149743 - Test Loss: 1.039316\n",
      "\n",
      "\n",
      "Epoch 48/750 - Train Cd Loss: 0.147427 - Test Loss: 0.049824\n",
      "Epoch 48/750 - Train pg Loss: 4.220506 - Test Loss: 1.013201\n",
      "\n",
      "\n",
      "Epoch 49/750 - Train Cd Loss: 0.147999 - Test Loss: 0.049960\n",
      "Epoch 49/750 - Train pg Loss: 4.105124 - Test Loss: 1.015176\n",
      "\n",
      "\n",
      "Epoch 50/750 - Train Cd Loss: 0.146988 - Test Loss: 0.051933\n",
      "Epoch 50/750 - Train pg Loss: 4.124197 - Test Loss: 1.030611\n",
      "\n",
      "\n",
      "Epoch 51/750 - Train Cd Loss: 0.152025 - Test Loss: 0.049489\n",
      "Epoch 51/750 - Train pg Loss: 4.208332 - Test Loss: 1.018889\n",
      "\n",
      "\n",
      "Epoch 52/750 - Train Cd Loss: 0.146950 - Test Loss: 0.049919\n",
      "Epoch 52/750 - Train pg Loss: 4.152231 - Test Loss: 1.051089\n",
      "\n",
      "\n",
      "Epoch 53/750 - Train Cd Loss: 0.144897 - Test Loss: 0.050289\n",
      "Epoch 53/750 - Train pg Loss: 4.200391 - Test Loss: 0.982924\n",
      "\n",
      "\n",
      "Epoch 54/750 - Train Cd Loss: 0.148947 - Test Loss: 0.049976\n",
      "Epoch 54/750 - Train pg Loss: 4.091877 - Test Loss: 1.024647\n",
      "\n",
      "\n",
      "Epoch 55/750 - Train Cd Loss: 0.145728 - Test Loss: 0.050900\n",
      "Epoch 55/750 - Train pg Loss: 4.051657 - Test Loss: 1.003132\n",
      "\n",
      "\n",
      "Epoch 56/750 - Train Cd Loss: 0.148013 - Test Loss: 0.050024\n",
      "Epoch 56/750 - Train pg Loss: 4.113047 - Test Loss: 1.018396\n",
      "\n",
      "\n",
      "Epoch 57/750 - Train Cd Loss: 0.148708 - Test Loss: 0.050240\n",
      "Epoch 57/750 - Train pg Loss: 4.091283 - Test Loss: 0.997112\n",
      "\n",
      "\n",
      "Epoch 58/750 - Train Cd Loss: 0.147979 - Test Loss: 0.051257\n",
      "Epoch 58/750 - Train pg Loss: 4.068634 - Test Loss: 1.010414\n",
      "\n",
      "\n",
      "Epoch 59/750 - Train Cd Loss: 0.145421 - Test Loss: 0.050725\n",
      "Epoch 59/750 - Train pg Loss: 4.120959 - Test Loss: 0.988723\n",
      "\n",
      "\n",
      "Epoch 60/750 - Train Cd Loss: 0.147821 - Test Loss: 0.050213\n",
      "Epoch 60/750 - Train pg Loss: 3.945287 - Test Loss: 0.990151\n",
      "\n",
      "\n",
      "Epoch 61/750 - Train Cd Loss: 0.147813 - Test Loss: 0.050566\n",
      "Epoch 61/750 - Train pg Loss: 4.129942 - Test Loss: 1.033705\n",
      "\n",
      "\n",
      "Epoch 62/750 - Train Cd Loss: 0.146750 - Test Loss: 0.051072\n",
      "Epoch 62/750 - Train pg Loss: 4.154790 - Test Loss: 1.024485\n",
      "\n",
      "\n",
      "Epoch 63/750 - Train Cd Loss: 0.147309 - Test Loss: 0.050617\n",
      "Epoch 63/750 - Train pg Loss: 4.059536 - Test Loss: 0.998064\n",
      "\n",
      "\n",
      "Epoch 64/750 - Train Cd Loss: 0.145173 - Test Loss: 0.050916\n",
      "Epoch 64/750 - Train pg Loss: 4.019272 - Test Loss: 0.979225\n",
      "\n",
      "\n",
      "Epoch 65/750 - Train Cd Loss: 0.148033 - Test Loss: 0.050507\n",
      "Epoch 65/750 - Train pg Loss: 4.027089 - Test Loss: 0.984664\n",
      "\n",
      "\n",
      "Epoch 66/750 - Train Cd Loss: 0.148838 - Test Loss: 0.050452\n",
      "Epoch 66/750 - Train pg Loss: 3.957858 - Test Loss: 0.977267\n",
      "\n",
      "\n",
      "Epoch 67/750 - Train Cd Loss: 0.144582 - Test Loss: 0.050632\n",
      "Epoch 67/750 - Train pg Loss: 3.973433 - Test Loss: 0.973319\n",
      "\n",
      "\n",
      "Epoch 68/750 - Train Cd Loss: 0.147410 - Test Loss: 0.050635\n",
      "Epoch 68/750 - Train pg Loss: 3.994789 - Test Loss: 0.978381\n",
      "\n",
      "\n",
      "Epoch 69/750 - Train Cd Loss: 0.146748 - Test Loss: 0.050589\n",
      "Epoch 69/750 - Train pg Loss: 3.925128 - Test Loss: 0.975572\n",
      "\n",
      "\n",
      "Epoch 70/750 - Train Cd Loss: 0.146379 - Test Loss: 0.051144\n",
      "Epoch 70/750 - Train pg Loss: 4.099806 - Test Loss: 1.007480\n",
      "\n",
      "\n",
      "Epoch 71/750 - Train Cd Loss: 0.145214 - Test Loss: 0.051009\n",
      "Epoch 71/750 - Train pg Loss: 4.082411 - Test Loss: 1.010456\n",
      "\n",
      "\n",
      "Epoch 72/750 - Train Cd Loss: 0.146111 - Test Loss: 0.050678\n",
      "Epoch 72/750 - Train pg Loss: 4.147248 - Test Loss: 1.012338\n",
      "\n",
      "\n",
      "Epoch 73/750 - Train Cd Loss: 0.145282 - Test Loss: 0.050831\n",
      "Epoch 73/750 - Train pg Loss: 4.189853 - Test Loss: 1.038349\n",
      "\n",
      "\n",
      "Epoch 74/750 - Train Cd Loss: 0.146888 - Test Loss: 0.050741\n",
      "Epoch 74/750 - Train pg Loss: 4.217204 - Test Loss: 0.997478\n",
      "\n",
      "\n",
      "Epoch 75/750 - Train Cd Loss: 0.144655 - Test Loss: 0.050764\n",
      "Epoch 75/750 - Train pg Loss: 4.037845 - Test Loss: 0.990708\n",
      "\n",
      "\n",
      "Epoch 76/750 - Train Cd Loss: 0.146239 - Test Loss: 0.051464\n",
      "Epoch 76/750 - Train pg Loss: 4.045967 - Test Loss: 0.951444\n",
      "\n",
      "\n",
      "Epoch 77/750 - Train Cd Loss: 0.146655 - Test Loss: 0.051075\n",
      "Epoch 77/750 - Train pg Loss: 3.964959 - Test Loss: 0.968689\n",
      "\n",
      "\n",
      "Epoch 78/750 - Train Cd Loss: 0.145126 - Test Loss: 0.050576\n",
      "Epoch 78/750 - Train pg Loss: 3.810372 - Test Loss: 0.951610\n",
      "\n",
      "\n",
      "Epoch 79/750 - Train Cd Loss: 0.145351 - Test Loss: 0.051033\n",
      "Epoch 79/750 - Train pg Loss: 3.941323 - Test Loss: 0.963905\n",
      "\n",
      "\n",
      "Epoch 80/750 - Train Cd Loss: 0.144339 - Test Loss: 0.050726\n",
      "Epoch 80/750 - Train pg Loss: 3.938278 - Test Loss: 0.947697\n",
      "\n",
      "\n",
      "Epoch 81/750 - Train Cd Loss: 0.144963 - Test Loss: 0.051022\n",
      "Epoch 81/750 - Train pg Loss: 3.961787 - Test Loss: 0.965412\n",
      "\n",
      "\n",
      "Epoch 82/750 - Train Cd Loss: 0.144147 - Test Loss: 0.051433\n",
      "Epoch 82/750 - Train pg Loss: 3.933928 - Test Loss: 0.908910\n",
      "\n",
      "\n",
      "Epoch 83/750 - Train Cd Loss: 0.146129 - Test Loss: 0.050581\n",
      "Epoch 83/750 - Train pg Loss: 3.729726 - Test Loss: 0.879102\n",
      "\n",
      "\n",
      "Epoch 84/750 - Train Cd Loss: 0.144861 - Test Loss: 0.050701\n",
      "Epoch 84/750 - Train pg Loss: 3.476323 - Test Loss: 0.873034\n",
      "\n",
      "\n",
      "Epoch 85/750 - Train Cd Loss: 0.144026 - Test Loss: 0.051063\n",
      "Epoch 85/750 - Train pg Loss: 3.710102 - Test Loss: 0.914285\n",
      "\n",
      "\n",
      "Epoch 86/750 - Train Cd Loss: 0.144327 - Test Loss: 0.051325\n",
      "Epoch 86/750 - Train pg Loss: 3.681701 - Test Loss: 0.902572\n",
      "\n",
      "\n",
      "Epoch 87/750 - Train Cd Loss: 0.143756 - Test Loss: 0.051314\n",
      "Epoch 87/750 - Train pg Loss: 3.666937 - Test Loss: 0.902021\n",
      "\n",
      "\n",
      "Epoch 88/750 - Train Cd Loss: 0.142609 - Test Loss: 0.051658\n",
      "Epoch 88/750 - Train pg Loss: 3.734805 - Test Loss: 0.924355\n",
      "\n",
      "\n",
      "Epoch 89/750 - Train Cd Loss: 0.143574 - Test Loss: 0.050862\n",
      "Epoch 89/750 - Train pg Loss: 3.754445 - Test Loss: 0.895237\n",
      "\n",
      "\n",
      "Epoch 90/750 - Train Cd Loss: 0.144638 - Test Loss: 0.050795\n",
      "Epoch 90/750 - Train pg Loss: 3.761818 - Test Loss: 0.902780\n",
      "\n",
      "\n",
      "Epoch 91/750 - Train Cd Loss: 0.144906 - Test Loss: 0.050719\n",
      "Epoch 91/750 - Train pg Loss: 3.857863 - Test Loss: 0.934098\n",
      "\n",
      "\n",
      "Epoch 92/750 - Train Cd Loss: 0.143441 - Test Loss: 0.050710\n",
      "Epoch 92/750 - Train pg Loss: 3.939265 - Test Loss: 0.966084\n",
      "\n",
      "\n",
      "Epoch 93/750 - Train Cd Loss: 0.143432 - Test Loss: 0.051098\n",
      "Epoch 93/750 - Train pg Loss: 3.909950 - Test Loss: 0.938368\n",
      "\n",
      "\n",
      "Epoch 94/750 - Train Cd Loss: 0.141762 - Test Loss: 0.051301\n",
      "Epoch 94/750 - Train pg Loss: 3.900453 - Test Loss: 0.973663\n",
      "\n",
      "\n",
      "Epoch 95/750 - Train Cd Loss: 0.143067 - Test Loss: 0.050902\n",
      "Epoch 95/750 - Train pg Loss: 4.165259 - Test Loss: 1.014158\n",
      "\n",
      "\n",
      "Epoch 96/750 - Train Cd Loss: 0.141850 - Test Loss: 0.051794\n",
      "Epoch 96/750 - Train pg Loss: 4.120487 - Test Loss: 0.986189\n",
      "\n",
      "\n",
      "Epoch 97/750 - Train Cd Loss: 0.143214 - Test Loss: 0.051330\n",
      "Epoch 97/750 - Train pg Loss: 3.940918 - Test Loss: 0.948096\n",
      "\n",
      "\n",
      "Epoch 98/750 - Train Cd Loss: 0.141852 - Test Loss: 0.052171\n",
      "Epoch 98/750 - Train pg Loss: 3.928575 - Test Loss: 0.900804\n",
      "\n",
      "\n",
      "Epoch 99/750 - Train Cd Loss: 0.142979 - Test Loss: 0.052263\n",
      "Epoch 99/750 - Train pg Loss: 3.597555 - Test Loss: 0.870565\n",
      "\n",
      "\n",
      "Epoch 100/750 - Train Cd Loss: 0.144415 - Test Loss: 0.051694\n",
      "Epoch 100/750 - Train pg Loss: 3.770839 - Test Loss: 0.929662\n",
      "\n",
      "\n",
      "Epoch 101/750 - Train Cd Loss: 0.140752 - Test Loss: 0.051452\n",
      "Epoch 101/750 - Train pg Loss: 3.780218 - Test Loss: 0.915198\n",
      "\n",
      "\n",
      "Epoch 102/750 - Train Cd Loss: 0.142349 - Test Loss: 0.051764\n",
      "Epoch 102/750 - Train pg Loss: 3.637579 - Test Loss: 0.876400\n",
      "\n",
      "\n",
      "Epoch 103/750 - Train Cd Loss: 0.142958 - Test Loss: 0.050649\n",
      "Epoch 103/750 - Train pg Loss: 3.836660 - Test Loss: 0.932809\n",
      "\n",
      "\n",
      "Epoch 104/750 - Train Cd Loss: 0.143640 - Test Loss: 0.052335\n",
      "Epoch 104/750 - Train pg Loss: 3.946786 - Test Loss: 0.954322\n",
      "\n",
      "\n",
      "Epoch 105/750 - Train Cd Loss: 0.140831 - Test Loss: 0.051929\n",
      "Epoch 105/750 - Train pg Loss: 3.924093 - Test Loss: 0.926619\n",
      "\n",
      "\n",
      "Epoch 106/750 - Train Cd Loss: 0.140785 - Test Loss: 0.052188\n",
      "Epoch 106/750 - Train pg Loss: 3.740780 - Test Loss: 0.898585\n",
      "\n",
      "\n",
      "Epoch 107/750 - Train Cd Loss: 0.140177 - Test Loss: 0.051275\n",
      "Epoch 107/750 - Train pg Loss: 3.700503 - Test Loss: 0.923752\n",
      "\n",
      "\n",
      "Epoch 108/750 - Train Cd Loss: 0.140280 - Test Loss: 0.051203\n",
      "Epoch 108/750 - Train pg Loss: 3.711118 - Test Loss: 0.937011\n",
      "\n",
      "\n",
      "Epoch 109/750 - Train Cd Loss: 0.138567 - Test Loss: 0.051854\n",
      "Epoch 109/750 - Train pg Loss: 3.888645 - Test Loss: 0.948702\n",
      "\n",
      "\n",
      "Epoch 110/750 - Train Cd Loss: 0.139775 - Test Loss: 0.051430\n",
      "Epoch 110/750 - Train pg Loss: 3.870586 - Test Loss: 0.974552\n",
      "\n",
      "\n",
      "Epoch 111/750 - Train Cd Loss: 0.141954 - Test Loss: 0.051922\n",
      "Epoch 111/750 - Train pg Loss: 4.095672 - Test Loss: 0.965484\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/750 - Train Cd Loss: 0.138318 - Test Loss: 0.051322\n",
      "Epoch 112/750 - Train pg Loss: 3.968068 - Test Loss: 0.951246\n",
      "\n",
      "\n",
      "Epoch 113/750 - Train Cd Loss: 0.135251 - Test Loss: 0.052111\n",
      "Epoch 113/750 - Train pg Loss: 3.907713 - Test Loss: 0.945687\n",
      "\n",
      "\n",
      "Epoch 114/750 - Train Cd Loss: 0.135821 - Test Loss: 0.052505\n",
      "Epoch 114/750 - Train pg Loss: 4.000846 - Test Loss: 0.954245\n",
      "\n",
      "\n",
      "Epoch 115/750 - Train Cd Loss: 0.135782 - Test Loss: 0.052683\n",
      "Epoch 115/750 - Train pg Loss: 3.803408 - Test Loss: 0.930552\n",
      "\n",
      "\n",
      "Epoch 116/750 - Train Cd Loss: 0.138737 - Test Loss: 0.052103\n",
      "Epoch 116/750 - Train pg Loss: 3.867262 - Test Loss: 1.011647\n",
      "\n",
      "\n",
      "Epoch 117/750 - Train Cd Loss: 0.138673 - Test Loss: 0.051646\n",
      "Epoch 117/750 - Train pg Loss: 3.986761 - Test Loss: 0.986780\n",
      "\n",
      "\n",
      "Epoch 118/750 - Train Cd Loss: 0.137475 - Test Loss: 0.051151\n",
      "Epoch 118/750 - Train pg Loss: 4.226790 - Test Loss: 1.073990\n",
      "\n",
      "\n",
      "Epoch 119/750 - Train Cd Loss: 0.136496 - Test Loss: 0.051968\n",
      "Epoch 119/750 - Train pg Loss: 4.348486 - Test Loss: 0.969520\n",
      "\n",
      "\n",
      "Epoch 120/750 - Train Cd Loss: 0.137316 - Test Loss: 0.052040\n",
      "Epoch 120/750 - Train pg Loss: 4.147650 - Test Loss: 0.954140\n",
      "\n",
      "\n",
      "Epoch 121/750 - Train Cd Loss: 0.135830 - Test Loss: 0.051718\n",
      "Epoch 121/750 - Train pg Loss: 3.945848 - Test Loss: 0.938153\n",
      "\n",
      "\n",
      "Epoch 122/750 - Train Cd Loss: 0.138410 - Test Loss: 0.051794\n",
      "Epoch 122/750 - Train pg Loss: 4.097856 - Test Loss: 1.011176\n",
      "\n",
      "\n",
      "Epoch 123/750 - Train Cd Loss: 0.135795 - Test Loss: 0.051582\n",
      "Epoch 123/750 - Train pg Loss: 3.977600 - Test Loss: 0.972229\n",
      "\n",
      "\n",
      "Epoch 124/750 - Train Cd Loss: 0.134363 - Test Loss: 0.051703\n",
      "Epoch 124/750 - Train pg Loss: 3.909885 - Test Loss: 0.913387\n",
      "\n",
      "\n",
      "Epoch 125/750 - Train Cd Loss: 0.136780 - Test Loss: 0.052121\n",
      "Epoch 125/750 - Train pg Loss: 3.961087 - Test Loss: 0.916500\n",
      "\n",
      "\n",
      "Epoch 126/750 - Train Cd Loss: 0.135651 - Test Loss: 0.051545\n",
      "Epoch 126/750 - Train pg Loss: 3.573591 - Test Loss: 0.848371\n",
      "\n",
      "\n",
      "Epoch 127/750 - Train Cd Loss: 0.135034 - Test Loss: 0.053445\n",
      "Epoch 127/750 - Train pg Loss: 3.867856 - Test Loss: 0.928498\n",
      "\n",
      "\n",
      "Epoch 128/750 - Train Cd Loss: 0.133060 - Test Loss: 0.052294\n",
      "Epoch 128/750 - Train pg Loss: 3.770927 - Test Loss: 0.892593\n",
      "\n",
      "\n",
      "Epoch 129/750 - Train Cd Loss: 0.136577 - Test Loss: 0.052615\n",
      "Epoch 129/750 - Train pg Loss: 3.609904 - Test Loss: 0.801540\n",
      "\n",
      "\n",
      "Epoch 130/750 - Train Cd Loss: 0.135965 - Test Loss: 0.052436\n",
      "Epoch 130/750 - Train pg Loss: 3.160249 - Test Loss: 0.783744\n",
      "\n",
      "\n",
      "Epoch 131/750 - Train Cd Loss: 0.130796 - Test Loss: 0.052376\n",
      "Epoch 131/750 - Train pg Loss: 3.637665 - Test Loss: 0.856277\n",
      "\n",
      "\n",
      "Epoch 132/750 - Train Cd Loss: 0.134543 - Test Loss: 0.053163\n",
      "Epoch 132/750 - Train pg Loss: 3.545012 - Test Loss: 0.842704\n",
      "\n",
      "\n",
      "Epoch 133/750 - Train Cd Loss: 0.134256 - Test Loss: 0.051716\n",
      "Epoch 133/750 - Train pg Loss: 3.509336 - Test Loss: 0.806429\n",
      "\n",
      "\n",
      "Epoch 134/750 - Train Cd Loss: 0.130285 - Test Loss: 0.051647\n",
      "Epoch 134/750 - Train pg Loss: 3.641908 - Test Loss: 0.876804\n",
      "\n",
      "\n",
      "Epoch 135/750 - Train Cd Loss: 0.132374 - Test Loss: 0.051740\n",
      "Epoch 135/750 - Train pg Loss: 3.534005 - Test Loss: 0.867489\n",
      "\n",
      "\n",
      "Epoch 136/750 - Train Cd Loss: 0.132483 - Test Loss: 0.052917\n",
      "Epoch 136/750 - Train pg Loss: 3.772194 - Test Loss: 0.952154\n",
      "\n",
      "\n",
      "Epoch 137/750 - Train Cd Loss: 0.129837 - Test Loss: 0.051597\n",
      "Epoch 137/750 - Train pg Loss: 4.072732 - Test Loss: 1.008537\n",
      "\n",
      "\n",
      "Epoch 138/750 - Train Cd Loss: 0.130083 - Test Loss: 0.052420\n",
      "Epoch 138/750 - Train pg Loss: 4.192369 - Test Loss: 0.997943\n",
      "\n",
      "\n",
      "Epoch 139/750 - Train Cd Loss: 0.128888 - Test Loss: 0.052286\n",
      "Epoch 139/750 - Train pg Loss: 4.227408 - Test Loss: 1.026942\n",
      "\n",
      "\n",
      "Epoch 140/750 - Train Cd Loss: 0.132624 - Test Loss: 0.053247\n",
      "Epoch 140/750 - Train pg Loss: 3.876549 - Test Loss: 0.929734\n",
      "\n",
      "\n",
      "Epoch 141/750 - Train Cd Loss: 0.131704 - Test Loss: 0.051325\n",
      "Epoch 141/750 - Train pg Loss: 4.031691 - Test Loss: 0.981758\n",
      "\n",
      "\n",
      "Epoch 142/750 - Train Cd Loss: 0.127707 - Test Loss: 0.052803\n",
      "Epoch 142/750 - Train pg Loss: 3.896988 - Test Loss: 0.883370\n",
      "\n",
      "\n",
      "Epoch 143/750 - Train Cd Loss: 0.129193 - Test Loss: 0.053337\n",
      "Epoch 143/750 - Train pg Loss: 3.679389 - Test Loss: 0.852719\n",
      "\n",
      "\n",
      "Epoch 144/750 - Train Cd Loss: 0.131066 - Test Loss: 0.052126\n",
      "Epoch 144/750 - Train pg Loss: 3.547463 - Test Loss: 0.918163\n",
      "\n",
      "\n",
      "Epoch 145/750 - Train Cd Loss: 0.132058 - Test Loss: 0.051962\n",
      "Epoch 145/750 - Train pg Loss: 4.185758 - Test Loss: 0.929566\n",
      "\n",
      "\n",
      "Epoch 146/750 - Train Cd Loss: 0.128318 - Test Loss: 0.051871\n",
      "Epoch 146/750 - Train pg Loss: 4.233197 - Test Loss: 0.907574\n",
      "\n",
      "\n",
      "Epoch 147/750 - Train Cd Loss: 0.128011 - Test Loss: 0.053707\n",
      "Epoch 147/750 - Train pg Loss: 3.366252 - Test Loss: 0.802249\n",
      "\n",
      "\n",
      "Epoch 148/750 - Train Cd Loss: 0.129873 - Test Loss: 0.052218\n",
      "Epoch 148/750 - Train pg Loss: 3.478410 - Test Loss: 0.810794\n",
      "\n",
      "\n",
      "Epoch 149/750 - Train Cd Loss: 0.125465 - Test Loss: 0.052214\n",
      "Epoch 149/750 - Train pg Loss: 3.563169 - Test Loss: 0.914802\n",
      "\n",
      "\n",
      "Epoch 150/750 - Train Cd Loss: 0.123698 - Test Loss: 0.051741\n",
      "Epoch 150/750 - Train pg Loss: 3.776366 - Test Loss: 0.942073\n",
      "\n",
      "\n",
      "Epoch 151/750 - Train Cd Loss: 0.127316 - Test Loss: 0.053167\n",
      "Epoch 151/750 - Train pg Loss: 4.492864 - Test Loss: 1.104300\n",
      "\n",
      "\n",
      "Epoch 152/750 - Train Cd Loss: 0.121326 - Test Loss: 0.052703\n",
      "Epoch 152/750 - Train pg Loss: 4.328835 - Test Loss: 0.925796\n",
      "\n",
      "\n",
      "Epoch 153/750 - Train Cd Loss: 0.122814 - Test Loss: 0.053895\n",
      "Epoch 153/750 - Train pg Loss: 3.727052 - Test Loss: 0.823912\n",
      "\n",
      "\n",
      "Epoch 154/750 - Train Cd Loss: 0.129980 - Test Loss: 0.052080\n",
      "Epoch 154/750 - Train pg Loss: 3.536904 - Test Loss: 0.912936\n",
      "\n",
      "\n",
      "Epoch 155/750 - Train Cd Loss: 0.124700 - Test Loss: 0.051856\n",
      "Epoch 155/750 - Train pg Loss: 3.798462 - Test Loss: 0.900430\n",
      "\n",
      "\n",
      "Epoch 156/750 - Train Cd Loss: 0.128928 - Test Loss: 0.052214\n",
      "Epoch 156/750 - Train pg Loss: 4.066129 - Test Loss: 1.010860\n",
      "\n",
      "\n",
      "Epoch 157/750 - Train Cd Loss: 0.121033 - Test Loss: 0.053565\n",
      "Epoch 157/750 - Train pg Loss: 3.653528 - Test Loss: 0.842055\n",
      "\n",
      "\n",
      "Epoch 158/750 - Train Cd Loss: 0.120608 - Test Loss: 0.052058\n",
      "Epoch 158/750 - Train pg Loss: 3.756855 - Test Loss: 0.988012\n",
      "\n",
      "\n",
      "Epoch 159/750 - Train Cd Loss: 0.123416 - Test Loss: 0.053562\n",
      "Epoch 159/750 - Train pg Loss: 3.842316 - Test Loss: 0.858515\n",
      "\n",
      "\n",
      "Epoch 160/750 - Train Cd Loss: 0.117302 - Test Loss: 0.052512\n",
      "Epoch 160/750 - Train pg Loss: 3.485249 - Test Loss: 0.869415\n",
      "\n",
      "\n",
      "Epoch 161/750 - Train Cd Loss: 0.124478 - Test Loss: 0.052650\n",
      "Epoch 161/750 - Train pg Loss: 3.432530 - Test Loss: 0.767957\n",
      "\n",
      "\n",
      "Epoch 162/750 - Train Cd Loss: 0.123564 - Test Loss: 0.052825\n",
      "Epoch 162/750 - Train pg Loss: 3.212590 - Test Loss: 0.756580\n",
      "\n",
      "\n",
      "Epoch 163/750 - Train Cd Loss: 0.119817 - Test Loss: 0.052705\n",
      "Epoch 163/750 - Train pg Loss: 3.309094 - Test Loss: 0.916470\n",
      "\n",
      "\n",
      "Epoch 164/750 - Train Cd Loss: 0.111785 - Test Loss: 0.051631\n",
      "Epoch 164/750 - Train pg Loss: 3.575405 - Test Loss: 0.757620\n",
      "\n",
      "\n",
      "Epoch 165/750 - Train Cd Loss: 0.117383 - Test Loss: 0.052253\n",
      "Epoch 165/750 - Train pg Loss: 2.869744 - Test Loss: 0.654231\n",
      "\n",
      "\n",
      "Epoch 166/750 - Train Cd Loss: 0.114986 - Test Loss: 0.052418\n",
      "Epoch 166/750 - Train pg Loss: 2.883759 - Test Loss: 0.663465\n",
      "\n",
      "\n",
      "Epoch 167/750 - Train Cd Loss: 0.118961 - Test Loss: 0.052547\n",
      "Epoch 167/750 - Train pg Loss: 3.095327 - Test Loss: 0.685907\n",
      "\n",
      "\n",
      "Epoch 168/750 - Train Cd Loss: 0.118472 - Test Loss: 0.052227\n",
      "Epoch 168/750 - Train pg Loss: 3.663560 - Test Loss: 0.839894\n",
      "\n",
      "\n",
      "Epoch 169/750 - Train Cd Loss: 0.122286 - Test Loss: 0.052146\n",
      "Epoch 169/750 - Train pg Loss: 3.401505 - Test Loss: 0.799038\n",
      "\n",
      "\n",
      "Epoch 170/750 - Train Cd Loss: 0.116680 - Test Loss: 0.053146\n",
      "Epoch 170/750 - Train pg Loss: 3.612118 - Test Loss: 0.906331\n",
      "\n",
      "\n",
      "Epoch 171/750 - Train Cd Loss: 0.114140 - Test Loss: 0.053488\n",
      "Epoch 171/750 - Train pg Loss: 3.548530 - Test Loss: 0.795350\n",
      "\n",
      "\n",
      "Epoch 172/750 - Train Cd Loss: 0.116002 - Test Loss: 0.052857\n",
      "Epoch 172/750 - Train pg Loss: 2.970185 - Test Loss: 0.727374\n",
      "\n",
      "\n",
      "Epoch 173/750 - Train Cd Loss: 0.115891 - Test Loss: 0.052951\n",
      "Epoch 173/750 - Train pg Loss: 3.187333 - Test Loss: 0.793485\n",
      "\n",
      "\n",
      "Epoch 174/750 - Train Cd Loss: 0.115353 - Test Loss: 0.053241\n",
      "Epoch 174/750 - Train pg Loss: 3.162236 - Test Loss: 0.663194\n",
      "\n",
      "\n",
      "Epoch 175/750 - Train Cd Loss: 0.114964 - Test Loss: 0.052019\n",
      "Epoch 175/750 - Train pg Loss: 3.024220 - Test Loss: 0.725430\n",
      "\n",
      "\n",
      "Epoch 176/750 - Train Cd Loss: 0.111369 - Test Loss: 0.052486\n",
      "Epoch 176/750 - Train pg Loss: 3.228658 - Test Loss: 0.857182\n",
      "\n",
      "\n",
      "Epoch 177/750 - Train Cd Loss: 0.107332 - Test Loss: 0.053187\n",
      "Epoch 177/750 - Train pg Loss: 3.560956 - Test Loss: 0.879409\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/750 - Train Cd Loss: 0.115238 - Test Loss: 0.052449\n",
      "Epoch 178/750 - Train pg Loss: 3.865453 - Test Loss: 0.876916\n",
      "\n",
      "\n",
      "Epoch 179/750 - Train Cd Loss: 0.114622 - Test Loss: 0.052492\n",
      "Epoch 179/750 - Train pg Loss: 3.917605 - Test Loss: 0.892998\n",
      "\n",
      "\n",
      "Epoch 180/750 - Train Cd Loss: 0.114845 - Test Loss: 0.054629\n",
      "Epoch 180/750 - Train pg Loss: 3.689672 - Test Loss: 0.882236\n",
      "\n",
      "\n",
      "Epoch 181/750 - Train Cd Loss: 0.112518 - Test Loss: 0.053760\n",
      "Epoch 181/750 - Train pg Loss: 4.041122 - Test Loss: 1.011373\n",
      "\n",
      "\n",
      "Epoch 182/750 - Train Cd Loss: 0.111661 - Test Loss: 0.052567\n",
      "Epoch 182/750 - Train pg Loss: 3.868681 - Test Loss: 0.883972\n",
      "\n",
      "\n",
      "Epoch 183/750 - Train Cd Loss: 0.113556 - Test Loss: 0.053278\n",
      "Epoch 183/750 - Train pg Loss: 3.710096 - Test Loss: 0.915331\n",
      "\n",
      "\n",
      "Epoch 184/750 - Train Cd Loss: 0.121334 - Test Loss: 0.052997\n",
      "Epoch 184/750 - Train pg Loss: 4.726170 - Test Loss: 1.017943\n",
      "\n",
      "\n",
      "Epoch 185/750 - Train Cd Loss: 0.112113 - Test Loss: 0.054345\n",
      "Epoch 185/750 - Train pg Loss: 4.324906 - Test Loss: 1.082428\n",
      "\n",
      "\n",
      "Epoch 186/750 - Train Cd Loss: 0.113052 - Test Loss: 0.052494\n",
      "Epoch 186/750 - Train pg Loss: 4.125305 - Test Loss: 1.080981\n",
      "\n",
      "\n",
      "Epoch 187/750 - Train Cd Loss: 0.105083 - Test Loss: 0.053597\n",
      "Epoch 187/750 - Train pg Loss: 4.437609 - Test Loss: 1.071240\n",
      "\n",
      "\n",
      "Epoch 188/750 - Train Cd Loss: 0.113919 - Test Loss: 0.054541\n",
      "Epoch 188/750 - Train pg Loss: 4.599550 - Test Loss: 1.014176\n",
      "\n",
      "\n",
      "Epoch 189/750 - Train Cd Loss: 0.107860 - Test Loss: 0.055502\n",
      "Epoch 189/750 - Train pg Loss: 4.074429 - Test Loss: 0.945156\n",
      "\n",
      "\n",
      "Epoch 190/750 - Train Cd Loss: 0.115379 - Test Loss: 0.052841\n",
      "Epoch 190/750 - Train pg Loss: 4.541102 - Test Loss: 1.175253\n",
      "\n",
      "\n",
      "Epoch 191/750 - Train Cd Loss: 0.105605 - Test Loss: 0.056829\n",
      "Epoch 191/750 - Train pg Loss: 4.358010 - Test Loss: 0.916733\n",
      "\n",
      "\n",
      "Epoch 192/750 - Train Cd Loss: 0.124559 - Test Loss: 0.057086\n",
      "Epoch 192/750 - Train pg Loss: 5.245990 - Test Loss: 1.145829\n",
      "\n",
      "\n",
      "Epoch 193/750 - Train Cd Loss: 0.107296 - Test Loss: 0.055415\n",
      "Epoch 193/750 - Train pg Loss: 4.935868 - Test Loss: 1.297667\n",
      "\n",
      "\n",
      "Epoch 194/750 - Train Cd Loss: 0.110554 - Test Loss: 0.054511\n",
      "Epoch 194/750 - Train pg Loss: 5.631735 - Test Loss: 1.249129\n",
      "\n",
      "\n",
      "Epoch 195/750 - Train Cd Loss: 0.110149 - Test Loss: 0.057239\n",
      "Epoch 195/750 - Train pg Loss: 5.085275 - Test Loss: 1.186747\n",
      "\n",
      "\n",
      "Epoch 196/750 - Train Cd Loss: 0.110150 - Test Loss: 0.052768\n",
      "Epoch 196/750 - Train pg Loss: 4.839906 - Test Loss: 1.388944\n",
      "\n",
      "\n",
      "Epoch 197/750 - Train Cd Loss: 0.103154 - Test Loss: 0.054779\n",
      "Epoch 197/750 - Train pg Loss: 5.106143 - Test Loss: 1.230957\n",
      "\n",
      "\n",
      "Epoch 198/750 - Train Cd Loss: 0.109156 - Test Loss: 0.055243\n",
      "Epoch 198/750 - Train pg Loss: 4.868553 - Test Loss: 1.206280\n",
      "\n",
      "\n",
      "Epoch 199/750 - Train Cd Loss: 0.109605 - Test Loss: 0.052932\n",
      "Epoch 199/750 - Train pg Loss: 4.654541 - Test Loss: 1.122126\n",
      "\n",
      "\n",
      "Epoch 200/750 - Train Cd Loss: 0.110051 - Test Loss: 0.053512\n",
      "Epoch 200/750 - Train pg Loss: 4.362944 - Test Loss: 1.112023\n",
      "\n",
      "\n",
      "Epoch 201/750 - Train Cd Loss: 0.104851 - Test Loss: 0.055806\n",
      "Epoch 201/750 - Train pg Loss: 4.203293 - Test Loss: 1.113914\n",
      "\n",
      "\n",
      "Epoch 202/750 - Train Cd Loss: 0.103747 - Test Loss: 0.054853\n",
      "Epoch 202/750 - Train pg Loss: 4.617335 - Test Loss: 1.198350\n",
      "\n",
      "\n",
      "Epoch 203/750 - Train Cd Loss: 0.102916 - Test Loss: 0.055861\n",
      "Epoch 203/750 - Train pg Loss: 4.845294 - Test Loss: 1.187286\n",
      "\n",
      "\n",
      "Epoch 204/750 - Train Cd Loss: 0.098517 - Test Loss: 0.055754\n",
      "Epoch 204/750 - Train pg Loss: 4.504976 - Test Loss: 1.214483\n",
      "\n",
      "\n",
      "Epoch 205/750 - Train Cd Loss: 0.103961 - Test Loss: 0.055799\n",
      "Epoch 205/750 - Train pg Loss: 4.324813 - Test Loss: 1.047437\n",
      "\n",
      "\n",
      "Epoch 206/750 - Train Cd Loss: 0.116884 - Test Loss: 0.055556\n",
      "Epoch 206/750 - Train pg Loss: 5.145332 - Test Loss: 1.419936\n",
      "\n",
      "\n",
      "Epoch 207/750 - Train Cd Loss: 0.099343 - Test Loss: 0.055497\n",
      "Epoch 207/750 - Train pg Loss: 6.236731 - Test Loss: 1.657601\n",
      "\n",
      "\n",
      "Epoch 208/750 - Train Cd Loss: 0.098983 - Test Loss: 0.055441\n",
      "Epoch 208/750 - Train pg Loss: 6.811635 - Test Loss: 1.699958\n",
      "\n",
      "\n",
      "Epoch 209/750 - Train Cd Loss: 0.099540 - Test Loss: 0.055056\n",
      "Epoch 209/750 - Train pg Loss: 6.671103 - Test Loss: 1.676543\n",
      "\n",
      "\n",
      "Epoch 210/750 - Train Cd Loss: 0.104675 - Test Loss: 0.058165\n",
      "Epoch 210/750 - Train pg Loss: 6.217511 - Test Loss: 1.629478\n",
      "\n",
      "\n",
      "Epoch 211/750 - Train Cd Loss: 0.098556 - Test Loss: 0.055136\n",
      "Epoch 211/750 - Train pg Loss: 6.241323 - Test Loss: 1.629539\n",
      "\n",
      "\n",
      "Epoch 212/750 - Train Cd Loss: 0.100261 - Test Loss: 0.055147\n",
      "Epoch 212/750 - Train pg Loss: 6.350331 - Test Loss: 1.518227\n",
      "\n",
      "\n",
      "Epoch 213/750 - Train Cd Loss: 0.104412 - Test Loss: 0.057223\n",
      "Epoch 213/750 - Train pg Loss: 5.502091 - Test Loss: 1.314553\n",
      "\n",
      "\n",
      "Epoch 214/750 - Train Cd Loss: 0.100488 - Test Loss: 0.055377\n",
      "Epoch 214/750 - Train pg Loss: 5.196711 - Test Loss: 1.287983\n",
      "\n",
      "\n",
      "Epoch 215/750 - Train Cd Loss: 0.101559 - Test Loss: 0.056179\n",
      "Epoch 215/750 - Train pg Loss: 5.267097 - Test Loss: 1.449653\n",
      "\n",
      "\n",
      "Epoch 216/750 - Train Cd Loss: 0.113745 - Test Loss: 0.056465\n",
      "Epoch 216/750 - Train pg Loss: 7.525725 - Test Loss: 2.022336\n",
      "\n",
      "\n",
      "Epoch 217/750 - Train Cd Loss: 0.097173 - Test Loss: 0.058627\n",
      "Epoch 217/750 - Train pg Loss: 7.895083 - Test Loss: 2.207754\n",
      "\n",
      "\n",
      "Epoch 218/750 - Train Cd Loss: 0.097720 - Test Loss: 0.057705\n",
      "Epoch 218/750 - Train pg Loss: 8.309088 - Test Loss: 2.002899\n",
      "\n",
      "\n",
      "Epoch 219/750 - Train Cd Loss: 0.095255 - Test Loss: 0.054065\n",
      "Epoch 219/750 - Train pg Loss: 7.006459 - Test Loss: 1.761067\n",
      "\n",
      "\n",
      "Epoch 220/750 - Train Cd Loss: 0.097035 - Test Loss: 0.057915\n",
      "Epoch 220/750 - Train pg Loss: 6.648208 - Test Loss: 1.444588\n",
      "\n",
      "\n",
      "Epoch 221/750 - Train Cd Loss: 0.096181 - Test Loss: 0.055629\n",
      "Epoch 221/750 - Train pg Loss: 5.575752 - Test Loss: 1.521931\n",
      "\n",
      "\n",
      "Epoch 222/750 - Train Cd Loss: 0.095638 - Test Loss: 0.055480\n",
      "Epoch 222/750 - Train pg Loss: 6.011947 - Test Loss: 1.858925\n",
      "\n",
      "\n",
      "Epoch 223/750 - Train Cd Loss: 0.098849 - Test Loss: 0.056306\n",
      "Epoch 223/750 - Train pg Loss: 7.121058 - Test Loss: 1.909320\n",
      "\n",
      "\n",
      "Epoch 224/750 - Train Cd Loss: 0.097792 - Test Loss: 0.057296\n",
      "Epoch 224/750 - Train pg Loss: 7.765912 - Test Loss: 1.930860\n",
      "\n",
      "\n",
      "Epoch 225/750 - Train Cd Loss: 0.093546 - Test Loss: 0.057713\n",
      "Epoch 225/750 - Train pg Loss: 7.191606 - Test Loss: 1.944126\n",
      "\n",
      "\n",
      "Epoch 226/750 - Train Cd Loss: 0.099931 - Test Loss: 0.057630\n",
      "Epoch 226/750 - Train pg Loss: 6.997343 - Test Loss: 1.918948\n",
      "\n",
      "\n",
      "Epoch 227/750 - Train Cd Loss: 0.104322 - Test Loss: 0.056409\n",
      "Epoch 227/750 - Train pg Loss: 7.952180 - Test Loss: 2.184724\n",
      "\n",
      "\n",
      "Epoch 228/750 - Train Cd Loss: 0.094083 - Test Loss: 0.057120\n",
      "Epoch 228/750 - Train pg Loss: 8.510005 - Test Loss: 2.516006\n",
      "\n",
      "\n",
      "Epoch 229/750 - Train Cd Loss: 0.099022 - Test Loss: 0.055977\n",
      "Epoch 229/750 - Train pg Loss: 9.191217 - Test Loss: 2.308940\n",
      "\n",
      "\n",
      "Epoch 230/750 - Train Cd Loss: 0.094572 - Test Loss: 0.059201\n",
      "Epoch 230/750 - Train pg Loss: 7.812344 - Test Loss: 2.145664\n",
      "\n",
      "\n",
      "Epoch 231/750 - Train Cd Loss: 0.091403 - Test Loss: 0.057230\n",
      "Epoch 231/750 - Train pg Loss: 7.769873 - Test Loss: 2.155921\n",
      "\n",
      "\n",
      "Epoch 232/750 - Train Cd Loss: 0.095244 - Test Loss: 0.056439\n",
      "Epoch 232/750 - Train pg Loss: 7.427058 - Test Loss: 1.740132\n",
      "\n",
      "\n",
      "Epoch 233/750 - Train Cd Loss: 0.092364 - Test Loss: 0.056386\n",
      "Epoch 233/750 - Train pg Loss: 6.575482 - Test Loss: 1.797426\n",
      "\n",
      "\n",
      "Epoch 234/750 - Train Cd Loss: 0.092990 - Test Loss: 0.058426\n",
      "Epoch 234/750 - Train pg Loss: 7.144598 - Test Loss: 1.853832\n",
      "\n",
      "\n",
      "Epoch 235/750 - Train Cd Loss: 0.092665 - Test Loss: 0.057711\n",
      "Epoch 235/750 - Train pg Loss: 7.189246 - Test Loss: 2.003707\n",
      "\n",
      "\n",
      "Epoch 236/750 - Train Cd Loss: 0.094481 - Test Loss: 0.058650\n",
      "Epoch 236/750 - Train pg Loss: 7.740886 - Test Loss: 2.128523\n",
      "\n",
      "\n",
      "Epoch 237/750 - Train Cd Loss: 0.111422 - Test Loss: 0.058360\n",
      "Epoch 237/750 - Train pg Loss: 8.387801 - Test Loss: 2.030031\n",
      "\n",
      "\n",
      "Epoch 238/750 - Train Cd Loss: 0.105887 - Test Loss: 0.055424\n",
      "Epoch 238/750 - Train pg Loss: 7.625939 - Test Loss: 2.123437\n",
      "\n",
      "\n",
      "Epoch 239/750 - Train Cd Loss: 0.090516 - Test Loss: 0.058889\n",
      "Epoch 239/750 - Train pg Loss: 7.430312 - Test Loss: 2.137613\n",
      "\n",
      "\n",
      "Epoch 240/750 - Train Cd Loss: 0.093482 - Test Loss: 0.057631\n",
      "Epoch 240/750 - Train pg Loss: 7.714188 - Test Loss: 2.050256\n",
      "\n",
      "\n",
      "Epoch 241/750 - Train Cd Loss: 0.096730 - Test Loss: 0.056458\n",
      "Epoch 241/750 - Train pg Loss: 6.423811 - Test Loss: 1.969158\n",
      "\n",
      "\n",
      "Epoch 242/750 - Train Cd Loss: 0.091876 - Test Loss: 0.058339\n",
      "Epoch 242/750 - Train pg Loss: 7.202044 - Test Loss: 1.989424\n",
      "\n",
      "\n",
      "Epoch 243/750 - Train Cd Loss: 0.091180 - Test Loss: 0.062165\n",
      "Epoch 243/750 - Train pg Loss: 6.411065 - Test Loss: 1.728051\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244/750 - Train Cd Loss: 0.094461 - Test Loss: 0.057378\n",
      "Epoch 244/750 - Train pg Loss: 6.681968 - Test Loss: 1.845887\n",
      "\n",
      "\n",
      "Epoch 245/750 - Train Cd Loss: 0.096956 - Test Loss: 0.058271\n",
      "Epoch 245/750 - Train pg Loss: 5.937335 - Test Loss: 1.638907\n",
      "\n",
      "\n",
      "Epoch 246/750 - Train Cd Loss: 0.091660 - Test Loss: 0.058747\n",
      "Epoch 246/750 - Train pg Loss: 6.204548 - Test Loss: 1.743558\n",
      "\n",
      "\n",
      "Epoch 247/750 - Train Cd Loss: 0.088708 - Test Loss: 0.058593\n",
      "Epoch 247/750 - Train pg Loss: 6.370406 - Test Loss: 1.820306\n",
      "\n",
      "\n",
      "Epoch 248/750 - Train Cd Loss: 0.090493 - Test Loss: 0.059173\n",
      "Epoch 248/750 - Train pg Loss: 7.159410 - Test Loss: 1.908543\n",
      "\n",
      "\n",
      "Epoch 249/750 - Train Cd Loss: 0.094851 - Test Loss: 0.058529\n",
      "Epoch 249/750 - Train pg Loss: 8.139132 - Test Loss: 2.304475\n",
      "\n",
      "\n",
      "Epoch 250/750 - Train Cd Loss: 0.086387 - Test Loss: 0.061656\n",
      "Epoch 250/750 - Train pg Loss: 8.886006 - Test Loss: 2.328350\n",
      "\n",
      "\n",
      "Epoch 251/750 - Train Cd Loss: 0.091066 - Test Loss: 0.057689\n",
      "Epoch 251/750 - Train pg Loss: 9.657837 - Test Loss: 2.599855\n",
      "\n",
      "\n",
      "Epoch 252/750 - Train Cd Loss: 0.110100 - Test Loss: 0.060065\n",
      "Epoch 252/750 - Train pg Loss: 10.177080 - Test Loss: 2.371522\n",
      "\n",
      "\n",
      "Epoch 253/750 - Train Cd Loss: 0.089725 - Test Loss: 0.059137\n",
      "Epoch 253/750 - Train pg Loss: 8.484505 - Test Loss: 2.557784\n",
      "\n",
      "\n",
      "Epoch 254/750 - Train Cd Loss: 0.092385 - Test Loss: 0.059202\n",
      "Epoch 254/750 - Train pg Loss: 8.862491 - Test Loss: 2.329051\n",
      "\n",
      "\n",
      "Epoch 255/750 - Train Cd Loss: 0.088541 - Test Loss: 0.059155\n",
      "Epoch 255/750 - Train pg Loss: 7.690633 - Test Loss: 2.307559\n",
      "\n",
      "\n",
      "Epoch 256/750 - Train Cd Loss: 0.092333 - Test Loss: 0.058168\n",
      "Epoch 256/750 - Train pg Loss: 8.011325 - Test Loss: 2.410514\n",
      "\n",
      "\n",
      "Epoch 257/750 - Train Cd Loss: 0.092889 - Test Loss: 0.061151\n",
      "Epoch 257/750 - Train pg Loss: 7.624622 - Test Loss: 1.918743\n",
      "\n",
      "\n",
      "Epoch 258/750 - Train Cd Loss: 0.086748 - Test Loss: 0.060224\n",
      "Epoch 258/750 - Train pg Loss: 7.003095 - Test Loss: 2.022856\n",
      "\n",
      "\n",
      "Epoch 259/750 - Train Cd Loss: 0.083607 - Test Loss: 0.059033\n",
      "Epoch 259/750 - Train pg Loss: 7.193539 - Test Loss: 2.181864\n",
      "\n",
      "\n",
      "Epoch 260/750 - Train Cd Loss: 0.090163 - Test Loss: 0.061259\n",
      "Epoch 260/750 - Train pg Loss: 7.450856 - Test Loss: 2.052968\n",
      "\n",
      "\n",
      "Epoch 261/750 - Train Cd Loss: 0.087932 - Test Loss: 0.059375\n",
      "Epoch 261/750 - Train pg Loss: 8.967358 - Test Loss: 2.421279\n",
      "\n",
      "\n",
      "Epoch 262/750 - Train Cd Loss: 0.094143 - Test Loss: 0.060217\n",
      "Epoch 262/750 - Train pg Loss: 9.348785 - Test Loss: 2.409836\n",
      "\n",
      "\n",
      "Epoch 263/750 - Train Cd Loss: 0.083782 - Test Loss: 0.057988\n",
      "Epoch 263/750 - Train pg Loss: 9.828590 - Test Loss: 2.793298\n",
      "\n",
      "\n",
      "Epoch 264/750 - Train Cd Loss: 0.082996 - Test Loss: 0.059304\n",
      "Epoch 264/750 - Train pg Loss: 10.112779 - Test Loss: 2.693372\n",
      "\n",
      "\n",
      "Epoch 265/750 - Train Cd Loss: 0.086322 - Test Loss: 0.061086\n",
      "Epoch 265/750 - Train pg Loss: 9.798221 - Test Loss: 2.185009\n",
      "\n",
      "\n",
      "Epoch 266/750 - Train Cd Loss: 0.089987 - Test Loss: 0.060120\n",
      "Epoch 266/750 - Train pg Loss: 8.652561 - Test Loss: 2.424904\n",
      "\n",
      "\n",
      "Epoch 267/750 - Train Cd Loss: 0.098953 - Test Loss: 0.059530\n",
      "Epoch 267/750 - Train pg Loss: 9.291664 - Test Loss: 2.242650\n",
      "\n",
      "\n",
      "Epoch 268/750 - Train Cd Loss: 0.089077 - Test Loss: 0.059434\n",
      "Epoch 268/750 - Train pg Loss: 7.658514 - Test Loss: 2.179433\n",
      "\n",
      "\n",
      "Epoch 269/750 - Train Cd Loss: 0.083940 - Test Loss: 0.058828\n",
      "Epoch 269/750 - Train pg Loss: 8.430838 - Test Loss: 2.188725\n",
      "\n",
      "\n",
      "Epoch 270/750 - Train Cd Loss: 0.086312 - Test Loss: 0.060469\n",
      "Epoch 270/750 - Train pg Loss: 6.790186 - Test Loss: 1.932425\n",
      "\n",
      "\n",
      "Epoch 271/750 - Train Cd Loss: 0.086901 - Test Loss: 0.059871\n",
      "Epoch 271/750 - Train pg Loss: 7.576083 - Test Loss: 2.287717\n",
      "\n",
      "\n",
      "Epoch 272/750 - Train Cd Loss: 0.081425 - Test Loss: 0.059736\n",
      "Epoch 272/750 - Train pg Loss: 7.509379 - Test Loss: 1.930070\n",
      "\n",
      "\n",
      "Epoch 273/750 - Train Cd Loss: 0.090396 - Test Loss: 0.059975\n",
      "Epoch 273/750 - Train pg Loss: 8.227242 - Test Loss: 2.423240\n",
      "\n",
      "\n",
      "Epoch 274/750 - Train Cd Loss: 0.089665 - Test Loss: 0.060287\n",
      "Epoch 274/750 - Train pg Loss: 10.124080 - Test Loss: 3.161281\n",
      "\n",
      "\n",
      "Epoch 275/750 - Train Cd Loss: 0.083218 - Test Loss: 0.059390\n",
      "Epoch 275/750 - Train pg Loss: 11.420097 - Test Loss: 3.012425\n",
      "\n",
      "\n",
      "Epoch 276/750 - Train Cd Loss: 0.082356 - Test Loss: 0.061522\n",
      "Epoch 276/750 - Train pg Loss: 9.680359 - Test Loss: 2.811823\n",
      "\n",
      "\n",
      "Epoch 277/750 - Train Cd Loss: 0.082290 - Test Loss: 0.061844\n",
      "Epoch 277/750 - Train pg Loss: 10.124678 - Test Loss: 2.668173\n",
      "\n",
      "\n",
      "Epoch 278/750 - Train Cd Loss: 0.083814 - Test Loss: 0.062448\n",
      "Epoch 278/750 - Train pg Loss: 9.036468 - Test Loss: 2.937080\n",
      "\n",
      "\n",
      "Epoch 279/750 - Train Cd Loss: 0.080567 - Test Loss: nan\n",
      "Epoch 279/750 - Train pg Loss: 11.068663 - Test Loss: 3.650952\n",
      "\n",
      "\n",
      "Epoch 280/750 - Train Cd Loss: 0.078747 - Test Loss: 0.061756\n",
      "Epoch 280/750 - Train pg Loss: 8.893977 - Test Loss: 2.566884\n",
      "\n",
      "\n",
      "Epoch 281/750 - Train Cd Loss: 0.082340 - Test Loss: nan\n",
      "Epoch 281/750 - Train pg Loss: 9.233538 - Test Loss: 3.414633\n",
      "\n",
      "\n",
      "Epoch 282/750 - Train Cd Loss: 0.080772 - Test Loss: 0.061580\n",
      "Epoch 282/750 - Train pg Loss: 9.746747 - Test Loss: 2.886144\n",
      "\n",
      "\n",
      "Epoch 283/750 - Train Cd Loss: 0.090360 - Test Loss: 0.059536\n",
      "Epoch 283/750 - Train pg Loss: 9.868896 - Test Loss: 2.939364\n",
      "\n",
      "\n",
      "Epoch 284/750 - Train Cd Loss: 0.079188 - Test Loss: 0.062063\n",
      "Epoch 284/750 - Train pg Loss: 10.662232 - Test Loss: 3.022414\n",
      "\n",
      "\n",
      "Epoch 285/750 - Train Cd Loss: 0.083349 - Test Loss: 0.060614\n",
      "Epoch 285/750 - Train pg Loss: 9.982557 - Test Loss: 2.915873\n",
      "\n",
      "\n",
      "Epoch 286/750 - Train Cd Loss: 0.085360 - Test Loss: 0.057820\n",
      "Epoch 286/750 - Train pg Loss: 8.938548 - Test Loss: 2.635010\n",
      "\n",
      "\n",
      "Epoch 287/750 - Train Cd Loss: 0.082944 - Test Loss: 0.062187\n",
      "Epoch 287/750 - Train pg Loss: 8.538911 - Test Loss: 2.420920\n",
      "\n",
      "\n",
      "Epoch 288/750 - Train Cd Loss: 0.080894 - Test Loss: 0.061603\n",
      "Epoch 288/750 - Train pg Loss: 8.830639 - Test Loss: 2.634123\n",
      "\n",
      "\n",
      "Epoch 289/750 - Train Cd Loss: 0.080621 - Test Loss: 0.061375\n",
      "Epoch 289/750 - Train pg Loss: 9.003377 - Test Loss: 2.865723\n",
      "\n",
      "\n",
      "Epoch 290/750 - Train Cd Loss: 0.082311 - Test Loss: 0.063292\n",
      "Epoch 290/750 - Train pg Loss: 11.618937 - Test Loss: 3.249082\n",
      "\n",
      "\n",
      "Epoch 291/750 - Train Cd Loss: 0.077723 - Test Loss: nan\n",
      "Epoch 291/750 - Train pg Loss: 11.719628 - Test Loss: 4.060705\n",
      "\n",
      "\n",
      "Epoch 292/750 - Train Cd Loss: 0.080408 - Test Loss: nan\n",
      "Epoch 292/750 - Train pg Loss: 11.081642 - Test Loss: 3.721589\n",
      "\n",
      "\n",
      "Epoch 293/750 - Train Cd Loss: 0.082040 - Test Loss: 0.058398\n",
      "Epoch 293/750 - Train pg Loss: 9.934093 - Test Loss: 2.748490\n",
      "\n",
      "\n",
      "Epoch 294/750 - Train Cd Loss: 0.090910 - Test Loss: 0.063970\n",
      "Epoch 294/750 - Train pg Loss: 10.629136 - Test Loss: 2.639416\n",
      "\n",
      "\n",
      "Epoch 295/750 - Train Cd Loss: 0.084215 - Test Loss: 0.060064\n",
      "Epoch 295/750 - Train pg Loss: 9.499957 - Test Loss: 2.963043\n",
      "\n",
      "\n",
      "Epoch 296/750 - Train Cd Loss: 0.082091 - Test Loss: 0.061071\n",
      "Epoch 296/750 - Train pg Loss: 9.701318 - Test Loss: 2.871160\n",
      "\n",
      "\n",
      "Epoch 297/750 - Train Cd Loss: 0.096253 - Test Loss: 0.064061\n",
      "Epoch 297/750 - Train pg Loss: 11.368270 - Test Loss: 3.047862\n",
      "\n",
      "\n",
      "Epoch 298/750 - Train Cd Loss: 0.082996 - Test Loss: 0.061446\n",
      "Epoch 298/750 - Train pg Loss: 11.298164 - Test Loss: 3.229324\n",
      "\n",
      "\n",
      "Epoch 299/750 - Train Cd Loss: 0.082409 - Test Loss: 0.064657\n",
      "Epoch 299/750 - Train pg Loss: 11.932808 - Test Loss: 3.111265\n",
      "\n",
      "\n",
      "Epoch 300/750 - Train Cd Loss: 0.081091 - Test Loss: 0.063827\n",
      "Epoch 300/750 - Train pg Loss: 10.692763 - Test Loss: 3.030220\n",
      "\n",
      "\n",
      "Epoch 301/750 - Train Cd Loss: 0.081057 - Test Loss: nan\n",
      "Epoch 301/750 - Train pg Loss: 9.736869 - Test Loss: 3.251604\n",
      "\n",
      "\n",
      "Epoch 302/750 - Train Cd Loss: 0.083115 - Test Loss: nan\n",
      "Epoch 302/750 - Train pg Loss: 7.999448 - Test Loss: 2.943496\n",
      "\n",
      "\n",
      "Epoch 303/750 - Train Cd Loss: 0.084414 - Test Loss: 0.060732\n",
      "Epoch 303/750 - Train pg Loss: 7.336833 - Test Loss: 2.479681\n",
      "\n",
      "\n",
      "Epoch 304/750 - Train Cd Loss: 0.079997 - Test Loss: 0.061865\n",
      "Epoch 304/750 - Train pg Loss: 9.702621 - Test Loss: 2.623176\n",
      "\n",
      "\n",
      "Epoch 305/750 - Train Cd Loss: 0.101548 - Test Loss: 0.060019\n",
      "Epoch 305/750 - Train pg Loss: 8.312380 - Test Loss: 2.422283\n",
      "\n",
      "\n",
      "Epoch 306/750 - Train Cd Loss: 0.077206 - Test Loss: 0.057070\n",
      "Epoch 306/750 - Train pg Loss: 7.717193 - Test Loss: 2.399793\n",
      "\n",
      "\n",
      "Epoch 307/750 - Train Cd Loss: 0.079835 - Test Loss: 0.058508\n",
      "Epoch 307/750 - Train pg Loss: 6.747559 - Test Loss: 2.091096\n",
      "\n",
      "\n",
      "Epoch 308/750 - Train Cd Loss: 0.075137 - Test Loss: 0.061304\n",
      "Epoch 308/750 - Train pg Loss: 7.348674 - Test Loss: 2.173379\n",
      "\n",
      "\n",
      "Epoch 309/750 - Train Cd Loss: 0.073546 - Test Loss: 0.061663\n",
      "Epoch 309/750 - Train pg Loss: 7.159724 - Test Loss: 2.175904\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 310/750 - Train Cd Loss: 0.076758 - Test Loss: nan\n",
      "Epoch 310/750 - Train pg Loss: 7.696146 - Test Loss: 3.396444\n",
      "\n",
      "\n",
      "Epoch 311/750 - Train Cd Loss: 0.070980 - Test Loss: nan\n",
      "Epoch 311/750 - Train pg Loss: 7.687209 - Test Loss: 3.338471\n",
      "\n",
      "\n",
      "Epoch 312/750 - Train Cd Loss: 0.071014 - Test Loss: nan\n",
      "Epoch 312/750 - Train pg Loss: 8.678522 - Test Loss: 3.600755\n",
      "\n",
      "\n",
      "Epoch 313/750 - Train Cd Loss: 0.078695 - Test Loss: 0.062616\n",
      "Epoch 313/750 - Train pg Loss: 8.617341 - Test Loss: 2.690498\n",
      "\n",
      "\n",
      "Epoch 314/750 - Train Cd Loss: 0.073641 - Test Loss: 0.062448\n",
      "Epoch 314/750 - Train pg Loss: 10.475312 - Test Loss: 2.790665\n",
      "\n",
      "\n",
      "Epoch 315/750 - Train Cd Loss: 0.075313 - Test Loss: nan\n",
      "Epoch 315/750 - Train pg Loss: 9.940371 - Test Loss: 2.949429\n",
      "\n",
      "\n",
      "Epoch 316/750 - Train Cd Loss: 0.091502 - Test Loss: 0.061188\n",
      "Epoch 316/750 - Train pg Loss: 10.977654 - Test Loss: 3.168777\n",
      "\n",
      "\n",
      "Epoch 317/750 - Train Cd Loss: 0.070351 - Test Loss: 0.062997\n",
      "Epoch 317/750 - Train pg Loss: 11.138905 - Test Loss: 4.016303\n",
      "\n",
      "\n",
      "Epoch 318/750 - Train Cd Loss: 0.078078 - Test Loss: 0.062771\n",
      "Epoch 318/750 - Train pg Loss: 12.987763 - Test Loss: 4.260649\n",
      "\n",
      "\n",
      "Epoch 319/750 - Train Cd Loss: 0.077509 - Test Loss: nan\n",
      "Epoch 319/750 - Train pg Loss: 16.054893 - Test Loss: 4.766908\n",
      "\n",
      "\n",
      "Epoch 320/750 - Train Cd Loss: 0.081214 - Test Loss: 0.061875\n",
      "Epoch 320/750 - Train pg Loss: 15.505119 - Test Loss: 4.552666\n",
      "\n",
      "\n",
      "Epoch 321/750 - Train Cd Loss: 0.074700 - Test Loss: nan\n",
      "Epoch 321/750 - Train pg Loss: 14.098834 - Test Loss: 4.697293\n",
      "\n",
      "\n",
      "Epoch 322/750 - Train Cd Loss: 0.076145 - Test Loss: 0.063462\n",
      "Epoch 322/750 - Train pg Loss: 12.547743 - Test Loss: 3.607424\n",
      "\n",
      "\n",
      "Epoch 323/750 - Train Cd Loss: 0.075093 - Test Loss: nan\n",
      "Epoch 323/750 - Train pg Loss: 11.881474 - Test Loss: 4.300042\n",
      "\n",
      "\n",
      "Epoch 324/750 - Train Cd Loss: 0.080614 - Test Loss: nan\n",
      "Epoch 324/750 - Train pg Loss: 11.208954 - Test Loss: 4.019895\n",
      "\n",
      "\n",
      "Epoch 325/750 - Train Cd Loss: 0.074547 - Test Loss: nan\n",
      "Epoch 325/750 - Train pg Loss: 10.619515 - Test Loss: 4.123102\n",
      "\n",
      "\n",
      "Epoch 326/750 - Train Cd Loss: 0.074953 - Test Loss: nan\n",
      "Epoch 326/750 - Train pg Loss: 9.852128 - Test Loss: 3.744880\n",
      "\n",
      "\n",
      "Epoch 327/750 - Train Cd Loss: 0.077175 - Test Loss: 0.062412\n",
      "Epoch 327/750 - Train pg Loss: 11.883089 - Test Loss: 3.123086\n",
      "\n",
      "\n",
      "Epoch 328/750 - Train Cd Loss: 0.077163 - Test Loss: 0.062597\n",
      "Epoch 328/750 - Train pg Loss: 10.091115 - Test Loss: 3.221352\n",
      "\n",
      "\n",
      "Epoch 329/750 - Train Cd Loss: 0.070273 - Test Loss: 0.061944\n",
      "Epoch 329/750 - Train pg Loss: 11.040249 - Test Loss: 3.246616\n",
      "\n",
      "\n",
      "Epoch 330/750 - Train Cd Loss: 0.067439 - Test Loss: 0.063652\n",
      "Epoch 330/750 - Train pg Loss: 11.308119 - Test Loss: 3.391589\n",
      "\n",
      "\n",
      "Epoch 331/750 - Train Cd Loss: 0.070287 - Test Loss: nan\n",
      "Epoch 331/750 - Train pg Loss: 11.038791 - Test Loss: 3.927821\n",
      "\n",
      "\n",
      "Epoch 332/750 - Train Cd Loss: 0.076616 - Test Loss: 0.064244\n",
      "Epoch 332/750 - Train pg Loss: 11.427085 - Test Loss: 3.083156\n",
      "\n",
      "\n",
      "Epoch 333/750 - Train Cd Loss: 0.082527 - Test Loss: 0.062017\n",
      "Epoch 333/750 - Train pg Loss: 10.260633 - Test Loss: 2.750715\n",
      "\n",
      "\n",
      "Epoch 334/750 - Train Cd Loss: 0.072651 - Test Loss: 0.064378\n",
      "Epoch 334/750 - Train pg Loss: 10.143316 - Test Loss: 3.206783\n",
      "\n",
      "\n",
      "Epoch 335/750 - Train Cd Loss: 0.071705 - Test Loss: 0.066425\n",
      "Epoch 335/750 - Train pg Loss: 11.111379 - Test Loss: 3.244168\n",
      "\n",
      "\n",
      "Epoch 336/750 - Train Cd Loss: 0.069696 - Test Loss: 0.063924\n",
      "Epoch 336/750 - Train pg Loss: 11.586120 - Test Loss: 3.321699\n",
      "\n",
      "\n",
      "Epoch 337/750 - Train Cd Loss: 0.071628 - Test Loss: nan\n",
      "Epoch 337/750 - Train pg Loss: 11.600949 - Test Loss: 3.344564\n",
      "\n",
      "\n",
      "Epoch 338/750 - Train Cd Loss: 0.073198 - Test Loss: 0.063402\n",
      "Epoch 338/750 - Train pg Loss: 13.034746 - Test Loss: 3.413357\n",
      "\n",
      "\n",
      "Epoch 339/750 - Train Cd Loss: 0.068563 - Test Loss: 0.063012\n",
      "Epoch 339/750 - Train pg Loss: 10.742640 - Test Loss: 3.405683\n",
      "\n",
      "\n",
      "Epoch 340/750 - Train Cd Loss: 0.085984 - Test Loss: 0.064829\n",
      "Epoch 340/750 - Train pg Loss: 13.811241 - Test Loss: 3.853034\n",
      "\n",
      "\n",
      "Epoch 341/750 - Train Cd Loss: 0.071791 - Test Loss: 0.063289\n",
      "Epoch 341/750 - Train pg Loss: 13.221063 - Test Loss: 3.590429\n",
      "\n",
      "\n",
      "Epoch 342/750 - Train Cd Loss: 0.069503 - Test Loss: nan\n",
      "Epoch 342/750 - Train pg Loss: 11.736717 - Test Loss: 3.274092\n",
      "\n",
      "\n",
      "Epoch 343/750 - Train Cd Loss: 0.071220 - Test Loss: 0.063448\n",
      "Epoch 343/750 - Train pg Loss: 10.189414 - Test Loss: 3.383599\n",
      "\n",
      "\n",
      "Epoch 344/750 - Train Cd Loss: 0.090356 - Test Loss: 0.064420\n",
      "Epoch 344/750 - Train pg Loss: 11.569587 - Test Loss: 3.626584\n",
      "\n",
      "\n",
      "Epoch 345/750 - Train Cd Loss: 0.074471 - Test Loss: 0.063467\n",
      "Epoch 345/750 - Train pg Loss: 11.411079 - Test Loss: 3.713608\n",
      "\n",
      "\n",
      "Epoch 346/750 - Train Cd Loss: 0.072341 - Test Loss: 0.062187\n",
      "Epoch 346/750 - Train pg Loss: 13.325884 - Test Loss: 3.430352\n",
      "\n",
      "\n",
      "Epoch 347/750 - Train Cd Loss: 0.081295 - Test Loss: nan\n",
      "Epoch 347/750 - Train pg Loss: 10.075971 - Test Loss: 3.754884\n",
      "\n",
      "\n",
      "Epoch 348/750 - Train Cd Loss: 0.069954 - Test Loss: 0.063871\n",
      "Epoch 348/750 - Train pg Loss: 11.937610 - Test Loss: 3.217351\n",
      "\n",
      "\n",
      "Epoch 349/750 - Train Cd Loss: 0.072027 - Test Loss: 0.064324\n",
      "Epoch 349/750 - Train pg Loss: 11.184414 - Test Loss: 3.590102\n",
      "\n",
      "\n",
      "Epoch 350/750 - Train Cd Loss: 0.063223 - Test Loss: 0.065297\n",
      "Epoch 350/750 - Train pg Loss: 12.665071 - Test Loss: 3.898464\n",
      "\n",
      "\n",
      "Epoch 351/750 - Train Cd Loss: 0.075978 - Test Loss: 0.068219\n",
      "Epoch 351/750 - Train pg Loss: 14.325291 - Test Loss: 3.501621\n",
      "\n",
      "\n",
      "Epoch 352/750 - Train Cd Loss: 0.072506 - Test Loss: 0.062248\n",
      "Epoch 352/750 - Train pg Loss: 11.872897 - Test Loss: 3.359193\n",
      "\n",
      "\n",
      "Epoch 353/750 - Train Cd Loss: 0.062984 - Test Loss: 0.059615\n",
      "Epoch 353/750 - Train pg Loss: 10.130808 - Test Loss: 3.110059\n",
      "\n",
      "\n",
      "Epoch 354/750 - Train Cd Loss: 0.094848 - Test Loss: 0.066853\n",
      "Epoch 354/750 - Train pg Loss: 14.946101 - Test Loss: 3.875072\n",
      "\n",
      "\n",
      "Epoch 355/750 - Train Cd Loss: 0.069810 - Test Loss: 0.061924\n",
      "Epoch 355/750 - Train pg Loss: 13.113685 - Test Loss: 4.049908\n",
      "\n",
      "\n",
      "Epoch 356/750 - Train Cd Loss: 0.072746 - Test Loss: 0.062744\n",
      "Epoch 356/750 - Train pg Loss: 14.687850 - Test Loss: 3.875666\n",
      "\n",
      "\n",
      "Epoch 357/750 - Train Cd Loss: 0.067266 - Test Loss: 0.064984\n",
      "Epoch 357/750 - Train pg Loss: 12.641594 - Test Loss: 3.809624\n",
      "\n",
      "\n",
      "Epoch 358/750 - Train Cd Loss: 0.071467 - Test Loss: nan\n",
      "Epoch 358/750 - Train pg Loss: 13.484921 - Test Loss: 4.999924\n",
      "\n",
      "\n",
      "Epoch 359/750 - Train Cd Loss: 0.072688 - Test Loss: 0.067200\n",
      "Epoch 359/750 - Train pg Loss: 14.171135 - Test Loss: 3.453669\n",
      "\n",
      "\n",
      "Epoch 360/750 - Train Cd Loss: 0.075122 - Test Loss: nan\n",
      "Epoch 360/750 - Train pg Loss: 10.618383 - Test Loss: 4.269012\n",
      "\n",
      "\n",
      "Epoch 361/750 - Train Cd Loss: 0.069344 - Test Loss: 0.062714\n",
      "Epoch 361/750 - Train pg Loss: 11.568238 - Test Loss: 3.482312\n",
      "\n",
      "\n",
      "Epoch 362/750 - Train Cd Loss: 0.063828 - Test Loss: nan\n",
      "Epoch 362/750 - Train pg Loss: 12.019174 - Test Loss: 5.337702\n",
      "\n",
      "\n",
      "Epoch 363/750 - Train Cd Loss: 0.069017 - Test Loss: nan\n",
      "Epoch 363/750 - Train pg Loss: 12.701155 - Test Loss: 4.039325\n",
      "\n",
      "\n",
      "Epoch 364/750 - Train Cd Loss: 0.064698 - Test Loss: nan\n",
      "Epoch 364/750 - Train pg Loss: 11.493201 - Test Loss: 4.579398\n",
      "\n",
      "\n",
      "Epoch 365/750 - Train Cd Loss: 0.071552 - Test Loss: nan\n",
      "Epoch 365/750 - Train pg Loss: 10.998930 - Test Loss: 4.598453\n",
      "\n",
      "\n",
      "Epoch 366/750 - Train Cd Loss: 0.068072 - Test Loss: 0.064708\n",
      "Epoch 366/750 - Train pg Loss: 11.849834 - Test Loss: 3.698400\n",
      "\n",
      "\n",
      "Epoch 367/750 - Train Cd Loss: 0.071169 - Test Loss: 0.063330\n",
      "Epoch 367/750 - Train pg Loss: 12.425583 - Test Loss: 3.755339\n",
      "\n",
      "\n",
      "Epoch 368/750 - Train Cd Loss: 0.068247 - Test Loss: 0.064721\n",
      "Epoch 368/750 - Train pg Loss: 11.624877 - Test Loss: 2.935993\n",
      "\n",
      "\n",
      "Epoch 369/750 - Train Cd Loss: 0.069296 - Test Loss: nan\n",
      "Epoch 369/750 - Train pg Loss: 11.624901 - Test Loss: 4.710499\n",
      "\n",
      "\n",
      "Epoch 370/750 - Train Cd Loss: 0.072934 - Test Loss: 0.065806\n",
      "Epoch 370/750 - Train pg Loss: 15.501385 - Test Loss: 3.942261\n",
      "\n",
      "\n",
      "Epoch 371/750 - Train Cd Loss: 0.065410 - Test Loss: 0.064705\n",
      "Epoch 371/750 - Train pg Loss: 12.738116 - Test Loss: 4.074681\n",
      "\n",
      "\n",
      "Epoch 372/750 - Train Cd Loss: 0.064327 - Test Loss: nan\n",
      "Epoch 372/750 - Train pg Loss: 12.128938 - Test Loss: 4.716234\n",
      "\n",
      "\n",
      "Epoch 373/750 - Train Cd Loss: 0.059892 - Test Loss: nan\n",
      "Epoch 373/750 - Train pg Loss: 12.177626 - Test Loss: 4.923458\n",
      "\n",
      "\n",
      "Epoch 374/750 - Train Cd Loss: 0.064877 - Test Loss: nan\n",
      "Epoch 374/750 - Train pg Loss: 14.006372 - Test Loss: 5.494711\n",
      "\n",
      "\n",
      "Epoch 375/750 - Train Cd Loss: 0.076904 - Test Loss: 0.066247\n",
      "Epoch 375/750 - Train pg Loss: 17.184250 - Test Loss: 5.024055\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376/750 - Train Cd Loss: 0.078131 - Test Loss: 0.064702\n",
      "Epoch 376/750 - Train pg Loss: 16.068178 - Test Loss: 4.596506\n",
      "\n",
      "\n",
      "Epoch 377/750 - Train Cd Loss: 0.065349 - Test Loss: 0.063904\n",
      "Epoch 377/750 - Train pg Loss: 13.345119 - Test Loss: 3.868139\n",
      "\n",
      "\n",
      "Epoch 378/750 - Train Cd Loss: 0.059493 - Test Loss: nan\n",
      "Epoch 378/750 - Train pg Loss: 12.514260 - Test Loss: 4.827991\n",
      "\n",
      "\n",
      "Epoch 379/750 - Train Cd Loss: 0.072349 - Test Loss: 0.065928\n",
      "Epoch 379/750 - Train pg Loss: 12.775508 - Test Loss: 3.898841\n",
      "\n",
      "\n",
      "Epoch 380/750 - Train Cd Loss: 0.064637 - Test Loss: 0.067048\n",
      "Epoch 380/750 - Train pg Loss: 13.473322 - Test Loss: 3.972802\n",
      "\n",
      "\n",
      "Epoch 381/750 - Train Cd Loss: 0.067797 - Test Loss: 0.063442\n",
      "Epoch 381/750 - Train pg Loss: 12.761890 - Test Loss: 3.794435\n",
      "\n",
      "\n",
      "Epoch 382/750 - Train Cd Loss: 0.063186 - Test Loss: nan\n",
      "Epoch 382/750 - Train pg Loss: 12.650569 - Test Loss: 4.888173\n",
      "\n",
      "\n",
      "Epoch 383/750 - Train Cd Loss: 0.063938 - Test Loss: nan\n",
      "Epoch 383/750 - Train pg Loss: 15.330564 - Test Loss: 5.414798\n",
      "\n",
      "\n",
      "Epoch 384/750 - Train Cd Loss: 0.060624 - Test Loss: 0.065759\n",
      "Epoch 384/750 - Train pg Loss: 15.125526 - Test Loss: 4.317824\n",
      "\n",
      "\n",
      "Epoch 385/750 - Train Cd Loss: 0.065072 - Test Loss: nan\n",
      "Epoch 385/750 - Train pg Loss: 13.438762 - Test Loss: 4.650143\n",
      "\n",
      "\n",
      "Epoch 386/750 - Train Cd Loss: 0.081156 - Test Loss: 0.067395\n",
      "Epoch 386/750 - Train pg Loss: 12.672655 - Test Loss: 4.154418\n",
      "\n",
      "\n",
      "Epoch 387/750 - Train Cd Loss: 0.070392 - Test Loss: nan\n",
      "Epoch 387/750 - Train pg Loss: 15.150031 - Test Loss: 5.796550\n",
      "\n",
      "\n",
      "Epoch 388/750 - Train Cd Loss: 0.065369 - Test Loss: 0.067400\n",
      "Epoch 388/750 - Train pg Loss: 15.523808 - Test Loss: 4.454372\n",
      "\n",
      "\n",
      "Epoch 389/750 - Train Cd Loss: 0.065180 - Test Loss: 0.065248\n",
      "Epoch 389/750 - Train pg Loss: 14.561502 - Test Loss: 4.559206\n",
      "\n",
      "\n",
      "Epoch 390/750 - Train Cd Loss: 0.061325 - Test Loss: 0.063615\n",
      "Epoch 390/750 - Train pg Loss: 15.039914 - Test Loss: 4.020243\n",
      "\n",
      "\n",
      "Epoch 391/750 - Train Cd Loss: 0.069520 - Test Loss: nan\n",
      "Epoch 391/750 - Train pg Loss: 12.610393 - Test Loss: 4.832096\n",
      "\n",
      "\n",
      "Epoch 392/750 - Train Cd Loss: 0.067862 - Test Loss: 0.062655\n",
      "Epoch 392/750 - Train pg Loss: 13.270527 - Test Loss: 4.016272\n",
      "\n",
      "\n",
      "Epoch 393/750 - Train Cd Loss: 0.066261 - Test Loss: 0.065176\n",
      "Epoch 393/750 - Train pg Loss: 11.869509 - Test Loss: 4.135723\n",
      "\n",
      "\n",
      "Epoch 394/750 - Train Cd Loss: 0.059395 - Test Loss: 0.064443\n",
      "Epoch 394/750 - Train pg Loss: 14.351277 - Test Loss: 4.436837\n",
      "\n",
      "\n",
      "Epoch 395/750 - Train Cd Loss: 0.062575 - Test Loss: nan\n",
      "Epoch 395/750 - Train pg Loss: 13.674891 - Test Loss: 5.421028\n",
      "\n",
      "\n",
      "Epoch 396/750 - Train Cd Loss: 0.065248 - Test Loss: 0.067478\n",
      "Epoch 396/750 - Train pg Loss: 15.690629 - Test Loss: 4.605078\n",
      "\n",
      "\n",
      "Epoch 397/750 - Train Cd Loss: 0.063784 - Test Loss: 0.064651\n",
      "Epoch 397/750 - Train pg Loss: 16.086939 - Test Loss: 4.981768\n",
      "\n",
      "\n",
      "Epoch 398/750 - Train Cd Loss: 0.071667 - Test Loss: 0.068362\n",
      "Epoch 398/750 - Train pg Loss: 18.898422 - Test Loss: 5.647818\n",
      "\n",
      "\n",
      "Epoch 399/750 - Train Cd Loss: 0.065846 - Test Loss: nan\n",
      "Epoch 399/750 - Train pg Loss: 19.872923 - Test Loss: 7.035035\n",
      "\n",
      "\n",
      "Epoch 400/750 - Train Cd Loss: 0.062130 - Test Loss: nan\n",
      "Epoch 400/750 - Train pg Loss: 19.735245 - Test Loss: 5.689534\n",
      "\n",
      "\n",
      "Epoch 401/750 - Train Cd Loss: 0.057120 - Test Loss: nan\n",
      "Epoch 401/750 - Train pg Loss: 18.100386 - Test Loss: 5.851941\n",
      "\n",
      "\n",
      "Epoch 402/750 - Train Cd Loss: 0.058878 - Test Loss: nan\n",
      "Epoch 402/750 - Train pg Loss: 15.653238 - Test Loss: 5.979129\n",
      "\n",
      "\n",
      "Epoch 403/750 - Train Cd Loss: 0.072376 - Test Loss: nan\n",
      "Epoch 403/750 - Train pg Loss: 18.520958 - Test Loss: 5.853066\n",
      "\n",
      "\n",
      "Epoch 404/750 - Train Cd Loss: 0.061730 - Test Loss: 0.063867\n",
      "Epoch 404/750 - Train pg Loss: 17.212862 - Test Loss: 5.060785\n",
      "\n",
      "\n",
      "Epoch 405/750 - Train Cd Loss: 0.058132 - Test Loss: 0.065295\n",
      "Epoch 405/750 - Train pg Loss: 16.055490 - Test Loss: 4.428964\n",
      "\n",
      "\n",
      "Epoch 406/750 - Train Cd Loss: 0.059454 - Test Loss: 0.068288\n",
      "Epoch 406/750 - Train pg Loss: 15.132268 - Test Loss: 4.206809\n",
      "\n",
      "\n",
      "Epoch 407/750 - Train Cd Loss: 0.063307 - Test Loss: 0.063904\n",
      "Epoch 407/750 - Train pg Loss: 15.723860 - Test Loss: 4.400033\n",
      "\n",
      "\n",
      "Epoch 408/750 - Train Cd Loss: 0.069328 - Test Loss: 0.065557\n",
      "Epoch 408/750 - Train pg Loss: 16.409702 - Test Loss: 4.466210\n",
      "\n",
      "\n",
      "Epoch 409/750 - Train Cd Loss: 0.060771 - Test Loss: 0.060373\n",
      "Epoch 409/750 - Train pg Loss: 14.532626 - Test Loss: 4.525400\n",
      "\n",
      "\n",
      "Epoch 410/750 - Train Cd Loss: 0.063719 - Test Loss: nan\n",
      "Epoch 410/750 - Train pg Loss: 16.732471 - Test Loss: 6.034095\n",
      "\n",
      "\n",
      "Epoch 411/750 - Train Cd Loss: 0.063260 - Test Loss: 0.066278\n",
      "Epoch 411/750 - Train pg Loss: 20.101269 - Test Loss: 6.347052\n",
      "\n",
      "\n",
      "Epoch 412/750 - Train Cd Loss: 0.059970 - Test Loss: nan\n",
      "Epoch 412/750 - Train pg Loss: 21.383915 - Test Loss: 7.412562\n",
      "\n",
      "\n",
      "Epoch 413/750 - Train Cd Loss: 0.063995 - Test Loss: 0.065669\n",
      "Epoch 413/750 - Train pg Loss: 20.031664 - Test Loss: 5.622617\n",
      "\n",
      "\n",
      "Epoch 414/750 - Train Cd Loss: 0.061421 - Test Loss: 0.066923\n",
      "Epoch 414/750 - Train pg Loss: 18.577394 - Test Loss: 5.528181\n",
      "\n",
      "\n",
      "Epoch 415/750 - Train Cd Loss: 0.076137 - Test Loss: nan\n",
      "Epoch 415/750 - Train pg Loss: 17.932196 - Test Loss: 5.722824\n",
      "\n",
      "\n",
      "Epoch 416/750 - Train Cd Loss: 0.052683 - Test Loss: 0.065562\n",
      "Epoch 416/750 - Train pg Loss: 17.710068 - Test Loss: 5.837491\n",
      "\n",
      "\n",
      "Epoch 417/750 - Train Cd Loss: 0.055181 - Test Loss: nan\n",
      "Epoch 417/750 - Train pg Loss: 16.495930 - Test Loss: 7.454419\n",
      "\n",
      "\n",
      "Epoch 418/750 - Train Cd Loss: 0.076552 - Test Loss: 0.065379\n",
      "Epoch 418/750 - Train pg Loss: 21.323298 - Test Loss: 5.630937\n",
      "\n",
      "\n",
      "Epoch 419/750 - Train Cd Loss: 0.057891 - Test Loss: nan\n",
      "Epoch 419/750 - Train pg Loss: 17.397772 - Test Loss: 5.823086\n",
      "\n",
      "\n",
      "Epoch 420/750 - Train Cd Loss: 0.054735 - Test Loss: 0.066105\n",
      "Epoch 420/750 - Train pg Loss: 18.318056 - Test Loss: 5.711173\n",
      "\n",
      "\n",
      "Epoch 421/750 - Train Cd Loss: 0.087676 - Test Loss: 0.063807\n",
      "Epoch 421/750 - Train pg Loss: 18.819859 - Test Loss: 5.439628\n",
      "\n",
      "\n",
      "Epoch 422/750 - Train Cd Loss: 0.058552 - Test Loss: 0.062878\n",
      "Epoch 422/750 - Train pg Loss: 18.987858 - Test Loss: 5.270185\n",
      "\n",
      "\n",
      "Epoch 423/750 - Train Cd Loss: 0.055323 - Test Loss: nan\n",
      "Epoch 423/750 - Train pg Loss: 14.983232 - Test Loss: 5.369678\n",
      "\n",
      "\n",
      "Epoch 424/750 - Train Cd Loss: 0.047396 - Test Loss: nan\n",
      "Epoch 424/750 - Train pg Loss: 18.397970 - Test Loss: 6.366591\n",
      "\n",
      "\n",
      "Epoch 425/750 - Train Cd Loss: 0.056320 - Test Loss: nan\n",
      "Epoch 425/750 - Train pg Loss: 18.812630 - Test Loss: 6.206896\n",
      "\n",
      "\n",
      "Epoch 426/750 - Train Cd Loss: 0.065768 - Test Loss: nan\n",
      "Epoch 426/750 - Train pg Loss: 18.672087 - Test Loss: 5.776154\n",
      "\n",
      "\n",
      "Epoch 427/750 - Train Cd Loss: 0.055552 - Test Loss: 0.066356\n",
      "Epoch 427/750 - Train pg Loss: 18.756546 - Test Loss: 5.108141\n",
      "\n",
      "\n",
      "Epoch 428/750 - Train Cd Loss: 0.058175 - Test Loss: 0.065587\n",
      "Epoch 428/750 - Train pg Loss: 15.541680 - Test Loss: 4.599232\n",
      "\n",
      "\n",
      "Epoch 429/750 - Train Cd Loss: 0.070073 - Test Loss: 0.068247\n",
      "Epoch 429/750 - Train pg Loss: 17.207314 - Test Loss: 5.432142\n",
      "\n",
      "\n",
      "Epoch 430/750 - Train Cd Loss: 0.059827 - Test Loss: nan\n",
      "Epoch 430/750 - Train pg Loss: 18.234402 - Test Loss: 5.963750\n",
      "\n",
      "\n",
      "Epoch 431/750 - Train Cd Loss: 0.054376 - Test Loss: nan\n",
      "Epoch 431/750 - Train pg Loss: 16.754873 - Test Loss: 5.312536\n",
      "\n",
      "\n",
      "Epoch 432/750 - Train Cd Loss: 0.053719 - Test Loss: 0.066729\n",
      "Epoch 432/750 - Train pg Loss: 16.590343 - Test Loss: 5.253404\n",
      "\n",
      "\n",
      "Epoch 433/750 - Train Cd Loss: 0.056378 - Test Loss: nan\n",
      "Epoch 433/750 - Train pg Loss: 18.733538 - Test Loss: 6.472658\n",
      "\n",
      "\n",
      "Epoch 434/750 - Train Cd Loss: 0.059192 - Test Loss: nan\n",
      "Epoch 434/750 - Train pg Loss: 16.836754 - Test Loss: 5.605953\n",
      "\n",
      "\n",
      "Epoch 435/750 - Train Cd Loss: 0.069923 - Test Loss: nan\n",
      "Epoch 435/750 - Train pg Loss: 17.132256 - Test Loss: 5.665887\n",
      "\n",
      "\n",
      "Epoch 436/750 - Train Cd Loss: 0.055349 - Test Loss: 0.065152\n",
      "Epoch 436/750 - Train pg Loss: 17.137718 - Test Loss: 5.170842\n",
      "\n",
      "\n",
      "Epoch 437/750 - Train Cd Loss: 0.049566 - Test Loss: nan\n",
      "Epoch 437/750 - Train pg Loss: 15.180745 - Test Loss: 5.181316\n",
      "\n",
      "\n",
      "Epoch 438/750 - Train Cd Loss: 0.059592 - Test Loss: 0.065344\n",
      "Epoch 438/750 - Train pg Loss: 19.712677 - Test Loss: 5.200576\n",
      "\n",
      "\n",
      "Epoch 439/750 - Train Cd Loss: 0.053550 - Test Loss: nan\n",
      "Epoch 439/750 - Train pg Loss: 17.779047 - Test Loss: 6.488206\n",
      "\n",
      "\n",
      "Epoch 440/750 - Train Cd Loss: 0.053776 - Test Loss: nan\n",
      "Epoch 440/750 - Train pg Loss: 17.436390 - Test Loss: 5.716330\n",
      "\n",
      "\n",
      "Epoch 441/750 - Train Cd Loss: 0.051959 - Test Loss: nan\n",
      "Epoch 441/750 - Train pg Loss: 16.045866 - Test Loss: 5.893278\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 442/750 - Train Cd Loss: 0.050462 - Test Loss: nan\n",
      "Epoch 442/750 - Train pg Loss: 16.895779 - Test Loss: 6.282983\n",
      "\n",
      "\n",
      "Epoch 443/750 - Train Cd Loss: 0.083991 - Test Loss: 0.068007\n",
      "Epoch 443/750 - Train pg Loss: 20.332790 - Test Loss: 6.857440\n",
      "\n",
      "\n",
      "Epoch 444/750 - Train Cd Loss: 0.055320 - Test Loss: 0.067360\n",
      "Epoch 444/750 - Train pg Loss: 21.102407 - Test Loss: 6.438538\n",
      "\n",
      "\n",
      "Epoch 445/750 - Train Cd Loss: 0.050034 - Test Loss: nan\n",
      "Epoch 445/750 - Train pg Loss: 19.478094 - Test Loss: 6.574103\n",
      "\n",
      "\n",
      "Epoch 446/750 - Train Cd Loss: 0.059260 - Test Loss: nan\n",
      "Epoch 446/750 - Train pg Loss: 16.872747 - Test Loss: 6.441337\n",
      "\n",
      "\n",
      "Epoch 447/750 - Train Cd Loss: 0.057612 - Test Loss: nan\n",
      "Epoch 447/750 - Train pg Loss: 18.187901 - Test Loss: 6.836168\n",
      "\n",
      "\n",
      "Epoch 448/750 - Train Cd Loss: 0.056327 - Test Loss: nan\n",
      "Epoch 448/750 - Train pg Loss: 20.850033 - Test Loss: 7.127147\n",
      "\n",
      "\n",
      "Epoch 449/750 - Train Cd Loss: 0.053313 - Test Loss: 0.067330\n",
      "Epoch 449/750 - Train pg Loss: 22.365229 - Test Loss: 6.035928\n",
      "\n",
      "\n",
      "Epoch 450/750 - Train Cd Loss: 0.054323 - Test Loss: nan\n",
      "Epoch 450/750 - Train pg Loss: 19.538832 - Test Loss: 7.830301\n",
      "\n",
      "\n",
      "Epoch 451/750 - Train Cd Loss: 0.055058 - Test Loss: nan\n",
      "Epoch 451/750 - Train pg Loss: 20.274254 - Test Loss: 6.852020\n",
      "\n",
      "\n",
      "Epoch 452/750 - Train Cd Loss: 0.068007 - Test Loss: 0.065122\n",
      "Epoch 452/750 - Train pg Loss: 21.024260 - Test Loss: 6.093008\n",
      "\n",
      "\n",
      "Epoch 453/750 - Train Cd Loss: 0.056199 - Test Loss: nan\n",
      "Epoch 453/750 - Train pg Loss: 18.197144 - Test Loss: 6.209698\n",
      "\n",
      "\n",
      "Epoch 454/750 - Train Cd Loss: 0.055099 - Test Loss: nan\n",
      "Epoch 454/750 - Train pg Loss: 15.943791 - Test Loss: 5.322803\n",
      "\n",
      "\n",
      "Epoch 455/750 - Train Cd Loss: 0.052748 - Test Loss: nan\n",
      "Epoch 455/750 - Train pg Loss: 16.300161 - Test Loss: 5.789160\n",
      "\n",
      "\n",
      "Epoch 456/750 - Train Cd Loss: 0.063571 - Test Loss: 0.066377\n",
      "Epoch 456/750 - Train pg Loss: 15.645447 - Test Loss: 4.440473\n",
      "\n",
      "\n",
      "Epoch 457/750 - Train Cd Loss: 0.069026 - Test Loss: 0.063821\n",
      "Epoch 457/750 - Train pg Loss: 14.080400 - Test Loss: 4.556569\n",
      "\n",
      "\n",
      "Epoch 458/750 - Train Cd Loss: 0.055242 - Test Loss: 0.065949\n",
      "Epoch 458/750 - Train pg Loss: 15.164808 - Test Loss: 4.593823\n",
      "\n",
      "\n",
      "Epoch 459/750 - Train Cd Loss: 0.055575 - Test Loss: nan\n",
      "Epoch 459/750 - Train pg Loss: 14.889980 - Test Loss: 6.079732\n",
      "\n",
      "\n",
      "Epoch 460/750 - Train Cd Loss: 0.053337 - Test Loss: nan\n",
      "Epoch 460/750 - Train pg Loss: 17.673473 - Test Loss: 6.150991\n",
      "\n",
      "\n",
      "Epoch 461/750 - Train Cd Loss: 0.054953 - Test Loss: nan\n",
      "Epoch 461/750 - Train pg Loss: 19.051752 - Test Loss: 5.451163\n",
      "\n",
      "\n",
      "Epoch 462/750 - Train Cd Loss: 0.064584 - Test Loss: 0.065951\n",
      "Epoch 462/750 - Train pg Loss: 17.463526 - Test Loss: 5.661215\n",
      "\n",
      "\n",
      "Epoch 463/750 - Train Cd Loss: 0.052346 - Test Loss: 0.066889\n",
      "Epoch 463/750 - Train pg Loss: 20.918926 - Test Loss: 6.334997\n",
      "\n",
      "\n",
      "Epoch 464/750 - Train Cd Loss: 0.056621 - Test Loss: 0.066542\n",
      "Epoch 464/750 - Train pg Loss: 20.203201 - Test Loss: 5.907283\n",
      "\n",
      "\n",
      "Epoch 465/750 - Train Cd Loss: 0.051816 - Test Loss: nan\n",
      "Epoch 465/750 - Train pg Loss: 15.919805 - Test Loss: 6.061441\n",
      "\n",
      "\n",
      "Epoch 466/750 - Train Cd Loss: 0.053095 - Test Loss: nan\n",
      "Epoch 466/750 - Train pg Loss: 17.759365 - Test Loss: 6.004723\n",
      "\n",
      "\n",
      "Epoch 467/750 - Train Cd Loss: 0.047715 - Test Loss: nan\n",
      "Epoch 467/750 - Train pg Loss: 18.285324 - Test Loss: 6.362927\n",
      "\n",
      "\n",
      "Epoch 468/750 - Train Cd Loss: 0.050108 - Test Loss: nan\n",
      "Epoch 468/750 - Train pg Loss: 17.904274 - Test Loss: 7.601801\n",
      "\n",
      "\n",
      "Epoch 469/750 - Train Cd Loss: 0.049490 - Test Loss: nan\n",
      "Epoch 469/750 - Train pg Loss: 18.769871 - Test Loss: 7.249912\n",
      "\n",
      "\n",
      "Epoch 470/750 - Train Cd Loss: 0.079297 - Test Loss: 0.064399\n",
      "Epoch 470/750 - Train pg Loss: 20.820612 - Test Loss: 5.885053\n",
      "\n",
      "\n",
      "Epoch 471/750 - Train Cd Loss: 0.058913 - Test Loss: 0.063588\n",
      "Epoch 471/750 - Train pg Loss: 19.913040 - Test Loss: 5.620195\n",
      "\n",
      "\n",
      "Epoch 472/750 - Train Cd Loss: 0.051026 - Test Loss: 0.063026\n",
      "Epoch 472/750 - Train pg Loss: 17.063421 - Test Loss: 4.543076\n",
      "\n",
      "\n",
      "Epoch 473/750 - Train Cd Loss: 0.053394 - Test Loss: nan\n",
      "Epoch 473/750 - Train pg Loss: 15.099267 - Test Loss: 6.048586\n",
      "\n",
      "\n",
      "Epoch 474/750 - Train Cd Loss: 0.047153 - Test Loss: 0.066258\n",
      "Epoch 474/750 - Train pg Loss: 15.941113 - Test Loss: 5.015414\n",
      "\n",
      "\n",
      "Epoch 475/750 - Train Cd Loss: 0.054379 - Test Loss: nan\n",
      "Epoch 475/750 - Train pg Loss: 16.728458 - Test Loss: 5.853842\n",
      "\n",
      "\n",
      "Epoch 476/750 - Train Cd Loss: 0.044574 - Test Loss: nan\n",
      "Epoch 476/750 - Train pg Loss: 16.860605 - Test Loss: 6.295580\n",
      "\n",
      "\n",
      "Epoch 477/750 - Train Cd Loss: 0.055796 - Test Loss: nan\n",
      "Epoch 477/750 - Train pg Loss: 18.254515 - Test Loss: 5.653051\n",
      "\n",
      "\n",
      "Epoch 478/750 - Train Cd Loss: 0.065476 - Test Loss: 0.066364\n",
      "Epoch 478/750 - Train pg Loss: 18.639957 - Test Loss: 5.393499\n",
      "\n",
      "\n",
      "Epoch 479/750 - Train Cd Loss: 0.043559 - Test Loss: nan\n",
      "Epoch 479/750 - Train pg Loss: 18.932526 - Test Loss: 6.916416\n",
      "\n",
      "\n",
      "Epoch 480/750 - Train Cd Loss: 0.050777 - Test Loss: nan\n",
      "Epoch 480/750 - Train pg Loss: 18.739002 - Test Loss: 5.711020\n",
      "\n",
      "\n",
      "Epoch 481/750 - Train Cd Loss: 0.052943 - Test Loss: nan\n",
      "Epoch 481/750 - Train pg Loss: 20.172619 - Test Loss: 7.582784\n",
      "\n",
      "\n",
      "Epoch 482/750 - Train Cd Loss: 0.060746 - Test Loss: nan\n",
      "Epoch 482/750 - Train pg Loss: 18.031818 - Test Loss: 6.186303\n",
      "\n",
      "\n",
      "Epoch 483/750 - Train Cd Loss: 0.060920 - Test Loss: nan\n",
      "Epoch 483/750 - Train pg Loss: 18.956894 - Test Loss: 6.927350\n",
      "\n",
      "\n",
      "Epoch 484/750 - Train Cd Loss: 0.051778 - Test Loss: nan\n",
      "Epoch 484/750 - Train pg Loss: 17.889656 - Test Loss: 6.113411\n",
      "\n",
      "\n",
      "Epoch 485/750 - Train Cd Loss: 0.056948 - Test Loss: nan\n",
      "Epoch 485/750 - Train pg Loss: 20.535311 - Test Loss: 7.566301\n",
      "\n",
      "\n",
      "Epoch 486/750 - Train Cd Loss: 0.051433 - Test Loss: 0.071018\n",
      "Epoch 486/750 - Train pg Loss: 21.429655 - Test Loss: 5.688613\n",
      "\n",
      "\n",
      "Epoch 487/750 - Train Cd Loss: 0.047602 - Test Loss: nan\n",
      "Epoch 487/750 - Train pg Loss: 18.065704 - Test Loss: 6.248043\n",
      "\n",
      "\n",
      "Epoch 488/750 - Train Cd Loss: 0.040386 - Test Loss: nan\n",
      "Epoch 488/750 - Train pg Loss: 17.346693 - Test Loss: 6.538491\n",
      "\n",
      "\n",
      "Epoch 489/750 - Train Cd Loss: 0.048897 - Test Loss: nan\n",
      "Epoch 489/750 - Train pg Loss: 19.263929 - Test Loss: 6.270090\n",
      "\n",
      "\n",
      "Epoch 490/750 - Train Cd Loss: 0.058401 - Test Loss: 0.070109\n",
      "Epoch 490/750 - Train pg Loss: 19.129620 - Test Loss: 5.939582\n",
      "\n",
      "\n",
      "Epoch 491/750 - Train Cd Loss: 0.043660 - Test Loss: 0.069758\n",
      "Epoch 491/750 - Train pg Loss: 18.075329 - Test Loss: 5.453032\n",
      "\n",
      "\n",
      "Epoch 492/750 - Train Cd Loss: 0.059871 - Test Loss: 0.068642\n",
      "Epoch 492/750 - Train pg Loss: 20.011393 - Test Loss: 6.350208\n",
      "\n",
      "\n",
      "Epoch 493/750 - Train Cd Loss: 0.041233 - Test Loss: nan\n",
      "Epoch 493/750 - Train pg Loss: 19.919758 - Test Loss: 6.872139\n",
      "\n",
      "\n",
      "Epoch 494/750 - Train Cd Loss: 0.048757 - Test Loss: nan\n",
      "Epoch 494/750 - Train pg Loss: 18.981947 - Test Loss: 6.690792\n",
      "\n",
      "\n",
      "Epoch 495/750 - Train Cd Loss: 0.057798 - Test Loss: nan\n",
      "Epoch 495/750 - Train pg Loss: 18.182739 - Test Loss: 5.905011\n",
      "\n",
      "\n",
      "Epoch 496/750 - Train Cd Loss: 0.057200 - Test Loss: 0.067946\n",
      "Epoch 496/750 - Train pg Loss: 19.379793 - Test Loss: 5.480325\n",
      "\n",
      "\n",
      "Epoch 497/750 - Train Cd Loss: 0.050025 - Test Loss: 0.064271\n",
      "Epoch 497/750 - Train pg Loss: 18.115089 - Test Loss: 4.928607\n",
      "\n",
      "\n",
      "Epoch 498/750 - Train Cd Loss: 0.054077 - Test Loss: nan\n",
      "Epoch 498/750 - Train pg Loss: 16.198736 - Test Loss: 5.051996\n",
      "\n",
      "\n",
      "Epoch 499/750 - Train Cd Loss: 0.046987 - Test Loss: nan\n",
      "Epoch 499/750 - Train pg Loss: 16.377760 - Test Loss: 5.734411\n",
      "\n",
      "\n",
      "Epoch 500/750 - Train Cd Loss: 0.056837 - Test Loss: nan\n",
      "Epoch 500/750 - Train pg Loss: 18.074297 - Test Loss: 5.376949\n",
      "\n",
      "\n",
      "Epoch 501/750 - Train Cd Loss: 0.045753 - Test Loss: nan\n",
      "Epoch 501/750 - Train pg Loss: 16.625330 - Test Loss: 5.844802\n",
      "\n",
      "\n",
      "Epoch 502/750 - Train Cd Loss: 0.058744 - Test Loss: nan\n",
      "Epoch 502/750 - Train pg Loss: 16.474604 - Test Loss: 5.385117\n",
      "\n",
      "\n",
      "Epoch 503/750 - Train Cd Loss: 0.064851 - Test Loss: nan\n",
      "Epoch 503/750 - Train pg Loss: 16.026968 - Test Loss: 6.714604\n",
      "\n",
      "\n",
      "Epoch 504/750 - Train Cd Loss: 0.046820 - Test Loss: nan\n",
      "Epoch 504/750 - Train pg Loss: 19.298626 - Test Loss: 6.287248\n",
      "\n",
      "\n",
      "Epoch 505/750 - Train Cd Loss: 0.049615 - Test Loss: 0.069593\n",
      "Epoch 505/750 - Train pg Loss: 21.591970 - Test Loss: 6.290864\n",
      "\n",
      "\n",
      "Epoch 506/750 - Train Cd Loss: 0.047098 - Test Loss: nan\n",
      "Epoch 506/750 - Train pg Loss: 21.042557 - Test Loss: 7.170890\n",
      "\n",
      "\n",
      "Epoch 507/750 - Train Cd Loss: 0.049625 - Test Loss: nan\n",
      "Epoch 507/750 - Train pg Loss: 23.308004 - Test Loss: 7.568321\n",
      "\n",
      "\n",
      "Epoch 508/750 - Train Cd Loss: 0.047871 - Test Loss: nan\n",
      "Epoch 508/750 - Train pg Loss: 21.110516 - Test Loss: 6.655636\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 509/750 - Train Cd Loss: 0.064329 - Test Loss: 0.066168\n",
      "Epoch 509/750 - Train pg Loss: 23.968704 - Test Loss: 6.587755\n",
      "\n",
      "\n",
      "Epoch 510/750 - Train Cd Loss: 0.049386 - Test Loss: nan\n",
      "Epoch 510/750 - Train pg Loss: 20.365953 - Test Loss: 6.378637\n",
      "\n",
      "\n",
      "Epoch 511/750 - Train Cd Loss: 0.057444 - Test Loss: 0.066971\n",
      "Epoch 511/750 - Train pg Loss: 19.674461 - Test Loss: 6.537383\n",
      "\n",
      "\n",
      "Epoch 512/750 - Train Cd Loss: 0.048127 - Test Loss: 0.067676\n",
      "Epoch 512/750 - Train pg Loss: 22.234413 - Test Loss: 6.178805\n",
      "\n",
      "\n",
      "Epoch 513/750 - Train Cd Loss: 0.044276 - Test Loss: nan\n",
      "Epoch 513/750 - Train pg Loss: 20.041622 - Test Loss: 5.769340\n",
      "\n",
      "\n",
      "Epoch 514/750 - Train Cd Loss: 0.061185 - Test Loss: nan\n",
      "Epoch 514/750 - Train pg Loss: 18.596235 - Test Loss: 7.544682\n",
      "\n",
      "\n",
      "Epoch 515/750 - Train Cd Loss: 0.043337 - Test Loss: nan\n",
      "Epoch 515/750 - Train pg Loss: 20.011705 - Test Loss: 6.863318\n",
      "\n",
      "\n",
      "Epoch 516/750 - Train Cd Loss: 0.041395 - Test Loss: nan\n",
      "Epoch 516/750 - Train pg Loss: 20.501684 - Test Loss: 7.111642\n",
      "\n",
      "\n",
      "Epoch 517/750 - Train Cd Loss: 0.058658 - Test Loss: nan\n",
      "Epoch 517/750 - Train pg Loss: 22.807543 - Test Loss: 6.104470\n",
      "\n",
      "\n",
      "Epoch 518/750 - Train Cd Loss: 0.053394 - Test Loss: 0.068246\n",
      "Epoch 518/750 - Train pg Loss: 23.316212 - Test Loss: 6.896295\n",
      "\n",
      "\n",
      "Epoch 519/750 - Train Cd Loss: 0.043214 - Test Loss: 0.071162\n",
      "Epoch 519/750 - Train pg Loss: 22.775003 - Test Loss: 6.474075\n",
      "\n",
      "\n",
      "Epoch 520/750 - Train Cd Loss: 0.044447 - Test Loss: nan\n",
      "Epoch 520/750 - Train pg Loss: 18.318001 - Test Loss: 8.628874\n",
      "\n",
      "\n",
      "Epoch 521/750 - Train Cd Loss: 0.055677 - Test Loss: nan\n",
      "Epoch 521/750 - Train pg Loss: 24.365545 - Test Loss: 6.961446\n",
      "\n",
      "\n",
      "Epoch 522/750 - Train Cd Loss: 0.039129 - Test Loss: 0.067235\n",
      "Epoch 522/750 - Train pg Loss: 20.492802 - Test Loss: 5.333748\n",
      "\n",
      "\n",
      "Epoch 523/750 - Train Cd Loss: 0.064403 - Test Loss: 0.066439\n",
      "Epoch 523/750 - Train pg Loss: 19.392067 - Test Loss: 5.319007\n",
      "\n",
      "\n",
      "Epoch 524/750 - Train Cd Loss: 0.044650 - Test Loss: 0.066989\n",
      "Epoch 524/750 - Train pg Loss: 17.581772 - Test Loss: 5.782758\n",
      "\n",
      "\n",
      "Epoch 525/750 - Train Cd Loss: 0.044416 - Test Loss: nan\n",
      "Epoch 525/750 - Train pg Loss: 18.855051 - Test Loss: 7.128368\n",
      "\n",
      "\n",
      "Epoch 526/750 - Train Cd Loss: 0.060109 - Test Loss: nan\n",
      "Epoch 526/750 - Train pg Loss: 19.069643 - Test Loss: 6.107928\n",
      "\n",
      "\n",
      "Epoch 527/750 - Train Cd Loss: 0.063865 - Test Loss: 0.065328\n",
      "Epoch 527/750 - Train pg Loss: 19.191895 - Test Loss: 6.117726\n",
      "\n",
      "\n",
      "Epoch 528/750 - Train Cd Loss: 0.045610 - Test Loss: nan\n",
      "Epoch 528/750 - Train pg Loss: 21.601871 - Test Loss: 6.664358\n",
      "\n",
      "\n",
      "Epoch 529/750 - Train Cd Loss: 0.042061 - Test Loss: nan\n",
      "Epoch 529/750 - Train pg Loss: 16.458366 - Test Loss: 6.024279\n",
      "\n",
      "\n",
      "Epoch 530/750 - Train Cd Loss: 0.043433 - Test Loss: nan\n",
      "Epoch 530/750 - Train pg Loss: 19.407623 - Test Loss: 6.575575\n",
      "\n",
      "\n",
      "Epoch 531/750 - Train Cd Loss: 0.061796 - Test Loss: nan\n",
      "Epoch 531/750 - Train pg Loss: 19.317648 - Test Loss: 5.907063\n",
      "\n",
      "\n",
      "Epoch 532/750 - Train Cd Loss: 0.052669 - Test Loss: nan\n",
      "Epoch 532/750 - Train pg Loss: 16.323526 - Test Loss: 5.683468\n",
      "\n",
      "\n",
      "Epoch 533/750 - Train Cd Loss: 0.041504 - Test Loss: nan\n",
      "Epoch 533/750 - Train pg Loss: 18.771814 - Test Loss: 5.936200\n",
      "\n",
      "\n",
      "Epoch 534/750 - Train Cd Loss: 0.056529 - Test Loss: nan\n",
      "Epoch 534/750 - Train pg Loss: 16.345325 - Test Loss: 5.101780\n",
      "\n",
      "\n",
      "Epoch 535/750 - Train Cd Loss: 0.061937 - Test Loss: 0.064982\n",
      "Epoch 535/750 - Train pg Loss: 18.263159 - Test Loss: 5.450855\n",
      "\n",
      "\n",
      "Epoch 536/750 - Train Cd Loss: 0.043758 - Test Loss: 0.066251\n",
      "Epoch 536/750 - Train pg Loss: 17.613659 - Test Loss: 5.260062\n",
      "\n",
      "\n",
      "Epoch 537/750 - Train Cd Loss: 0.039893 - Test Loss: 0.070227\n",
      "Epoch 537/750 - Train pg Loss: 16.197132 - Test Loss: 4.711895\n",
      "\n",
      "\n",
      "Epoch 538/750 - Train Cd Loss: 0.048417 - Test Loss: 0.067845\n",
      "Epoch 538/750 - Train pg Loss: 19.766253 - Test Loss: 5.733484\n",
      "\n",
      "\n",
      "Epoch 539/750 - Train Cd Loss: 0.050070 - Test Loss: nan\n",
      "Epoch 539/750 - Train pg Loss: 17.169418 - Test Loss: 5.887115\n",
      "\n",
      "\n",
      "Epoch 540/750 - Train Cd Loss: 0.038028 - Test Loss: nan\n",
      "Epoch 540/750 - Train pg Loss: 22.064140 - Test Loss: 7.139215\n",
      "\n",
      "\n",
      "Epoch 541/750 - Train Cd Loss: 0.067253 - Test Loss: 0.067318\n",
      "Epoch 541/750 - Train pg Loss: 19.503767 - Test Loss: 4.746644\n",
      "\n",
      "\n",
      "Epoch 542/750 - Train Cd Loss: 0.058816 - Test Loss: nan\n",
      "Epoch 542/750 - Train pg Loss: 14.340390 - Test Loss: 5.302303\n",
      "\n",
      "\n",
      "Epoch 543/750 - Train Cd Loss: 0.041842 - Test Loss: 0.068378\n",
      "Epoch 543/750 - Train pg Loss: 16.168488 - Test Loss: 4.655151\n",
      "\n",
      "\n",
      "Epoch 544/750 - Train Cd Loss: 0.041615 - Test Loss: nan\n",
      "Epoch 544/750 - Train pg Loss: 15.042480 - Test Loss: 5.334615\n",
      "\n",
      "\n",
      "Epoch 545/750 - Train Cd Loss: 0.058278 - Test Loss: 0.069163\n",
      "Epoch 545/750 - Train pg Loss: 17.694468 - Test Loss: 5.210691\n",
      "\n",
      "\n",
      "Epoch 546/750 - Train Cd Loss: 0.050484 - Test Loss: 0.068313\n",
      "Epoch 546/750 - Train pg Loss: 16.708900 - Test Loss: 4.985547\n",
      "\n",
      "\n",
      "Epoch 547/750 - Train Cd Loss: 0.040232 - Test Loss: nan\n",
      "Epoch 547/750 - Train pg Loss: 17.081339 - Test Loss: 5.951107\n",
      "\n",
      "\n",
      "Epoch 548/750 - Train Cd Loss: 0.048102 - Test Loss: nan\n",
      "Epoch 548/750 - Train pg Loss: 19.315565 - Test Loss: 7.281174\n",
      "\n",
      "\n",
      "Epoch 549/750 - Train Cd Loss: 0.036424 - Test Loss: nan\n",
      "Epoch 549/750 - Train pg Loss: 22.860594 - Test Loss: 7.033396\n",
      "\n",
      "\n",
      "Epoch 550/750 - Train Cd Loss: 0.065566 - Test Loss: nan\n",
      "Epoch 550/750 - Train pg Loss: 22.451380 - Test Loss: 6.673741\n",
      "\n",
      "\n",
      "Epoch 551/750 - Train Cd Loss: 0.042014 - Test Loss: 0.071687\n",
      "Epoch 551/750 - Train pg Loss: 19.740572 - Test Loss: 6.563929\n",
      "\n",
      "\n",
      "Epoch 552/750 - Train Cd Loss: 0.052200 - Test Loss: 0.073084\n",
      "Epoch 552/750 - Train pg Loss: 22.307056 - Test Loss: 6.597815\n",
      "\n",
      "\n",
      "Epoch 553/750 - Train Cd Loss: 0.055051 - Test Loss: nan\n",
      "Epoch 553/750 - Train pg Loss: 22.232643 - Test Loss: 7.012178\n",
      "\n",
      "\n",
      "Epoch 554/750 - Train Cd Loss: 0.044537 - Test Loss: 0.066391\n",
      "Epoch 554/750 - Train pg Loss: 19.845322 - Test Loss: 5.450405\n",
      "\n",
      "\n",
      "Epoch 555/750 - Train Cd Loss: 0.053048 - Test Loss: nan\n",
      "Epoch 555/750 - Train pg Loss: 18.866632 - Test Loss: 6.259174\n",
      "\n",
      "\n",
      "Epoch 556/750 - Train Cd Loss: 0.041128 - Test Loss: 0.069094\n",
      "Epoch 556/750 - Train pg Loss: 18.463808 - Test Loss: 5.236648\n",
      "\n",
      "\n",
      "Epoch 557/750 - Train Cd Loss: 0.057203 - Test Loss: 0.067052\n",
      "Epoch 557/750 - Train pg Loss: 17.541386 - Test Loss: 5.464774\n",
      "\n",
      "\n",
      "Epoch 558/750 - Train Cd Loss: 0.037934 - Test Loss: 0.070571\n",
      "Epoch 558/750 - Train pg Loss: 16.873859 - Test Loss: 5.405432\n",
      "\n",
      "\n",
      "Epoch 559/750 - Train Cd Loss: 0.036736 - Test Loss: nan\n",
      "Epoch 559/750 - Train pg Loss: 20.494900 - Test Loss: 6.424582\n",
      "\n",
      "\n",
      "Epoch 560/750 - Train Cd Loss: 0.046230 - Test Loss: 0.069146\n",
      "Epoch 560/750 - Train pg Loss: 19.824141 - Test Loss: 5.484572\n",
      "\n",
      "\n",
      "Epoch 561/750 - Train Cd Loss: 0.039963 - Test Loss: nan\n",
      "Epoch 561/750 - Train pg Loss: 21.710686 - Test Loss: 6.545943\n",
      "\n",
      "\n",
      "Epoch 562/750 - Train Cd Loss: 0.037251 - Test Loss: nan\n",
      "Epoch 562/750 - Train pg Loss: 18.161362 - Test Loss: 6.334952\n",
      "\n",
      "\n",
      "Epoch 563/750 - Train Cd Loss: 0.038436 - Test Loss: nan\n",
      "Epoch 563/750 - Train pg Loss: 20.431536 - Test Loss: 6.305170\n",
      "\n",
      "\n",
      "Epoch 564/750 - Train Cd Loss: 0.077256 - Test Loss: 0.071434\n",
      "Epoch 564/750 - Train pg Loss: 20.321617 - Test Loss: 5.580760\n",
      "\n",
      "\n",
      "Epoch 565/750 - Train Cd Loss: 0.037666 - Test Loss: nan\n",
      "Epoch 565/750 - Train pg Loss: 20.360472 - Test Loss: 6.768976\n",
      "\n",
      "\n",
      "Epoch 566/750 - Train Cd Loss: 0.042192 - Test Loss: nan\n",
      "Epoch 566/750 - Train pg Loss: 22.826237 - Test Loss: 6.703544\n",
      "\n",
      "\n",
      "Epoch 567/750 - Train Cd Loss: 0.043655 - Test Loss: 0.069077\n",
      "Epoch 567/750 - Train pg Loss: 21.511312 - Test Loss: 6.313219\n",
      "\n",
      "\n",
      "Epoch 568/750 - Train Cd Loss: 0.042293 - Test Loss: nan\n",
      "Epoch 568/750 - Train pg Loss: 19.265892 - Test Loss: 7.644821\n",
      "\n",
      "\n",
      "Epoch 569/750 - Train Cd Loss: 0.040213 - Test Loss: 0.074033\n",
      "Epoch 569/750 - Train pg Loss: 20.928028 - Test Loss: 6.976886\n",
      "\n",
      "\n",
      "Epoch 570/750 - Train Cd Loss: 0.036616 - Test Loss: 0.074488\n",
      "Epoch 570/750 - Train pg Loss: 21.328770 - Test Loss: 6.676822\n",
      "\n",
      "\n",
      "Epoch 571/750 - Train Cd Loss: 0.050975 - Test Loss: 0.068158\n",
      "Epoch 571/750 - Train pg Loss: 22.044397 - Test Loss: 5.945486\n",
      "\n",
      "\n",
      "Epoch 572/750 - Train Cd Loss: 0.052934 - Test Loss: 0.064882\n",
      "Epoch 572/750 - Train pg Loss: 18.899855 - Test Loss: 5.318762\n",
      "\n",
      "\n",
      "Epoch 573/750 - Train Cd Loss: 0.037261 - Test Loss: nan\n",
      "Epoch 573/750 - Train pg Loss: 17.864483 - Test Loss: 5.815058\n",
      "\n",
      "\n",
      "Epoch 574/750 - Train Cd Loss: 0.038479 - Test Loss: 0.068275\n",
      "Epoch 574/750 - Train pg Loss: 19.477558 - Test Loss: 6.154063\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 575/750 - Train Cd Loss: 0.073365 - Test Loss: 0.070077\n",
      "Epoch 575/750 - Train pg Loss: 19.776983 - Test Loss: 5.355971\n",
      "\n",
      "\n",
      "Epoch 576/750 - Train Cd Loss: 0.043816 - Test Loss: 0.067835\n",
      "Epoch 576/750 - Train pg Loss: 19.258036 - Test Loss: 5.495096\n",
      "\n",
      "\n",
      "Epoch 577/750 - Train Cd Loss: 0.038654 - Test Loss: 0.070426\n",
      "Epoch 577/750 - Train pg Loss: 18.562895 - Test Loss: 5.380306\n",
      "\n",
      "\n",
      "Epoch 578/750 - Train Cd Loss: 0.061575 - Test Loss: nan\n",
      "Epoch 578/750 - Train pg Loss: 20.568310 - Test Loss: 6.803178\n",
      "\n",
      "\n",
      "Epoch 579/750 - Train Cd Loss: 0.040728 - Test Loss: 0.065426\n",
      "Epoch 579/750 - Train pg Loss: 19.342947 - Test Loss: 5.550720\n",
      "\n",
      "\n",
      "Epoch 580/750 - Train Cd Loss: 0.037964 - Test Loss: nan\n",
      "Epoch 580/750 - Train pg Loss: 18.248791 - Test Loss: 6.554774\n",
      "\n",
      "\n",
      "Epoch 581/750 - Train Cd Loss: 0.046824 - Test Loss: 0.065221\n",
      "Epoch 581/750 - Train pg Loss: 21.384640 - Test Loss: 5.498050\n",
      "\n",
      "\n",
      "Epoch 582/750 - Train Cd Loss: 0.041137 - Test Loss: nan\n",
      "Epoch 582/750 - Train pg Loss: 21.434525 - Test Loss: 6.157109\n",
      "\n",
      "\n",
      "Epoch 583/750 - Train Cd Loss: 0.037705 - Test Loss: 0.071983\n",
      "Epoch 583/750 - Train pg Loss: 15.766983 - Test Loss: 5.142088\n",
      "\n",
      "\n",
      "Epoch 584/750 - Train Cd Loss: 0.069007 - Test Loss: 0.068965\n",
      "Epoch 584/750 - Train pg Loss: 23.728622 - Test Loss: 6.408113\n",
      "\n",
      "\n",
      "Epoch 585/750 - Train Cd Loss: 0.034728 - Test Loss: 0.068018\n",
      "Epoch 585/750 - Train pg Loss: 22.318241 - Test Loss: 5.968010\n",
      "\n",
      "\n",
      "Epoch 586/750 - Train Cd Loss: 0.038484 - Test Loss: nan\n",
      "Epoch 586/750 - Train pg Loss: 19.180647 - Test Loss: 6.623082\n",
      "\n",
      "\n",
      "Epoch 587/750 - Train Cd Loss: 0.047441 - Test Loss: nan\n",
      "Epoch 587/750 - Train pg Loss: 22.694548 - Test Loss: 8.301516\n",
      "\n",
      "\n",
      "Epoch 588/750 - Train Cd Loss: 0.040854 - Test Loss: nan\n",
      "Epoch 588/750 - Train pg Loss: 25.803978 - Test Loss: 8.090770\n",
      "\n",
      "\n",
      "Epoch 589/750 - Train Cd Loss: 0.035275 - Test Loss: 0.069044\n",
      "Epoch 589/750 - Train pg Loss: 23.094946 - Test Loss: 6.007989\n",
      "\n",
      "\n",
      "Epoch 590/750 - Train Cd Loss: 0.039233 - Test Loss: 0.075147\n",
      "Epoch 590/750 - Train pg Loss: 20.153820 - Test Loss: 5.990031\n",
      "\n",
      "\n",
      "Epoch 591/750 - Train Cd Loss: 0.034991 - Test Loss: 0.070023\n",
      "Epoch 591/750 - Train pg Loss: 20.761461 - Test Loss: 6.171350\n",
      "\n",
      "\n",
      "Epoch 592/750 - Train Cd Loss: 0.040193 - Test Loss: 0.069822\n",
      "Epoch 592/750 - Train pg Loss: 18.210764 - Test Loss: 5.748508\n",
      "\n",
      "\n",
      "Epoch 593/750 - Train Cd Loss: 0.036835 - Test Loss: nan\n",
      "Epoch 593/750 - Train pg Loss: 20.908533 - Test Loss: 7.145739\n",
      "\n",
      "\n",
      "Epoch 594/750 - Train Cd Loss: 0.052338 - Test Loss: nan\n",
      "Epoch 594/750 - Train pg Loss: 21.893726 - Test Loss: 6.326640\n",
      "\n",
      "\n",
      "Epoch 595/750 - Train Cd Loss: 0.033618 - Test Loss: nan\n",
      "Epoch 595/750 - Train pg Loss: 18.743086 - Test Loss: 6.760697\n",
      "\n",
      "\n",
      "Epoch 596/750 - Train Cd Loss: 0.068612 - Test Loss: 0.070146\n",
      "Epoch 596/750 - Train pg Loss: 19.957199 - Test Loss: 5.138946\n",
      "\n",
      "\n",
      "Epoch 597/750 - Train Cd Loss: 0.040982 - Test Loss: 0.066594\n",
      "Epoch 597/750 - Train pg Loss: 19.882074 - Test Loss: 6.507178\n",
      "\n",
      "\n",
      "Epoch 598/750 - Train Cd Loss: 0.049538 - Test Loss: 0.069166\n",
      "Epoch 598/750 - Train pg Loss: 21.221325 - Test Loss: 5.893031\n",
      "\n",
      "\n",
      "Epoch 599/750 - Train Cd Loss: 0.039929 - Test Loss: 0.069008\n",
      "Epoch 599/750 - Train pg Loss: 21.809607 - Test Loss: 5.754417\n",
      "\n",
      "\n",
      "Epoch 600/750 - Train Cd Loss: 0.048758 - Test Loss: 0.066661\n",
      "Epoch 600/750 - Train pg Loss: 18.834259 - Test Loss: 5.828547\n",
      "\n",
      "\n",
      "Epoch 601/750 - Train Cd Loss: 0.045794 - Test Loss: 0.071542\n",
      "Epoch 601/750 - Train pg Loss: 19.978830 - Test Loss: 5.950937\n",
      "\n",
      "\n",
      "Epoch 602/750 - Train Cd Loss: 0.032136 - Test Loss: nan\n",
      "Epoch 602/750 - Train pg Loss: 19.872900 - Test Loss: 7.257949\n",
      "\n",
      "\n",
      "Epoch 603/750 - Train Cd Loss: 0.057548 - Test Loss: 0.071859\n",
      "Epoch 603/750 - Train pg Loss: 21.150841 - Test Loss: 6.018534\n",
      "\n",
      "\n",
      "Epoch 604/750 - Train Cd Loss: 0.036115 - Test Loss: 0.066467\n",
      "Epoch 604/750 - Train pg Loss: 20.711689 - Test Loss: 5.147987\n",
      "\n",
      "\n",
      "Epoch 605/750 - Train Cd Loss: 0.039983 - Test Loss: nan\n",
      "Epoch 605/750 - Train pg Loss: 17.229942 - Test Loss: 5.809550\n",
      "\n",
      "\n",
      "Epoch 606/750 - Train Cd Loss: 0.048631 - Test Loss: 0.073262\n",
      "Epoch 606/750 - Train pg Loss: 20.003811 - Test Loss: 5.341643\n",
      "\n",
      "\n",
      "Epoch 607/750 - Train Cd Loss: 0.034596 - Test Loss: 0.071477\n",
      "Epoch 607/750 - Train pg Loss: 21.063869 - Test Loss: 6.880822\n",
      "\n",
      "\n",
      "Epoch 608/750 - Train Cd Loss: 0.037334 - Test Loss: nan\n",
      "Epoch 608/750 - Train pg Loss: 19.672691 - Test Loss: 6.847700\n",
      "\n",
      "\n",
      "Epoch 609/750 - Train Cd Loss: 0.053829 - Test Loss: 0.069813\n",
      "Epoch 609/750 - Train pg Loss: 20.032837 - Test Loss: 5.918719\n",
      "\n",
      "\n",
      "Epoch 610/750 - Train Cd Loss: 0.034638 - Test Loss: nan\n",
      "Epoch 610/750 - Train pg Loss: 21.555513 - Test Loss: 7.438733\n",
      "\n",
      "\n",
      "Epoch 611/750 - Train Cd Loss: 0.045764 - Test Loss: 0.063528\n",
      "Epoch 611/750 - Train pg Loss: 23.644958 - Test Loss: 6.229209\n",
      "\n",
      "\n",
      "Epoch 612/750 - Train Cd Loss: 0.033607 - Test Loss: nan\n",
      "Epoch 612/750 - Train pg Loss: 20.834417 - Test Loss: 6.181298\n",
      "\n",
      "\n",
      "Epoch 613/750 - Train Cd Loss: 0.049531 - Test Loss: 0.069105\n",
      "Epoch 613/750 - Train pg Loss: 20.126657 - Test Loss: 6.196055\n",
      "\n",
      "\n",
      "Epoch 614/750 - Train Cd Loss: 0.032498 - Test Loss: 0.070978\n",
      "Epoch 614/750 - Train pg Loss: 23.191162 - Test Loss: 6.164154\n",
      "\n",
      "\n",
      "Epoch 615/750 - Train Cd Loss: 0.036535 - Test Loss: nan\n",
      "Epoch 615/750 - Train pg Loss: 20.971228 - Test Loss: 6.223276\n",
      "\n",
      "\n",
      "Epoch 616/750 - Train Cd Loss: 0.049358 - Test Loss: nan\n",
      "Epoch 616/750 - Train pg Loss: 22.061506 - Test Loss: 7.244973\n",
      "\n",
      "\n",
      "Epoch 617/750 - Train Cd Loss: 0.048509 - Test Loss: 0.069078\n",
      "Epoch 617/750 - Train pg Loss: 24.341633 - Test Loss: 6.929297\n",
      "\n",
      "\n",
      "Epoch 618/750 - Train Cd Loss: 0.031736 - Test Loss: 0.072623\n",
      "Epoch 618/750 - Train pg Loss: 24.512798 - Test Loss: 6.235960\n",
      "\n",
      "\n",
      "Epoch 619/750 - Train Cd Loss: 0.045467 - Test Loss: 0.068357\n",
      "Epoch 619/750 - Train pg Loss: 22.061834 - Test Loss: 5.918861\n",
      "\n",
      "\n",
      "Epoch 620/750 - Train Cd Loss: 0.031205 - Test Loss: 0.069590\n",
      "Epoch 620/750 - Train pg Loss: 22.047714 - Test Loss: 6.233871\n",
      "\n",
      "\n",
      "Epoch 621/750 - Train Cd Loss: 0.048073 - Test Loss: 0.067457\n",
      "Epoch 621/750 - Train pg Loss: 21.150230 - Test Loss: 6.072065\n",
      "\n",
      "\n",
      "Epoch 622/750 - Train Cd Loss: 0.046146 - Test Loss: 0.070261\n",
      "Epoch 622/750 - Train pg Loss: 24.354168 - Test Loss: 7.116384\n",
      "\n",
      "\n",
      "Epoch 623/750 - Train Cd Loss: 0.030641 - Test Loss: nan\n",
      "Epoch 623/750 - Train pg Loss: 23.816133 - Test Loss: 8.512378\n",
      "\n",
      "\n",
      "Epoch 624/750 - Train Cd Loss: 0.044642 - Test Loss: 0.069906\n",
      "Epoch 624/750 - Train pg Loss: 26.854338 - Test Loss: 6.973988\n",
      "\n",
      "\n",
      "Epoch 625/750 - Train Cd Loss: 0.033507 - Test Loss: nan\n",
      "Epoch 625/750 - Train pg Loss: 25.319536 - Test Loss: 7.847967\n",
      "\n",
      "\n",
      "Epoch 626/750 - Train Cd Loss: 0.041446 - Test Loss: 0.072134\n",
      "Epoch 626/750 - Train pg Loss: 19.374489 - Test Loss: 6.211837\n",
      "\n",
      "\n",
      "Epoch 627/750 - Train Cd Loss: 0.035910 - Test Loss: nan\n",
      "Epoch 627/750 - Train pg Loss: 22.580408 - Test Loss: 7.701155\n",
      "\n",
      "\n",
      "Epoch 628/750 - Train Cd Loss: 0.039352 - Test Loss: nan\n",
      "Epoch 628/750 - Train pg Loss: 18.739773 - Test Loss: 6.309426\n",
      "\n",
      "\n",
      "Epoch 629/750 - Train Cd Loss: 0.029315 - Test Loss: 0.068648\n",
      "Epoch 629/750 - Train pg Loss: 24.954599 - Test Loss: 6.538882\n",
      "\n",
      "\n",
      "Epoch 630/750 - Train Cd Loss: 0.035633 - Test Loss: nan\n",
      "Epoch 630/750 - Train pg Loss: 19.978609 - Test Loss: 6.198605\n",
      "\n",
      "\n",
      "Epoch 631/750 - Train Cd Loss: 0.045041 - Test Loss: 0.069535\n",
      "Epoch 631/750 - Train pg Loss: 20.472528 - Test Loss: 5.633231\n",
      "\n",
      "\n",
      "Epoch 632/750 - Train Cd Loss: 0.031946 - Test Loss: 0.071596\n",
      "Epoch 632/750 - Train pg Loss: 17.022381 - Test Loss: 4.743309\n",
      "\n",
      "\n",
      "Epoch 633/750 - Train Cd Loss: 0.049720 - Test Loss: 0.069504\n",
      "Epoch 633/750 - Train pg Loss: 18.144745 - Test Loss: 5.052726\n",
      "\n",
      "\n",
      "Epoch 634/750 - Train Cd Loss: 0.042131 - Test Loss: nan\n",
      "Epoch 634/750 - Train pg Loss: 16.747890 - Test Loss: 6.893239\n",
      "\n",
      "\n",
      "Epoch 635/750 - Train Cd Loss: 0.032129 - Test Loss: nan\n",
      "Epoch 635/750 - Train pg Loss: 15.706220 - Test Loss: 6.660296\n",
      "\n",
      "\n",
      "Epoch 636/750 - Train Cd Loss: 0.049638 - Test Loss: 0.069457\n",
      "Epoch 636/750 - Train pg Loss: 22.646835 - Test Loss: 5.443425\n",
      "\n",
      "\n",
      "Epoch 637/750 - Train Cd Loss: 0.029039 - Test Loss: nan\n",
      "Epoch 637/750 - Train pg Loss: 17.420500 - Test Loss: 6.066558\n",
      "\n",
      "\n",
      "Epoch 638/750 - Train Cd Loss: 0.030664 - Test Loss: nan\n",
      "Epoch 638/750 - Train pg Loss: 18.906139 - Test Loss: 5.964614\n",
      "\n",
      "\n",
      "Epoch 639/750 - Train Cd Loss: 0.063453 - Test Loss: nan\n",
      "Epoch 639/750 - Train pg Loss: 23.425430 - Test Loss: 7.097651\n",
      "\n",
      "\n",
      "Epoch 640/750 - Train Cd Loss: 0.029314 - Test Loss: nan\n",
      "Epoch 640/750 - Train pg Loss: 22.225155 - Test Loss: 7.530459\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 641/750 - Train Cd Loss: 0.030760 - Test Loss: nan\n",
      "Epoch 641/750 - Train pg Loss: 21.623545 - Test Loss: 8.223222\n",
      "\n",
      "\n",
      "Epoch 642/750 - Train Cd Loss: 0.042124 - Test Loss: 0.070019\n",
      "Epoch 642/750 - Train pg Loss: 23.526878 - Test Loss: 5.669713\n",
      "\n",
      "\n",
      "Epoch 643/750 - Train Cd Loss: 0.029698 - Test Loss: nan\n",
      "Epoch 643/750 - Train pg Loss: 22.312504 - Test Loss: 6.806749\n",
      "\n",
      "\n",
      "Epoch 644/750 - Train Cd Loss: 0.041119 - Test Loss: 0.075667\n",
      "Epoch 644/750 - Train pg Loss: 22.006901 - Test Loss: 6.141866\n",
      "\n",
      "\n",
      "Epoch 645/750 - Train Cd Loss: 0.047522 - Test Loss: 0.067640\n",
      "Epoch 645/750 - Train pg Loss: 23.812223 - Test Loss: 6.116634\n",
      "\n",
      "\n",
      "Epoch 646/750 - Train Cd Loss: 0.034444 - Test Loss: nan\n",
      "Epoch 646/750 - Train pg Loss: 21.033434 - Test Loss: 7.196841\n",
      "\n",
      "\n",
      "Epoch 647/750 - Train Cd Loss: 0.026397 - Test Loss: nan\n",
      "Epoch 647/750 - Train pg Loss: 22.947166 - Test Loss: 7.401155\n",
      "\n",
      "\n",
      "Epoch 648/750 - Train Cd Loss: 0.053607 - Test Loss: nan\n",
      "Epoch 648/750 - Train pg Loss: 25.668917 - Test Loss: 7.969766\n",
      "\n",
      "\n",
      "Epoch 649/750 - Train Cd Loss: 0.032077 - Test Loss: nan\n",
      "Epoch 649/750 - Train pg Loss: 24.360933 - Test Loss: 8.607605\n",
      "\n",
      "\n",
      "Epoch 650/750 - Train Cd Loss: 0.035715 - Test Loss: 0.071590\n",
      "Epoch 650/750 - Train pg Loss: 27.862064 - Test Loss: 7.341920\n",
      "\n",
      "\n",
      "Epoch 651/750 - Train Cd Loss: 0.029951 - Test Loss: 0.071158\n",
      "Epoch 651/750 - Train pg Loss: 22.404251 - Test Loss: 7.175387\n",
      "\n",
      "\n",
      "Epoch 652/750 - Train Cd Loss: 0.043500 - Test Loss: 0.072637\n",
      "Epoch 652/750 - Train pg Loss: 23.443848 - Test Loss: 5.780841\n",
      "\n",
      "\n",
      "Epoch 653/750 - Train Cd Loss: 0.030948 - Test Loss: 0.068657\n",
      "Epoch 653/750 - Train pg Loss: 19.435028 - Test Loss: 6.694716\n",
      "\n",
      "\n",
      "Epoch 654/750 - Train Cd Loss: 0.031497 - Test Loss: 0.077119\n",
      "Epoch 654/750 - Train pg Loss: 16.681877 - Test Loss: 6.185785\n",
      "\n",
      "\n",
      "Epoch 655/750 - Train Cd Loss: 0.029085 - Test Loss: nan\n",
      "Epoch 655/750 - Train pg Loss: 22.582376 - Test Loss: 7.506382\n",
      "\n",
      "\n",
      "Epoch 656/750 - Train Cd Loss: 0.027290 - Test Loss: nan\n",
      "Epoch 656/750 - Train pg Loss: 19.233713 - Test Loss: 6.467758\n",
      "\n",
      "\n",
      "Epoch 657/750 - Train Cd Loss: 0.032230 - Test Loss: nan\n",
      "Epoch 657/750 - Train pg Loss: 18.669693 - Test Loss: 7.286927\n",
      "\n",
      "\n",
      "Epoch 658/750 - Train Cd Loss: 0.031814 - Test Loss: nan\n",
      "Epoch 658/750 - Train pg Loss: 21.945431 - Test Loss: 7.160860\n",
      "\n",
      "\n",
      "Epoch 659/750 - Train Cd Loss: 0.041743 - Test Loss: 0.071037\n",
      "Epoch 659/750 - Train pg Loss: 21.744757 - Test Loss: 5.973850\n",
      "\n",
      "\n",
      "Epoch 660/750 - Train Cd Loss: 0.029475 - Test Loss: 0.077563\n",
      "Epoch 660/750 - Train pg Loss: 23.159510 - Test Loss: 5.742306\n",
      "\n",
      "\n",
      "Epoch 661/750 - Train Cd Loss: 0.038811 - Test Loss: 0.069880\n",
      "Epoch 661/750 - Train pg Loss: 21.671032 - Test Loss: 7.030367\n",
      "\n",
      "\n",
      "Epoch 662/750 - Train Cd Loss: 0.033555 - Test Loss: nan\n",
      "Epoch 662/750 - Train pg Loss: 22.898083 - Test Loss: 6.806069\n",
      "\n",
      "\n",
      "Epoch 663/750 - Train Cd Loss: 0.036984 - Test Loss: nan\n",
      "Epoch 663/750 - Train pg Loss: 19.439493 - Test Loss: 7.841660\n",
      "\n",
      "\n",
      "Epoch 664/750 - Train Cd Loss: 0.043910 - Test Loss: 0.071511\n",
      "Epoch 664/750 - Train pg Loss: 26.381577 - Test Loss: 7.065567\n",
      "\n",
      "\n",
      "Epoch 665/750 - Train Cd Loss: 0.032170 - Test Loss: 0.068860\n",
      "Epoch 665/750 - Train pg Loss: 24.479004 - Test Loss: 6.236859\n",
      "\n",
      "\n",
      "Epoch 666/750 - Train Cd Loss: 0.042263 - Test Loss: 0.069225\n",
      "Epoch 666/750 - Train pg Loss: 23.257971 - Test Loss: 6.493367\n",
      "\n",
      "\n",
      "Epoch 667/750 - Train Cd Loss: 0.034539 - Test Loss: 0.073193\n",
      "Epoch 667/750 - Train pg Loss: 23.229681 - Test Loss: 5.746665\n",
      "\n",
      "\n",
      "Epoch 668/750 - Train Cd Loss: 0.053270 - Test Loss: 0.067833\n",
      "Epoch 668/750 - Train pg Loss: 18.043499 - Test Loss: 5.073586\n",
      "\n",
      "\n",
      "Epoch 669/750 - Train Cd Loss: 0.028966 - Test Loss: 0.064761\n",
      "Epoch 669/750 - Train pg Loss: 17.306101 - Test Loss: 5.308304\n",
      "\n",
      "\n",
      "Epoch 670/750 - Train Cd Loss: 0.026969 - Test Loss: 0.074001\n",
      "Epoch 670/750 - Train pg Loss: 20.751526 - Test Loss: 5.776013\n",
      "\n",
      "\n",
      "Epoch 671/750 - Train Cd Loss: 0.042111 - Test Loss: 0.070376\n",
      "Epoch 671/750 - Train pg Loss: 21.849363 - Test Loss: 6.171139\n",
      "\n",
      "\n",
      "Epoch 672/750 - Train Cd Loss: 0.024042 - Test Loss: 0.072143\n",
      "Epoch 672/750 - Train pg Loss: 24.398695 - Test Loss: 6.515790\n",
      "\n",
      "\n",
      "Epoch 673/750 - Train Cd Loss: 0.025379 - Test Loss: nan\n",
      "Epoch 673/750 - Train pg Loss: 23.552904 - Test Loss: 6.692286\n",
      "\n",
      "\n",
      "Epoch 674/750 - Train Cd Loss: 0.028312 - Test Loss: nan\n",
      "Epoch 674/750 - Train pg Loss: 22.296364 - Test Loss: 7.124309\n",
      "\n",
      "\n",
      "Epoch 675/750 - Train Cd Loss: 0.043687 - Test Loss: 0.075765\n",
      "Epoch 675/750 - Train pg Loss: 26.785292 - Test Loss: 6.068271\n",
      "\n",
      "\n",
      "Epoch 676/750 - Train Cd Loss: 0.038248 - Test Loss: nan\n",
      "Epoch 676/750 - Train pg Loss: 20.379414 - Test Loss: 7.697454\n",
      "\n",
      "\n",
      "Epoch 677/750 - Train Cd Loss: 0.033342 - Test Loss: 0.072938\n",
      "Epoch 677/750 - Train pg Loss: 20.870646 - Test Loss: 5.932024\n",
      "\n",
      "\n",
      "Epoch 678/750 - Train Cd Loss: 0.039830 - Test Loss: 0.071415\n",
      "Epoch 678/750 - Train pg Loss: 19.160507 - Test Loss: 6.268187\n",
      "\n",
      "\n",
      "Epoch 679/750 - Train Cd Loss: 0.028713 - Test Loss: nan\n",
      "Epoch 679/750 - Train pg Loss: 21.101341 - Test Loss: 6.611339\n",
      "\n",
      "\n",
      "Epoch 680/750 - Train Cd Loss: 0.048333 - Test Loss: nan\n",
      "Epoch 680/750 - Train pg Loss: 19.930372 - Test Loss: 6.821586\n",
      "\n",
      "\n",
      "Epoch 681/750 - Train Cd Loss: 0.031873 - Test Loss: nan\n",
      "Epoch 681/750 - Train pg Loss: 20.228167 - Test Loss: 5.216311\n",
      "\n",
      "\n",
      "Epoch 682/750 - Train Cd Loss: 0.043825 - Test Loss: nan\n",
      "Epoch 682/750 - Train pg Loss: 22.818737 - Test Loss: 6.449111\n",
      "\n",
      "\n",
      "Epoch 683/750 - Train Cd Loss: 0.043601 - Test Loss: 0.071885\n",
      "Epoch 683/750 - Train pg Loss: 23.616076 - Test Loss: 6.396847\n",
      "\n",
      "\n",
      "Epoch 684/750 - Train Cd Loss: 0.025769 - Test Loss: nan\n",
      "Epoch 684/750 - Train pg Loss: 24.525938 - Test Loss: 7.992389\n",
      "\n",
      "\n",
      "Epoch 685/750 - Train Cd Loss: 0.036553 - Test Loss: nan\n",
      "Epoch 685/750 - Train pg Loss: 22.391054 - Test Loss: 7.224606\n",
      "\n",
      "\n",
      "Epoch 686/750 - Train Cd Loss: 0.025897 - Test Loss: nan\n",
      "Epoch 686/750 - Train pg Loss: 20.312174 - Test Loss: 6.420909\n",
      "\n",
      "\n",
      "Epoch 687/750 - Train Cd Loss: 0.025748 - Test Loss: nan\n",
      "Epoch 687/750 - Train pg Loss: 19.323236 - Test Loss: 6.314055\n",
      "\n",
      "\n",
      "Epoch 688/750 - Train Cd Loss: 0.040632 - Test Loss: nan\n",
      "Epoch 688/750 - Train pg Loss: 23.232031 - Test Loss: 6.869570\n",
      "\n",
      "\n",
      "Epoch 689/750 - Train Cd Loss: 0.039190 - Test Loss: 0.068476\n",
      "Epoch 689/750 - Train pg Loss: 24.620028 - Test Loss: 7.114738\n",
      "\n",
      "\n",
      "Epoch 690/750 - Train Cd Loss: 0.028534 - Test Loss: nan\n",
      "Epoch 690/750 - Train pg Loss: 20.686270 - Test Loss: 7.133371\n",
      "\n",
      "\n",
      "Epoch 691/750 - Train Cd Loss: 0.027329 - Test Loss: nan\n",
      "Epoch 691/750 - Train pg Loss: 22.700352 - Test Loss: 6.990001\n",
      "\n",
      "\n",
      "Epoch 692/750 - Train Cd Loss: 0.035246 - Test Loss: 0.075287\n",
      "Epoch 692/750 - Train pg Loss: 24.755651 - Test Loss: 7.237096\n",
      "\n",
      "\n",
      "Epoch 693/750 - Train Cd Loss: 0.041714 - Test Loss: 0.069258\n",
      "Epoch 693/750 - Train pg Loss: 26.991203 - Test Loss: 6.967830\n",
      "\n",
      "\n",
      "Epoch 694/750 - Train Cd Loss: 0.024693 - Test Loss: 0.070267\n",
      "Epoch 694/750 - Train pg Loss: 24.400728 - Test Loss: 6.446658\n",
      "\n",
      "\n",
      "Epoch 695/750 - Train Cd Loss: 0.027472 - Test Loss: nan\n",
      "Epoch 695/750 - Train pg Loss: 23.676464 - Test Loss: 7.552901\n",
      "\n",
      "\n",
      "Epoch 696/750 - Train Cd Loss: 0.026629 - Test Loss: nan\n",
      "Epoch 696/750 - Train pg Loss: 25.904993 - Test Loss: 8.204109\n",
      "\n",
      "\n",
      "Epoch 697/750 - Train Cd Loss: 0.037865 - Test Loss: nan\n",
      "Epoch 697/750 - Train pg Loss: 23.192369 - Test Loss: 6.792910\n",
      "\n",
      "\n",
      "Epoch 698/750 - Train Cd Loss: 0.026451 - Test Loss: nan\n",
      "Epoch 698/750 - Train pg Loss: 22.577721 - Test Loss: 8.131051\n",
      "\n",
      "\n",
      "Epoch 699/750 - Train Cd Loss: 0.035723 - Test Loss: 0.070423\n",
      "Epoch 699/750 - Train pg Loss: 24.480198 - Test Loss: 6.867977\n",
      "\n",
      "\n",
      "Epoch 700/750 - Train Cd Loss: 0.022979 - Test Loss: 0.074088\n",
      "Epoch 700/750 - Train pg Loss: 23.689896 - Test Loss: 7.251330\n",
      "\n",
      "\n",
      "Epoch 701/750 - Train Cd Loss: 0.026571 - Test Loss: nan\n",
      "Epoch 701/750 - Train pg Loss: 23.137156 - Test Loss: 6.858587\n",
      "\n",
      "\n",
      "Epoch 702/750 - Train Cd Loss: 0.053275 - Test Loss: nan\n",
      "Epoch 702/750 - Train pg Loss: 23.140230 - Test Loss: 7.951706\n",
      "\n",
      "\n",
      "Epoch 703/750 - Train Cd Loss: 0.029339 - Test Loss: nan\n",
      "Epoch 703/750 - Train pg Loss: 23.697933 - Test Loss: 6.940408\n",
      "\n",
      "\n",
      "Epoch 704/750 - Train Cd Loss: 0.065284 - Test Loss: 0.069180\n",
      "Epoch 704/750 - Train pg Loss: 21.949675 - Test Loss: 6.191051\n",
      "\n",
      "\n",
      "Epoch 705/750 - Train Cd Loss: 0.028213 - Test Loss: nan\n",
      "Epoch 705/750 - Train pg Loss: 23.733822 - Test Loss: 6.962575\n",
      "\n",
      "\n",
      "Epoch 706/750 - Train Cd Loss: 0.024232 - Test Loss: nan\n",
      "Epoch 706/750 - Train pg Loss: 23.759706 - Test Loss: 7.585581\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 707/750 - Train Cd Loss: 0.038352 - Test Loss: 0.077411\n",
      "Epoch 707/750 - Train pg Loss: 25.916927 - Test Loss: 6.774352\n",
      "\n",
      "\n",
      "Epoch 708/750 - Train Cd Loss: 0.026332 - Test Loss: nan\n",
      "Epoch 708/750 - Train pg Loss: 22.475595 - Test Loss: 7.975441\n",
      "\n",
      "\n",
      "Epoch 709/750 - Train Cd Loss: 0.024417 - Test Loss: nan\n",
      "Epoch 709/750 - Train pg Loss: 26.788628 - Test Loss: 8.903122\n",
      "\n",
      "\n",
      "Epoch 710/750 - Train Cd Loss: 0.037096 - Test Loss: 0.080907\n",
      "Epoch 710/750 - Train pg Loss: 28.814829 - Test Loss: 7.986928\n",
      "\n",
      "\n",
      "Epoch 711/750 - Train Cd Loss: 0.025576 - Test Loss: nan\n",
      "Epoch 711/750 - Train pg Loss: 22.934782 - Test Loss: 8.348063\n",
      "\n",
      "\n",
      "Epoch 712/750 - Train Cd Loss: 0.055754 - Test Loss: 0.070991\n",
      "Epoch 712/750 - Train pg Loss: 30.069239 - Test Loss: 8.168312\n",
      "\n",
      "\n",
      "Epoch 713/750 - Train Cd Loss: 0.027804 - Test Loss: nan\n",
      "Epoch 713/750 - Train pg Loss: 29.256428 - Test Loss: 8.430999\n",
      "\n",
      "\n",
      "Epoch 714/750 - Train Cd Loss: 0.038806 - Test Loss: nan\n",
      "Epoch 714/750 - Train pg Loss: 25.070168 - Test Loss: 8.192068\n",
      "\n",
      "\n",
      "Epoch 715/750 - Train Cd Loss: 0.024837 - Test Loss: 0.076545\n",
      "Epoch 715/750 - Train pg Loss: 23.863684 - Test Loss: 7.561852\n",
      "\n",
      "\n",
      "Epoch 716/750 - Train Cd Loss: 0.027706 - Test Loss: nan\n",
      "Epoch 716/750 - Train pg Loss: 25.089310 - Test Loss: 8.457874\n",
      "\n",
      "\n",
      "Epoch 717/750 - Train Cd Loss: 0.038917 - Test Loss: nan\n",
      "Epoch 717/750 - Train pg Loss: 23.660826 - Test Loss: 8.787506\n",
      "\n",
      "\n",
      "Epoch 718/750 - Train Cd Loss: 0.040483 - Test Loss: 0.073343\n",
      "Epoch 718/750 - Train pg Loss: 24.600914 - Test Loss: 7.510237\n",
      "\n",
      "\n",
      "Epoch 719/750 - Train Cd Loss: 0.045123 - Test Loss: 0.068574\n",
      "Epoch 719/750 - Train pg Loss: 27.099657 - Test Loss: 6.744406\n",
      "\n",
      "\n",
      "Epoch 720/750 - Train Cd Loss: 0.025776 - Test Loss: 0.070713\n",
      "Epoch 720/750 - Train pg Loss: 26.163639 - Test Loss: 7.698234\n",
      "\n",
      "\n",
      "Epoch 721/750 - Train Cd Loss: 0.040476 - Test Loss: nan\n",
      "Epoch 721/750 - Train pg Loss: 29.427147 - Test Loss: 7.976385\n",
      "\n",
      "\n",
      "Epoch 722/750 - Train Cd Loss: 0.024092 - Test Loss: 0.076404\n",
      "Epoch 722/750 - Train pg Loss: 22.280983 - Test Loss: 6.539802\n",
      "\n",
      "\n",
      "Epoch 723/750 - Train Cd Loss: 0.022404 - Test Loss: nan\n",
      "Epoch 723/750 - Train pg Loss: 18.141338 - Test Loss: 5.793582\n",
      "\n",
      "\n",
      "Epoch 724/750 - Train Cd Loss: 0.041859 - Test Loss: 0.075367\n",
      "Epoch 724/750 - Train pg Loss: 23.156099 - Test Loss: 6.964122\n",
      "\n",
      "\n",
      "Epoch 725/750 - Train Cd Loss: 0.023970 - Test Loss: nan\n",
      "Epoch 725/750 - Train pg Loss: 25.557764 - Test Loss: 7.617992\n",
      "\n",
      "\n",
      "Epoch 726/750 - Train Cd Loss: 0.030706 - Test Loss: nan\n",
      "Epoch 726/750 - Train pg Loss: 25.309265 - Test Loss: 8.488660\n",
      "\n",
      "\n",
      "Epoch 727/750 - Train Cd Loss: 0.023182 - Test Loss: nan\n",
      "Epoch 727/750 - Train pg Loss: 28.026520 - Test Loss: 7.323889\n",
      "\n",
      "\n",
      "Epoch 728/750 - Train Cd Loss: 0.037378 - Test Loss: 0.075862\n",
      "Epoch 728/750 - Train pg Loss: 25.191824 - Test Loss: 7.446321\n",
      "\n",
      "\n",
      "Epoch 729/750 - Train Cd Loss: 0.047978 - Test Loss: 0.075497\n",
      "Epoch 729/750 - Train pg Loss: 23.736712 - Test Loss: 6.095379\n",
      "\n",
      "\n",
      "Epoch 730/750 - Train Cd Loss: 0.025092 - Test Loss: nan\n",
      "Epoch 730/750 - Train pg Loss: 17.879704 - Test Loss: 7.335515\n",
      "\n",
      "\n",
      "Epoch 731/750 - Train Cd Loss: 0.036774 - Test Loss: nan\n",
      "Epoch 731/750 - Train pg Loss: 25.433456 - Test Loss: 7.053555\n",
      "\n",
      "\n",
      "Epoch 732/750 - Train Cd Loss: 0.041726 - Test Loss: nan\n",
      "Epoch 732/750 - Train pg Loss: 18.666904 - Test Loss: 6.889590\n",
      "\n",
      "\n",
      "Epoch 733/750 - Train Cd Loss: 0.024389 - Test Loss: nan\n",
      "Epoch 733/750 - Train pg Loss: 24.378178 - Test Loss: 7.022648\n",
      "\n",
      "\n",
      "Epoch 734/750 - Train Cd Loss: 0.045656 - Test Loss: nan\n",
      "Epoch 734/750 - Train pg Loss: 22.014603 - Test Loss: 7.410354\n",
      "\n",
      "\n",
      "Epoch 735/750 - Train Cd Loss: 0.040112 - Test Loss: nan\n",
      "Epoch 735/750 - Train pg Loss: 22.186596 - Test Loss: 7.850137\n",
      "\n",
      "\n",
      "Epoch 736/750 - Train Cd Loss: 0.036592 - Test Loss: 0.071464\n",
      "Epoch 736/750 - Train pg Loss: 25.263287 - Test Loss: 6.593809\n",
      "\n",
      "\n",
      "Epoch 737/750 - Train Cd Loss: 0.023480 - Test Loss: nan\n",
      "Epoch 737/750 - Train pg Loss: 24.534561 - Test Loss: 8.029274\n",
      "\n",
      "\n",
      "Epoch 738/750 - Train Cd Loss: 0.025584 - Test Loss: nan\n",
      "Epoch 738/750 - Train pg Loss: 23.955296 - Test Loss: 7.978376\n",
      "\n",
      "\n",
      "Epoch 739/750 - Train Cd Loss: 0.042675 - Test Loss: nan\n",
      "Epoch 739/750 - Train pg Loss: 26.983006 - Test Loss: 7.700617\n",
      "\n",
      "\n",
      "Epoch 740/750 - Train Cd Loss: 0.024583 - Test Loss: nan\n",
      "Epoch 740/750 - Train pg Loss: 22.186359 - Test Loss: 7.557260\n",
      "\n",
      "\n",
      "Epoch 741/750 - Train Cd Loss: 0.035912 - Test Loss: nan\n",
      "Epoch 741/750 - Train pg Loss: 25.555002 - Test Loss: 7.349595\n",
      "\n",
      "\n",
      "Epoch 742/750 - Train Cd Loss: 0.032484 - Test Loss: 0.073025\n",
      "Epoch 742/750 - Train pg Loss: 26.488058 - Test Loss: 6.996564\n",
      "\n",
      "\n",
      "Epoch 743/750 - Train Cd Loss: 0.023544 - Test Loss: nan\n",
      "Epoch 743/750 - Train pg Loss: 26.804770 - Test Loss: 8.437347\n",
      "\n",
      "\n",
      "Epoch 744/750 - Train Cd Loss: 0.024128 - Test Loss: nan\n",
      "Epoch 744/750 - Train pg Loss: 29.349871 - Test Loss: 7.706299\n",
      "\n",
      "\n",
      "Epoch 745/750 - Train Cd Loss: 0.037286 - Test Loss: nan\n",
      "Epoch 745/750 - Train pg Loss: 27.947844 - Test Loss: 9.420565\n",
      "\n",
      "\n",
      "Epoch 746/750 - Train Cd Loss: 0.037239 - Test Loss: 0.073159\n",
      "Epoch 746/750 - Train pg Loss: 29.221786 - Test Loss: 8.179664\n",
      "\n",
      "\n",
      "Epoch 747/750 - Train Cd Loss: 0.023363 - Test Loss: nan\n",
      "Epoch 747/750 - Train pg Loss: 28.996067 - Test Loss: 7.899296\n",
      "\n",
      "\n",
      "Epoch 748/750 - Train Cd Loss: 0.047317 - Test Loss: 0.073889\n",
      "Epoch 748/750 - Train pg Loss: 26.523424 - Test Loss: 7.651902\n",
      "\n",
      "\n",
      "Epoch 749/750 - Train Cd Loss: 0.026735 - Test Loss: 0.075778\n",
      "Epoch 749/750 - Train pg Loss: 24.059700 - Test Loss: 6.497036\n",
      "\n",
      "\n",
      "Epoch 750/750 - Train Cd Loss: 0.031526 - Test Loss: 0.073357\n",
      "Epoch 750/750 - Train pg Loss: 24.050529 - Test Loss: 6.986422\n",
      "\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch 1/750 - Train Cd Loss: 0.172496 - Test Loss: 0.030513\n",
      "Epoch 1/750 - Train pg Loss: 2.667874 - Test Loss: 0.651805\n",
      "\n",
      "\n",
      "Epoch 2/750 - Train Cd Loss: 0.171323 - Test Loss: 0.030559\n",
      "Epoch 2/750 - Train pg Loss: 2.602895 - Test Loss: 0.637110\n",
      "\n",
      "\n",
      "Epoch 3/750 - Train Cd Loss: 0.170527 - Test Loss: 0.030668\n",
      "Epoch 3/750 - Train pg Loss: 2.568951 - Test Loss: 0.627037\n",
      "\n",
      "\n",
      "Epoch 4/750 - Train Cd Loss: 0.170538 - Test Loss: 0.030684\n",
      "Epoch 4/750 - Train pg Loss: 2.535599 - Test Loss: 0.626979\n",
      "\n",
      "\n",
      "Epoch 5/750 - Train Cd Loss: 0.169645 - Test Loss: 0.030735\n",
      "Epoch 5/750 - Train pg Loss: 2.530196 - Test Loss: 0.623371\n",
      "\n",
      "\n",
      "Epoch 6/750 - Train Cd Loss: 0.169626 - Test Loss: 0.030842\n",
      "Epoch 6/750 - Train pg Loss: 2.499802 - Test Loss: 0.613218\n",
      "\n",
      "\n",
      "Epoch 7/750 - Train Cd Loss: 0.169119 - Test Loss: 0.030989\n",
      "Epoch 7/750 - Train pg Loss: 2.476289 - Test Loss: 0.609476\n",
      "\n",
      "\n",
      "Epoch 8/750 - Train Cd Loss: 0.168819 - Test Loss: 0.031126\n",
      "Epoch 8/750 - Train pg Loss: 2.476996 - Test Loss: 0.612819\n",
      "\n",
      "\n",
      "Epoch 9/750 - Train Cd Loss: 0.168757 - Test Loss: 0.031152\n",
      "Epoch 9/750 - Train pg Loss: 2.478909 - Test Loss: 0.611124\n",
      "\n",
      "\n",
      "Epoch 10/750 - Train Cd Loss: 0.168053 - Test Loss: 0.030651\n",
      "Epoch 10/750 - Train pg Loss: 2.474644 - Test Loss: 0.611888\n",
      "\n",
      "\n",
      "Epoch 11/750 - Train Cd Loss: 0.168461 - Test Loss: 0.030970\n",
      "Epoch 11/750 - Train pg Loss: 2.470955 - Test Loss: 0.608200\n",
      "\n",
      "\n",
      "Epoch 12/750 - Train Cd Loss: 0.168356 - Test Loss: 0.031240\n",
      "Epoch 12/750 - Train pg Loss: 2.470143 - Test Loss: 0.607303\n",
      "\n",
      "\n",
      "Epoch 13/750 - Train Cd Loss: 0.166435 - Test Loss: 0.031200\n",
      "Epoch 13/750 - Train pg Loss: 2.452332 - Test Loss: 0.608010\n",
      "\n",
      "\n",
      "Epoch 14/750 - Train Cd Loss: 0.168518 - Test Loss: 0.031394\n",
      "Epoch 14/750 - Train pg Loss: 2.460182 - Test Loss: 0.603886\n",
      "\n",
      "\n",
      "Epoch 15/750 - Train Cd Loss: 0.165942 - Test Loss: 0.031212\n",
      "Epoch 15/750 - Train pg Loss: 2.450012 - Test Loss: 0.608877\n",
      "\n",
      "\n",
      "Epoch 16/750 - Train Cd Loss: 0.167804 - Test Loss: 0.031613\n",
      "Epoch 16/750 - Train pg Loss: 2.471479 - Test Loss: 0.608690\n",
      "\n",
      "\n",
      "Epoch 17/750 - Train Cd Loss: 0.167555 - Test Loss: 0.031858\n",
      "Epoch 17/750 - Train pg Loss: 2.477107 - Test Loss: 0.609624\n",
      "\n",
      "\n",
      "Epoch 18/750 - Train Cd Loss: 0.166545 - Test Loss: 0.031127\n",
      "Epoch 18/750 - Train pg Loss: 2.467413 - Test Loss: 0.605167\n",
      "\n",
      "\n",
      "Epoch 19/750 - Train Cd Loss: 0.167970 - Test Loss: 0.031681\n",
      "Epoch 19/750 - Train pg Loss: 2.437964 - Test Loss: 0.605972\n",
      "\n",
      "\n",
      "Epoch 20/750 - Train Cd Loss: 0.166107 - Test Loss: 0.031873\n",
      "Epoch 20/750 - Train pg Loss: 2.437725 - Test Loss: 0.605776\n",
      "\n",
      "\n",
      "Epoch 21/750 - Train Cd Loss: 0.168692 - Test Loss: 0.031629\n",
      "Epoch 21/750 - Train pg Loss: 2.450727 - Test Loss: 0.605964\n",
      "\n",
      "\n",
      "Epoch 22/750 - Train Cd Loss: 0.165990 - Test Loss: 0.032158\n",
      "Epoch 22/750 - Train pg Loss: 2.472007 - Test Loss: 0.614125\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/750 - Train Cd Loss: 0.168387 - Test Loss: 0.031935\n",
      "Epoch 23/750 - Train pg Loss: 2.481268 - Test Loss: 0.623248\n",
      "\n",
      "\n",
      "Epoch 24/750 - Train Cd Loss: 0.168230 - Test Loss: 0.031490\n",
      "Epoch 24/750 - Train pg Loss: 2.531127 - Test Loss: 0.636809\n",
      "\n",
      "\n",
      "Epoch 25/750 - Train Cd Loss: 0.168023 - Test Loss: 0.031635\n",
      "Epoch 25/750 - Train pg Loss: 2.581690 - Test Loss: 0.639540\n",
      "\n",
      "\n",
      "Epoch 26/750 - Train Cd Loss: 0.167059 - Test Loss: 0.031533\n",
      "Epoch 26/750 - Train pg Loss: 2.592811 - Test Loss: 0.643187\n",
      "\n",
      "\n",
      "Epoch 27/750 - Train Cd Loss: 0.168055 - Test Loss: 0.031742\n",
      "Epoch 27/750 - Train pg Loss: 2.605120 - Test Loss: 0.642456\n",
      "\n",
      "\n",
      "Epoch 28/750 - Train Cd Loss: 0.166330 - Test Loss: 0.031751\n",
      "Epoch 28/750 - Train pg Loss: 2.598935 - Test Loss: 0.647211\n",
      "\n",
      "\n",
      "Epoch 29/750 - Train Cd Loss: 0.167936 - Test Loss: 0.031567\n",
      "Epoch 29/750 - Train pg Loss: 2.608644 - Test Loss: 0.650328\n",
      "\n",
      "\n",
      "Epoch 30/750 - Train Cd Loss: 0.168156 - Test Loss: 0.031686\n",
      "Epoch 30/750 - Train pg Loss: 2.637950 - Test Loss: 0.651762\n",
      "\n",
      "\n",
      "Epoch 31/750 - Train Cd Loss: 0.165838 - Test Loss: 0.031928\n",
      "Epoch 31/750 - Train pg Loss: 2.656429 - Test Loss: 0.652302\n",
      "\n",
      "\n",
      "Epoch 32/750 - Train Cd Loss: 0.167173 - Test Loss: 0.031831\n",
      "Epoch 32/750 - Train pg Loss: 2.691853 - Test Loss: 0.662816\n",
      "\n",
      "\n",
      "Epoch 33/750 - Train Cd Loss: 0.166065 - Test Loss: 0.031566\n",
      "Epoch 33/750 - Train pg Loss: 2.668938 - Test Loss: 0.660391\n",
      "\n",
      "\n",
      "Epoch 34/750 - Train Cd Loss: 0.166807 - Test Loss: 0.031622\n",
      "Epoch 34/750 - Train pg Loss: 2.689028 - Test Loss: 0.664830\n",
      "\n",
      "\n",
      "Epoch 35/750 - Train Cd Loss: 0.166978 - Test Loss: 0.031599\n",
      "Epoch 35/750 - Train pg Loss: 2.693342 - Test Loss: 0.664806\n",
      "\n",
      "\n",
      "Epoch 36/750 - Train Cd Loss: 0.166611 - Test Loss: 0.031647\n",
      "Epoch 36/750 - Train pg Loss: 2.733443 - Test Loss: 0.667452\n",
      "\n",
      "\n",
      "Epoch 37/750 - Train Cd Loss: 0.167115 - Test Loss: 0.031954\n",
      "Epoch 37/750 - Train pg Loss: 2.743268 - Test Loss: 0.674465\n",
      "\n",
      "\n",
      "Epoch 38/750 - Train Cd Loss: 0.166721 - Test Loss: 0.031592\n",
      "Epoch 38/750 - Train pg Loss: 2.752378 - Test Loss: 0.683125\n",
      "\n",
      "\n",
      "Epoch 39/750 - Train Cd Loss: 0.166206 - Test Loss: 0.031643\n",
      "Epoch 39/750 - Train pg Loss: 2.814838 - Test Loss: 0.684032\n",
      "\n",
      "\n",
      "Epoch 40/750 - Train Cd Loss: 0.165403 - Test Loss: 0.031813\n",
      "Epoch 40/750 - Train pg Loss: 2.783867 - Test Loss: 0.690047\n",
      "\n",
      "\n",
      "Epoch 41/750 - Train Cd Loss: 0.164991 - Test Loss: 0.031885\n",
      "Epoch 41/750 - Train pg Loss: 2.768035 - Test Loss: 0.691959\n",
      "\n",
      "\n",
      "Epoch 42/750 - Train Cd Loss: 0.167927 - Test Loss: 0.031411\n",
      "Epoch 42/750 - Train pg Loss: 2.792432 - Test Loss: 0.687728\n",
      "\n",
      "\n",
      "Epoch 43/750 - Train Cd Loss: 0.166253 - Test Loss: 0.031732\n",
      "Epoch 43/750 - Train pg Loss: 2.750813 - Test Loss: 0.682906\n",
      "\n",
      "\n",
      "Epoch 44/750 - Train Cd Loss: 0.165476 - Test Loss: 0.031549\n",
      "Epoch 44/750 - Train pg Loss: 2.801452 - Test Loss: 0.692512\n",
      "\n",
      "\n",
      "Epoch 45/750 - Train Cd Loss: 0.166580 - Test Loss: 0.032007\n",
      "Epoch 45/750 - Train pg Loss: 2.821576 - Test Loss: 0.687716\n",
      "\n",
      "\n",
      "Epoch 46/750 - Train Cd Loss: 0.164975 - Test Loss: 0.031331\n",
      "Epoch 46/750 - Train pg Loss: 2.869621 - Test Loss: 0.717210\n",
      "\n",
      "\n",
      "Epoch 47/750 - Train Cd Loss: 0.166717 - Test Loss: 0.031405\n",
      "Epoch 47/750 - Train pg Loss: 2.936144 - Test Loss: 0.721167\n",
      "\n",
      "\n",
      "Epoch 48/750 - Train Cd Loss: 0.164762 - Test Loss: 0.031035\n",
      "Epoch 48/750 - Train pg Loss: 2.909691 - Test Loss: 0.716554\n",
      "\n",
      "\n",
      "Epoch 49/750 - Train Cd Loss: 0.165984 - Test Loss: 0.031796\n",
      "Epoch 49/750 - Train pg Loss: 2.838906 - Test Loss: 0.698743\n",
      "\n",
      "\n",
      "Epoch 50/750 - Train Cd Loss: 0.163569 - Test Loss: 0.031748\n",
      "Epoch 50/750 - Train pg Loss: 2.878275 - Test Loss: 0.699751\n",
      "\n",
      "\n",
      "Epoch 51/750 - Train Cd Loss: 0.167506 - Test Loss: 0.032093\n",
      "Epoch 51/750 - Train pg Loss: 2.867332 - Test Loss: 0.699713\n",
      "\n",
      "\n",
      "Epoch 52/750 - Train Cd Loss: 0.166699 - Test Loss: 0.031540\n",
      "Epoch 52/750 - Train pg Loss: 2.813663 - Test Loss: 0.691155\n",
      "\n",
      "\n",
      "Epoch 53/750 - Train Cd Loss: 0.162683 - Test Loss: 0.031174\n",
      "Epoch 53/750 - Train pg Loss: 2.764042 - Test Loss: 0.687879\n",
      "\n",
      "\n",
      "Epoch 54/750 - Train Cd Loss: 0.166528 - Test Loss: 0.031289\n",
      "Epoch 54/750 - Train pg Loss: 2.857564 - Test Loss: 0.702901\n",
      "\n",
      "\n",
      "Epoch 55/750 - Train Cd Loss: 0.167233 - Test Loss: 0.031708\n",
      "Epoch 55/750 - Train pg Loss: 2.894464 - Test Loss: 0.711758\n",
      "\n",
      "\n",
      "Epoch 56/750 - Train Cd Loss: 0.164795 - Test Loss: 0.031411\n",
      "Epoch 56/750 - Train pg Loss: 2.903307 - Test Loss: 0.708636\n",
      "\n",
      "\n",
      "Epoch 57/750 - Train Cd Loss: 0.164736 - Test Loss: 0.031548\n",
      "Epoch 57/750 - Train pg Loss: 2.901651 - Test Loss: 0.717060\n",
      "\n",
      "\n",
      "Epoch 58/750 - Train Cd Loss: 0.164944 - Test Loss: 0.031408\n",
      "Epoch 58/750 - Train pg Loss: 2.949507 - Test Loss: 0.719982\n",
      "\n",
      "\n",
      "Epoch 59/750 - Train Cd Loss: 0.163440 - Test Loss: 0.031366\n",
      "Epoch 59/750 - Train pg Loss: 2.923909 - Test Loss: 0.719978\n",
      "\n",
      "\n",
      "Epoch 60/750 - Train Cd Loss: 0.162092 - Test Loss: 0.031727\n",
      "Epoch 60/750 - Train pg Loss: 2.994568 - Test Loss: 0.732602\n",
      "\n",
      "\n",
      "Epoch 61/750 - Train Cd Loss: 0.162108 - Test Loss: 0.031475\n",
      "Epoch 61/750 - Train pg Loss: 3.017639 - Test Loss: 0.735409\n",
      "\n",
      "\n",
      "Epoch 62/750 - Train Cd Loss: 0.162902 - Test Loss: 0.031810\n",
      "Epoch 62/750 - Train pg Loss: 2.990246 - Test Loss: 0.738074\n",
      "\n",
      "\n",
      "Epoch 63/750 - Train Cd Loss: 0.164893 - Test Loss: 0.031566\n",
      "Epoch 63/750 - Train pg Loss: 3.016575 - Test Loss: 0.744199\n",
      "\n",
      "\n",
      "Epoch 64/750 - Train Cd Loss: 0.164165 - Test Loss: 0.031427\n",
      "Epoch 64/750 - Train pg Loss: 3.046510 - Test Loss: 0.741692\n",
      "\n",
      "\n",
      "Epoch 65/750 - Train Cd Loss: 0.162338 - Test Loss: 0.031566\n",
      "Epoch 65/750 - Train pg Loss: 3.077096 - Test Loss: 0.758604\n",
      "\n",
      "\n",
      "Epoch 66/750 - Train Cd Loss: 0.162925 - Test Loss: 0.031079\n",
      "Epoch 66/750 - Train pg Loss: 3.079317 - Test Loss: 0.742714\n",
      "\n",
      "\n",
      "Epoch 67/750 - Train Cd Loss: 0.163398 - Test Loss: 0.031359\n",
      "Epoch 67/750 - Train pg Loss: 2.945125 - Test Loss: 0.716440\n",
      "\n",
      "\n",
      "Epoch 68/750 - Train Cd Loss: 0.163024 - Test Loss: 0.031364\n",
      "Epoch 68/750 - Train pg Loss: 2.963263 - Test Loss: 0.725097\n",
      "\n",
      "\n",
      "Epoch 69/750 - Train Cd Loss: 0.161996 - Test Loss: 0.032053\n",
      "Epoch 69/750 - Train pg Loss: 2.851430 - Test Loss: 0.690167\n",
      "\n",
      "\n",
      "Epoch 70/750 - Train Cd Loss: 0.162499 - Test Loss: 0.031661\n",
      "Epoch 70/750 - Train pg Loss: 2.767421 - Test Loss: 0.678880\n",
      "\n",
      "\n",
      "Epoch 71/750 - Train Cd Loss: 0.162728 - Test Loss: 0.032335\n",
      "Epoch 71/750 - Train pg Loss: 2.706906 - Test Loss: 0.668717\n",
      "\n",
      "\n",
      "Epoch 72/750 - Train Cd Loss: 0.161222 - Test Loss: 0.032296\n",
      "Epoch 72/750 - Train pg Loss: 2.743561 - Test Loss: 0.681545\n",
      "\n",
      "\n",
      "Epoch 73/750 - Train Cd Loss: 0.163257 - Test Loss: 0.032235\n",
      "Epoch 73/750 - Train pg Loss: 2.723485 - Test Loss: 0.679674\n",
      "\n",
      "\n",
      "Epoch 74/750 - Train Cd Loss: 0.160094 - Test Loss: 0.031997\n",
      "Epoch 74/750 - Train pg Loss: 2.736378 - Test Loss: 0.696659\n",
      "\n",
      "\n",
      "Epoch 75/750 - Train Cd Loss: 0.161950 - Test Loss: 0.031376\n",
      "Epoch 75/750 - Train pg Loss: 2.915438 - Test Loss: 0.718055\n",
      "\n",
      "\n",
      "Epoch 76/750 - Train Cd Loss: 0.160441 - Test Loss: 0.031587\n",
      "Epoch 76/750 - Train pg Loss: 2.868253 - Test Loss: 0.694416\n",
      "\n",
      "\n",
      "Epoch 77/750 - Train Cd Loss: 0.159020 - Test Loss: 0.031650\n",
      "Epoch 77/750 - Train pg Loss: 2.819297 - Test Loss: 0.700281\n",
      "\n",
      "\n",
      "Epoch 78/750 - Train Cd Loss: 0.161749 - Test Loss: 0.031691\n",
      "Epoch 78/750 - Train pg Loss: 2.867546 - Test Loss: 0.709584\n",
      "\n",
      "\n",
      "Epoch 79/750 - Train Cd Loss: 0.157684 - Test Loss: 0.031962\n",
      "Epoch 79/750 - Train pg Loss: 2.885890 - Test Loss: 0.697851\n",
      "\n",
      "\n",
      "Epoch 80/750 - Train Cd Loss: 0.158716 - Test Loss: 0.032009\n",
      "Epoch 80/750 - Train pg Loss: 2.914989 - Test Loss: 0.716221\n",
      "\n",
      "\n",
      "Epoch 81/750 - Train Cd Loss: 0.160216 - Test Loss: 0.031559\n",
      "Epoch 81/750 - Train pg Loss: 2.918429 - Test Loss: 0.713388\n",
      "\n",
      "\n",
      "Epoch 82/750 - Train Cd Loss: 0.158186 - Test Loss: 0.031811\n",
      "Epoch 82/750 - Train pg Loss: 2.850849 - Test Loss: 0.679229\n",
      "\n",
      "\n",
      "Epoch 83/750 - Train Cd Loss: 0.158798 - Test Loss: 0.032017\n",
      "Epoch 83/750 - Train pg Loss: 2.746120 - Test Loss: 0.655598\n",
      "\n",
      "\n",
      "Epoch 84/750 - Train Cd Loss: 0.159778 - Test Loss: 0.031283\n",
      "Epoch 84/750 - Train pg Loss: 2.704454 - Test Loss: 0.682131\n",
      "\n",
      "\n",
      "Epoch 85/750 - Train Cd Loss: 0.158463 - Test Loss: 0.032104\n",
      "Epoch 85/750 - Train pg Loss: 2.726959 - Test Loss: 0.677174\n",
      "\n",
      "\n",
      "Epoch 86/750 - Train Cd Loss: 0.155542 - Test Loss: 0.032032\n",
      "Epoch 86/750 - Train pg Loss: 2.637397 - Test Loss: 0.651672\n",
      "\n",
      "\n",
      "Epoch 87/750 - Train Cd Loss: 0.157671 - Test Loss: 0.032627\n",
      "Epoch 87/750 - Train pg Loss: 2.622531 - Test Loss: 0.628692\n",
      "\n",
      "\n",
      "Epoch 88/750 - Train Cd Loss: 0.157987 - Test Loss: 0.032550\n",
      "Epoch 88/750 - Train pg Loss: 2.546631 - Test Loss: 0.629608\n",
      "\n",
      "\n",
      "Epoch 89/750 - Train Cd Loss: 0.152039 - Test Loss: 0.031390\n",
      "Epoch 89/750 - Train pg Loss: 2.574416 - Test Loss: 0.625220\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/750 - Train Cd Loss: 0.158791 - Test Loss: 0.032567\n",
      "Epoch 90/750 - Train pg Loss: 2.542910 - Test Loss: 0.636758\n",
      "\n",
      "\n",
      "Epoch 91/750 - Train Cd Loss: 0.158703 - Test Loss: 0.031946\n",
      "Epoch 91/750 - Train pg Loss: 2.653223 - Test Loss: 0.664634\n",
      "\n",
      "\n",
      "Epoch 92/750 - Train Cd Loss: 0.156360 - Test Loss: 0.031637\n",
      "Epoch 92/750 - Train pg Loss: 2.702147 - Test Loss: 0.656818\n",
      "\n",
      "\n",
      "Epoch 93/750 - Train Cd Loss: 0.155652 - Test Loss: 0.031698\n",
      "Epoch 93/750 - Train pg Loss: 2.679906 - Test Loss: 0.669070\n",
      "\n",
      "\n",
      "Epoch 94/750 - Train Cd Loss: 0.155035 - Test Loss: 0.031821\n",
      "Epoch 94/750 - Train pg Loss: 2.762269 - Test Loss: 0.689646\n",
      "\n",
      "\n",
      "Epoch 95/750 - Train Cd Loss: 0.156508 - Test Loss: 0.031488\n",
      "Epoch 95/750 - Train pg Loss: 2.813028 - Test Loss: 0.696580\n",
      "\n",
      "\n",
      "Epoch 96/750 - Train Cd Loss: 0.154144 - Test Loss: 0.031616\n",
      "Epoch 96/750 - Train pg Loss: 2.861382 - Test Loss: 0.730255\n",
      "\n",
      "\n",
      "Epoch 97/750 - Train Cd Loss: 0.154346 - Test Loss: 0.032527\n",
      "Epoch 97/750 - Train pg Loss: 2.899662 - Test Loss: 0.716597\n",
      "\n",
      "\n",
      "Epoch 98/750 - Train Cd Loss: 0.151835 - Test Loss: 0.031812\n",
      "Epoch 98/750 - Train pg Loss: 2.866592 - Test Loss: 0.719407\n",
      "\n",
      "\n",
      "Epoch 99/750 - Train Cd Loss: 0.148962 - Test Loss: 0.032176\n",
      "Epoch 99/750 - Train pg Loss: 2.823084 - Test Loss: 0.660073\n",
      "\n",
      "\n",
      "Epoch 100/750 - Train Cd Loss: 0.150300 - Test Loss: 0.031701\n",
      "Epoch 100/750 - Train pg Loss: 2.699527 - Test Loss: 0.671615\n",
      "\n",
      "\n",
      "Epoch 101/750 - Train Cd Loss: 0.150320 - Test Loss: 0.033294\n",
      "Epoch 101/750 - Train pg Loss: 2.688948 - Test Loss: 0.649947\n",
      "\n",
      "\n",
      "Epoch 102/750 - Train Cd Loss: 0.153861 - Test Loss: 0.032568\n",
      "Epoch 102/750 - Train pg Loss: 2.667815 - Test Loss: 0.655113\n",
      "\n",
      "\n",
      "Epoch 103/750 - Train Cd Loss: 0.150025 - Test Loss: 0.032278\n",
      "Epoch 103/750 - Train pg Loss: 2.786017 - Test Loss: 0.722095\n",
      "\n",
      "\n",
      "Epoch 104/750 - Train Cd Loss: 0.151817 - Test Loss: 0.031413\n",
      "Epoch 104/750 - Train pg Loss: 2.994345 - Test Loss: 0.737942\n",
      "\n",
      "\n",
      "Epoch 105/750 - Train Cd Loss: 0.147270 - Test Loss: 0.031998\n",
      "Epoch 105/750 - Train pg Loss: 2.948968 - Test Loss: 0.700763\n",
      "\n",
      "\n",
      "Epoch 106/750 - Train Cd Loss: 0.147774 - Test Loss: 0.032729\n",
      "Epoch 106/750 - Train pg Loss: 2.795074 - Test Loss: 0.623696\n",
      "\n",
      "\n",
      "Epoch 107/750 - Train Cd Loss: 0.150117 - Test Loss: 0.031904\n",
      "Epoch 107/750 - Train pg Loss: 2.578748 - Test Loss: 0.611915\n",
      "\n",
      "\n",
      "Epoch 108/750 - Train Cd Loss: 0.148324 - Test Loss: 0.031910\n",
      "Epoch 108/750 - Train pg Loss: 2.636956 - Test Loss: 0.655285\n",
      "\n",
      "\n",
      "Epoch 109/750 - Train Cd Loss: 0.148785 - Test Loss: 0.031671\n",
      "Epoch 109/750 - Train pg Loss: 2.715046 - Test Loss: 0.667800\n",
      "\n",
      "\n",
      "Epoch 110/750 - Train Cd Loss: 0.144078 - Test Loss: 0.031927\n",
      "Epoch 110/750 - Train pg Loss: 2.602940 - Test Loss: 0.629470\n",
      "\n",
      "\n",
      "Epoch 111/750 - Train Cd Loss: 0.145596 - Test Loss: 0.031483\n",
      "Epoch 111/750 - Train pg Loss: 2.738815 - Test Loss: 0.680151\n",
      "\n",
      "\n",
      "Epoch 112/750 - Train Cd Loss: 0.149811 - Test Loss: 0.033642\n",
      "Epoch 112/750 - Train pg Loss: 2.672128 - Test Loss: 0.660093\n",
      "\n",
      "\n",
      "Epoch 113/750 - Train Cd Loss: 0.147627 - Test Loss: 0.031624\n",
      "Epoch 113/750 - Train pg Loss: 2.916499 - Test Loss: 0.708501\n",
      "\n",
      "\n",
      "Epoch 114/750 - Train Cd Loss: 0.149850 - Test Loss: 0.031887\n",
      "Epoch 114/750 - Train pg Loss: 2.968647 - Test Loss: 0.711820\n",
      "\n",
      "\n",
      "Epoch 115/750 - Train Cd Loss: 0.145927 - Test Loss: 0.031297\n",
      "Epoch 115/750 - Train pg Loss: 3.174428 - Test Loss: 0.736063\n",
      "\n",
      "\n",
      "Epoch 116/750 - Train Cd Loss: 0.147317 - Test Loss: 0.032400\n",
      "Epoch 116/750 - Train pg Loss: 2.987231 - Test Loss: 0.724275\n",
      "\n",
      "\n",
      "Epoch 117/750 - Train Cd Loss: 0.145606 - Test Loss: 0.032769\n",
      "Epoch 117/750 - Train pg Loss: 3.010780 - Test Loss: 0.735564\n",
      "\n",
      "\n",
      "Epoch 118/750 - Train Cd Loss: 0.139977 - Test Loss: 0.032134\n",
      "Epoch 118/750 - Train pg Loss: 3.091401 - Test Loss: 0.759413\n",
      "\n",
      "\n",
      "Epoch 119/750 - Train Cd Loss: 0.141911 - Test Loss: 0.032002\n",
      "Epoch 119/750 - Train pg Loss: 3.005099 - Test Loss: 0.709706\n",
      "\n",
      "\n",
      "Epoch 120/750 - Train Cd Loss: 0.142487 - Test Loss: 0.033262\n",
      "Epoch 120/750 - Train pg Loss: 2.961957 - Test Loss: 0.716691\n",
      "\n",
      "\n",
      "Epoch 121/750 - Train Cd Loss: 0.144891 - Test Loss: 0.031303\n",
      "Epoch 121/750 - Train pg Loss: 3.097832 - Test Loss: 0.769296\n",
      "\n",
      "\n",
      "Epoch 122/750 - Train Cd Loss: 0.138042 - Test Loss: 0.032151\n",
      "Epoch 122/750 - Train pg Loss: 3.228606 - Test Loss: 0.716827\n",
      "\n",
      "\n",
      "Epoch 123/750 - Train Cd Loss: 0.160327 - Test Loss: 0.031764\n",
      "Epoch 123/750 - Train pg Loss: 3.574685 - Test Loss: 0.796906\n",
      "\n",
      "\n",
      "Epoch 124/750 - Train Cd Loss: 0.145561 - Test Loss: 0.030407\n",
      "Epoch 124/750 - Train pg Loss: 3.436830 - Test Loss: 0.814695\n",
      "\n",
      "\n",
      "Epoch 125/750 - Train Cd Loss: 0.144215 - Test Loss: 0.030518\n",
      "Epoch 125/750 - Train pg Loss: 3.512027 - Test Loss: 0.824041\n",
      "\n",
      "\n",
      "Epoch 126/750 - Train Cd Loss: 0.144366 - Test Loss: 0.032852\n",
      "Epoch 126/750 - Train pg Loss: 3.146672 - Test Loss: 0.730221\n",
      "\n",
      "\n",
      "Epoch 127/750 - Train Cd Loss: 0.141721 - Test Loss: 0.032483\n",
      "Epoch 127/750 - Train pg Loss: 3.103305 - Test Loss: 0.774940\n",
      "\n",
      "\n",
      "Epoch 128/750 - Train Cd Loss: 0.142648 - Test Loss: 0.032453\n",
      "Epoch 128/750 - Train pg Loss: 3.083243 - Test Loss: 0.722752\n",
      "\n",
      "\n",
      "Epoch 129/750 - Train Cd Loss: 0.140935 - Test Loss: 0.033349\n",
      "Epoch 129/750 - Train pg Loss: 2.980902 - Test Loss: 0.727221\n",
      "\n",
      "\n",
      "Epoch 130/750 - Train Cd Loss: 0.143341 - Test Loss: 0.031314\n",
      "Epoch 130/750 - Train pg Loss: 3.276448 - Test Loss: 0.777517\n",
      "\n",
      "\n",
      "Epoch 131/750 - Train Cd Loss: 0.139113 - Test Loss: 0.033965\n",
      "Epoch 131/750 - Train pg Loss: 2.964073 - Test Loss: 0.640837\n",
      "\n",
      "\n",
      "Epoch 132/750 - Train Cd Loss: 0.140076 - Test Loss: 0.031810\n",
      "Epoch 132/750 - Train pg Loss: 3.001096 - Test Loss: 0.736014\n",
      "\n",
      "\n",
      "Epoch 133/750 - Train Cd Loss: 0.149730 - Test Loss: 0.031213\n",
      "Epoch 133/750 - Train pg Loss: 3.437373 - Test Loss: 0.794588\n",
      "\n",
      "\n",
      "Epoch 134/750 - Train Cd Loss: 0.133543 - Test Loss: 0.031108\n",
      "Epoch 134/750 - Train pg Loss: 3.661647 - Test Loss: 0.876859\n",
      "\n",
      "\n",
      "Epoch 135/750 - Train Cd Loss: 0.141950 - Test Loss: 0.031420\n",
      "Epoch 135/750 - Train pg Loss: 3.880494 - Test Loss: 0.835524\n",
      "\n",
      "\n",
      "Epoch 136/750 - Train Cd Loss: 0.136823 - Test Loss: 0.032055\n",
      "Epoch 136/750 - Train pg Loss: 3.536837 - Test Loss: 0.867068\n",
      "\n",
      "\n",
      "Epoch 137/750 - Train Cd Loss: 0.151528 - Test Loss: 0.031041\n",
      "Epoch 137/750 - Train pg Loss: 4.296720 - Test Loss: 0.941395\n",
      "\n",
      "\n",
      "Epoch 138/750 - Train Cd Loss: 0.139254 - Test Loss: 0.031235\n",
      "Epoch 138/750 - Train pg Loss: 3.940358 - Test Loss: 0.937807\n",
      "\n",
      "\n",
      "Epoch 139/750 - Train Cd Loss: 0.142936 - Test Loss: 0.031830\n",
      "Epoch 139/750 - Train pg Loss: 3.723212 - Test Loss: 0.809758\n",
      "\n",
      "\n",
      "Epoch 140/750 - Train Cd Loss: 0.136494 - Test Loss: 0.031082\n",
      "Epoch 140/750 - Train pg Loss: 3.264628 - Test Loss: 0.747928\n",
      "\n",
      "\n",
      "Epoch 141/750 - Train Cd Loss: 0.135186 - Test Loss: 0.030752\n",
      "Epoch 141/750 - Train pg Loss: 3.109611 - Test Loss: 0.689306\n",
      "\n",
      "\n",
      "Epoch 142/750 - Train Cd Loss: 0.130525 - Test Loss: 0.033301\n",
      "Epoch 142/750 - Train pg Loss: 2.703064 - Test Loss: 0.640031\n",
      "\n",
      "\n",
      "Epoch 143/750 - Train Cd Loss: 0.132883 - Test Loss: 0.031129\n",
      "Epoch 143/750 - Train pg Loss: 2.710996 - Test Loss: 0.664822\n",
      "\n",
      "\n",
      "Epoch 144/750 - Train Cd Loss: 0.137442 - Test Loss: 0.031484\n",
      "Epoch 144/750 - Train pg Loss: 3.121905 - Test Loss: 0.705687\n",
      "\n",
      "\n",
      "Epoch 145/750 - Train Cd Loss: 0.128230 - Test Loss: 0.032240\n",
      "Epoch 145/750 - Train pg Loss: 3.621576 - Test Loss: 0.825578\n",
      "\n",
      "\n",
      "Epoch 146/750 - Train Cd Loss: 0.138817 - Test Loss: 0.030771\n",
      "Epoch 146/750 - Train pg Loss: 3.532748 - Test Loss: 0.798742\n",
      "\n",
      "\n",
      "Epoch 147/750 - Train Cd Loss: 0.143175 - Test Loss: 0.030306\n",
      "Epoch 147/750 - Train pg Loss: 3.206838 - Test Loss: 0.727790\n",
      "\n",
      "\n",
      "Epoch 148/750 - Train Cd Loss: 0.141292 - Test Loss: 0.029808\n",
      "Epoch 148/750 - Train pg Loss: 3.827673 - Test Loss: 0.836812\n",
      "\n",
      "\n",
      "Epoch 149/750 - Train Cd Loss: 0.136848 - Test Loss: 0.030934\n",
      "Epoch 149/750 - Train pg Loss: 3.403728 - Test Loss: 0.786936\n",
      "\n",
      "\n",
      "Epoch 150/750 - Train Cd Loss: 0.135792 - Test Loss: 0.031796\n",
      "Epoch 150/750 - Train pg Loss: 3.363696 - Test Loss: 0.759953\n",
      "\n",
      "\n",
      "Epoch 151/750 - Train Cd Loss: 0.139187 - Test Loss: 0.031436\n",
      "Epoch 151/750 - Train pg Loss: 3.132401 - Test Loss: 0.710029\n",
      "\n",
      "\n",
      "Epoch 152/750 - Train Cd Loss: 0.132456 - Test Loss: 0.031267\n",
      "Epoch 152/750 - Train pg Loss: 2.981738 - Test Loss: 0.668113\n",
      "\n",
      "\n",
      "Epoch 153/750 - Train Cd Loss: 0.130618 - Test Loss: 0.031219\n",
      "Epoch 153/750 - Train pg Loss: 2.805081 - Test Loss: 0.646203\n",
      "\n",
      "\n",
      "Epoch 154/750 - Train Cd Loss: 0.136793 - Test Loss: 0.031248\n",
      "Epoch 154/750 - Train pg Loss: 2.931215 - Test Loss: 0.696604\n",
      "\n",
      "\n",
      "Epoch 155/750 - Train Cd Loss: 0.129320 - Test Loss: 0.033316\n",
      "Epoch 155/750 - Train pg Loss: 2.811816 - Test Loss: 0.617395\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/750 - Train Cd Loss: 0.140519 - Test Loss: 0.029950\n",
      "Epoch 156/750 - Train pg Loss: 3.592108 - Test Loss: 0.727163\n",
      "\n",
      "\n",
      "Epoch 157/750 - Train Cd Loss: 0.131074 - Test Loss: 0.030178\n",
      "Epoch 157/750 - Train pg Loss: 3.310482 - Test Loss: 0.808840\n",
      "\n",
      "\n",
      "Epoch 158/750 - Train Cd Loss: 0.134170 - Test Loss: 0.031075\n",
      "Epoch 158/750 - Train pg Loss: 3.368193 - Test Loss: 0.739666\n",
      "\n",
      "\n",
      "Epoch 159/750 - Train Cd Loss: 0.131269 - Test Loss: 0.030841\n",
      "Epoch 159/750 - Train pg Loss: 3.296938 - Test Loss: 0.696694\n",
      "\n",
      "\n",
      "Epoch 160/750 - Train Cd Loss: 0.132539 - Test Loss: 0.031024\n",
      "Epoch 160/750 - Train pg Loss: 2.855844 - Test Loss: 0.678605\n",
      "\n",
      "\n",
      "Epoch 161/750 - Train Cd Loss: 0.146889 - Test Loss: 0.030481\n",
      "Epoch 161/750 - Train pg Loss: 3.678779 - Test Loss: 0.713249\n",
      "\n",
      "\n",
      "Epoch 162/750 - Train Cd Loss: 0.128776 - Test Loss: 0.029966\n",
      "Epoch 162/750 - Train pg Loss: 3.715333 - Test Loss: 0.806971\n",
      "\n",
      "\n",
      "Epoch 163/750 - Train Cd Loss: 0.131879 - Test Loss: 0.031882\n",
      "Epoch 163/750 - Train pg Loss: 3.735183 - Test Loss: 0.774378\n",
      "\n",
      "\n",
      "Epoch 164/750 - Train Cd Loss: 0.131774 - Test Loss: 0.029312\n",
      "Epoch 164/750 - Train pg Loss: 3.499070 - Test Loss: 0.695795\n",
      "\n",
      "\n",
      "Epoch 165/750 - Train Cd Loss: 0.130088 - Test Loss: 0.029957\n",
      "Epoch 165/750 - Train pg Loss: 3.126109 - Test Loss: 0.701329\n",
      "\n",
      "\n",
      "Epoch 166/750 - Train Cd Loss: 0.127078 - Test Loss: 0.031162\n",
      "Epoch 166/750 - Train pg Loss: 3.045820 - Test Loss: 0.616339\n",
      "\n",
      "\n",
      "Epoch 167/750 - Train Cd Loss: 0.133871 - Test Loss: 0.030116\n",
      "Epoch 167/750 - Train pg Loss: 3.237219 - Test Loss: 0.694951\n",
      "\n",
      "\n",
      "Epoch 168/750 - Train Cd Loss: 0.138656 - Test Loss: 0.030368\n",
      "Epoch 168/750 - Train pg Loss: 4.132530 - Test Loss: 0.839256\n",
      "\n",
      "\n",
      "Epoch 169/750 - Train Cd Loss: 0.127709 - Test Loss: 0.031360\n",
      "Epoch 169/750 - Train pg Loss: 3.913786 - Test Loss: 0.823740\n",
      "\n",
      "\n",
      "Epoch 170/750 - Train Cd Loss: 0.128009 - Test Loss: 0.029749\n",
      "Epoch 170/750 - Train pg Loss: 3.631742 - Test Loss: 0.736294\n",
      "\n",
      "\n",
      "Epoch 171/750 - Train Cd Loss: 0.129310 - Test Loss: 0.031535\n",
      "Epoch 171/750 - Train pg Loss: 3.680674 - Test Loss: 0.759685\n",
      "\n",
      "\n",
      "Epoch 172/750 - Train Cd Loss: 0.129497 - Test Loss: 0.030547\n",
      "Epoch 172/750 - Train pg Loss: 3.696425 - Test Loss: 0.853587\n",
      "\n",
      "\n",
      "Epoch 173/750 - Train Cd Loss: 0.123887 - Test Loss: 0.030771\n",
      "Epoch 173/750 - Train pg Loss: 3.973407 - Test Loss: 0.841918\n",
      "\n",
      "\n",
      "Epoch 174/750 - Train Cd Loss: 0.126119 - Test Loss: 0.029478\n",
      "Epoch 174/750 - Train pg Loss: 3.819733 - Test Loss: 0.790122\n",
      "\n",
      "\n",
      "Epoch 175/750 - Train Cd Loss: 0.122560 - Test Loss: 0.032550\n",
      "Epoch 175/750 - Train pg Loss: 3.610968 - Test Loss: 0.775096\n",
      "\n",
      "\n",
      "Epoch 176/750 - Train Cd Loss: 0.123879 - Test Loss: 0.032771\n",
      "Epoch 176/750 - Train pg Loss: 3.319779 - Test Loss: 0.789689\n",
      "\n",
      "\n",
      "Epoch 177/750 - Train Cd Loss: 0.137450 - Test Loss: 0.030264\n",
      "Epoch 177/750 - Train pg Loss: 4.138954 - Test Loss: 0.955815\n",
      "\n",
      "\n",
      "Epoch 178/750 - Train Cd Loss: 0.124997 - Test Loss: 0.028989\n",
      "Epoch 178/750 - Train pg Loss: 4.347968 - Test Loss: 1.032008\n",
      "\n",
      "\n",
      "Epoch 179/750 - Train Cd Loss: 0.123205 - Test Loss: 0.028979\n",
      "Epoch 179/750 - Train pg Loss: 4.949863 - Test Loss: 0.956517\n",
      "\n",
      "\n",
      "Epoch 180/750 - Train Cd Loss: 0.123004 - Test Loss: 0.030420\n",
      "Epoch 180/750 - Train pg Loss: 4.412320 - Test Loss: 0.796114\n",
      "\n",
      "\n",
      "Epoch 181/750 - Train Cd Loss: 0.121341 - Test Loss: 0.029703\n",
      "Epoch 181/750 - Train pg Loss: 3.406842 - Test Loss: 0.747040\n",
      "\n",
      "\n",
      "Epoch 182/750 - Train Cd Loss: 0.130572 - Test Loss: 0.030136\n",
      "Epoch 182/750 - Train pg Loss: 4.312599 - Test Loss: 0.903115\n",
      "\n",
      "\n",
      "Epoch 183/750 - Train Cd Loss: 0.137052 - Test Loss: 0.029514\n",
      "Epoch 183/750 - Train pg Loss: 4.674756 - Test Loss: 0.998435\n",
      "\n",
      "\n",
      "Epoch 184/750 - Train Cd Loss: 0.128689 - Test Loss: 0.028814\n",
      "Epoch 184/750 - Train pg Loss: 4.637249 - Test Loss: 1.001775\n",
      "\n",
      "\n",
      "Epoch 185/750 - Train Cd Loss: 0.123149 - Test Loss: 0.028370\n",
      "Epoch 185/750 - Train pg Loss: 4.191737 - Test Loss: 0.908321\n",
      "\n",
      "\n",
      "Epoch 186/750 - Train Cd Loss: 0.120844 - Test Loss: 0.031151\n",
      "Epoch 186/750 - Train pg Loss: 4.096657 - Test Loss: 0.757457\n",
      "\n",
      "\n",
      "Epoch 187/750 - Train Cd Loss: 0.120116 - Test Loss: 0.031192\n",
      "Epoch 187/750 - Train pg Loss: 3.105126 - Test Loss: 0.668471\n",
      "\n",
      "\n",
      "Epoch 188/750 - Train Cd Loss: 0.119724 - Test Loss: 0.030314\n",
      "Epoch 188/750 - Train pg Loss: 3.230935 - Test Loss: 0.712692\n",
      "\n",
      "\n",
      "Epoch 189/750 - Train Cd Loss: 0.134463 - Test Loss: 0.030921\n",
      "Epoch 189/750 - Train pg Loss: 4.217173 - Test Loss: 0.846588\n",
      "\n",
      "\n",
      "Epoch 190/750 - Train Cd Loss: 0.118775 - Test Loss: 0.029145\n",
      "Epoch 190/750 - Train pg Loss: 4.074970 - Test Loss: 0.871097\n",
      "\n",
      "\n",
      "Epoch 191/750 - Train Cd Loss: 0.123697 - Test Loss: 0.029791\n",
      "Epoch 191/750 - Train pg Loss: 4.297306 - Test Loss: 0.845385\n",
      "\n",
      "\n",
      "Epoch 192/750 - Train Cd Loss: 0.120302 - Test Loss: 0.029636\n",
      "Epoch 192/750 - Train pg Loss: 3.917717 - Test Loss: 0.814123\n",
      "\n",
      "\n",
      "Epoch 193/750 - Train Cd Loss: 0.120837 - Test Loss: 0.030591\n",
      "Epoch 193/750 - Train pg Loss: 3.538439 - Test Loss: 0.767441\n",
      "\n",
      "\n",
      "Epoch 194/750 - Train Cd Loss: 0.121378 - Test Loss: 0.028502\n",
      "Epoch 194/750 - Train pg Loss: 3.722492 - Test Loss: 0.811322\n",
      "\n",
      "\n",
      "Epoch 195/750 - Train Cd Loss: 0.134641 - Test Loss: 0.030481\n",
      "Epoch 195/750 - Train pg Loss: 4.372606 - Test Loss: 0.848145\n",
      "\n",
      "\n",
      "Epoch 196/750 - Train Cd Loss: 0.121633 - Test Loss: 0.027640\n",
      "Epoch 196/750 - Train pg Loss: 4.308346 - Test Loss: 0.951573\n",
      "\n",
      "\n",
      "Epoch 197/750 - Train Cd Loss: 0.122688 - Test Loss: 0.027432\n",
      "Epoch 197/750 - Train pg Loss: 4.478832 - Test Loss: 0.961530\n",
      "\n",
      "\n",
      "Epoch 198/750 - Train Cd Loss: 0.114420 - Test Loss: 0.031740\n",
      "Epoch 198/750 - Train pg Loss: 3.856997 - Test Loss: 0.790866\n",
      "\n",
      "\n",
      "Epoch 199/750 - Train Cd Loss: 0.132448 - Test Loss: 0.031240\n",
      "Epoch 199/750 - Train pg Loss: 4.381665 - Test Loss: 0.882630\n",
      "\n",
      "\n",
      "Epoch 200/750 - Train Cd Loss: 0.122654 - Test Loss: 0.029809\n",
      "Epoch 200/750 - Train pg Loss: 4.583724 - Test Loss: 0.922970\n",
      "\n",
      "\n",
      "Epoch 201/750 - Train Cd Loss: 0.116410 - Test Loss: 0.030664\n",
      "Epoch 201/750 - Train pg Loss: 4.321365 - Test Loss: 0.864314\n",
      "\n",
      "\n",
      "Epoch 202/750 - Train Cd Loss: 0.121079 - Test Loss: 0.030629\n",
      "Epoch 202/750 - Train pg Loss: 3.700211 - Test Loss: 0.775138\n",
      "\n",
      "\n",
      "Epoch 203/750 - Train Cd Loss: 0.112814 - Test Loss: 0.030481\n",
      "Epoch 203/750 - Train pg Loss: 3.862990 - Test Loss: 0.746894\n",
      "\n",
      "\n",
      "Epoch 204/750 - Train Cd Loss: 0.111717 - Test Loss: 0.029708\n",
      "Epoch 204/750 - Train pg Loss: 3.652559 - Test Loss: 0.795437\n",
      "\n",
      "\n",
      "Epoch 205/750 - Train Cd Loss: 0.109616 - Test Loss: 0.030093\n",
      "Epoch 205/750 - Train pg Loss: 3.950300 - Test Loss: 0.853075\n",
      "\n",
      "\n",
      "Epoch 206/750 - Train Cd Loss: 0.115495 - Test Loss: 0.028612\n",
      "Epoch 206/750 - Train pg Loss: 4.252471 - Test Loss: 1.013990\n",
      "\n",
      "\n",
      "Epoch 207/750 - Train Cd Loss: 0.117934 - Test Loss: 0.029792\n",
      "Epoch 207/750 - Train pg Loss: 4.480692 - Test Loss: 0.817083\n",
      "\n",
      "\n",
      "Epoch 208/750 - Train Cd Loss: 0.109359 - Test Loss: 0.030935\n",
      "Epoch 208/750 - Train pg Loss: 3.837728 - Test Loss: 0.769658\n",
      "\n",
      "\n",
      "Epoch 209/750 - Train Cd Loss: 0.112322 - Test Loss: 0.029665\n",
      "Epoch 209/750 - Train pg Loss: 3.697551 - Test Loss: 0.783697\n",
      "\n",
      "\n",
      "Epoch 210/750 - Train Cd Loss: 0.108888 - Test Loss: 0.031542\n",
      "Epoch 210/750 - Train pg Loss: 4.161057 - Test Loss: 0.695685\n",
      "\n",
      "\n",
      "Epoch 211/750 - Train Cd Loss: 0.125925 - Test Loss: 0.029313\n",
      "Epoch 211/750 - Train pg Loss: 4.511209 - Test Loss: 0.831086\n",
      "\n",
      "\n",
      "Epoch 212/750 - Train Cd Loss: 0.106935 - Test Loss: 0.029484\n",
      "Epoch 212/750 - Train pg Loss: 4.068698 - Test Loss: 0.798790\n",
      "\n",
      "\n",
      "Epoch 213/750 - Train Cd Loss: 0.117719 - Test Loss: 0.032799\n",
      "Epoch 213/750 - Train pg Loss: 3.210963 - Test Loss: 0.635261\n",
      "\n",
      "\n",
      "Epoch 214/750 - Train Cd Loss: 0.111380 - Test Loss: 0.029780\n",
      "Epoch 214/750 - Train pg Loss: 3.175106 - Test Loss: 0.710451\n",
      "\n",
      "\n",
      "Epoch 215/750 - Train Cd Loss: 0.105528 - Test Loss: 0.030063\n",
      "Epoch 215/750 - Train pg Loss: 3.804962 - Test Loss: 0.720748\n",
      "\n",
      "\n",
      "Epoch 216/750 - Train Cd Loss: 0.108284 - Test Loss: 0.028946\n",
      "Epoch 216/750 - Train pg Loss: 4.546431 - Test Loss: 0.992785\n",
      "\n",
      "\n",
      "Epoch 217/750 - Train Cd Loss: 0.114484 - Test Loss: 0.030962\n",
      "Epoch 217/750 - Train pg Loss: 4.877944 - Test Loss: 0.949425\n",
      "\n",
      "\n",
      "Epoch 218/750 - Train Cd Loss: 0.115763 - Test Loss: 0.029152\n",
      "Epoch 218/750 - Train pg Loss: 4.790948 - Test Loss: 0.848640\n",
      "\n",
      "\n",
      "Epoch 219/750 - Train Cd Loss: 0.111937 - Test Loss: 0.028784\n",
      "Epoch 219/750 - Train pg Loss: 4.650195 - Test Loss: 0.918344\n",
      "\n",
      "\n",
      "Epoch 220/750 - Train Cd Loss: 0.109046 - Test Loss: 0.027484\n",
      "Epoch 220/750 - Train pg Loss: 4.083637 - Test Loss: 0.828682\n",
      "\n",
      "\n",
      "Epoch 221/750 - Train Cd Loss: 0.110434 - Test Loss: 0.029566\n",
      "Epoch 221/750 - Train pg Loss: 4.279474 - Test Loss: 0.862404\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/750 - Train Cd Loss: 0.102588 - Test Loss: 0.027772\n",
      "Epoch 222/750 - Train pg Loss: 4.444674 - Test Loss: 0.970169\n",
      "\n",
      "\n",
      "Epoch 223/750 - Train Cd Loss: 0.112671 - Test Loss: 0.031029\n",
      "Epoch 223/750 - Train pg Loss: 4.268137 - Test Loss: 0.782573\n",
      "\n",
      "\n",
      "Epoch 224/750 - Train Cd Loss: 0.105073 - Test Loss: 0.030608\n",
      "Epoch 224/750 - Train pg Loss: 4.189069 - Test Loss: 0.825716\n",
      "\n",
      "\n",
      "Epoch 225/750 - Train Cd Loss: 0.116433 - Test Loss: 0.032610\n",
      "Epoch 225/750 - Train pg Loss: 5.529827 - Test Loss: 0.815241\n",
      "\n",
      "\n",
      "Epoch 226/750 - Train Cd Loss: 0.105160 - Test Loss: 0.029268\n",
      "Epoch 226/750 - Train pg Loss: 4.196330 - Test Loss: 0.879604\n",
      "\n",
      "\n",
      "Epoch 227/750 - Train Cd Loss: 0.125582 - Test Loss: 0.027114\n",
      "Epoch 227/750 - Train pg Loss: 5.949767 - Test Loss: 1.084679\n",
      "\n",
      "\n",
      "Epoch 228/750 - Train Cd Loss: 0.109134 - Test Loss: 0.028998\n",
      "Epoch 228/750 - Train pg Loss: 5.329945 - Test Loss: 0.996581\n",
      "\n",
      "\n",
      "Epoch 229/750 - Train Cd Loss: 0.107109 - Test Loss: 0.030443\n",
      "Epoch 229/750 - Train pg Loss: 5.000641 - Test Loss: 0.753144\n",
      "\n",
      "\n",
      "Epoch 230/750 - Train Cd Loss: 0.102064 - Test Loss: 0.030410\n",
      "Epoch 230/750 - Train pg Loss: 3.691056 - Test Loss: 0.818116\n",
      "\n",
      "\n",
      "Epoch 231/750 - Train Cd Loss: 0.108842 - Test Loss: 0.030327\n",
      "Epoch 231/750 - Train pg Loss: 4.109519 - Test Loss: 0.880123\n",
      "\n",
      "\n",
      "Epoch 232/750 - Train Cd Loss: 0.096912 - Test Loss: 0.028680\n",
      "Epoch 232/750 - Train pg Loss: 5.297502 - Test Loss: 0.951679\n",
      "\n",
      "\n",
      "Epoch 233/750 - Train Cd Loss: 0.100942 - Test Loss: 0.032637\n",
      "Epoch 233/750 - Train pg Loss: 3.897604 - Test Loss: 0.794362\n",
      "\n",
      "\n",
      "Epoch 234/750 - Train Cd Loss: 0.125350 - Test Loss: 0.028157\n",
      "Epoch 234/750 - Train pg Loss: 6.866077 - Test Loss: 1.096937\n",
      "\n",
      "\n",
      "Epoch 235/750 - Train Cd Loss: 0.103730 - Test Loss: 0.027254\n",
      "Epoch 235/750 - Train pg Loss: 5.572824 - Test Loss: 0.925378\n",
      "\n",
      "\n",
      "Epoch 236/750 - Train Cd Loss: 0.120229 - Test Loss: 0.029538\n",
      "Epoch 236/750 - Train pg Loss: 4.974634 - Test Loss: 0.873107\n",
      "\n",
      "\n",
      "Epoch 237/750 - Train Cd Loss: 0.103721 - Test Loss: 0.030730\n",
      "Epoch 237/750 - Train pg Loss: 4.267450 - Test Loss: 0.733764\n",
      "\n",
      "\n",
      "Epoch 238/750 - Train Cd Loss: 0.113854 - Test Loss: 0.027963\n",
      "Epoch 238/750 - Train pg Loss: 4.522564 - Test Loss: 0.881168\n",
      "\n",
      "\n",
      "Epoch 239/750 - Train Cd Loss: 0.104898 - Test Loss: 0.027829\n",
      "Epoch 239/750 - Train pg Loss: 6.017237 - Test Loss: 0.927411\n",
      "\n",
      "\n",
      "Epoch 240/750 - Train Cd Loss: 0.107826 - Test Loss: 0.030228\n",
      "Epoch 240/750 - Train pg Loss: 3.770841 - Test Loss: 0.815421\n",
      "\n",
      "\n",
      "Epoch 241/750 - Train Cd Loss: 0.097240 - Test Loss: 0.029179\n",
      "Epoch 241/750 - Train pg Loss: 4.042459 - Test Loss: 0.825817\n",
      "\n",
      "\n",
      "Epoch 242/750 - Train Cd Loss: 0.099275 - Test Loss: 0.029785\n",
      "Epoch 242/750 - Train pg Loss: 4.271548 - Test Loss: 0.787450\n",
      "\n",
      "\n",
      "Epoch 243/750 - Train Cd Loss: 0.125014 - Test Loss: 0.030302\n",
      "Epoch 243/750 - Train pg Loss: 5.064142 - Test Loss: 0.849063\n",
      "\n",
      "\n",
      "Epoch 244/750 - Train Cd Loss: 0.113983 - Test Loss: 0.027417\n",
      "Epoch 244/750 - Train pg Loss: 4.348849 - Test Loss: 0.935318\n",
      "\n",
      "\n",
      "Epoch 245/750 - Train Cd Loss: 0.100968 - Test Loss: 0.029588\n",
      "Epoch 245/750 - Train pg Loss: 4.279412 - Test Loss: 0.744925\n",
      "\n",
      "\n",
      "Epoch 246/750 - Train Cd Loss: 0.095010 - Test Loss: 0.031344\n",
      "Epoch 246/750 - Train pg Loss: 3.853060 - Test Loss: 0.734342\n",
      "\n",
      "\n",
      "Epoch 247/750 - Train Cd Loss: 0.100783 - Test Loss: 0.029327\n",
      "Epoch 247/750 - Train pg Loss: 4.105045 - Test Loss: 0.893674\n",
      "\n",
      "\n",
      "Epoch 248/750 - Train Cd Loss: 0.091788 - Test Loss: 0.032841\n",
      "Epoch 248/750 - Train pg Loss: 4.169144 - Test Loss: 0.718879\n",
      "\n",
      "\n",
      "Epoch 249/750 - Train Cd Loss: 0.137651 - Test Loss: 0.031721\n",
      "Epoch 249/750 - Train pg Loss: 5.884321 - Test Loss: 0.666140\n",
      "\n",
      "\n",
      "Epoch 250/750 - Train Cd Loss: 0.095232 - Test Loss: 0.029903\n",
      "Epoch 250/750 - Train pg Loss: 4.121164 - Test Loss: 0.929233\n",
      "\n",
      "\n",
      "Epoch 251/750 - Train Cd Loss: 0.097953 - Test Loss: 0.030302\n",
      "Epoch 251/750 - Train pg Loss: 4.091837 - Test Loss: 0.869878\n",
      "\n",
      "\n",
      "Epoch 252/750 - Train Cd Loss: 0.108429 - Test Loss: 0.030963\n",
      "Epoch 252/750 - Train pg Loss: 4.294203 - Test Loss: 0.905688\n",
      "\n",
      "\n",
      "Epoch 253/750 - Train Cd Loss: 0.093530 - Test Loss: 0.030757\n",
      "Epoch 253/750 - Train pg Loss: 4.529050 - Test Loss: 0.847277\n",
      "\n",
      "\n",
      "Epoch 254/750 - Train Cd Loss: 0.101752 - Test Loss: 0.030061\n",
      "Epoch 254/750 - Train pg Loss: 4.373701 - Test Loss: 0.840637\n",
      "\n",
      "\n",
      "Epoch 255/750 - Train Cd Loss: 0.101233 - Test Loss: 0.029027\n",
      "Epoch 255/750 - Train pg Loss: 4.246090 - Test Loss: 0.975318\n",
      "\n",
      "\n",
      "Epoch 256/750 - Train Cd Loss: 0.116658 - Test Loss: 0.029307\n",
      "Epoch 256/750 - Train pg Loss: 5.538321 - Test Loss: 0.921374\n",
      "\n",
      "\n",
      "Epoch 257/750 - Train Cd Loss: 0.093564 - Test Loss: 0.033705\n",
      "Epoch 257/750 - Train pg Loss: 3.982371 - Test Loss: 0.700721\n",
      "\n",
      "\n",
      "Epoch 258/750 - Train Cd Loss: 0.095493 - Test Loss: 0.029521\n",
      "Epoch 258/750 - Train pg Loss: 4.441807 - Test Loss: 0.818789\n",
      "\n",
      "\n",
      "Epoch 259/750 - Train Cd Loss: 0.098576 - Test Loss: 0.029300\n",
      "Epoch 259/750 - Train pg Loss: 4.720174 - Test Loss: 0.986214\n",
      "\n",
      "\n",
      "Epoch 260/750 - Train Cd Loss: 0.095162 - Test Loss: 0.028149\n",
      "Epoch 260/750 - Train pg Loss: 5.245249 - Test Loss: 0.900273\n",
      "\n",
      "\n",
      "Epoch 261/750 - Train Cd Loss: 0.095679 - Test Loss: 0.031507\n",
      "Epoch 261/750 - Train pg Loss: 3.841897 - Test Loss: 0.789682\n",
      "\n",
      "\n",
      "Epoch 262/750 - Train Cd Loss: 0.097999 - Test Loss: 0.030678\n",
      "Epoch 262/750 - Train pg Loss: 5.503520 - Test Loss: 0.840415\n",
      "\n",
      "\n",
      "Epoch 263/750 - Train Cd Loss: 0.098184 - Test Loss: 0.031979\n",
      "Epoch 263/750 - Train pg Loss: 4.530676 - Test Loss: 0.790836\n",
      "\n",
      "\n",
      "Epoch 264/750 - Train Cd Loss: 0.092429 - Test Loss: 0.030877\n",
      "Epoch 264/750 - Train pg Loss: 4.929039 - Test Loss: 0.858970\n",
      "\n",
      "\n",
      "Epoch 265/750 - Train Cd Loss: 0.096539 - Test Loss: 0.028993\n",
      "Epoch 265/750 - Train pg Loss: 5.392540 - Test Loss: 1.039325\n",
      "\n",
      "\n",
      "Epoch 266/750 - Train Cd Loss: 0.099896 - Test Loss: 0.028325\n",
      "Epoch 266/750 - Train pg Loss: 6.958989 - Test Loss: 1.139298\n",
      "\n",
      "\n",
      "Epoch 267/750 - Train Cd Loss: 0.090523 - Test Loss: 0.028326\n",
      "Epoch 267/750 - Train pg Loss: 5.658474 - Test Loss: 1.048535\n",
      "\n",
      "\n",
      "Epoch 268/750 - Train Cd Loss: 0.092348 - Test Loss: 0.030979\n",
      "Epoch 268/750 - Train pg Loss: 6.344308 - Test Loss: 0.936217\n",
      "\n",
      "\n",
      "Epoch 269/750 - Train Cd Loss: 0.090754 - Test Loss: 0.029366\n",
      "Epoch 269/750 - Train pg Loss: 4.909409 - Test Loss: 0.953906\n",
      "\n",
      "\n",
      "Epoch 270/750 - Train Cd Loss: 0.101122 - Test Loss: 0.029359\n",
      "Epoch 270/750 - Train pg Loss: 6.125348 - Test Loss: 1.006026\n",
      "\n",
      "\n",
      "Epoch 271/750 - Train Cd Loss: 0.104879 - Test Loss: 0.028917\n",
      "Epoch 271/750 - Train pg Loss: 6.051288 - Test Loss: 1.056851\n",
      "\n",
      "\n",
      "Epoch 272/750 - Train Cd Loss: 0.091212 - Test Loss: 0.029578\n",
      "Epoch 272/750 - Train pg Loss: 4.610701 - Test Loss: 0.881248\n",
      "\n",
      "\n",
      "Epoch 273/750 - Train Cd Loss: 0.083729 - Test Loss: 0.029786\n",
      "Epoch 273/750 - Train pg Loss: 4.216808 - Test Loss: 0.752455\n",
      "\n",
      "\n",
      "Epoch 274/750 - Train Cd Loss: 0.096806 - Test Loss: 0.032054\n",
      "Epoch 274/750 - Train pg Loss: 5.168314 - Test Loss: 0.898250\n",
      "\n",
      "\n",
      "Epoch 275/750 - Train Cd Loss: 0.116942 - Test Loss: 0.030515\n",
      "Epoch 275/750 - Train pg Loss: 5.175268 - Test Loss: 0.910633\n",
      "\n",
      "\n",
      "Epoch 276/750 - Train Cd Loss: 0.089579 - Test Loss: 0.029334\n",
      "Epoch 276/750 - Train pg Loss: 4.381876 - Test Loss: 0.952963\n",
      "\n",
      "\n",
      "Epoch 277/750 - Train Cd Loss: 0.092159 - Test Loss: 0.029970\n",
      "Epoch 277/750 - Train pg Loss: 4.607560 - Test Loss: 0.966156\n",
      "\n",
      "\n",
      "Epoch 278/750 - Train Cd Loss: 0.081419 - Test Loss: 0.029773\n",
      "Epoch 278/750 - Train pg Loss: 5.762538 - Test Loss: 0.970820\n",
      "\n",
      "\n",
      "Epoch 279/750 - Train Cd Loss: 0.127669 - Test Loss: 0.029763\n",
      "Epoch 279/750 - Train pg Loss: 6.828757 - Test Loss: 1.087070\n",
      "\n",
      "\n",
      "Epoch 280/750 - Train Cd Loss: 0.100120 - Test Loss: 0.027500\n",
      "Epoch 280/750 - Train pg Loss: 6.833835 - Test Loss: 1.304333\n",
      "\n",
      "\n",
      "Epoch 281/750 - Train Cd Loss: 0.092190 - Test Loss: 0.028988\n",
      "Epoch 281/750 - Train pg Loss: 5.742559 - Test Loss: 1.178935\n",
      "\n",
      "\n",
      "Epoch 282/750 - Train Cd Loss: 0.090231 - Test Loss: 0.029558\n",
      "Epoch 282/750 - Train pg Loss: 6.161111 - Test Loss: 1.113745\n",
      "\n",
      "\n",
      "Epoch 283/750 - Train Cd Loss: 0.086445 - Test Loss: 0.030239\n",
      "Epoch 283/750 - Train pg Loss: 5.086143 - Test Loss: 1.080985\n",
      "\n",
      "\n",
      "Epoch 284/750 - Train Cd Loss: 0.095268 - Test Loss: 0.028964\n",
      "Epoch 284/750 - Train pg Loss: 5.845498 - Test Loss: 1.113917\n",
      "\n",
      "\n",
      "Epoch 285/750 - Train Cd Loss: 0.087982 - Test Loss: 0.029845\n",
      "Epoch 285/750 - Train pg Loss: 6.468882 - Test Loss: 1.108737\n",
      "\n",
      "\n",
      "Epoch 286/750 - Train Cd Loss: 0.085536 - Test Loss: 0.030138\n",
      "Epoch 286/750 - Train pg Loss: 5.266201 - Test Loss: 0.969176\n",
      "\n",
      "\n",
      "Epoch 287/750 - Train Cd Loss: 0.107660 - Test Loss: 0.034042\n",
      "Epoch 287/750 - Train pg Loss: 5.741171 - Test Loss: 0.932936\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288/750 - Train Cd Loss: 0.084713 - Test Loss: 0.030625\n",
      "Epoch 288/750 - Train pg Loss: 5.434843 - Test Loss: 1.052796\n",
      "\n",
      "\n",
      "Epoch 289/750 - Train Cd Loss: 0.087184 - Test Loss: 0.029971\n",
      "Epoch 289/750 - Train pg Loss: 5.520364 - Test Loss: 1.054042\n",
      "\n",
      "\n",
      "Epoch 290/750 - Train Cd Loss: 0.083128 - Test Loss: 0.032471\n",
      "Epoch 290/750 - Train pg Loss: 4.850116 - Test Loss: 0.948726\n",
      "\n",
      "\n",
      "Epoch 291/750 - Train Cd Loss: 0.107123 - Test Loss: 0.030961\n",
      "Epoch 291/750 - Train pg Loss: 6.465938 - Test Loss: 1.146101\n",
      "\n",
      "\n",
      "Epoch 292/750 - Train Cd Loss: 0.087806 - Test Loss: 0.029507\n",
      "Epoch 292/750 - Train pg Loss: 6.624354 - Test Loss: 1.395947\n",
      "\n",
      "\n",
      "Epoch 293/750 - Train Cd Loss: 0.085492 - Test Loss: 0.031985\n",
      "Epoch 293/750 - Train pg Loss: 7.264562 - Test Loss: 1.239677\n",
      "\n",
      "\n",
      "Epoch 294/750 - Train Cd Loss: 0.079897 - Test Loss: 0.029143\n",
      "Epoch 294/750 - Train pg Loss: 6.318193 - Test Loss: 1.216691\n",
      "\n",
      "\n",
      "Epoch 295/750 - Train Cd Loss: 0.091239 - Test Loss: 0.029143\n",
      "Epoch 295/750 - Train pg Loss: 7.135976 - Test Loss: 1.311539\n",
      "\n",
      "\n",
      "Epoch 296/750 - Train Cd Loss: 0.082973 - Test Loss: 0.029384\n",
      "Epoch 296/750 - Train pg Loss: 7.369410 - Test Loss: 1.388455\n",
      "\n",
      "\n",
      "Epoch 297/750 - Train Cd Loss: 0.094837 - Test Loss: 0.030580\n",
      "Epoch 297/750 - Train pg Loss: 6.452624 - Test Loss: 1.179696\n",
      "\n",
      "\n",
      "Epoch 298/750 - Train Cd Loss: 0.086118 - Test Loss: 0.029589\n",
      "Epoch 298/750 - Train pg Loss: 6.128481 - Test Loss: 1.268465\n",
      "\n",
      "\n",
      "Epoch 299/750 - Train Cd Loss: 0.087511 - Test Loss: 0.032471\n",
      "Epoch 299/750 - Train pg Loss: 6.781153 - Test Loss: 1.236827\n",
      "\n",
      "\n",
      "Epoch 300/750 - Train Cd Loss: 0.079720 - Test Loss: 0.031005\n",
      "Epoch 300/750 - Train pg Loss: 6.806460 - Test Loss: 1.359636\n",
      "\n",
      "\n",
      "Epoch 301/750 - Train Cd Loss: 0.089699 - Test Loss: 0.031162\n",
      "Epoch 301/750 - Train pg Loss: 7.301528 - Test Loss: 1.261971\n",
      "\n",
      "\n",
      "Epoch 302/750 - Train Cd Loss: 0.088319 - Test Loss: 0.031031\n",
      "Epoch 302/750 - Train pg Loss: 7.540624 - Test Loss: 1.460088\n",
      "\n",
      "\n",
      "Epoch 303/750 - Train Cd Loss: 0.081967 - Test Loss: 0.029845\n",
      "Epoch 303/750 - Train pg Loss: 6.095238 - Test Loss: 1.333632\n",
      "\n",
      "\n",
      "Epoch 304/750 - Train Cd Loss: 0.090151 - Test Loss: 0.029146\n",
      "Epoch 304/750 - Train pg Loss: 6.954005 - Test Loss: 1.489285\n",
      "\n",
      "\n",
      "Epoch 305/750 - Train Cd Loss: 0.083127 - Test Loss: 0.030036\n",
      "Epoch 305/750 - Train pg Loss: 6.905035 - Test Loss: 1.418647\n",
      "\n",
      "\n",
      "Epoch 306/750 - Train Cd Loss: 0.081220 - Test Loss: 0.032213\n",
      "Epoch 306/750 - Train pg Loss: 7.651818 - Test Loss: 1.416286\n",
      "\n",
      "\n",
      "Epoch 307/750 - Train Cd Loss: 0.077841 - Test Loss: 0.029693\n",
      "Epoch 307/750 - Train pg Loss: 7.601034 - Test Loss: 1.401117\n",
      "\n",
      "\n",
      "Epoch 308/750 - Train Cd Loss: 0.105852 - Test Loss: 0.033597\n",
      "Epoch 308/750 - Train pg Loss: 9.198119 - Test Loss: 1.095955\n",
      "\n",
      "\n",
      "Epoch 309/750 - Train Cd Loss: 0.089567 - Test Loss: 0.029755\n",
      "Epoch 309/750 - Train pg Loss: 6.289840 - Test Loss: 1.188165\n",
      "\n",
      "\n",
      "Epoch 310/750 - Train Cd Loss: 0.080708 - Test Loss: 0.031477\n",
      "Epoch 310/750 - Train pg Loss: 5.709000 - Test Loss: 1.041547\n",
      "\n",
      "\n",
      "Epoch 311/750 - Train Cd Loss: 0.079058 - Test Loss: 0.031178\n",
      "Epoch 311/750 - Train pg Loss: 5.452022 - Test Loss: 1.219209\n",
      "\n",
      "\n",
      "Epoch 312/750 - Train Cd Loss: 0.077498 - Test Loss: 0.031428\n",
      "Epoch 312/750 - Train pg Loss: 7.090038 - Test Loss: 1.308117\n",
      "\n",
      "\n",
      "Epoch 313/750 - Train Cd Loss: 0.078312 - Test Loss: 0.030769\n",
      "Epoch 313/750 - Train pg Loss: 5.888573 - Test Loss: 1.265899\n",
      "\n",
      "\n",
      "Epoch 314/750 - Train Cd Loss: 0.079441 - Test Loss: 0.030336\n",
      "Epoch 314/750 - Train pg Loss: 7.271284 - Test Loss: 1.432545\n",
      "\n",
      "\n",
      "Epoch 315/750 - Train Cd Loss: 0.088619 - Test Loss: 0.031180\n",
      "Epoch 315/750 - Train pg Loss: 7.713842 - Test Loss: 1.476490\n",
      "\n",
      "\n",
      "Epoch 316/750 - Train Cd Loss: 0.109005 - Test Loss: 0.030074\n",
      "Epoch 316/750 - Train pg Loss: 8.820170 - Test Loss: 1.529788\n",
      "\n",
      "\n",
      "Epoch 317/750 - Train Cd Loss: 0.080709 - Test Loss: 0.030333\n",
      "Epoch 317/750 - Train pg Loss: 8.975406 - Test Loss: 1.595270\n",
      "\n",
      "\n",
      "Epoch 318/750 - Train Cd Loss: 0.082683 - Test Loss: 0.029235\n",
      "Epoch 318/750 - Train pg Loss: 7.920797 - Test Loss: 1.666697\n",
      "\n",
      "\n",
      "Epoch 319/750 - Train Cd Loss: 0.090630 - Test Loss: 0.029539\n",
      "Epoch 319/750 - Train pg Loss: 9.802110 - Test Loss: 1.996826\n",
      "\n",
      "\n",
      "Epoch 320/750 - Train Cd Loss: 0.076911 - Test Loss: 0.030755\n",
      "Epoch 320/750 - Train pg Loss: 9.358882 - Test Loss: 1.560070\n",
      "\n",
      "\n",
      "Epoch 321/750 - Train Cd Loss: 0.078578 - Test Loss: 0.031889\n",
      "Epoch 321/750 - Train pg Loss: 8.800389 - Test Loss: 1.480901\n",
      "\n",
      "\n",
      "Epoch 322/750 - Train Cd Loss: 0.091942 - Test Loss: 0.030026\n",
      "Epoch 322/750 - Train pg Loss: 11.280701 - Test Loss: 1.910698\n",
      "\n",
      "\n",
      "Epoch 323/750 - Train Cd Loss: 0.077585 - Test Loss: 0.029132\n",
      "Epoch 323/750 - Train pg Loss: 10.394003 - Test Loss: 1.741156\n",
      "\n",
      "\n",
      "Epoch 324/750 - Train Cd Loss: 0.074777 - Test Loss: 0.030291\n",
      "Epoch 324/750 - Train pg Loss: 9.219873 - Test Loss: 1.513540\n",
      "\n",
      "\n",
      "Epoch 325/750 - Train Cd Loss: 0.084036 - Test Loss: 0.032974\n",
      "Epoch 325/750 - Train pg Loss: 7.595486 - Test Loss: 1.244635\n",
      "\n",
      "\n",
      "Epoch 326/750 - Train Cd Loss: 0.083388 - Test Loss: 0.030511\n",
      "Epoch 326/750 - Train pg Loss: 8.198000 - Test Loss: 1.364169\n",
      "\n",
      "\n",
      "Epoch 327/750 - Train Cd Loss: 0.076158 - Test Loss: 0.031567\n",
      "Epoch 327/750 - Train pg Loss: 7.267667 - Test Loss: 1.374781\n",
      "\n",
      "\n",
      "Epoch 328/750 - Train Cd Loss: 0.086736 - Test Loss: 0.031610\n",
      "Epoch 328/750 - Train pg Loss: 8.665590 - Test Loss: 1.181357\n",
      "\n",
      "\n",
      "Epoch 329/750 - Train Cd Loss: 0.071254 - Test Loss: 0.031740\n",
      "Epoch 329/750 - Train pg Loss: 5.639061 - Test Loss: 1.169108\n",
      "\n",
      "\n",
      "Epoch 330/750 - Train Cd Loss: 0.084578 - Test Loss: 0.028740\n",
      "Epoch 330/750 - Train pg Loss: 7.768587 - Test Loss: 1.232771\n",
      "\n",
      "\n",
      "Epoch 331/750 - Train Cd Loss: 0.087984 - Test Loss: 0.028734\n",
      "Epoch 331/750 - Train pg Loss: 6.975329 - Test Loss: 1.382279\n",
      "\n",
      "\n",
      "Epoch 332/750 - Train Cd Loss: 0.078605 - Test Loss: 0.030102\n",
      "Epoch 332/750 - Train pg Loss: 6.535980 - Test Loss: 1.253015\n",
      "\n",
      "\n",
      "Epoch 333/750 - Train Cd Loss: 0.078267 - Test Loss: 0.031092\n",
      "Epoch 333/750 - Train pg Loss: 7.527258 - Test Loss: 1.087744\n",
      "\n",
      "\n",
      "Epoch 334/750 - Train Cd Loss: 0.076751 - Test Loss: 0.030784\n",
      "Epoch 334/750 - Train pg Loss: 5.285998 - Test Loss: 1.116681\n",
      "\n",
      "\n",
      "Epoch 335/750 - Train Cd Loss: 0.078845 - Test Loss: 0.030491\n",
      "Epoch 335/750 - Train pg Loss: 6.820639 - Test Loss: 1.272461\n",
      "\n",
      "\n",
      "Epoch 336/750 - Train Cd Loss: 0.092722 - Test Loss: 0.030040\n",
      "Epoch 336/750 - Train pg Loss: 9.503816 - Test Loss: 1.456979\n",
      "\n",
      "\n",
      "Epoch 337/750 - Train Cd Loss: 0.086630 - Test Loss: 0.029955\n",
      "Epoch 337/750 - Train pg Loss: 9.387787 - Test Loss: 1.421934\n",
      "\n",
      "\n",
      "Epoch 338/750 - Train Cd Loss: 0.080201 - Test Loss: 0.030395\n",
      "Epoch 338/750 - Train pg Loss: 8.696281 - Test Loss: 1.340555\n",
      "\n",
      "\n",
      "Epoch 339/750 - Train Cd Loss: 0.076371 - Test Loss: 0.030971\n",
      "Epoch 339/750 - Train pg Loss: 7.034669 - Test Loss: 1.315701\n",
      "\n",
      "\n",
      "Epoch 340/750 - Train Cd Loss: 0.076473 - Test Loss: 0.032587\n",
      "Epoch 340/750 - Train pg Loss: 7.808515 - Test Loss: 1.275482\n",
      "\n",
      "\n",
      "Epoch 341/750 - Train Cd Loss: 0.084509 - Test Loss: 0.031281\n",
      "Epoch 341/750 - Train pg Loss: 7.338277 - Test Loss: 1.352573\n",
      "\n",
      "\n",
      "Epoch 342/750 - Train Cd Loss: 0.087377 - Test Loss: 0.029564\n",
      "Epoch 342/750 - Train pg Loss: 9.623164 - Test Loss: 1.364169\n",
      "\n",
      "\n",
      "Epoch 343/750 - Train Cd Loss: 0.073818 - Test Loss: 0.028570\n",
      "Epoch 343/750 - Train pg Loss: 7.493322 - Test Loss: 1.361880\n",
      "\n",
      "\n",
      "Epoch 344/750 - Train Cd Loss: 0.075507 - Test Loss: 0.029972\n",
      "Epoch 344/750 - Train pg Loss: 7.406583 - Test Loss: 1.273405\n",
      "\n",
      "\n",
      "Epoch 345/750 - Train Cd Loss: 0.075563 - Test Loss: 0.034053\n",
      "Epoch 345/750 - Train pg Loss: 8.266644 - Test Loss: 1.231902\n",
      "\n",
      "\n",
      "Epoch 346/750 - Train Cd Loss: 0.079475 - Test Loss: 0.030313\n",
      "Epoch 346/750 - Train pg Loss: 9.119681 - Test Loss: 1.418576\n",
      "\n",
      "\n",
      "Epoch 347/750 - Train Cd Loss: 0.066527 - Test Loss: 0.032268\n",
      "Epoch 347/750 - Train pg Loss: 7.748482 - Test Loss: 1.311199\n",
      "\n",
      "\n",
      "Epoch 348/750 - Train Cd Loss: 0.082583 - Test Loss: 0.031500\n",
      "Epoch 348/750 - Train pg Loss: 9.989897 - Test Loss: 1.770102\n",
      "\n",
      "\n",
      "Epoch 349/750 - Train Cd Loss: 0.073081 - Test Loss: 0.031455\n",
      "Epoch 349/750 - Train pg Loss: 11.149007 - Test Loss: 1.541480\n",
      "\n",
      "\n",
      "Epoch 350/750 - Train Cd Loss: 0.068447 - Test Loss: 0.032225\n",
      "Epoch 350/750 - Train pg Loss: 8.641376 - Test Loss: 1.242848\n",
      "\n",
      "\n",
      "Epoch 351/750 - Train Cd Loss: 0.080766 - Test Loss: 0.030940\n",
      "Epoch 351/750 - Train pg Loss: 9.400047 - Test Loss: 1.275575\n",
      "\n",
      "\n",
      "Epoch 352/750 - Train Cd Loss: 0.070958 - Test Loss: 0.029282\n",
      "Epoch 352/750 - Train pg Loss: 6.986756 - Test Loss: 1.508835\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 353/750 - Train Cd Loss: 0.066434 - Test Loss: 0.032229\n",
      "Epoch 353/750 - Train pg Loss: 7.777337 - Test Loss: 1.480572\n",
      "\n",
      "\n",
      "Epoch 354/750 - Train Cd Loss: 0.068404 - Test Loss: 0.032067\n",
      "Epoch 354/750 - Train pg Loss: 7.798306 - Test Loss: 1.348294\n",
      "\n",
      "\n",
      "Epoch 355/750 - Train Cd Loss: 0.090358 - Test Loss: 0.030586\n",
      "Epoch 355/750 - Train pg Loss: 8.690548 - Test Loss: 1.369174\n",
      "\n",
      "\n",
      "Epoch 356/750 - Train Cd Loss: 0.074090 - Test Loss: 0.030399\n",
      "Epoch 356/750 - Train pg Loss: 8.359281 - Test Loss: 1.314708\n",
      "\n",
      "\n",
      "Epoch 357/750 - Train Cd Loss: 0.069329 - Test Loss: 0.031957\n",
      "Epoch 357/750 - Train pg Loss: 6.754502 - Test Loss: 1.202715\n",
      "\n",
      "\n",
      "Epoch 358/750 - Train Cd Loss: 0.078265 - Test Loss: 0.031287\n",
      "Epoch 358/750 - Train pg Loss: 7.095192 - Test Loss: 1.262545\n",
      "\n",
      "\n",
      "Epoch 359/750 - Train Cd Loss: 0.064495 - Test Loss: 0.031213\n",
      "Epoch 359/750 - Train pg Loss: 7.727047 - Test Loss: 1.246096\n",
      "\n",
      "\n",
      "Epoch 360/750 - Train Cd Loss: 0.071148 - Test Loss: 0.030467\n",
      "Epoch 360/750 - Train pg Loss: 6.961478 - Test Loss: 1.268482\n",
      "\n",
      "\n",
      "Epoch 361/750 - Train Cd Loss: 0.069860 - Test Loss: 0.031056\n",
      "Epoch 361/750 - Train pg Loss: 7.372430 - Test Loss: 1.239828\n",
      "\n",
      "\n",
      "Epoch 362/750 - Train Cd Loss: 0.076317 - Test Loss: 0.033791\n",
      "Epoch 362/750 - Train pg Loss: 7.587552 - Test Loss: 1.270763\n",
      "\n",
      "\n",
      "Epoch 363/750 - Train Cd Loss: 0.086646 - Test Loss: 0.032097\n",
      "Epoch 363/750 - Train pg Loss: 8.386225 - Test Loss: 1.346327\n",
      "\n",
      "\n",
      "Epoch 364/750 - Train Cd Loss: 0.070211 - Test Loss: 0.029966\n",
      "Epoch 364/750 - Train pg Loss: 7.579654 - Test Loss: 1.478009\n",
      "\n",
      "\n",
      "Epoch 365/750 - Train Cd Loss: 0.066181 - Test Loss: 0.031876\n",
      "Epoch 365/750 - Train pg Loss: 6.961690 - Test Loss: 1.236281\n",
      "\n",
      "\n",
      "Epoch 366/750 - Train Cd Loss: 0.063890 - Test Loss: 0.034818\n",
      "Epoch 366/750 - Train pg Loss: 7.001535 - Test Loss: 1.262271\n",
      "\n",
      "\n",
      "Epoch 367/750 - Train Cd Loss: 0.066773 - Test Loss: 0.033149\n",
      "Epoch 367/750 - Train pg Loss: 7.334718 - Test Loss: 1.535707\n",
      "\n",
      "\n",
      "Epoch 368/750 - Train Cd Loss: 0.071324 - Test Loss: 0.032951\n",
      "Epoch 368/750 - Train pg Loss: 8.071817 - Test Loss: 1.686247\n",
      "\n",
      "\n",
      "Epoch 369/750 - Train Cd Loss: 0.097237 - Test Loss: 0.032886\n",
      "Epoch 369/750 - Train pg Loss: 11.097543 - Test Loss: 1.631069\n",
      "\n",
      "\n",
      "Epoch 370/750 - Train Cd Loss: 0.062790 - Test Loss: 0.032560\n",
      "Epoch 370/750 - Train pg Loss: 6.952121 - Test Loss: 1.385642\n",
      "\n",
      "\n",
      "Epoch 371/750 - Train Cd Loss: 0.064361 - Test Loss: 0.033188\n",
      "Epoch 371/750 - Train pg Loss: 7.194193 - Test Loss: 1.451710\n",
      "\n",
      "\n",
      "Epoch 372/750 - Train Cd Loss: 0.075005 - Test Loss: 0.031860\n",
      "Epoch 372/750 - Train pg Loss: 9.222120 - Test Loss: 1.747010\n",
      "\n",
      "\n",
      "Epoch 373/750 - Train Cd Loss: 0.066589 - Test Loss: 0.033415\n",
      "Epoch 373/750 - Train pg Loss: 9.279579 - Test Loss: 1.638719\n",
      "\n",
      "\n",
      "Epoch 374/750 - Train Cd Loss: 0.083287 - Test Loss: 0.029674\n",
      "Epoch 374/750 - Train pg Loss: 10.624068 - Test Loss: 1.674998\n",
      "\n",
      "\n",
      "Epoch 375/750 - Train Cd Loss: 0.065338 - Test Loss: 0.035155\n",
      "Epoch 375/750 - Train pg Loss: 8.115323 - Test Loss: 1.487159\n",
      "\n",
      "\n",
      "Epoch 376/750 - Train Cd Loss: 0.064224 - Test Loss: 0.033592\n",
      "Epoch 376/750 - Train pg Loss: 9.489962 - Test Loss: 1.770285\n",
      "\n",
      "\n",
      "Epoch 377/750 - Train Cd Loss: 0.074279 - Test Loss: 0.032846\n",
      "Epoch 377/750 - Train pg Loss: 10.239646 - Test Loss: 1.723223\n",
      "\n",
      "\n",
      "Epoch 378/750 - Train Cd Loss: 0.055926 - Test Loss: 0.032709\n",
      "Epoch 378/750 - Train pg Loss: 9.497634 - Test Loss: 1.743375\n",
      "\n",
      "\n",
      "Epoch 379/750 - Train Cd Loss: 0.089409 - Test Loss: 0.032410\n",
      "Epoch 379/750 - Train pg Loss: 11.000738 - Test Loss: 1.739933\n",
      "\n",
      "\n",
      "Epoch 380/750 - Train Cd Loss: 0.068500 - Test Loss: 0.031223\n",
      "Epoch 380/750 - Train pg Loss: 10.654454 - Test Loss: 1.426477\n",
      "\n",
      "\n",
      "Epoch 381/750 - Train Cd Loss: 0.076884 - Test Loss: 0.033674\n",
      "Epoch 381/750 - Train pg Loss: 7.219466 - Test Loss: 1.198799\n",
      "\n",
      "\n",
      "Epoch 382/750 - Train Cd Loss: 0.073492 - Test Loss: 0.032642\n",
      "Epoch 382/750 - Train pg Loss: 7.523190 - Test Loss: 1.358728\n",
      "\n",
      "\n",
      "Epoch 383/750 - Train Cd Loss: 0.062235 - Test Loss: 0.030440\n",
      "Epoch 383/750 - Train pg Loss: 7.887992 - Test Loss: 1.482294\n",
      "\n",
      "\n",
      "Epoch 384/750 - Train Cd Loss: 0.076800 - Test Loss: 0.033377\n",
      "Epoch 384/750 - Train pg Loss: 10.288765 - Test Loss: 1.618357\n",
      "\n",
      "\n",
      "Epoch 385/750 - Train Cd Loss: 0.072591 - Test Loss: 0.030208\n",
      "Epoch 385/750 - Train pg Loss: 9.554413 - Test Loss: 1.694034\n",
      "\n",
      "\n",
      "Epoch 386/750 - Train Cd Loss: 0.074992 - Test Loss: 0.032367\n",
      "Epoch 386/750 - Train pg Loss: 10.005429 - Test Loss: 1.545480\n",
      "\n",
      "\n",
      "Epoch 387/750 - Train Cd Loss: 0.075229 - Test Loss: 0.034650\n",
      "Epoch 387/750 - Train pg Loss: 9.383019 - Test Loss: 1.646845\n",
      "\n",
      "\n",
      "Epoch 388/750 - Train Cd Loss: 0.087965 - Test Loss: 0.030612\n",
      "Epoch 388/750 - Train pg Loss: 9.269674 - Test Loss: 1.693066\n",
      "\n",
      "\n",
      "Epoch 389/750 - Train Cd Loss: 0.070142 - Test Loss: 0.032440\n",
      "Epoch 389/750 - Train pg Loss: 8.381477 - Test Loss: 1.375823\n",
      "\n",
      "\n",
      "Epoch 390/750 - Train Cd Loss: 0.075270 - Test Loss: 0.032570\n",
      "Epoch 390/750 - Train pg Loss: 7.861417 - Test Loss: 1.451876\n",
      "\n",
      "\n",
      "Epoch 391/750 - Train Cd Loss: 0.056156 - Test Loss: 0.032902\n",
      "Epoch 391/750 - Train pg Loss: 7.122894 - Test Loss: 1.626082\n",
      "\n",
      "\n",
      "Epoch 392/750 - Train Cd Loss: 0.067627 - Test Loss: 0.029984\n",
      "Epoch 392/750 - Train pg Loss: 9.697034 - Test Loss: 1.659261\n",
      "\n",
      "\n",
      "Epoch 393/750 - Train Cd Loss: 0.063783 - Test Loss: 0.032020\n",
      "Epoch 393/750 - Train pg Loss: 10.040625 - Test Loss: 1.541569\n",
      "\n",
      "\n",
      "Epoch 394/750 - Train Cd Loss: 0.074019 - Test Loss: 0.032553\n",
      "Epoch 394/750 - Train pg Loss: 8.684566 - Test Loss: 1.683628\n",
      "\n",
      "\n",
      "Epoch 395/750 - Train Cd Loss: 0.062935 - Test Loss: 0.034599\n",
      "Epoch 395/750 - Train pg Loss: 9.612405 - Test Loss: 1.426599\n",
      "\n",
      "\n",
      "Epoch 396/750 - Train Cd Loss: 0.057801 - Test Loss: 0.033760\n",
      "Epoch 396/750 - Train pg Loss: 10.087090 - Test Loss: 1.499548\n",
      "\n",
      "\n",
      "Epoch 397/750 - Train Cd Loss: 0.073955 - Test Loss: 0.035401\n",
      "Epoch 397/750 - Train pg Loss: 11.091685 - Test Loss: 1.517422\n",
      "\n",
      "\n",
      "Epoch 398/750 - Train Cd Loss: 0.094870 - Test Loss: 0.032293\n",
      "Epoch 398/750 - Train pg Loss: 11.415256 - Test Loss: 1.488034\n",
      "\n",
      "\n",
      "Epoch 399/750 - Train Cd Loss: 0.064079 - Test Loss: 0.032404\n",
      "Epoch 399/750 - Train pg Loss: 9.056745 - Test Loss: 1.396990\n",
      "\n",
      "\n",
      "Epoch 400/750 - Train Cd Loss: 0.075365 - Test Loss: 0.032348\n",
      "Epoch 400/750 - Train pg Loss: 9.012708 - Test Loss: 1.560527\n",
      "\n",
      "\n",
      "Epoch 401/750 - Train Cd Loss: 0.066199 - Test Loss: 0.031655\n",
      "Epoch 401/750 - Train pg Loss: 8.755321 - Test Loss: 1.612884\n",
      "\n",
      "\n",
      "Epoch 402/750 - Train Cd Loss: 0.054015 - Test Loss: 0.030890\n",
      "Epoch 402/750 - Train pg Loss: 8.741476 - Test Loss: 1.651635\n",
      "\n",
      "\n",
      "Epoch 403/750 - Train Cd Loss: 0.078056 - Test Loss: 0.032983\n",
      "Epoch 403/750 - Train pg Loss: 11.058274 - Test Loss: 1.462540\n",
      "\n",
      "\n",
      "Epoch 404/750 - Train Cd Loss: 0.083497 - Test Loss: 0.030919\n",
      "Epoch 404/750 - Train pg Loss: 8.899188 - Test Loss: 1.512173\n",
      "\n",
      "\n",
      "Epoch 405/750 - Train Cd Loss: 0.074668 - Test Loss: 0.032843\n",
      "Epoch 405/750 - Train pg Loss: 8.836410 - Test Loss: 1.877931\n",
      "\n",
      "\n",
      "Epoch 406/750 - Train Cd Loss: 0.068182 - Test Loss: 0.031482\n",
      "Epoch 406/750 - Train pg Loss: 10.832995 - Test Loss: 1.856681\n",
      "\n",
      "\n",
      "Epoch 407/750 - Train Cd Loss: 0.076307 - Test Loss: 0.031565\n",
      "Epoch 407/750 - Train pg Loss: 10.858512 - Test Loss: 1.712462\n",
      "\n",
      "\n",
      "Epoch 408/750 - Train Cd Loss: 0.057520 - Test Loss: 0.031896\n",
      "Epoch 408/750 - Train pg Loss: 10.080306 - Test Loss: 1.763312\n",
      "\n",
      "\n",
      "Epoch 409/750 - Train Cd Loss: 0.058784 - Test Loss: 0.032488\n",
      "Epoch 409/750 - Train pg Loss: 9.466858 - Test Loss: 1.634888\n",
      "\n",
      "\n",
      "Epoch 410/750 - Train Cd Loss: 0.052977 - Test Loss: 0.034483\n",
      "Epoch 410/750 - Train pg Loss: 9.696098 - Test Loss: 1.632820\n",
      "\n",
      "\n",
      "Epoch 411/750 - Train Cd Loss: 0.078905 - Test Loss: 0.031571\n",
      "Epoch 411/750 - Train pg Loss: 9.852161 - Test Loss: 1.845720\n",
      "\n",
      "\n",
      "Epoch 412/750 - Train Cd Loss: 0.084432 - Test Loss: 0.031856\n",
      "Epoch 412/750 - Train pg Loss: 9.897415 - Test Loss: 1.792935\n",
      "\n",
      "\n",
      "Epoch 413/750 - Train Cd Loss: 0.063820 - Test Loss: 0.032105\n",
      "Epoch 413/750 - Train pg Loss: 9.945217 - Test Loss: 1.681698\n",
      "\n",
      "\n",
      "Epoch 414/750 - Train Cd Loss: 0.060475 - Test Loss: 0.031948\n",
      "Epoch 414/750 - Train pg Loss: 11.423931 - Test Loss: 1.685978\n",
      "\n",
      "\n",
      "Epoch 415/750 - Train Cd Loss: 0.061547 - Test Loss: 0.032536\n",
      "Epoch 415/750 - Train pg Loss: 10.324079 - Test Loss: 1.701188\n",
      "\n",
      "\n",
      "Epoch 416/750 - Train Cd Loss: 0.080780 - Test Loss: 0.032143\n",
      "Epoch 416/750 - Train pg Loss: 11.266857 - Test Loss: 1.731000\n",
      "\n",
      "\n",
      "Epoch 417/750 - Train Cd Loss: 0.056688 - Test Loss: 0.033068\n",
      "Epoch 417/750 - Train pg Loss: 10.342647 - Test Loss: 1.762851\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 418/750 - Train Cd Loss: 0.069104 - Test Loss: 0.032302\n",
      "Epoch 418/750 - Train pg Loss: 10.315543 - Test Loss: 1.773416\n",
      "\n",
      "\n",
      "Epoch 419/750 - Train Cd Loss: 0.052814 - Test Loss: 0.034560\n",
      "Epoch 419/750 - Train pg Loss: 8.437268 - Test Loss: 1.517331\n",
      "\n",
      "\n",
      "Epoch 420/750 - Train Cd Loss: 0.071378 - Test Loss: 0.031735\n",
      "Epoch 420/750 - Train pg Loss: 10.164682 - Test Loss: 1.868782\n",
      "\n",
      "\n",
      "Epoch 421/750 - Train Cd Loss: 0.056011 - Test Loss: 0.032362\n",
      "Epoch 421/750 - Train pg Loss: 10.412647 - Test Loss: 1.801964\n",
      "\n",
      "\n",
      "Epoch 422/750 - Train Cd Loss: 0.073023 - Test Loss: 0.032594\n",
      "Epoch 422/750 - Train pg Loss: 10.357792 - Test Loss: 1.826674\n",
      "\n",
      "\n",
      "Epoch 423/750 - Train Cd Loss: 0.058323 - Test Loss: 0.034433\n",
      "Epoch 423/750 - Train pg Loss: 10.058160 - Test Loss: 1.695564\n",
      "\n",
      "\n",
      "Epoch 424/750 - Train Cd Loss: 0.074024 - Test Loss: 0.032212\n",
      "Epoch 424/750 - Train pg Loss: 12.277581 - Test Loss: 1.791366\n",
      "\n",
      "\n",
      "Epoch 425/750 - Train Cd Loss: 0.070023 - Test Loss: 0.032022\n",
      "Epoch 425/750 - Train pg Loss: 11.446325 - Test Loss: 1.836938\n",
      "\n",
      "\n",
      "Epoch 426/750 - Train Cd Loss: 0.059974 - Test Loss: 0.032247\n",
      "Epoch 426/750 - Train pg Loss: 9.973125 - Test Loss: 1.658994\n",
      "\n",
      "\n",
      "Epoch 427/750 - Train Cd Loss: 0.090782 - Test Loss: 0.032415\n",
      "Epoch 427/750 - Train pg Loss: 12.634835 - Test Loss: 1.733535\n",
      "\n",
      "\n",
      "Epoch 428/750 - Train Cd Loss: 0.058257 - Test Loss: 0.031535\n",
      "Epoch 428/750 - Train pg Loss: 10.399920 - Test Loss: 1.598766\n",
      "\n",
      "\n",
      "Epoch 429/750 - Train Cd Loss: 0.075297 - Test Loss: 0.033185\n",
      "Epoch 429/750 - Train pg Loss: 9.039614 - Test Loss: 1.822785\n",
      "\n",
      "\n",
      "Epoch 430/750 - Train Cd Loss: 0.057225 - Test Loss: 0.033080\n",
      "Epoch 430/750 - Train pg Loss: 11.297749 - Test Loss: 1.951429\n",
      "\n",
      "\n",
      "Epoch 431/750 - Train Cd Loss: 0.052897 - Test Loss: 0.035019\n",
      "Epoch 431/750 - Train pg Loss: 10.936225 - Test Loss: 1.889051\n",
      "\n",
      "\n",
      "Epoch 432/750 - Train Cd Loss: 0.076158 - Test Loss: 0.034384\n",
      "Epoch 432/750 - Train pg Loss: 12.754807 - Test Loss: 1.641297\n",
      "\n",
      "\n",
      "Epoch 433/750 - Train Cd Loss: 0.055854 - Test Loss: 0.032762\n",
      "Epoch 433/750 - Train pg Loss: 10.308382 - Test Loss: 1.756512\n",
      "\n",
      "\n",
      "Epoch 434/750 - Train Cd Loss: 0.069818 - Test Loss: 0.032995\n",
      "Epoch 434/750 - Train pg Loss: 9.367721 - Test Loss: 1.484205\n",
      "\n",
      "\n",
      "Epoch 435/750 - Train Cd Loss: 0.054292 - Test Loss: 0.032105\n",
      "Epoch 435/750 - Train pg Loss: 9.865437 - Test Loss: 1.650088\n",
      "\n",
      "\n",
      "Epoch 436/750 - Train Cd Loss: 0.072537 - Test Loss: 0.030982\n",
      "Epoch 436/750 - Train pg Loss: 11.868151 - Test Loss: 1.572508\n",
      "\n",
      "\n",
      "Epoch 437/750 - Train Cd Loss: 0.053460 - Test Loss: 0.031345\n",
      "Epoch 437/750 - Train pg Loss: 7.252067 - Test Loss: 1.576101\n",
      "\n",
      "\n",
      "Epoch 438/750 - Train Cd Loss: 0.054629 - Test Loss: 0.032310\n",
      "Epoch 438/750 - Train pg Loss: 9.651295 - Test Loss: 1.651483\n",
      "\n",
      "\n",
      "Epoch 439/750 - Train Cd Loss: 0.070117 - Test Loss: 0.033388\n",
      "Epoch 439/750 - Train pg Loss: 11.313292 - Test Loss: 1.792161\n",
      "\n",
      "\n",
      "Epoch 440/750 - Train Cd Loss: 0.065664 - Test Loss: 0.032952\n",
      "Epoch 440/750 - Train pg Loss: 13.667716 - Test Loss: 1.979850\n",
      "\n",
      "\n",
      "Epoch 441/750 - Train Cd Loss: 0.054007 - Test Loss: 0.032517\n",
      "Epoch 441/750 - Train pg Loss: 12.856995 - Test Loss: 1.699816\n",
      "\n",
      "\n",
      "Epoch 442/750 - Train Cd Loss: 0.063788 - Test Loss: 0.034875\n",
      "Epoch 442/750 - Train pg Loss: 10.916481 - Test Loss: 1.368049\n",
      "\n",
      "\n",
      "Epoch 443/750 - Train Cd Loss: 0.064447 - Test Loss: 0.032194\n",
      "Epoch 443/750 - Train pg Loss: 9.319566 - Test Loss: 1.365136\n",
      "\n",
      "\n",
      "Epoch 444/750 - Train Cd Loss: 0.055690 - Test Loss: 0.032032\n",
      "Epoch 444/750 - Train pg Loss: 7.230262 - Test Loss: 1.507217\n",
      "\n",
      "\n",
      "Epoch 445/750 - Train Cd Loss: 0.056505 - Test Loss: 0.034649\n",
      "Epoch 445/750 - Train pg Loss: 8.706321 - Test Loss: 1.598238\n",
      "\n",
      "\n",
      "Epoch 446/750 - Train Cd Loss: 0.067792 - Test Loss: 0.033210\n",
      "Epoch 446/750 - Train pg Loss: 10.927733 - Test Loss: 1.695908\n",
      "\n",
      "\n",
      "Epoch 447/750 - Train Cd Loss: 0.051767 - Test Loss: 0.034797\n",
      "Epoch 447/750 - Train pg Loss: 10.358000 - Test Loss: 1.727804\n",
      "\n",
      "\n",
      "Epoch 448/750 - Train Cd Loss: 0.053019 - Test Loss: 0.030991\n",
      "Epoch 448/750 - Train pg Loss: 9.437757 - Test Loss: 1.614808\n",
      "\n",
      "\n",
      "Epoch 449/750 - Train Cd Loss: 0.045644 - Test Loss: 0.034857\n",
      "Epoch 449/750 - Train pg Loss: 9.269221 - Test Loss: 1.538801\n",
      "\n",
      "\n",
      "Epoch 450/750 - Train Cd Loss: 0.065914 - Test Loss: 0.032007\n",
      "Epoch 450/750 - Train pg Loss: 13.196280 - Test Loss: 2.174247\n",
      "\n",
      "\n",
      "Epoch 451/750 - Train Cd Loss: 0.070061 - Test Loss: 0.034941\n",
      "Epoch 451/750 - Train pg Loss: 12.195866 - Test Loss: 1.752832\n",
      "\n",
      "\n",
      "Epoch 452/750 - Train Cd Loss: 0.057359 - Test Loss: 0.033797\n",
      "Epoch 452/750 - Train pg Loss: 9.937232 - Test Loss: 1.529092\n",
      "\n",
      "\n",
      "Epoch 453/750 - Train Cd Loss: 0.072245 - Test Loss: 0.030758\n",
      "Epoch 453/750 - Train pg Loss: 11.386533 - Test Loss: 1.819306\n",
      "\n",
      "\n",
      "Epoch 454/750 - Train Cd Loss: 0.061773 - Test Loss: 0.031135\n",
      "Epoch 454/750 - Train pg Loss: 10.484730 - Test Loss: 1.595536\n",
      "\n",
      "\n",
      "Epoch 455/750 - Train Cd Loss: 0.063194 - Test Loss: 0.033501\n",
      "Epoch 455/750 - Train pg Loss: 9.834028 - Test Loss: 1.526255\n",
      "\n",
      "\n",
      "Epoch 456/750 - Train Cd Loss: 0.062693 - Test Loss: 0.029853\n",
      "Epoch 456/750 - Train pg Loss: 10.112437 - Test Loss: 1.779330\n",
      "\n",
      "\n",
      "Epoch 457/750 - Train Cd Loss: 0.049718 - Test Loss: 0.030326\n",
      "Epoch 457/750 - Train pg Loss: 10.303504 - Test Loss: 1.561497\n",
      "\n",
      "\n",
      "Epoch 458/750 - Train Cd Loss: 0.046040 - Test Loss: 0.035560\n",
      "Epoch 458/750 - Train pg Loss: 9.622323 - Test Loss: 1.649251\n",
      "\n",
      "\n",
      "Epoch 459/750 - Train Cd Loss: 0.062737 - Test Loss: 0.035881\n",
      "Epoch 459/750 - Train pg Loss: 10.910776 - Test Loss: 1.623412\n",
      "\n",
      "\n",
      "Epoch 460/750 - Train Cd Loss: 0.068806 - Test Loss: 0.031238\n",
      "Epoch 460/750 - Train pg Loss: 11.527186 - Test Loss: 1.818711\n",
      "\n",
      "\n",
      "Epoch 461/750 - Train Cd Loss: 0.069780 - Test Loss: 0.030694\n",
      "Epoch 461/750 - Train pg Loss: 11.633504 - Test Loss: 1.852177\n",
      "\n",
      "\n",
      "Epoch 462/750 - Train Cd Loss: 0.051751 - Test Loss: 0.035010\n",
      "Epoch 462/750 - Train pg Loss: 10.257157 - Test Loss: 1.785818\n",
      "\n",
      "\n",
      "Epoch 463/750 - Train Cd Loss: 0.052959 - Test Loss: 0.033159\n",
      "Epoch 463/750 - Train pg Loss: 12.857163 - Test Loss: 1.926011\n",
      "\n",
      "\n",
      "Epoch 464/750 - Train Cd Loss: 0.044278 - Test Loss: 0.033813\n",
      "Epoch 464/750 - Train pg Loss: 11.977032 - Test Loss: 1.868062\n",
      "\n",
      "\n",
      "Epoch 465/750 - Train Cd Loss: 0.079931 - Test Loss: 0.038015\n",
      "Epoch 465/750 - Train pg Loss: 13.317944 - Test Loss: 1.802509\n",
      "\n",
      "\n",
      "Epoch 466/750 - Train Cd Loss: 0.062288 - Test Loss: 0.031864\n",
      "Epoch 466/750 - Train pg Loss: 11.688005 - Test Loss: 2.040414\n",
      "\n",
      "\n",
      "Epoch 467/750 - Train Cd Loss: 0.050702 - Test Loss: 0.033539\n",
      "Epoch 467/750 - Train pg Loss: 11.131071 - Test Loss: 1.742371\n",
      "\n",
      "\n",
      "Epoch 468/750 - Train Cd Loss: 0.073528 - Test Loss: 0.035537\n",
      "Epoch 468/750 - Train pg Loss: 14.974194 - Test Loss: 1.817106\n",
      "\n",
      "\n",
      "Epoch 469/750 - Train Cd Loss: 0.050364 - Test Loss: 0.034140\n",
      "Epoch 469/750 - Train pg Loss: 9.941732 - Test Loss: 2.062541\n",
      "\n",
      "\n",
      "Epoch 470/750 - Train Cd Loss: 0.063925 - Test Loss: 0.032215\n",
      "Epoch 470/750 - Train pg Loss: 11.601492 - Test Loss: 1.892762\n",
      "\n",
      "\n",
      "Epoch 471/750 - Train Cd Loss: 0.069479 - Test Loss: 0.032840\n",
      "Epoch 471/750 - Train pg Loss: 11.352620 - Test Loss: 2.300603\n",
      "\n",
      "\n",
      "Epoch 472/750 - Train Cd Loss: 0.045390 - Test Loss: 0.033626\n",
      "Epoch 472/750 - Train pg Loss: 12.973598 - Test Loss: 2.428890\n",
      "\n",
      "\n",
      "Epoch 473/750 - Train Cd Loss: 0.048852 - Test Loss: nan\n",
      "Epoch 473/750 - Train pg Loss: 13.041840 - Test Loss: 2.564585\n",
      "\n",
      "\n",
      "Epoch 474/750 - Train Cd Loss: 0.055768 - Test Loss: 0.034853\n",
      "Epoch 474/750 - Train pg Loss: 11.473787 - Test Loss: 1.944596\n",
      "\n",
      "\n",
      "Epoch 475/750 - Train Cd Loss: 0.051751 - Test Loss: 0.035189\n",
      "Epoch 475/750 - Train pg Loss: 12.748224 - Test Loss: 1.787469\n",
      "\n",
      "\n",
      "Epoch 476/750 - Train Cd Loss: 0.061100 - Test Loss: 0.035816\n",
      "Epoch 476/750 - Train pg Loss: 12.432298 - Test Loss: 1.637167\n",
      "\n",
      "\n",
      "Epoch 477/750 - Train Cd Loss: 0.059717 - Test Loss: 0.036668\n",
      "Epoch 477/750 - Train pg Loss: 10.480967 - Test Loss: 1.720894\n",
      "\n",
      "\n",
      "Epoch 478/750 - Train Cd Loss: 0.043753 - Test Loss: 0.034522\n",
      "Epoch 478/750 - Train pg Loss: 9.562513 - Test Loss: 1.664752\n",
      "\n",
      "\n",
      "Epoch 479/750 - Train Cd Loss: 0.068479 - Test Loss: 0.034398\n",
      "Epoch 479/750 - Train pg Loss: 12.645662 - Test Loss: 1.811192\n",
      "\n",
      "\n",
      "Epoch 480/750 - Train Cd Loss: 0.059650 - Test Loss: 0.032286\n",
      "Epoch 480/750 - Train pg Loss: 12.198828 - Test Loss: 1.875831\n",
      "\n",
      "\n",
      "Epoch 481/750 - Train Cd Loss: 0.058116 - Test Loss: 0.034949\n",
      "Epoch 481/750 - Train pg Loss: 11.271639 - Test Loss: 1.576526\n",
      "\n",
      "\n",
      "Epoch 482/750 - Train Cd Loss: 0.046507 - Test Loss: 0.033424\n",
      "Epoch 482/750 - Train pg Loss: 10.198401 - Test Loss: 1.624637\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 483/750 - Train Cd Loss: 0.053714 - Test Loss: 0.035439\n",
      "Epoch 483/750 - Train pg Loss: 11.930231 - Test Loss: 1.995879\n",
      "\n",
      "\n",
      "Epoch 484/750 - Train Cd Loss: 0.056914 - Test Loss: 0.035757\n",
      "Epoch 484/750 - Train pg Loss: 9.520910 - Test Loss: 1.582943\n",
      "\n",
      "\n",
      "Epoch 485/750 - Train Cd Loss: 0.053908 - Test Loss: 0.035840\n",
      "Epoch 485/750 - Train pg Loss: 10.512871 - Test Loss: 1.692883\n",
      "\n",
      "\n",
      "Epoch 486/750 - Train Cd Loss: 0.058915 - Test Loss: 0.032290\n",
      "Epoch 486/750 - Train pg Loss: 12.657778 - Test Loss: 1.700056\n",
      "\n",
      "\n",
      "Epoch 487/750 - Train Cd Loss: 0.042674 - Test Loss: 0.035058\n",
      "Epoch 487/750 - Train pg Loss: 11.409103 - Test Loss: 1.623262\n",
      "\n",
      "\n",
      "Epoch 488/750 - Train Cd Loss: 0.048518 - Test Loss: 0.032867\n",
      "Epoch 488/750 - Train pg Loss: 12.207957 - Test Loss: 1.637442\n",
      "\n",
      "\n",
      "Epoch 489/750 - Train Cd Loss: 0.053138 - Test Loss: 0.032266\n",
      "Epoch 489/750 - Train pg Loss: 11.405641 - Test Loss: 1.651223\n",
      "\n",
      "\n",
      "Epoch 490/750 - Train Cd Loss: 0.069532 - Test Loss: 0.035091\n",
      "Epoch 490/750 - Train pg Loss: 11.798494 - Test Loss: 1.730071\n",
      "\n",
      "\n",
      "Epoch 491/750 - Train Cd Loss: 0.061168 - Test Loss: 0.032390\n",
      "Epoch 491/750 - Train pg Loss: 12.484787 - Test Loss: 1.648238\n",
      "\n",
      "\n",
      "Epoch 492/750 - Train Cd Loss: 0.048441 - Test Loss: 0.032369\n",
      "Epoch 492/750 - Train pg Loss: 10.504816 - Test Loss: 1.608668\n",
      "\n",
      "\n",
      "Epoch 493/750 - Train Cd Loss: 0.075197 - Test Loss: 0.033786\n",
      "Epoch 493/750 - Train pg Loss: 11.588731 - Test Loss: 1.325412\n",
      "\n",
      "\n",
      "Epoch 494/750 - Train Cd Loss: 0.053883 - Test Loss: 0.029814\n",
      "Epoch 494/750 - Train pg Loss: 9.673451 - Test Loss: 1.973071\n",
      "\n",
      "\n",
      "Epoch 495/750 - Train Cd Loss: 0.046718 - Test Loss: 0.031102\n",
      "Epoch 495/750 - Train pg Loss: 11.242126 - Test Loss: 1.832658\n",
      "\n",
      "\n",
      "Epoch 496/750 - Train Cd Loss: 0.057639 - Test Loss: 0.032910\n",
      "Epoch 496/750 - Train pg Loss: 11.935687 - Test Loss: 1.830532\n",
      "\n",
      "\n",
      "Epoch 497/750 - Train Cd Loss: 0.052778 - Test Loss: 0.030998\n",
      "Epoch 497/750 - Train pg Loss: 12.107459 - Test Loss: 1.946173\n",
      "\n",
      "\n",
      "Epoch 498/750 - Train Cd Loss: 0.053704 - Test Loss: 0.033295\n",
      "Epoch 498/750 - Train pg Loss: 11.568015 - Test Loss: 1.826182\n",
      "\n",
      "\n",
      "Epoch 499/750 - Train Cd Loss: 0.058905 - Test Loss: 0.034244\n",
      "Epoch 499/750 - Train pg Loss: 12.485925 - Test Loss: 1.973744\n",
      "\n",
      "\n",
      "Epoch 500/750 - Train Cd Loss: 0.054548 - Test Loss: 0.035340\n",
      "Epoch 500/750 - Train pg Loss: 13.112157 - Test Loss: 2.306656\n",
      "\n",
      "\n",
      "Epoch 501/750 - Train Cd Loss: 0.062237 - Test Loss: 0.033464\n",
      "Epoch 501/750 - Train pg Loss: 14.872808 - Test Loss: 2.426542\n",
      "\n",
      "\n",
      "Epoch 502/750 - Train Cd Loss: 0.048188 - Test Loss: 0.033238\n",
      "Epoch 502/750 - Train pg Loss: 13.203404 - Test Loss: 2.404859\n",
      "\n",
      "\n",
      "Epoch 503/750 - Train Cd Loss: 0.040633 - Test Loss: 0.032889\n",
      "Epoch 503/750 - Train pg Loss: 14.270472 - Test Loss: 2.307841\n",
      "\n",
      "\n",
      "Epoch 504/750 - Train Cd Loss: 0.058882 - Test Loss: 0.035060\n",
      "Epoch 504/750 - Train pg Loss: 14.438988 - Test Loss: 2.193887\n",
      "\n",
      "\n",
      "Epoch 505/750 - Train Cd Loss: 0.052988 - Test Loss: 0.030838\n",
      "Epoch 505/750 - Train pg Loss: 12.253981 - Test Loss: 2.560919\n",
      "\n",
      "\n",
      "Epoch 506/750 - Train Cd Loss: 0.049905 - Test Loss: 0.032764\n",
      "Epoch 506/750 - Train pg Loss: 15.254527 - Test Loss: 2.467882\n",
      "\n",
      "\n",
      "Epoch 507/750 - Train Cd Loss: 0.049640 - Test Loss: 0.033409\n",
      "Epoch 507/750 - Train pg Loss: 13.634910 - Test Loss: 2.384962\n",
      "\n",
      "\n",
      "Epoch 508/750 - Train Cd Loss: 0.061574 - Test Loss: 0.034926\n",
      "Epoch 508/750 - Train pg Loss: 12.379323 - Test Loss: 2.397717\n",
      "\n",
      "\n",
      "Epoch 509/750 - Train Cd Loss: 0.047557 - Test Loss: nan\n",
      "Epoch 509/750 - Train pg Loss: 14.893306 - Test Loss: 2.643716\n",
      "\n",
      "\n",
      "Epoch 510/750 - Train Cd Loss: 0.062565 - Test Loss: 0.030653\n",
      "Epoch 510/750 - Train pg Loss: 15.299208 - Test Loss: 2.386337\n",
      "\n",
      "\n",
      "Epoch 511/750 - Train Cd Loss: 0.044654 - Test Loss: 0.033878\n",
      "Epoch 511/750 - Train pg Loss: 13.110146 - Test Loss: 2.125371\n",
      "\n",
      "\n",
      "Epoch 512/750 - Train Cd Loss: 0.051514 - Test Loss: 0.036039\n",
      "Epoch 512/750 - Train pg Loss: 14.412410 - Test Loss: 2.290112\n",
      "\n",
      "\n",
      "Epoch 513/750 - Train Cd Loss: 0.040530 - Test Loss: 0.032446\n",
      "Epoch 513/750 - Train pg Loss: 13.295364 - Test Loss: 2.616134\n",
      "\n",
      "\n",
      "Epoch 514/750 - Train Cd Loss: 0.066390 - Test Loss: 0.032548\n",
      "Epoch 514/750 - Train pg Loss: 15.767184 - Test Loss: 2.464953\n",
      "\n",
      "\n",
      "Epoch 515/750 - Train Cd Loss: 0.045027 - Test Loss: 0.034703\n",
      "Epoch 515/750 - Train pg Loss: 14.283656 - Test Loss: 2.139870\n",
      "\n",
      "\n",
      "Epoch 516/750 - Train Cd Loss: 0.042365 - Test Loss: nan\n",
      "Epoch 516/750 - Train pg Loss: 12.479398 - Test Loss: 2.705493\n",
      "\n",
      "\n",
      "Epoch 517/750 - Train Cd Loss: 0.079993 - Test Loss: 0.031641\n",
      "Epoch 517/750 - Train pg Loss: 16.727552 - Test Loss: 2.681266\n",
      "\n",
      "\n",
      "Epoch 518/750 - Train Cd Loss: 0.046604 - Test Loss: 0.033349\n",
      "Epoch 518/750 - Train pg Loss: 14.343137 - Test Loss: 2.484174\n",
      "\n",
      "\n",
      "Epoch 519/750 - Train Cd Loss: 0.041030 - Test Loss: 0.032599\n",
      "Epoch 519/750 - Train pg Loss: 13.347264 - Test Loss: 2.153969\n",
      "\n",
      "\n",
      "Epoch 520/750 - Train Cd Loss: 0.037128 - Test Loss: 0.034850\n",
      "Epoch 520/750 - Train pg Loss: 12.244287 - Test Loss: 2.469263\n",
      "\n",
      "\n",
      "Epoch 521/750 - Train Cd Loss: 0.070378 - Test Loss: 0.032330\n",
      "Epoch 521/750 - Train pg Loss: 17.079693 - Test Loss: 2.235158\n",
      "\n",
      "\n",
      "Epoch 522/750 - Train Cd Loss: 0.045904 - Test Loss: 0.033362\n",
      "Epoch 522/750 - Train pg Loss: 12.709316 - Test Loss: 2.180965\n",
      "\n",
      "\n",
      "Epoch 523/750 - Train Cd Loss: 0.051190 - Test Loss: 0.034252\n",
      "Epoch 523/750 - Train pg Loss: 13.235984 - Test Loss: 2.137006\n",
      "\n",
      "\n",
      "Epoch 524/750 - Train Cd Loss: 0.050989 - Test Loss: 0.032656\n",
      "Epoch 524/750 - Train pg Loss: 11.885586 - Test Loss: 2.258307\n",
      "\n",
      "\n",
      "Epoch 525/750 - Train Cd Loss: 0.045037 - Test Loss: 0.033764\n",
      "Epoch 525/750 - Train pg Loss: 12.601652 - Test Loss: 1.865516\n",
      "\n",
      "\n",
      "Epoch 526/750 - Train Cd Loss: 0.048820 - Test Loss: 0.035462\n",
      "Epoch 526/750 - Train pg Loss: 10.585861 - Test Loss: 1.841005\n",
      "\n",
      "\n",
      "Epoch 527/750 - Train Cd Loss: 0.068987 - Test Loss: 0.035062\n",
      "Epoch 527/750 - Train pg Loss: 13.372359 - Test Loss: 2.087314\n",
      "\n",
      "\n",
      "Epoch 528/750 - Train Cd Loss: 0.055685 - Test Loss: 0.033811\n",
      "Epoch 528/750 - Train pg Loss: 12.743867 - Test Loss: 2.096726\n",
      "\n",
      "\n",
      "Epoch 529/750 - Train Cd Loss: 0.035093 - Test Loss: 0.033206\n",
      "Epoch 529/750 - Train pg Loss: 11.593619 - Test Loss: 2.059122\n",
      "\n",
      "\n",
      "Epoch 530/750 - Train Cd Loss: 0.058193 - Test Loss: 0.035199\n",
      "Epoch 530/750 - Train pg Loss: 13.087372 - Test Loss: 2.314243\n",
      "\n",
      "\n",
      "Epoch 531/750 - Train Cd Loss: 0.040626 - Test Loss: 0.034359\n",
      "Epoch 531/750 - Train pg Loss: 12.497694 - Test Loss: 2.155251\n",
      "\n",
      "\n",
      "Epoch 532/750 - Train Cd Loss: 0.057127 - Test Loss: 0.035496\n",
      "Epoch 532/750 - Train pg Loss: 12.788593 - Test Loss: 2.128722\n",
      "\n",
      "\n",
      "Epoch 533/750 - Train Cd Loss: 0.051817 - Test Loss: nan\n",
      "Epoch 533/750 - Train pg Loss: 14.329316 - Test Loss: 3.515292\n",
      "\n",
      "\n",
      "Epoch 534/750 - Train Cd Loss: 0.060466 - Test Loss: 0.031725\n",
      "Epoch 534/750 - Train pg Loss: 14.393985 - Test Loss: 2.407510\n",
      "\n",
      "\n",
      "Epoch 535/750 - Train Cd Loss: 0.048965 - Test Loss: 0.032757\n",
      "Epoch 535/750 - Train pg Loss: 12.438491 - Test Loss: 2.316608\n",
      "\n",
      "\n",
      "Epoch 536/750 - Train Cd Loss: 0.035690 - Test Loss: 0.034161\n",
      "Epoch 536/750 - Train pg Loss: 13.355390 - Test Loss: 2.172027\n",
      "\n",
      "\n",
      "Epoch 537/750 - Train Cd Loss: 0.041849 - Test Loss: 0.035936\n",
      "Epoch 537/750 - Train pg Loss: 13.190223 - Test Loss: 2.248343\n",
      "\n",
      "\n",
      "Epoch 538/750 - Train Cd Loss: 0.035519 - Test Loss: 0.036661\n",
      "Epoch 538/750 - Train pg Loss: 13.856822 - Test Loss: 2.142533\n",
      "\n",
      "\n",
      "Epoch 539/750 - Train Cd Loss: 0.033695 - Test Loss: nan\n",
      "Epoch 539/750 - Train pg Loss: 14.794958 - Test Loss: 2.792749\n",
      "\n",
      "\n",
      "Epoch 540/750 - Train Cd Loss: 0.051428 - Test Loss: 0.035075\n",
      "Epoch 540/750 - Train pg Loss: 13.184884 - Test Loss: 2.340390\n",
      "\n",
      "\n",
      "Epoch 541/750 - Train Cd Loss: 0.056661 - Test Loss: 0.035134\n",
      "Epoch 541/750 - Train pg Loss: 14.090739 - Test Loss: 2.509107\n",
      "\n",
      "\n",
      "Epoch 542/750 - Train Cd Loss: 0.065142 - Test Loss: 0.032890\n",
      "Epoch 542/750 - Train pg Loss: 13.030527 - Test Loss: 2.038732\n",
      "\n",
      "\n",
      "Epoch 543/750 - Train Cd Loss: 0.040929 - Test Loss: 0.038020\n",
      "Epoch 543/750 - Train pg Loss: 11.039415 - Test Loss: 1.880986\n",
      "\n",
      "\n",
      "Epoch 544/750 - Train Cd Loss: 0.046559 - Test Loss: 0.036210\n",
      "Epoch 544/750 - Train pg Loss: 12.825920 - Test Loss: 1.826174\n",
      "\n",
      "\n",
      "Epoch 545/750 - Train Cd Loss: 0.054011 - Test Loss: 0.033696\n",
      "Epoch 545/750 - Train pg Loss: 12.570769 - Test Loss: 1.975965\n",
      "\n",
      "\n",
      "Epoch 546/750 - Train Cd Loss: 0.044727 - Test Loss: nan\n",
      "Epoch 546/750 - Train pg Loss: 12.139206 - Test Loss: 2.758744\n",
      "\n",
      "\n",
      "Epoch 547/750 - Train Cd Loss: 0.052367 - Test Loss: 0.035685\n",
      "Epoch 547/750 - Train pg Loss: 12.820334 - Test Loss: 2.265660\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 548/750 - Train Cd Loss: 0.053238 - Test Loss: nan\n",
      "Epoch 548/750 - Train pg Loss: 13.566298 - Test Loss: 3.331920\n",
      "\n",
      "\n",
      "Epoch 549/750 - Train Cd Loss: 0.052140 - Test Loss: 0.034950\n",
      "Epoch 549/750 - Train pg Loss: 14.060737 - Test Loss: 2.327123\n",
      "\n",
      "\n",
      "Epoch 550/750 - Train Cd Loss: 0.060081 - Test Loss: 0.034602\n",
      "Epoch 550/750 - Train pg Loss: 15.171453 - Test Loss: 2.104418\n",
      "\n",
      "\n",
      "Epoch 551/750 - Train Cd Loss: 0.038880 - Test Loss: 0.033182\n",
      "Epoch 551/750 - Train pg Loss: 12.641502 - Test Loss: 2.352507\n",
      "\n",
      "\n",
      "Epoch 552/750 - Train Cd Loss: 0.040358 - Test Loss: 0.035720\n",
      "Epoch 552/750 - Train pg Loss: 12.902147 - Test Loss: 2.267043\n",
      "\n",
      "\n",
      "Epoch 553/750 - Train Cd Loss: 0.038327 - Test Loss: nan\n",
      "Epoch 553/750 - Train pg Loss: 13.786695 - Test Loss: 2.859052\n",
      "\n",
      "\n",
      "Epoch 554/750 - Train Cd Loss: 0.061120 - Test Loss: 0.031786\n",
      "Epoch 554/750 - Train pg Loss: 14.618553 - Test Loss: 2.247040\n",
      "\n",
      "\n",
      "Epoch 555/750 - Train Cd Loss: 0.044726 - Test Loss: 0.035620\n",
      "Epoch 555/750 - Train pg Loss: 12.974925 - Test Loss: 2.105281\n",
      "\n",
      "\n",
      "Epoch 556/750 - Train Cd Loss: 0.035562 - Test Loss: 0.035127\n",
      "Epoch 556/750 - Train pg Loss: 13.843291 - Test Loss: 2.117128\n",
      "\n",
      "\n",
      "Epoch 557/750 - Train Cd Loss: 0.048887 - Test Loss: 0.037445\n",
      "Epoch 557/750 - Train pg Loss: 15.462266 - Test Loss: 2.307958\n",
      "\n",
      "\n",
      "Epoch 558/750 - Train Cd Loss: 0.046455 - Test Loss: 0.037864\n",
      "Epoch 558/750 - Train pg Loss: 13.888772 - Test Loss: 2.204738\n",
      "\n",
      "\n",
      "Epoch 559/750 - Train Cd Loss: 0.053271 - Test Loss: 0.033180\n",
      "Epoch 559/750 - Train pg Loss: 15.376878 - Test Loss: 2.159190\n",
      "\n",
      "\n",
      "Epoch 560/750 - Train Cd Loss: 0.039998 - Test Loss: 0.033513\n",
      "Epoch 560/750 - Train pg Loss: 15.593954 - Test Loss: 2.285951\n",
      "\n",
      "\n",
      "Epoch 561/750 - Train Cd Loss: 0.040797 - Test Loss: 0.033019\n",
      "Epoch 561/750 - Train pg Loss: 13.222283 - Test Loss: 2.468511\n",
      "\n",
      "\n",
      "Epoch 562/750 - Train Cd Loss: 0.051771 - Test Loss: 0.036310\n",
      "Epoch 562/750 - Train pg Loss: 15.489227 - Test Loss: 2.258763\n",
      "\n",
      "\n",
      "Epoch 563/750 - Train Cd Loss: 0.053741 - Test Loss: 0.037361\n",
      "Epoch 563/750 - Train pg Loss: 14.425363 - Test Loss: 2.201735\n",
      "\n",
      "\n",
      "Epoch 564/750 - Train Cd Loss: 0.040740 - Test Loss: 0.034874\n",
      "Epoch 564/750 - Train pg Loss: 12.774170 - Test Loss: 2.277832\n",
      "\n",
      "\n",
      "Epoch 565/750 - Train Cd Loss: 0.055079 - Test Loss: 0.036114\n",
      "Epoch 565/750 - Train pg Loss: 13.709184 - Test Loss: 1.999386\n",
      "\n",
      "\n",
      "Epoch 566/750 - Train Cd Loss: 0.033550 - Test Loss: nan\n",
      "Epoch 566/750 - Train pg Loss: 12.096889 - Test Loss: 2.963367\n",
      "\n",
      "\n",
      "Epoch 567/750 - Train Cd Loss: 0.065521 - Test Loss: 0.034428\n",
      "Epoch 567/750 - Train pg Loss: 13.634614 - Test Loss: 2.500656\n",
      "\n",
      "\n",
      "Epoch 568/750 - Train Cd Loss: 0.039576 - Test Loss: 0.034144\n",
      "Epoch 568/750 - Train pg Loss: 13.704009 - Test Loss: 2.156413\n",
      "\n",
      "\n",
      "Epoch 569/750 - Train Cd Loss: 0.057711 - Test Loss: 0.037721\n",
      "Epoch 569/750 - Train pg Loss: 12.999393 - Test Loss: 2.227837\n",
      "\n",
      "\n",
      "Epoch 570/750 - Train Cd Loss: 0.039678 - Test Loss: 0.036614\n",
      "Epoch 570/750 - Train pg Loss: 13.016408 - Test Loss: 2.191416\n",
      "\n",
      "\n",
      "Epoch 571/750 - Train Cd Loss: 0.042445 - Test Loss: 0.036907\n",
      "Epoch 571/750 - Train pg Loss: 14.148067 - Test Loss: 2.368594\n",
      "\n",
      "\n",
      "Epoch 572/750 - Train Cd Loss: 0.028828 - Test Loss: 0.037605\n",
      "Epoch 572/750 - Train pg Loss: 14.014595 - Test Loss: 2.143787\n",
      "\n",
      "\n",
      "Epoch 573/750 - Train Cd Loss: 0.053220 - Test Loss: 0.035848\n",
      "Epoch 573/750 - Train pg Loss: 12.778851 - Test Loss: 2.020177\n",
      "\n",
      "\n",
      "Epoch 574/750 - Train Cd Loss: 0.038496 - Test Loss: 0.035644\n",
      "Epoch 574/750 - Train pg Loss: 12.093822 - Test Loss: 2.140064\n",
      "\n",
      "\n",
      "Epoch 575/750 - Train Cd Loss: 0.037913 - Test Loss: 0.036579\n",
      "Epoch 575/750 - Train pg Loss: 11.824332 - Test Loss: 2.030519\n",
      "\n",
      "\n",
      "Epoch 576/750 - Train Cd Loss: 0.029630 - Test Loss: 0.037784\n",
      "Epoch 576/750 - Train pg Loss: 12.554785 - Test Loss: 1.964307\n",
      "\n",
      "\n",
      "Epoch 577/750 - Train Cd Loss: 0.031406 - Test Loss: nan\n",
      "Epoch 577/750 - Train pg Loss: 12.700480 - Test Loss: 3.251672\n",
      "\n",
      "\n",
      "Epoch 578/750 - Train Cd Loss: 0.042749 - Test Loss: 0.036259\n",
      "Epoch 578/750 - Train pg Loss: 15.502927 - Test Loss: 2.108300\n",
      "\n",
      "\n",
      "Epoch 579/750 - Train Cd Loss: 0.036519 - Test Loss: 0.036074\n",
      "Epoch 579/750 - Train pg Loss: 13.009522 - Test Loss: 2.356364\n",
      "\n",
      "\n",
      "Epoch 580/750 - Train Cd Loss: 0.038088 - Test Loss: 0.036843\n",
      "Epoch 580/750 - Train pg Loss: 12.562587 - Test Loss: 2.372608\n",
      "\n",
      "\n",
      "Epoch 581/750 - Train Cd Loss: 0.029831 - Test Loss: 0.035110\n",
      "Epoch 581/750 - Train pg Loss: 13.649749 - Test Loss: 2.380124\n",
      "\n",
      "\n",
      "Epoch 582/750 - Train Cd Loss: 0.044521 - Test Loss: 0.035190\n",
      "Epoch 582/750 - Train pg Loss: 15.558602 - Test Loss: 2.915710\n",
      "\n",
      "\n",
      "Epoch 583/750 - Train Cd Loss: 0.034132 - Test Loss: 0.037335\n",
      "Epoch 583/750 - Train pg Loss: 15.547342 - Test Loss: 2.295567\n",
      "\n",
      "\n",
      "Epoch 584/750 - Train Cd Loss: 0.032429 - Test Loss: 0.039974\n",
      "Epoch 584/750 - Train pg Loss: 13.555076 - Test Loss: 2.429598\n",
      "\n",
      "\n",
      "Epoch 585/750 - Train Cd Loss: 0.030559 - Test Loss: nan\n",
      "Epoch 585/750 - Train pg Loss: 16.306625 - Test Loss: 3.438324\n",
      "\n",
      "\n",
      "Epoch 586/750 - Train Cd Loss: 0.050363 - Test Loss: 0.035374\n",
      "Epoch 586/750 - Train pg Loss: 17.155899 - Test Loss: 2.428529\n",
      "\n",
      "\n",
      "Epoch 587/750 - Train Cd Loss: 0.036347 - Test Loss: 0.034090\n",
      "Epoch 587/750 - Train pg Loss: 14.023510 - Test Loss: 2.396337\n",
      "\n",
      "\n",
      "Epoch 588/750 - Train Cd Loss: 0.052958 - Test Loss: nan\n",
      "Epoch 588/750 - Train pg Loss: 17.680857 - Test Loss: 3.154607\n",
      "\n",
      "\n",
      "Epoch 589/750 - Train Cd Loss: 0.053195 - Test Loss: 0.033696\n",
      "Epoch 589/750 - Train pg Loss: 14.982584 - Test Loss: 2.570506\n",
      "\n",
      "\n",
      "Epoch 590/750 - Train Cd Loss: 0.037355 - Test Loss: 0.035790\n",
      "Epoch 590/750 - Train pg Loss: 12.853791 - Test Loss: 2.001145\n",
      "\n",
      "\n",
      "Epoch 591/750 - Train Cd Loss: 0.062920 - Test Loss: 0.033226\n",
      "Epoch 591/750 - Train pg Loss: 14.207688 - Test Loss: 2.435663\n",
      "\n",
      "\n",
      "Epoch 592/750 - Train Cd Loss: 0.035171 - Test Loss: 0.036103\n",
      "Epoch 592/750 - Train pg Loss: 12.470921 - Test Loss: 2.275340\n",
      "\n",
      "\n",
      "Epoch 593/750 - Train Cd Loss: 0.034279 - Test Loss: 0.038850\n",
      "Epoch 593/750 - Train pg Loss: 16.308657 - Test Loss: 2.236772\n",
      "\n",
      "\n",
      "Epoch 594/750 - Train Cd Loss: 0.033289 - Test Loss: 0.035486\n",
      "Epoch 594/750 - Train pg Loss: 13.808893 - Test Loss: 2.448481\n",
      "\n",
      "\n",
      "Epoch 595/750 - Train Cd Loss: 0.032792 - Test Loss: 0.036857\n",
      "Epoch 595/750 - Train pg Loss: 14.000063 - Test Loss: 2.540700\n",
      "\n",
      "\n",
      "Epoch 596/750 - Train Cd Loss: 0.044813 - Test Loss: 0.035591\n",
      "Epoch 596/750 - Train pg Loss: 15.032349 - Test Loss: 2.643684\n",
      "\n",
      "\n",
      "Epoch 597/750 - Train Cd Loss: 0.046148 - Test Loss: 0.036624\n",
      "Epoch 597/750 - Train pg Loss: 17.202454 - Test Loss: 2.464434\n",
      "\n",
      "\n",
      "Epoch 598/750 - Train Cd Loss: 0.033350 - Test Loss: 0.035592\n",
      "Epoch 598/750 - Train pg Loss: 15.834617 - Test Loss: 2.514285\n",
      "\n",
      "\n",
      "Epoch 599/750 - Train Cd Loss: 0.048520 - Test Loss: 0.035623\n",
      "Epoch 599/750 - Train pg Loss: 15.901843 - Test Loss: 2.589803\n",
      "\n",
      "\n",
      "Epoch 600/750 - Train Cd Loss: 0.032954 - Test Loss: 0.033768\n",
      "Epoch 600/750 - Train pg Loss: 15.804742 - Test Loss: 2.545971\n",
      "\n",
      "\n",
      "Epoch 601/750 - Train Cd Loss: 0.032518 - Test Loss: 0.037650\n",
      "Epoch 601/750 - Train pg Loss: 13.598770 - Test Loss: 2.287769\n",
      "\n",
      "\n",
      "Epoch 602/750 - Train Cd Loss: 0.035289 - Test Loss: 0.036359\n",
      "Epoch 602/750 - Train pg Loss: 14.446303 - Test Loss: 2.444024\n",
      "\n",
      "\n",
      "Epoch 603/750 - Train Cd Loss: 0.044909 - Test Loss: 0.035571\n",
      "Epoch 603/750 - Train pg Loss: 14.867805 - Test Loss: 2.781358\n",
      "\n",
      "\n",
      "Epoch 604/750 - Train Cd Loss: 0.029332 - Test Loss: 0.036808\n",
      "Epoch 604/750 - Train pg Loss: 18.668768 - Test Loss: 3.043968\n",
      "\n",
      "\n",
      "Epoch 605/750 - Train Cd Loss: 0.035472 - Test Loss: 0.035369\n",
      "Epoch 605/750 - Train pg Loss: 15.630616 - Test Loss: 2.884984\n",
      "\n",
      "\n",
      "Epoch 606/750 - Train Cd Loss: 0.042173 - Test Loss: nan\n",
      "Epoch 606/750 - Train pg Loss: 17.862078 - Test Loss: 3.164343\n",
      "\n",
      "\n",
      "Epoch 607/750 - Train Cd Loss: 0.064144 - Test Loss: 0.034231\n",
      "Epoch 607/750 - Train pg Loss: 18.696554 - Test Loss: 2.611562\n",
      "\n",
      "\n",
      "Epoch 608/750 - Train Cd Loss: 0.032853 - Test Loss: 0.035440\n",
      "Epoch 608/750 - Train pg Loss: 13.216308 - Test Loss: 2.382113\n",
      "\n",
      "\n",
      "Epoch 609/750 - Train Cd Loss: 0.044586 - Test Loss: 0.036603\n",
      "Epoch 609/750 - Train pg Loss: 15.023050 - Test Loss: 2.619691\n",
      "\n",
      "\n",
      "Epoch 610/750 - Train Cd Loss: 0.028745 - Test Loss: 0.039335\n",
      "Epoch 610/750 - Train pg Loss: 16.604813 - Test Loss: 2.359271\n",
      "\n",
      "\n",
      "Epoch 611/750 - Train Cd Loss: 0.044823 - Test Loss: 0.037774\n",
      "Epoch 611/750 - Train pg Loss: 13.135299 - Test Loss: 2.317063\n",
      "\n",
      "\n",
      "Epoch 612/750 - Train Cd Loss: 0.032216 - Test Loss: 0.038621\n",
      "Epoch 612/750 - Train pg Loss: 13.536388 - Test Loss: 2.576952\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 613/750 - Train Cd Loss: 0.035426 - Test Loss: 0.038886\n",
      "Epoch 613/750 - Train pg Loss: 16.023750 - Test Loss: 2.716925\n",
      "\n",
      "\n",
      "Epoch 614/750 - Train Cd Loss: 0.033478 - Test Loss: 0.036262\n",
      "Epoch 614/750 - Train pg Loss: 16.236986 - Test Loss: 2.645503\n",
      "\n",
      "\n",
      "Epoch 615/750 - Train Cd Loss: 0.031592 - Test Loss: 0.035886\n",
      "Epoch 615/750 - Train pg Loss: 15.058738 - Test Loss: 2.751604\n",
      "\n",
      "\n",
      "Epoch 616/750 - Train Cd Loss: 0.032423 - Test Loss: 0.035390\n",
      "Epoch 616/750 - Train pg Loss: 14.652566 - Test Loss: 2.563814\n",
      "\n",
      "\n",
      "Epoch 617/750 - Train Cd Loss: 0.026726 - Test Loss: 0.037546\n",
      "Epoch 617/750 - Train pg Loss: 17.021049 - Test Loss: 2.635634\n",
      "\n",
      "\n",
      "Epoch 618/750 - Train Cd Loss: 0.045600 - Test Loss: 0.033951\n",
      "Epoch 618/750 - Train pg Loss: 15.974146 - Test Loss: 2.664451\n",
      "\n",
      "\n",
      "Epoch 619/750 - Train Cd Loss: 0.033271 - Test Loss: 0.036454\n",
      "Epoch 619/750 - Train pg Loss: 16.625677 - Test Loss: 2.252430\n",
      "\n",
      "\n",
      "Epoch 620/750 - Train Cd Loss: 0.045352 - Test Loss: 0.035783\n",
      "Epoch 620/750 - Train pg Loss: 15.955766 - Test Loss: 2.134660\n",
      "\n",
      "\n",
      "Epoch 621/750 - Train Cd Loss: 0.042072 - Test Loss: 0.035034\n",
      "Epoch 621/750 - Train pg Loss: 15.664660 - Test Loss: 2.506621\n",
      "\n",
      "\n",
      "Epoch 622/750 - Train Cd Loss: 0.039990 - Test Loss: 0.036700\n",
      "Epoch 622/750 - Train pg Loss: 11.579597 - Test Loss: 2.264526\n",
      "\n",
      "\n",
      "Epoch 623/750 - Train Cd Loss: 0.046416 - Test Loss: 0.033403\n",
      "Epoch 623/750 - Train pg Loss: 15.156982 - Test Loss: 2.111463\n",
      "\n",
      "\n",
      "Epoch 624/750 - Train Cd Loss: 0.030262 - Test Loss: 0.035336\n",
      "Epoch 624/750 - Train pg Loss: 14.209079 - Test Loss: 2.151085\n",
      "\n",
      "\n",
      "Epoch 625/750 - Train Cd Loss: 0.023466 - Test Loss: 0.038686\n",
      "Epoch 625/750 - Train pg Loss: 14.374923 - Test Loss: 2.103956\n",
      "\n",
      "\n",
      "Epoch 626/750 - Train Cd Loss: 0.046133 - Test Loss: 0.037892\n",
      "Epoch 626/750 - Train pg Loss: 11.806062 - Test Loss: 2.181746\n",
      "\n",
      "\n",
      "Epoch 627/750 - Train Cd Loss: 0.043832 - Test Loss: 0.035036\n",
      "Epoch 627/750 - Train pg Loss: 15.311475 - Test Loss: 2.292848\n",
      "\n",
      "\n",
      "Epoch 628/750 - Train Cd Loss: 0.042541 - Test Loss: 0.035716\n",
      "Epoch 628/750 - Train pg Loss: 13.965309 - Test Loss: 2.052984\n",
      "\n",
      "\n",
      "Epoch 629/750 - Train Cd Loss: 0.027023 - Test Loss: 0.036259\n",
      "Epoch 629/750 - Train pg Loss: 10.450032 - Test Loss: 2.073595\n",
      "\n",
      "\n",
      "Epoch 630/750 - Train Cd Loss: 0.030675 - Test Loss: 0.037553\n",
      "Epoch 630/750 - Train pg Loss: 13.994412 - Test Loss: 2.093731\n",
      "\n",
      "\n",
      "Epoch 631/750 - Train Cd Loss: 0.058003 - Test Loss: 0.033765\n",
      "Epoch 631/750 - Train pg Loss: 15.217154 - Test Loss: 2.368904\n",
      "\n",
      "\n",
      "Epoch 632/750 - Train Cd Loss: 0.043881 - Test Loss: 0.033226\n",
      "Epoch 632/750 - Train pg Loss: 13.770007 - Test Loss: 2.221892\n",
      "\n",
      "\n",
      "Epoch 633/750 - Train Cd Loss: 0.047325 - Test Loss: 0.034951\n",
      "Epoch 633/750 - Train pg Loss: 14.045116 - Test Loss: 2.088331\n",
      "\n",
      "\n",
      "Epoch 634/750 - Train Cd Loss: 0.031885 - Test Loss: 0.035667\n",
      "Epoch 634/750 - Train pg Loss: 13.911956 - Test Loss: 2.142215\n",
      "\n",
      "\n",
      "Epoch 635/750 - Train Cd Loss: 0.035546 - Test Loss: 0.037915\n",
      "Epoch 635/750 - Train pg Loss: 14.967285 - Test Loss: 2.439339\n",
      "\n",
      "\n",
      "Epoch 636/750 - Train Cd Loss: 0.050107 - Test Loss: 0.038487\n",
      "Epoch 636/750 - Train pg Loss: 16.608511 - Test Loss: 2.214765\n",
      "\n",
      "\n",
      "Epoch 637/750 - Train Cd Loss: 0.032764 - Test Loss: 0.037349\n",
      "Epoch 637/750 - Train pg Loss: 13.434793 - Test Loss: 2.122510\n",
      "\n",
      "\n",
      "Epoch 638/750 - Train Cd Loss: 0.042327 - Test Loss: 0.036135\n",
      "Epoch 638/750 - Train pg Loss: 15.303455 - Test Loss: 2.324014\n",
      "\n",
      "\n",
      "Epoch 639/750 - Train Cd Loss: 0.025261 - Test Loss: 0.037391\n",
      "Epoch 639/750 - Train pg Loss: 12.641143 - Test Loss: 2.366530\n",
      "\n",
      "\n",
      "Epoch 640/750 - Train Cd Loss: 0.071451 - Test Loss: 0.033335\n",
      "Epoch 640/750 - Train pg Loss: 19.461775 - Test Loss: 2.789302\n",
      "\n",
      "\n",
      "Epoch 641/750 - Train Cd Loss: 0.039864 - Test Loss: 0.033857\n",
      "Epoch 641/750 - Train pg Loss: 16.326191 - Test Loss: 2.612775\n",
      "\n",
      "\n",
      "Epoch 642/750 - Train Cd Loss: 0.048809 - Test Loss: 0.036434\n",
      "Epoch 642/750 - Train pg Loss: 14.934086 - Test Loss: 2.609063\n",
      "\n",
      "\n",
      "Epoch 643/750 - Train Cd Loss: 0.043643 - Test Loss: 0.032537\n",
      "Epoch 643/750 - Train pg Loss: 17.590073 - Test Loss: 2.836697\n",
      "\n",
      "\n",
      "Epoch 644/750 - Train Cd Loss: 0.029549 - Test Loss: 0.037078\n",
      "Epoch 644/750 - Train pg Loss: 15.935863 - Test Loss: 2.758154\n",
      "\n",
      "\n",
      "Epoch 645/750 - Train Cd Loss: 0.046397 - Test Loss: 0.035383\n",
      "Epoch 645/750 - Train pg Loss: 17.233732 - Test Loss: 2.451283\n",
      "\n",
      "\n",
      "Epoch 646/750 - Train Cd Loss: 0.028497 - Test Loss: 0.035509\n",
      "Epoch 646/750 - Train pg Loss: 13.540552 - Test Loss: 2.341050\n",
      "\n",
      "\n",
      "Epoch 647/750 - Train Cd Loss: 0.029183 - Test Loss: 0.035504\n",
      "Epoch 647/750 - Train pg Loss: 14.681358 - Test Loss: 2.258435\n",
      "\n",
      "\n",
      "Epoch 648/750 - Train Cd Loss: 0.026769 - Test Loss: 0.038425\n",
      "Epoch 648/750 - Train pg Loss: 15.720140 - Test Loss: 2.500407\n",
      "\n",
      "\n",
      "Epoch 649/750 - Train Cd Loss: 0.045110 - Test Loss: 0.035556\n",
      "Epoch 649/750 - Train pg Loss: 16.965105 - Test Loss: 2.591956\n",
      "\n",
      "\n",
      "Epoch 650/750 - Train Cd Loss: 0.029262 - Test Loss: 0.035400\n",
      "Epoch 650/750 - Train pg Loss: 14.929645 - Test Loss: 2.512951\n",
      "\n",
      "\n",
      "Epoch 651/750 - Train Cd Loss: 0.041626 - Test Loss: 0.034556\n",
      "Epoch 651/750 - Train pg Loss: 13.249995 - Test Loss: 2.309316\n",
      "\n",
      "\n",
      "Epoch 652/750 - Train Cd Loss: 0.041672 - Test Loss: 0.035058\n",
      "Epoch 652/750 - Train pg Loss: 17.360554 - Test Loss: 2.452575\n",
      "\n",
      "\n",
      "Epoch 653/750 - Train Cd Loss: 0.027206 - Test Loss: 0.036287\n",
      "Epoch 653/750 - Train pg Loss: 17.510935 - Test Loss: 2.565437\n",
      "\n",
      "\n",
      "Epoch 654/750 - Train Cd Loss: 0.028935 - Test Loss: 0.036928\n",
      "Epoch 654/750 - Train pg Loss: 16.261505 - Test Loss: 2.853832\n",
      "\n",
      "\n",
      "Epoch 655/750 - Train Cd Loss: 0.046677 - Test Loss: 0.037949\n",
      "Epoch 655/750 - Train pg Loss: 18.344593 - Test Loss: 2.632028\n",
      "\n",
      "\n",
      "Epoch 656/750 - Train Cd Loss: 0.045107 - Test Loss: 0.037076\n",
      "Epoch 656/750 - Train pg Loss: 16.167124 - Test Loss: 2.282523\n",
      "\n",
      "\n",
      "Epoch 657/750 - Train Cd Loss: 0.031856 - Test Loss: 0.035342\n",
      "Epoch 657/750 - Train pg Loss: 14.870471 - Test Loss: 2.291783\n",
      "\n",
      "\n",
      "Epoch 658/750 - Train Cd Loss: 0.051059 - Test Loss: 0.034814\n",
      "Epoch 658/750 - Train pg Loss: 16.596376 - Test Loss: 2.481645\n",
      "\n",
      "\n",
      "Epoch 659/750 - Train Cd Loss: 0.026706 - Test Loss: 0.033970\n",
      "Epoch 659/750 - Train pg Loss: 14.393610 - Test Loss: 2.444031\n",
      "\n",
      "\n",
      "Epoch 660/750 - Train Cd Loss: 0.040603 - Test Loss: 0.035333\n",
      "Epoch 660/750 - Train pg Loss: 15.119007 - Test Loss: 2.760610\n",
      "\n",
      "\n",
      "Epoch 661/750 - Train Cd Loss: 0.047801 - Test Loss: 0.035442\n",
      "Epoch 661/750 - Train pg Loss: 14.729361 - Test Loss: 2.427397\n",
      "\n",
      "\n",
      "Epoch 662/750 - Train Cd Loss: 0.028904 - Test Loss: 0.035303\n",
      "Epoch 662/750 - Train pg Loss: 14.404967 - Test Loss: 2.331977\n",
      "\n",
      "\n",
      "Epoch 663/750 - Train Cd Loss: 0.040618 - Test Loss: 0.037627\n",
      "Epoch 663/750 - Train pg Loss: 15.587710 - Test Loss: 2.422027\n",
      "\n",
      "\n",
      "Epoch 664/750 - Train Cd Loss: 0.027135 - Test Loss: 0.034755\n",
      "Epoch 664/750 - Train pg Loss: 13.956882 - Test Loss: 2.483575\n",
      "\n",
      "\n",
      "Epoch 665/750 - Train Cd Loss: 0.031985 - Test Loss: 0.035274\n",
      "Epoch 665/750 - Train pg Loss: 13.251980 - Test Loss: 2.414169\n",
      "\n",
      "\n",
      "Epoch 666/750 - Train Cd Loss: 0.059922 - Test Loss: 0.031965\n",
      "Epoch 666/750 - Train pg Loss: 16.212410 - Test Loss: 2.680396\n",
      "\n",
      "\n",
      "Epoch 667/750 - Train Cd Loss: 0.028219 - Test Loss: 0.034250\n",
      "Epoch 667/750 - Train pg Loss: 20.000931 - Test Loss: 2.844860\n",
      "\n",
      "\n",
      "Epoch 668/750 - Train Cd Loss: 0.046871 - Test Loss: 0.032906\n",
      "Epoch 668/750 - Train pg Loss: 18.142569 - Test Loss: 3.181160\n",
      "\n",
      "\n",
      "Epoch 669/750 - Train Cd Loss: 0.028324 - Test Loss: 0.036902\n",
      "Epoch 669/750 - Train pg Loss: 17.108517 - Test Loss: 2.661360\n",
      "\n",
      "\n",
      "Epoch 670/750 - Train Cd Loss: 0.026706 - Test Loss: 0.038461\n",
      "Epoch 670/750 - Train pg Loss: 16.428690 - Test Loss: 2.495841\n",
      "\n",
      "\n",
      "Epoch 671/750 - Train Cd Loss: 0.040129 - Test Loss: 0.039896\n",
      "Epoch 671/750 - Train pg Loss: 17.423294 - Test Loss: 2.381191\n",
      "\n",
      "\n",
      "Epoch 672/750 - Train Cd Loss: 0.046845 - Test Loss: 0.035797\n",
      "Epoch 672/750 - Train pg Loss: 17.939913 - Test Loss: 2.299316\n",
      "\n",
      "\n",
      "Epoch 673/750 - Train Cd Loss: 0.027560 - Test Loss: 0.035223\n",
      "Epoch 673/750 - Train pg Loss: 12.601333 - Test Loss: 2.339613\n",
      "\n",
      "\n",
      "Epoch 674/750 - Train Cd Loss: 0.042976 - Test Loss: 0.036022\n",
      "Epoch 674/750 - Train pg Loss: 14.451827 - Test Loss: 2.745391\n",
      "\n",
      "\n",
      "Epoch 675/750 - Train Cd Loss: 0.041232 - Test Loss: 0.034764\n",
      "Epoch 675/750 - Train pg Loss: 17.133242 - Test Loss: 2.909017\n",
      "\n",
      "\n",
      "Epoch 676/750 - Train Cd Loss: 0.030604 - Test Loss: 0.036635\n",
      "Epoch 676/750 - Train pg Loss: 16.626534 - Test Loss: 2.633296\n",
      "\n",
      "\n",
      "Epoch 677/750 - Train Cd Loss: 0.026791 - Test Loss: 0.040756\n",
      "Epoch 677/750 - Train pg Loss: 14.860904 - Test Loss: 2.545901\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 678/750 - Train Cd Loss: 0.025466 - Test Loss: 0.038066\n",
      "Epoch 678/750 - Train pg Loss: 13.931656 - Test Loss: 2.571095\n",
      "\n",
      "\n",
      "Epoch 679/750 - Train Cd Loss: 0.044715 - Test Loss: 0.035980\n",
      "Epoch 679/750 - Train pg Loss: 15.604724 - Test Loss: 2.362668\n",
      "\n",
      "\n",
      "Epoch 680/750 - Train Cd Loss: 0.027855 - Test Loss: 0.035848\n",
      "Epoch 680/750 - Train pg Loss: 15.784589 - Test Loss: 2.245467\n",
      "\n",
      "\n",
      "Epoch 681/750 - Train Cd Loss: 0.036479 - Test Loss: 0.035707\n",
      "Epoch 681/750 - Train pg Loss: 15.445801 - Test Loss: 2.650441\n",
      "\n",
      "\n",
      "Epoch 682/750 - Train Cd Loss: 0.030530 - Test Loss: 0.038391\n",
      "Epoch 682/750 - Train pg Loss: 15.448370 - Test Loss: 2.935713\n",
      "\n",
      "\n",
      "Epoch 683/750 - Train Cd Loss: 0.027725 - Test Loss: nan\n",
      "Epoch 683/750 - Train pg Loss: 13.392847 - Test Loss: 2.796953\n",
      "\n",
      "\n",
      "Epoch 684/750 - Train Cd Loss: 0.041583 - Test Loss: 0.035944\n",
      "Epoch 684/750 - Train pg Loss: 15.939663 - Test Loss: 2.617118\n",
      "\n",
      "\n",
      "Epoch 685/750 - Train Cd Loss: 0.032434 - Test Loss: 0.035366\n",
      "Epoch 685/750 - Train pg Loss: 14.631083 - Test Loss: 2.088018\n",
      "\n",
      "\n",
      "Epoch 686/750 - Train Cd Loss: 0.048971 - Test Loss: 0.034526\n",
      "Epoch 686/750 - Train pg Loss: 15.461886 - Test Loss: 2.167034\n",
      "\n",
      "\n",
      "Epoch 687/750 - Train Cd Loss: 0.024889 - Test Loss: 0.038234\n",
      "Epoch 687/750 - Train pg Loss: 14.464609 - Test Loss: 2.460247\n",
      "\n",
      "\n",
      "Epoch 688/750 - Train Cd Loss: 0.037242 - Test Loss: 0.035512\n",
      "Epoch 688/750 - Train pg Loss: 16.689672 - Test Loss: 2.989041\n",
      "\n",
      "\n",
      "Epoch 689/750 - Train Cd Loss: 0.025297 - Test Loss: 0.034650\n",
      "Epoch 689/750 - Train pg Loss: 17.212069 - Test Loss: 3.126048\n",
      "\n",
      "\n",
      "Epoch 690/750 - Train Cd Loss: 0.022633 - Test Loss: 0.039480\n",
      "Epoch 690/750 - Train pg Loss: 15.619079 - Test Loss: 2.981230\n",
      "\n",
      "\n",
      "Epoch 691/750 - Train Cd Loss: 0.025722 - Test Loss: 0.038496\n",
      "Epoch 691/750 - Train pg Loss: 17.614592 - Test Loss: 2.850376\n",
      "\n",
      "\n",
      "Epoch 692/750 - Train Cd Loss: 0.053349 - Test Loss: 0.036639\n",
      "Epoch 692/750 - Train pg Loss: 20.377327 - Test Loss: 2.925349\n",
      "\n",
      "\n",
      "Epoch 693/750 - Train Cd Loss: 0.024036 - Test Loss: 0.034973\n",
      "Epoch 693/750 - Train pg Loss: 15.922455 - Test Loss: 2.546878\n",
      "\n",
      "\n",
      "Epoch 694/750 - Train Cd Loss: 0.026376 - Test Loss: 0.038023\n",
      "Epoch 694/750 - Train pg Loss: 13.509966 - Test Loss: 2.441982\n",
      "\n",
      "\n",
      "Epoch 695/750 - Train Cd Loss: 0.053247 - Test Loss: 0.035288\n",
      "Epoch 695/750 - Train pg Loss: 17.154478 - Test Loss: 2.580145\n",
      "\n",
      "\n",
      "Epoch 696/750 - Train Cd Loss: 0.029805 - Test Loss: 0.036039\n",
      "Epoch 696/750 - Train pg Loss: 14.400261 - Test Loss: 2.500070\n",
      "\n",
      "\n",
      "Epoch 697/750 - Train Cd Loss: 0.021491 - Test Loss: 0.039282\n",
      "Epoch 697/750 - Train pg Loss: 16.585470 - Test Loss: 2.472764\n",
      "\n",
      "\n",
      "Epoch 698/750 - Train Cd Loss: 0.025999 - Test Loss: 0.038560\n",
      "Epoch 698/750 - Train pg Loss: 15.211774 - Test Loss: 2.305467\n",
      "\n",
      "\n",
      "Epoch 699/750 - Train Cd Loss: 0.058985 - Test Loss: 0.035777\n",
      "Epoch 699/750 - Train pg Loss: 14.909457 - Test Loss: 2.537592\n",
      "\n",
      "\n",
      "Epoch 700/750 - Train Cd Loss: 0.025601 - Test Loss: 0.037593\n",
      "Epoch 700/750 - Train pg Loss: 15.459423 - Test Loss: 2.174339\n",
      "\n",
      "\n",
      "Epoch 701/750 - Train Cd Loss: 0.039854 - Test Loss: 0.037806\n",
      "Epoch 701/750 - Train pg Loss: 14.799798 - Test Loss: 2.163795\n",
      "\n",
      "\n",
      "Epoch 702/750 - Train Cd Loss: 0.026901 - Test Loss: 0.037374\n",
      "Epoch 702/750 - Train pg Loss: 14.994770 - Test Loss: 2.573013\n",
      "\n",
      "\n",
      "Epoch 703/750 - Train Cd Loss: 0.026967 - Test Loss: 0.037145\n",
      "Epoch 703/750 - Train pg Loss: 14.772387 - Test Loss: 2.614962\n",
      "\n",
      "\n",
      "Epoch 704/750 - Train Cd Loss: 0.044359 - Test Loss: 0.039447\n",
      "Epoch 704/750 - Train pg Loss: 18.644670 - Test Loss: 2.740297\n",
      "\n",
      "\n",
      "Epoch 705/750 - Train Cd Loss: 0.028439 - Test Loss: 0.037528\n",
      "Epoch 705/750 - Train pg Loss: 17.717476 - Test Loss: 2.904895\n",
      "\n",
      "\n",
      "Epoch 706/750 - Train Cd Loss: 0.024466 - Test Loss: nan\n",
      "Epoch 706/750 - Train pg Loss: 16.916065 - Test Loss: 3.563067\n",
      "\n",
      "\n",
      "Epoch 707/750 - Train Cd Loss: 0.064692 - Test Loss: 0.036000\n",
      "Epoch 707/750 - Train pg Loss: 22.334728 - Test Loss: 2.926028\n",
      "\n",
      "\n",
      "Epoch 708/750 - Train Cd Loss: 0.036106 - Test Loss: 0.035943\n",
      "Epoch 708/750 - Train pg Loss: 17.241625 - Test Loss: 2.734335\n",
      "\n",
      "\n",
      "Epoch 709/750 - Train Cd Loss: 0.041691 - Test Loss: 0.036392\n",
      "Epoch 709/750 - Train pg Loss: 16.581604 - Test Loss: 2.625284\n",
      "\n",
      "\n",
      "Epoch 710/750 - Train Cd Loss: 0.028834 - Test Loss: 0.040413\n",
      "Epoch 710/750 - Train pg Loss: 13.541761 - Test Loss: 2.338497\n",
      "\n",
      "\n",
      "Epoch 711/750 - Train Cd Loss: 0.024386 - Test Loss: 0.040844\n",
      "Epoch 711/750 - Train pg Loss: 14.971462 - Test Loss: 2.444840\n",
      "\n",
      "\n",
      "Epoch 712/750 - Train Cd Loss: 0.038470 - Test Loss: 0.037735\n",
      "Epoch 712/750 - Train pg Loss: 14.526228 - Test Loss: 2.338760\n",
      "\n",
      "\n",
      "Epoch 713/750 - Train Cd Loss: 0.019377 - Test Loss: 0.039323\n",
      "Epoch 713/750 - Train pg Loss: 14.619973 - Test Loss: 2.752774\n",
      "\n",
      "\n",
      "Epoch 714/750 - Train Cd Loss: 0.022982 - Test Loss: 0.039660\n",
      "Epoch 714/750 - Train pg Loss: 19.774771 - Test Loss: 2.741417\n",
      "\n",
      "\n",
      "Epoch 715/750 - Train Cd Loss: 0.040162 - Test Loss: 0.041930\n",
      "Epoch 715/750 - Train pg Loss: 17.289967 - Test Loss: 2.321759\n",
      "\n",
      "\n",
      "Epoch 716/750 - Train Cd Loss: 0.037216 - Test Loss: 0.037302\n",
      "Epoch 716/750 - Train pg Loss: 16.279810 - Test Loss: 2.316449\n",
      "\n",
      "\n",
      "Epoch 717/750 - Train Cd Loss: 0.027623 - Test Loss: 0.036731\n",
      "Epoch 717/750 - Train pg Loss: 11.202275 - Test Loss: 2.383874\n",
      "\n",
      "\n",
      "Epoch 718/750 - Train Cd Loss: 0.034104 - Test Loss: 0.036318\n",
      "Epoch 718/750 - Train pg Loss: 14.600002 - Test Loss: 2.447439\n",
      "\n",
      "\n",
      "Epoch 719/750 - Train Cd Loss: 0.020103 - Test Loss: 0.038073\n",
      "Epoch 719/750 - Train pg Loss: 16.804981 - Test Loss: 2.605494\n",
      "\n",
      "\n",
      "Epoch 720/750 - Train Cd Loss: 0.041020 - Test Loss: 0.038792\n",
      "Epoch 720/750 - Train pg Loss: 18.628414 - Test Loss: 3.254207\n",
      "\n",
      "\n",
      "Epoch 721/750 - Train Cd Loss: 0.025522 - Test Loss: 0.038455\n",
      "Epoch 721/750 - Train pg Loss: 17.532803 - Test Loss: 2.784357\n",
      "\n",
      "\n",
      "Epoch 722/750 - Train Cd Loss: 0.022161 - Test Loss: 0.039417\n",
      "Epoch 722/750 - Train pg Loss: 17.938133 - Test Loss: 2.748438\n",
      "\n",
      "\n",
      "Epoch 723/750 - Train Cd Loss: 0.023311 - Test Loss: 0.040851\n",
      "Epoch 723/750 - Train pg Loss: 19.162182 - Test Loss: 3.439476\n",
      "\n",
      "\n",
      "Epoch 724/750 - Train Cd Loss: 0.044484 - Test Loss: 0.039139\n",
      "Epoch 724/750 - Train pg Loss: 19.912531 - Test Loss: 2.979176\n",
      "\n",
      "\n",
      "Epoch 725/750 - Train Cd Loss: 0.059158 - Test Loss: 0.035331\n",
      "Epoch 725/750 - Train pg Loss: 17.147890 - Test Loss: 2.523726\n",
      "\n",
      "\n",
      "Epoch 726/750 - Train Cd Loss: 0.030603 - Test Loss: 0.037471\n",
      "Epoch 726/750 - Train pg Loss: 13.751302 - Test Loss: 2.532553\n",
      "\n",
      "\n",
      "Epoch 727/750 - Train Cd Loss: 0.021399 - Test Loss: 0.037147\n",
      "Epoch 727/750 - Train pg Loss: 16.465542 - Test Loss: 2.861678\n",
      "\n",
      "\n",
      "Epoch 728/750 - Train Cd Loss: 0.055799 - Test Loss: 0.037732\n",
      "Epoch 728/750 - Train pg Loss: 17.631577 - Test Loss: 2.660581\n",
      "\n",
      "\n",
      "Epoch 729/750 - Train Cd Loss: 0.027511 - Test Loss: 0.036091\n",
      "Epoch 729/750 - Train pg Loss: 16.724592 - Test Loss: 3.134095\n",
      "\n",
      "\n",
      "Epoch 730/750 - Train Cd Loss: 0.025183 - Test Loss: 0.039998\n",
      "Epoch 730/750 - Train pg Loss: 19.410194 - Test Loss: 3.276483\n",
      "\n",
      "\n",
      "Epoch 731/750 - Train Cd Loss: 0.020249 - Test Loss: 0.039708\n",
      "Epoch 731/750 - Train pg Loss: 19.404490 - Test Loss: 2.871434\n",
      "\n",
      "\n",
      "Epoch 732/750 - Train Cd Loss: 0.060107 - Test Loss: 0.036981\n",
      "Epoch 732/750 - Train pg Loss: 20.802982 - Test Loss: 3.087362\n",
      "\n",
      "\n",
      "Epoch 733/750 - Train Cd Loss: 0.026068 - Test Loss: 0.038589\n",
      "Epoch 733/750 - Train pg Loss: 17.178892 - Test Loss: 3.038205\n",
      "\n",
      "\n",
      "Epoch 734/750 - Train Cd Loss: 0.041197 - Test Loss: 0.035736\n",
      "Epoch 734/750 - Train pg Loss: 20.421116 - Test Loss: 2.846409\n",
      "\n",
      "\n",
      "Epoch 735/750 - Train Cd Loss: 0.024251 - Test Loss: 0.038983\n",
      "Epoch 735/750 - Train pg Loss: 18.699926 - Test Loss: 3.261705\n",
      "\n",
      "\n",
      "Epoch 736/750 - Train Cd Loss: 0.034358 - Test Loss: 0.039352\n",
      "Epoch 736/750 - Train pg Loss: 19.521118 - Test Loss: 3.456107\n",
      "\n",
      "\n",
      "Epoch 737/750 - Train Cd Loss: 0.023398 - Test Loss: 0.039308\n",
      "Epoch 737/750 - Train pg Loss: 17.926123 - Test Loss: 3.046288\n",
      "\n",
      "\n",
      "Epoch 738/750 - Train Cd Loss: 0.037671 - Test Loss: 0.037915\n",
      "Epoch 738/750 - Train pg Loss: 20.955507 - Test Loss: 2.788883\n",
      "\n",
      "\n",
      "Epoch 739/750 - Train Cd Loss: 0.033681 - Test Loss: 0.037565\n",
      "Epoch 739/750 - Train pg Loss: 18.875925 - Test Loss: 2.267591\n",
      "\n",
      "\n",
      "Epoch 740/750 - Train Cd Loss: 0.025851 - Test Loss: 0.038769\n",
      "Epoch 740/750 - Train pg Loss: 15.484739 - Test Loss: 2.483080\n",
      "\n",
      "\n",
      "Epoch 741/750 - Train Cd Loss: 0.023101 - Test Loss: 0.040625\n",
      "Epoch 741/750 - Train pg Loss: 15.219927 - Test Loss: 2.546752\n",
      "\n",
      "\n",
      "Epoch 742/750 - Train Cd Loss: 0.060541 - Test Loss: 0.037690\n",
      "Epoch 742/750 - Train pg Loss: 19.144657 - Test Loss: 2.719252\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 743/750 - Train Cd Loss: 0.022863 - Test Loss: 0.037159\n",
      "Epoch 743/750 - Train pg Loss: 15.467131 - Test Loss: 2.827969\n",
      "\n",
      "\n",
      "Epoch 744/750 - Train Cd Loss: 0.023816 - Test Loss: 0.039174\n",
      "Epoch 744/750 - Train pg Loss: 19.402935 - Test Loss: 2.856768\n",
      "\n",
      "\n",
      "Epoch 745/750 - Train Cd Loss: 0.038394 - Test Loss: 0.038000\n",
      "Epoch 745/750 - Train pg Loss: 17.541588 - Test Loss: 2.944204\n",
      "\n",
      "\n",
      "Epoch 746/750 - Train Cd Loss: 0.042633 - Test Loss: 0.035145\n",
      "Epoch 746/750 - Train pg Loss: 19.214771 - Test Loss: 2.766537\n",
      "\n",
      "\n",
      "Epoch 747/750 - Train Cd Loss: 0.029133 - Test Loss: 0.036264\n",
      "Epoch 747/750 - Train pg Loss: 16.621134 - Test Loss: 2.766465\n",
      "\n",
      "\n",
      "Epoch 748/750 - Train Cd Loss: 0.038338 - Test Loss: 0.039481\n",
      "Epoch 748/750 - Train pg Loss: 17.376003 - Test Loss: 2.823340\n",
      "\n",
      "\n",
      "Epoch 749/750 - Train Cd Loss: 0.038591 - Test Loss: 0.036317\n",
      "Epoch 749/750 - Train pg Loss: 19.499149 - Test Loss: 3.186172\n",
      "\n",
      "\n",
      "Epoch 750/750 - Train Cd Loss: 0.029272 - Test Loss: 0.039470\n",
      "Epoch 750/750 - Train pg Loss: 15.682821 - Test Loss: 2.824139\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    #torch.save(model.state_dict(), \"/Users/Crazz/Research Codes/LH PGNN analysis/lastLHHnSPREmodel.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([69, 25, 17, 76, 16])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goodplanmodel_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,z,w,v = kf.split(fulldata)\n",
    "LH_cur = LH_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"/Users/Crazz/Research Codes/WORKING MODELS/LH_COL_pg_k4.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "        dataset=fulldata,\n",
    "        batch_size=1,\n",
    "        sampler=torch.utils.data.SubsetRandomSampler(v[1])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_planout.to_csv('/Users/Crazz/Research Codes/WORKING MODELS/Kfold_outs/col_nonpretest_outs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_Cd_curves).to_csv('/Users/Crazz/Research Codes/WORKING MODELS/Kfold_outs/col_nonpretest_Cdcurve.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.215131531587343\n"
     ]
    }
   ],
   "source": [
    "nr = (np.sqrt(np.sum((hs_planout['massout'] - hs_planout['mass'])**2)/len((hs_planout['massout'] - hs_planout['mass'])**2))/2.644140625e-07)*100\n",
    "print(nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_out = Cd_acts*0.5*LH_cur['rho'][test_ids]*(LH_cur['vel'][test_ids]**2)*LH_cur['area'][test_ids]/9.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cd_errs = ((Cd_ans - Cd_outs)/abs(Cd_ans))*100\n",
    "Cd_errs_abs = (abs(Cd_ans - Cd_outs)/abs(Cd_ans))*100\n",
    "Cd_aerrs = -((Cd_actans - Cd_acts)/abs(Cd_actans))*100\n",
    "Cd_aerrs_abs = (abs(Cd_actans - Cd_acts)/abs(Cd_actans))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cd_mse = (Cd_acts - Cd_actans)**2\n",
    "Cd_rmse = np.sqrt(np.sum(Cd_mse)/len(Cd_mse))\n",
    "Cd_nrmse = (Cd_rmse/np.mean(Cd_actans))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.181227945351034\n",
      "4.181227945351034\n"
     ]
    }
   ],
   "source": [
    "print(Cd_aerrs.mean())\n",
    "print(Cd_nrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3591896879097165\n"
     ]
    }
   ],
   "source": [
    "mass_mse = (mass_out - LH_cur['mass'][test_ids])**2\n",
    "mass_rmse = np.sqrt(np.sum(mass_mse)/len(mass_mse))\n",
    "mass_nrmse = (mass_rmse/np.mean(LH_cur['mass'][test_ids]))*100\n",
    "print(mass_nrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vol_out_s = 4*np.pi/3*(sph_outs/(4*sar_outs) * LH_cur['area'][test_ids]/np.pi)**(3/2)\n",
    "rho_s = mass_out/Vol_out_s\n",
    "Vol_out_c = 4*np.pi/3*(c_sph_outs*Acrat_outs * LH_cur['area'][test_ids]/np.pi)**(3/2)\n",
    "rho_c = mass_out/Vol_out_c\n",
    "Vol_out_l = 4*np.pi/3*(l_sph_outs*(1/(2*sar_outs)-Alrat_outs) * LH_cur['area'][test_ids]/np.pi)**(3/2)\n",
    "rho_l = mass_out/Vol_out_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "predout = pd.DataFrame(por_outs,columns=['por'])\n",
    "predout['sar'] = sar_outs\n",
    "predout['sph'] = sph_outs\n",
    "predout['lsph'] = l_sph_outs\n",
    "predout['csph'] = c_sph_outs\n",
    "predout['Acrat'] = Acrat_outs\n",
    "predout['Alrat'] = Alrat_outs\n",
    "predout['Cdout'] = Cd_outs\n",
    "predout['massout'] = np.array(mass_out)\n",
    "predout['Rhos'] = np.array(rho_s)\n",
    "predout['Rhoc'] = np.array(rho_c)\n",
    "predout['Rhol'] = np.array(rho_l)\n",
    "predout['id'] = np.array(LH_cur['id'][test_ids])\n",
    "predout['Cd'] = np.array(LH_cur['Cd'][test_ids])\n",
    "predout['Re'] = np.array(LH_cur['Re'][test_ids])\n",
    "predout['mass'] = np.array(LH_cur['mass'][test_ids])\n",
    "predout.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Cd_aerrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 650.0)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(LH_cur['Re'][test_ids],Cd_acts,'.')\n",
    "plt.plot(LH_cur['Re'][test_ids],Cd_actans,'+')\n",
    "plt.xlabel('Reynolds number')\n",
    "plt.ylabel('Cd')\n",
    "plt.legend(['Predicted Cd','Measured Cd'])\n",
    "plt.ylim([0,6])\n",
    "plt.xlim([0,650])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Mass [kg]')"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xa = np.array([0,0.000002])\n",
    "ya = np.array([0,0.000002])\n",
    "plt.plot(LH_cur['mass'][test_ids],mass_out,'.')\n",
    "plt.plot(xa,ya)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Mass [kg]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_=plt.hist(por_outs,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_=plt.hist(sph_outs,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_=plt.hist(l_sph_outs,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_=plt.hist(c_sph_outs,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_=plt.hist(Acrat_outs,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_=plt.hist(Alrat_outs,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
